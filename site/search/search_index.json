{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sum\u00e1rio","text":"<p>Introdu\u00e7\u00e3o</p>"},{"location":"#ciencia-de-dados","title":"Ci\u00eancia de Dados","text":"<ul> <li>Estat\u00edstica</li> <li>Testes de Hip\u00f3teses<ul> <li>O que s\u00e3o os ts</li> <li>Testes de Hip\u00f3teses com Estat\u00edstica t</li> <li>Intervalo de confian\u00e7a com t student</li> <li>P-valor</li> <li>Notebook: t_student_teste_t</li> <li>Notebook: Permutacion teste</li> </ul> </li> <li>Machine Learning</li> </ul>"},{"location":"sobre/","title":"Sobre","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do projeto! Este \u00e9 um exemplo de p\u00e1gina \"Sobre\".</p>"},{"location":"sobre/#objetivo","title":"Objetivo","text":"<p>Este projeto tem como objetivo demonstrar como usar o MkDocs para criar documenta\u00e7\u00e3o.</p>"},{"location":"sobre/#contato","title":"Contato","text":"<ul> <li>Email: exemplo@email.com</li> <li>GitHub: meu-usuario</li> </ul>"},{"location":"1_estatistica/Introducao/","title":"Introdu\u00e7\u00e3o","text":"<p>Bem-vindo \u00e0 se\u00e7\u00e3o de Estat\u00edstica. Aqui voc\u00ea encontrar\u00e1 diversos conceitos importantes sobre an\u00e1lise de dados.</p>"},{"location":"1_estatistica/Introducao/#conteudos-disponiveis","title":"Conte\u00fados dispon\u00edveis:","text":"<ul> <li>Testes de Hip\u00f3teses</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/","title":"1.1.1. O que s\u00e3o os ts","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#1-o-que-e-estatistica-t-teste-t-e-distribuicao-t","title":"1. O que \u00e9 Estat\u00edstica t, Teste t e Distribui\u00e7\u00e3o t?","text":"<p>A estat\u00edstica \u00e9 a espinha dorsal da an\u00e1lise de dados, e a estat\u00edstica t, oriunda da distribui\u00e7\u00e3o t, \u00e9 um dos seus pilares fundamentais.</p> <p>Essa ferramenta n\u00e3o apenas desempenha um papel vital em testes de hip\u00f3teses, particularmente nos testes t, mas tamb\u00e9m \u00e9 a chave para entender como e por que certas conclus\u00f5es s\u00e3o retiradas de conjuntos de dados.</p> <p>Dominar a estat\u00edstica t \u00e9 mais do que uma mera habilidade acad\u00eamica; \u00e9 uma necessidade para qualquer um que queira analisar dados com precis\u00e3o e confian\u00e7a.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#2-pontos-chave","title":"2. Pontos-chave","text":"<ul> <li>Testes t avaliam diferen\u00e7as entre m\u00e9dias amostrais.</li> <li>A estat\u00edstica t considera desvio padr\u00e3o e tamanho da amostra.</li> <li>Testes t requerem a verifica\u00e7\u00e3o de premissas como normalidade.</li> <li><code>P-valores baixos sugerem diferen\u00e7as estatisticamente significativas</code>.</li> <li>Erros comuns incluem assumir normalidade e ignorar premissas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#3-estatistica-t","title":"3. Estat\u00edstica t","text":"<p>A estat\u00edstica t, tamb\u00e9m conhecida como valor t ou t de Student, \u00e9 uma medida que nos ajuda a determinar qu\u00e3o grande \u00e9 a diferen\u00e7a entre as m\u00e9dias de duas amostras, considerando a variabilidade nos dados.</p> <p>Em outras palavras, ela compara a diferen\u00e7a observada entre as m\u00e9dias das amostras com o que poder\u00edamos esperar por acaso. Se essa diferen\u00e7a for significativamente grande, conclu\u00edmos que as m\u00e9dias das popula\u00e7\u00f5es das quais as amostras foram retiradas provavelmente s\u00e3o diferentes.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#4-distribuicao-t","title":"4. Distribui\u00e7\u00e3o t","text":"<p>A distribui\u00e7\u00e3o t, tamb\u00e9m conhecida como distribui\u00e7\u00e3o de Student, \u00e9 uma das distribui\u00e7\u00f5es de probabilidade mais importantes no campo da estat\u00edstica, especialmente quando se trata de inferir sobre uma popula\u00e7\u00e3o a partir de uma amostra pequena.</p> <p><code>Origem:</code> A distribui\u00e7\u00e3o t foi introduzida por William Sealy Gosset sob o pseud\u00f4nimo \u201cStudent\u201d em 1908. Ele estava trabalhando na empresa de cervejaria Guinness e desenvolveu esta distribui\u00e7\u00e3o para lidar com problemas estat\u00edsticos envolvendo pequenas amostras.</p> <p></p> <p>Refer\u00eancia: https://estatisticafacil.org/estatistica-t/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#5-teste-t","title":"5. Teste t","text":"<p>O teste t \u00e9 um instrumento refinado de an\u00e1lise que se vale da estat\u00edstica t para confrontar as m\u00e9dias de dois conjuntos de dados. O que ele busca discernir \u00e9 a natureza da varia\u00e7\u00e3o entre esses conjuntos: \u00e9 uma diferen\u00e7a genuinamente significativa? Ou poderia essa varia\u00e7\u00e3o ser atribu\u00edda simplesmente ao capricho do acaso?</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#51-ha-tres-tipos-de-teste-t","title":"5.1. H\u00e1 tr\u00eas tipos de teste t:","text":"<p><code>Teste t de Uma Amostra:</code> O teste t de uma amostra confronta a m\u00e9dia de uma \u00fanica amostra com uma m\u00e9dia populacional j\u00e1 conhecida. Este tipo de teste \u00e9 frequentemente adotado quando os pesquisadores desejam verificar se a m\u00e9dia da amostra diverge de maneira significativa de um valor hipotetizado. Aqui, a estat\u00edstica t \u00e9 determinada comparando-se a m\u00e9dia da amostra com a m\u00e9dia da popula\u00e7\u00e3o, levando em considera\u00e7\u00e3o o tamanho da amostra e seu desvio padr\u00e3o.</p> <p><code>Teste t para Amostras Independentes:</code> Este teste, tamb\u00e9m conhecido como teste t de duas amostras, \u00e9 aplicado ao se comparar as m\u00e9dias de duas amostras independentes. O principal objetivo \u00e9 averiguar se existe uma diferen\u00e7a significativa entre as m\u00e9dias das popula\u00e7\u00f5es das quais as amostras foram extra\u00eddas. Para este teste, a estat\u00edstica t \u00e9 calculada considerando-se a discrep\u00e2ncia entre as m\u00e9dias das amostras, suas vari\u00e2ncias e os respectivos tamanhos das amostras.</p> <p><code>Teste t para Amostras Emparelhadas:</code> O teste t para amostras emparelhadas, ou teste t para amostras dependentes, \u00e9 indicado para compara\u00e7\u00e3o das m\u00e9dias de duas amostras relacionadas. Este teste \u00e9 utilizado quando as observa\u00e7\u00f5es s\u00e3o feitas em pares, como medi\u00e7\u00f5es antes e depois de um tratamento, ou sujeitos pareados em designs experimentais. Para este teste, a estat\u00edstica t \u00e9 derivada considerando-se as diferen\u00e7as entre as observa\u00e7\u00f5es emparelhadas e suas m\u00e9dias, bem como o desvio padr\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#6-premissas-do-teste-t","title":"6. Premissas do Teste t","text":"<p>Garantir que as premissas abaixo sejam atendidas permite aplicar os testes t e a estat\u00edstica t em suas pesquisas e an\u00e1lises de dados, conduzindo a conclus\u00f5es v\u00e1lidas e confi\u00e1veis.</p> <p><code>Dados em Escala de Intervalo ou Raz\u00e3o:</code> Os testes t s\u00e3o projetados para dados cont\u00ednuos que podem ser medidos em uma escala de raz\u00e3o ou intervalo. Estes tipos de dados possuem intervalos iguais entre os valores e um ponto zero significativo.</p> <p><code>Independ\u00eancia das Observa\u00e7\u00f5es:</code> As observa\u00e7\u00f5es nas amostras devem ser independentes entre si. Isso implica que a ocorr\u00eancia de uma observa\u00e7\u00e3o n\u00e3o deve influenciar a probabilidade de outra observa\u00e7\u00e3o acontecer. No teste t para amostras independentes, as amostras devem ser selecionadas de forma aleat\u00f3ria e n\u00e3o relacionadas entre si. Para o teste t de amostras emparelhadas, cada par de observa\u00e7\u00f5es deve ser independente dos outros pares. </p> <p><code>Normalidade:</code> Os dados devem ter uma distribui\u00e7\u00e3o aproximadamente normal, especialmente para tamanhos de amostras pequenos. Este pressuposto sugere que a distribui\u00e7\u00e3o de amostragem das m\u00e9dias segue uma distribui\u00e7\u00e3o normal ou quase normal. Embora os testes t sejam considerados robustos a desvios moderados da normalidade, viola\u00e7\u00f5es graves podem afetar a precis\u00e3o dos resultados do teste.</p> <p><code>Homogeneidade das Vari\u00e2ncias:</code> No teste t para amostras independentes, as vari\u00e2ncias das duas popula\u00e7\u00f5es comparadas devem ser iguais ou, pelo menos, aproximadamente iguais. Esse pressuposto \u00e9 conhecido como homogeneidade das vari\u00e2ncias. Se esse pressuposto for violado, testes alternativos, como o teste t de Welch, podem ser empregados, pois este \u00faltimo n\u00e3o exige vari\u00e2ncias iguais.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#7-graus-de-liberdade","title":"7. Graus de Liberdade","text":"<p>Os graus de liberdade representam um conceito fundamental na estat\u00edstica e t\u00eam implica\u00e7\u00f5es profundas no c\u00e1lculo da estat\u00edstica t e na determina\u00e7\u00e3o dos valores cr\u00edticos em testes t.</p> <p>Mas, o que s\u00e3o exatamente os graus de liberdade? S\u00e3o o n\u00famero de valores numa an\u00e1lise que t\u00eam a liberdade de variar sem infringir qualquer regra estabelecida \u2014 em outras palavras, s\u00e3o as observa\u00e7\u00f5es independentes que podem ser usadas para estimar um par\u00e2metro.</p> <p>Exemplo:</p> <p>Imagine que voc\u00ea tem cinco amigos e est\u00e1 tentando calcular a m\u00e9dia das idades deles. Voc\u00ea sabe que a m\u00e9dia de suas idades \u00e9 25 anos. Se voc\u00ea souber a idade de quatro desses amigos, voc\u00ea poder\u00e1 facilmente calcular a idade do quinto amigo, mesmo sem ningu\u00e9m te dizer qual \u00e9.</p> <p>Por exemplo: Amigo 1: 24 anos; Amigo 2: 25 anos; Amigo 3: 26 anos; e Amigo 4: 23 anos.</p> <p>Usando a informa\u00e7\u00e3o de que a m\u00e9dia \u00e9 25 anos, podemos calcular a idade do Amigo 5. Se somarmos as idades dos quatro primeiros amigos, obtemos um total de 98 anos. Para que a m\u00e9dia das cinco idades seja 25 anos, o total combinado deve ser 125 anos (25 anos x 5 amigos). Isso significa que o Amigo 5 tem 27 anos (125 \u2013 98 = 27).</p> <p>Neste exemplo, os graus de liberdade s\u00e3o 4. Isso porque podemos escolher qualquer idade para os primeiros quatro amigos, mas depois que essas idades forem determinadas, a idade do quinto amigo \u00e9 fixada pela m\u00e9dia que conhecemos. Portanto, s\u00f3 temos \u201cliberdade\u201d para variar as idades de 4 dos 5 amigos. </p> <p>No universo dos testes t, os graus de liberdade determinam a forma espec\u00edfica da distribui\u00e7\u00e3o t, essencial para calcular os valores p e tomar decis\u00f5es estat\u00edsticas sobre as diferen\u00e7as entre grupos.</p> <p>Como calculamos os graus de liberdade para diferentes testes t:</p> <p><code>Teste t de Uma Amostra:</code> Simplesmente subtrai-se um do tamanho total da amostra. Matematicamente falando: gl = n \u2013 1.</p> <p><code>Teste t para Amostras Independentes:</code> Neste cen\u00e1rio, temos duas amostras diferentes. A f\u00f3rmula considera o tamanho de ambas as amostras: gl = n1 + n2 \u2013 2.</p> <p><code>Teste t para Amostras Emparelhadas:</code> Aqui, comparamos dois conjuntos de observa\u00e7\u00f5es do mesmo grupo, como um \u201cantes e depois\u201d. Os graus de liberdade s\u00e3o calculados subtraindo um do n\u00famero total de pares: gl = n \u2013 1.</p> <p>A correta compreens\u00e3o e aplica\u00e7\u00e3o dos graus de liberdade n\u00e3o apenas asseguram a precis\u00e3o da sua an\u00e1lise, mas tamb\u00e9m a confiabilidade das conclus\u00f5es extra\u00eddas dela.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#8-estatistica-t-valor-de-p-e-intervalos-de-confianca","title":"8. Estat\u00edstica t, Valor de p e Intervalos de Confian\u00e7a","text":"<p>Estes tr\u00eas componentes formam a espinha dorsal da infer\u00eancia estat\u00edstica, permitindo aos pesquisadores e analistas de dados n\u00e3o apenas identificar diferen\u00e7as significativas em seus conjuntos de dados, mas tamb\u00e9m entender o contexto e a relev\u00e2ncia dessas diferen\u00e7as.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#81-estatistica-t","title":"8.1. Estat\u00edstica t:","text":"<p>Defini\u00e7\u00e3o: Originada da distribui\u00e7\u00e3o t, a estat\u00edstica-t quantifica a diferen\u00e7a entre m\u00e9dias amostrais, levando em considera\u00e7\u00e3o o desvio padr\u00e3o e o tamanho da amostra.</p> <p>Aplica\u00e7\u00e3o: Usada principalmente em testes t para contrastar m\u00e9dias amostrais, ela serve como um \u00edndice para avaliar o qu\u00e3o longe a nossa amostra est\u00e1 da popula\u00e7\u00e3o sob a hip\u00f3tese nula.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#82-valor-de-p","title":"8.2. Valor de p:","text":"<p>Defini\u00e7\u00e3o: Uma m\u00e9trica que indica a probabilidade de observar um resultado, como o obtido (ou mais extremo), assumindo que a hip\u00f3tese nula (H0) \u00e9 verdadeira.</p> <p>Interpreta\u00e7\u00e3o: Um <code>p-valor pequeno</code> \u2014 frequentemente, menor que 0.05 \u2014 sugere que os dados observados s\u00e3o <code>inconsistentes com a hip\u00f3tese nula (H0)</code>, permitindo-nos <code>rejeit\u00e1-la</code> em favor da hip\u00f3tese alternativa (H1). Portanto, <code>um p-valor baixo sinaliza uma diferen\u00e7a estatisticamente significativa.</code></p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#83-intervalos-de-confianca","title":"8.3. Intervalos de Confian\u00e7a:","text":"<p>Defini\u00e7\u00e3o: Uma estimativa de intervalo que indica a faixa dentro da qual esperamos que o verdadeiro valor da popula\u00e7\u00e3o esteja, com uma certa confian\u00e7a (como 95%).</p> <p>Interpreta\u00e7\u00e3o: Em testes t, esses intervalos nos oferecem uma faixa de valores prov\u00e1veis para as diferen\u00e7as entre as m\u00e9dias populacionais ou a m\u00e9dia da popula\u00e7\u00e3o em si. A amplitude desse intervalo \u00e9 influenciada por fatores como a estat\u00edstica-t, o tamanho da amostra e a variabilidade dos dados.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1.%20ts/#84-relacao-integrada","title":"8.4. Rela\u00e7\u00e3o Integrada:","text":"<p>A estat\u00edstica-t nos fornece uma m\u00e9trica de diferen\u00e7a que \u00e9, ent\u00e3o, avaliada em termos de sua probabilidade sob a hip\u00f3tese nula \u2014 da\u00ed surge o p-valor.</p> <p>Ao mesmo tempo, a estat\u00edstica-t alimenta a constru\u00e7\u00e3o dos intervalos de confian\u00e7a, proporcionando uma vis\u00e3o mais ampla da diferen\u00e7a, n\u00e3o apenas em termos de signific\u00e2ncia, mas tamb\u00e9m de magnitude e relev\u00e2ncia pr\u00e1tica.</p> <p>Em suma, ao combinar a estat\u00edstica-t, o p-valor e os intervalos de confian\u00e7a, obtemos uma imagem completa e multidimensional da diferen\u00e7a observada, auxiliando na tomada de decis\u00f5es informadas e na interpreta\u00e7\u00e3o precisa dos resultados.</p> <p>Refer\u00eancia: https://estatisticafacil.org/estatistica-t/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2.%20teste_t/","title":"1. Teste de Hip\u00f3teses com Estat\u00edstica-t","text":"<p>A baixo segue as principais etapas para se conduzir um teste de hip\u00f3teses com a Estat\u00edstica-t</p> <p>1. Estabele\u00e7a as hip\u00f3teses:</p> <ul> <li>Hip\u00f3tese nula (H0): Sugere que n\u00e3o existe uma diferen\u00e7a significativa entre as m\u00e9dias populacionais ou que a m\u00e9dia da amostra \u00e9 a mesma do valor proposto.</li> <li>Hip\u00f3tese alternativa (H1): Prop\u00f5e que pode existir uma diferen\u00e7a significativa entre as m\u00e9dias.</li> </ul> <p>2. Sele\u00e7\u00e3o do teste t correto: - Escolha o tipo de teste t que se alinha com o design da sua pesquisa, seja ele para uma \u00fanica amostra, amostras independentes ou amostras pareadas.</p> <p>3. Confirma\u00e7\u00e3o das premissas: - Assegure-se de que os dados atendam \u00e0s premissas necess\u00e1rias, como independ\u00eancia das observa\u00e7\u00f5es, normalidade e, quando aplic\u00e1vel, homogeneidade das vari\u00e2ncias.</p> <p>4. Computa\u00e7\u00e3o da estat\u00edstica-t: - Utilizando os dados da amostra, calcule a estat\u00edstica-t conforme a formula\u00e7\u00e3o espec\u00edfica do teste t selecionado.</p> <p>5. Determina\u00e7\u00e3o dos graus de liberdade (df): - Baseie-se no tamanho da amostra ou amostras para calcular os graus de liberdade.</p> <p>6. Obten\u00e7\u00e3o do p-valor: - Utilize a estat\u00edstica-t e os graus de liberdade para identificar o p-valor correspondente na distribui\u00e7\u00e3o t.</p> <p>7. Compara\u00e7\u00e3o com o n\u00edvel de signific\u00e2ncia (\u03b1): - Se o p-valor for menor que o n\u00edvel de signific\u00e2ncia definido (comumente 0,05), rejeite a hip\u00f3tese nula.</p> <p>Refer\u00eancia:  - estatisticafacil estatistica-t</p> <p>Conceitos Estat\u00edsticos</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2.%20teste_t/#ilustracao-pratica","title":"Ilustra\u00e7\u00e3o Pr\u00e1tica:","text":"<p>Imagine que deseja avaliar se um novo m\u00e9todo de ensino eleva as notas dos alunos.</p> <p>Coleta-se uma amostra de 25 alunos submetidos ao novo m\u00e9todo e compara-se a m\u00e9dia das suas notas \u00e0 m\u00e9dia populacional reconhecida de 80.</p> <p>Para esta situa\u00e7\u00e3o, utiliza-se o teste t para uma amostra.</p> <ol> <li>H0: \u03bc = 80; H1: \u03bc \u2260 80.</li> <li>Selecionado o teste t para uma \u00fanica amostra.</li> <li>Verificadas e validadas as premissas.</li> <li>Resultado da estat\u00edstica-t \u00e9 de 2,5.</li> <li>Graus de liberdade determinados como: df = 24.</li> <li>Com base na estat\u00edstica-t e df, o <code>p-valor</code> \u00e9 de <code>0,019</code>.</li> <li>Dado que <code>0,019</code> \u00e9 menor que 0,05, <code>rejeitamos H0</code>.</li> <li>Conclus\u00e3o: As evid\u00eancias apontam para uma melhoria significativa nas notas dos alunos devido ao novo m\u00e9todo de ensino.</li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/","title":"C\u00e1lculo de Intervalo de Confian\u00e7a Usando t-Student","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#dados-fornecidos","title":"Dados Fornecidos","text":"<p>Os dados fornecidos s\u00e3o do AUC_PR:</p> <ul> <li>$x_1 = 0.769682$</li> <li>$x_2 = 0.758596$</li> <li>$x_3 = 0.762273$</li> <li>$x_4 = 0.776236$</li> <li>$x_5 = 0.760402$</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#passo-1-calcular-a-media-amostral-barx","title":"Passo 1: Calcular a M\u00e9dia Amostral ($\\bar{x}$)","text":"<p>A m\u00e9dia amostral ## Passo 1: Calcular a M\u00e9dia Amostral ($\\bar{x}$) \u00e9 calculada somando todos os valores e dividindo pelo n\u00famero total de observa\u00e7\u00f5es ($n$):</p> <p>$$ \\bar{x} = \\frac{x_1 + x_2 + x_3 + x_4 + x_5}{5} $$</p> <p>$$ \\bar{x} = \\frac{0.769682 + 0.758596 + 0.762273 + 0.776236 + 0.760402}{5} $$</p> <p>$$ \\bar{x} = \\frac{3.827189}{5} $$</p> <p>$$ \\bar{x} = 0.765438 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#passo-2-calcular-o-desvio-padrao-amostral-s","title":"Passo 2: Calcular o Desvio Padr\u00e3o Amostral ($s$)","text":"<p>Para calcular o desvio padr\u00e3o amostral, utilizamos a f\u00f3rmula:</p> <p>$$ s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n - 1}} $$</p> <p>Primeiro, calculamos cada termo $(x_i - \\bar{x})^2$:</p> <ul> <li>$(x_1 - \\bar{x})^2 = (0.769682 - 0.765438)^2 = 0.00001806$</li> <li>$(x_2 - \\bar{x})^2 = (0.758596 - 0.765438)^2 = 0.00004683$</li> <li>$(x_3 - \\bar{x})^2 = (0.762273 - 0.765438)^2 = 0.00000998$</li> <li>$(x_4 - \\bar{x})^2 = (0.776236 - 0.765438)^2 = 0.00011589$</li> <li>$(x_5 - \\bar{x})^2 = (0.760402 - 0.765438)^2 = 0.00002534$</li> </ul> <p>Agora, somamos os quadrados das diferen\u00e7as:</p> <p>$$ \\sum_{i=1}^{n}(x_i - \\bar{x})^2 = 0.00001806 + 0.00004683 + 0.00000998 + 0.00011589 + 0.00002534 = 0.0002161 $$</p> <p>Calculando o desvio padr\u00e3o amostral ((s)):</p> <p>$$ s = \\sqrt{\\frac{0.0002161}{5 - 1}} = \\sqrt{\\frac{0.0002161}{4}} = \\sqrt{0.00005403} \\approx 0.00735 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#passo-3-calcular-o-intervalo-de-confianca","title":"Passo 3: Calcular o Intervalo de Confian\u00e7a","text":"<p>O intervalo de confian\u00e7a para a m\u00e9dia de uma amostra, usando a distribui\u00e7\u00e3o <code>t-Student</code>, \u00e9 dado por:</p> <p>$$ IC = \\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#entendendo-o","title":"Entendendo o $\ud835\udefc$","text":"<p>Para um intervalo de confian\u00e7a de 95%, o valor de  $\ud835\udefc$ representa a probabilidade de erro, ou seja, a \u00e1rea das caudas da distribui\u00e7\u00e3o <code>t-Student</code> que n\u00e3o \u00e9 coberta pelo intervalo de confian\u00e7a. Neste caso, $\ud835\udefc=1\u22120.95=0.05$, ou 5%. Isso significa que h\u00e1 uma chance de 5% de que a m\u00e9dia verdadeira n\u00e3o esteja dentro do intervalo calculado.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#divisao-de-entre-as-caudas","title":"Divis\u00e3o de $\ud835\udefc$ entre as Caudas","text":"<p>Como o intervalo de confian\u00e7a \u00e9 sim\u00e9trico em torno da m\u00e9dia amostral, o valor de $\ud835\udefc$ \u00e9 dividido igualmente entre as duas caudas da distribui\u00e7\u00e3o. Portanto, cada cauda tem uma \u00e1rea de $\ud835\udefc/2=0.025$.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#escolha-do-valor-de-t_alpha2-n-1","title":"Escolha do valor de $t_{\\alpha/2, n-1}$","text":"<p>O valor de $t_{\\alpha/2, n-1}$ \u00e9 obtido da tabela t-Student para $n\u22121=4$ graus de liberdade, correspondendo a uma cauda de 2.5% em cada lado da distribui\u00e7\u00e3o. O valor t\u00edpico para um n\u00edvel de confian\u00e7a de 95% e 4 graus de liberdade \u00e9 aproximadamente 2.776.</p> <p>Substituindo os valores:</p> <ul> <li>$\\bar{x} = 0.765438$</li> <li>$s = 0.00735$</li> <li>$n = 5$</li> <li>$t_{0.025, 4} \\approx 2.776$</li> </ul> <p>O erro padr\u00e3o da m\u00e9dia (SEM) \u00e9 calculado como:</p> <p>$$ \\frac{s}{\\sqrt{n}} = \\frac{0.00735}{\\sqrt{5}} = \\frac{0.00735}{2.236} \\approx 0.003285 $$</p> <ul> <li>$s$: Desvio padr\u00e3o da amostra, que mede a dispers\u00e3o dos dados em rela\u00e7\u00e3o \u00e0 m\u00e9dia amostral.</li> <li>$\ud835\udc5b$: Tamanho da amostra, ou seja, o n\u00famero total de observa\u00e7\u00f5es na amostra.</li> </ul> <p>Agora, calculamos o intervalo de confian\u00e7a:</p> <p>$$ IC = 0.765438 \\pm 2.776 \\times 0.003285 $$</p> <p>$$ IC = 0.765438 \\pm 0.009113 $$</p> <p>$$ IC = [0.756325, 0.774551] $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#resultado-final","title":"Resultado Final","text":"<p>O intervalo de confian\u00e7a de 95% para os dados fornecidos \u00e9 aproximadamente:</p> <p>$$ IC = [0.756325, 0.774551] $$</p> <p>Ou seja, com 95% de confian\u00e7a, podemos afirmar que a m\u00e9dia verdadeira dos dados est\u00e1 entre 0.756325 e 0.774551.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#interpretacao-do-intervalo-de-confianca","title":"Interpreta\u00e7\u00e3o do Intervalo de Confian\u00e7a","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#1-significado-do-intervalo-de-confianca","title":"1. Significado do Intervalo de Confian\u00e7a","text":"<ul> <li> <p>Intervalo Calculado: $[0.756325,0.774551]$.</p> <p>Isso significa que, com 95% de confian\u00e7a, a m\u00e9dia verdadeira da popula\u00e7\u00e3o da qual a amostra foi retirada est\u00e1 entre 0.756325 e 0.774551.</p> </li> <li> <p>M\u00e9dia Amostral ($\\bar{x}$): 0.765438.</p> <p>A m\u00e9dia amostral \u00e9 a melhor estimativa pontual da m\u00e9dia verdadeira da popula\u00e7\u00e3o. O intervalo de confian\u00e7a fornece uma faixa ao redor dessa m\u00e9dia, refletindo a incerteza da estimativa.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#2-nivel-de-confianca-de-95","title":"2. N\u00edvel de Confian\u00e7a de 95%","text":"<p>O n\u00edvel de confian\u00e7a de 95% implica que, se repet\u00edssemos o processo de amostragem muitas vezes (com diferentes amostras do mesmo tamanho), em 95% das vezes, o intervalo calculado conteria a verdadeira m\u00e9dia da popula\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#3-interpretacao-do-erro-padrao-da-media-sem","title":"3. Interpreta\u00e7\u00e3o do Erro Padr\u00e3o da M\u00e9dia (SEM)","text":"<ul> <li> <p>Erro Padr\u00e3o da M\u00e9dia (SEM): $0.003285$</p> <p>O SEM nos diz o quanto a m\u00e9dia amostral ($\\bar{x}$) pode variar de uma amostra para outra. Nesse caso, o SEM de $0.003285$ indica que a m\u00e9dia das amostras tende a variar em torno de $0.003285$ unidades em rela\u00e7\u00e3o \u00e0 m\u00e9dia verdadeira da popula\u00e7\u00e3o.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#4-precisao-da-estimativa","title":"4. Precis\u00e3o da Estimativa","text":"<ul> <li> <p>Intervalo Estreito: O intervalo relativamente estreito ($[0.756325,0.774551]$) indica que a estimativa da m\u00e9dia amostral \u00e9 bastante precisa. Isso ocorre porque o desvio padr\u00e3o \u00e9 pequeno e o tamanho da amostra \u00e9 adequado para garantir uma boa estimativa.</p> </li> <li> <p>Implica\u00e7\u00f5es Pr\u00e1ticas: Em contextos pr\u00e1ticos, como an\u00e1lise financeira ou pesquisa cient\u00edfica, essa precis\u00e3o significa que podemos confiar que a m\u00e9dia da popula\u00e7\u00e3o real est\u00e1 dentro do intervalo calculado com um alto n\u00edvel de confian\u00e7a.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3.%20t_student_Intervalo_Confianca/#interpretacao-generica-do-intervalo-de-confianca","title":"Interpreta\u00e7\u00e3o Generica do Intervalo de Confian\u00e7a","text":"<p>Um intervalo de confian\u00e7a de 95% para uma m\u00e9dia amostral significa que, se coletarmos 100 amostras diferentes e calcularmos um intervalo de confian\u00e7a para cada uma, esperamos que 95 desses intervalos contenham a verdadeira m\u00e9dia da popula\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/","title":"1.1.4. P-Valor","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/#1-o-que-e-p-valor","title":"1. O que \u00e9 P VALOR?","text":"<p>O valor de p representa a probabilidade de a diferen\u00e7a detectada entre os grupos analisados ter ocorrido ao acaso. </p> <p>Ent\u00e3o,</p> <p>\u2013 Um pequeno valor de p (p \u2264 0,05, ou seja, probabilidade menor ou igual a 5%):  indica que h\u00e1 uma pequena probabilidade de que a diferen\u00e7a observada entre os grupos seja ao acaso, ent\u00e3o, voc\u00ea considera que <code>h\u00e1 diferen\u00e7a significativa</code> entre os grupos.</p> <p>\u2013 Um grande valor de p (p &gt; 0,05, ou seja, probabilidade maior que 5%):  indica que h\u00e1 uma grande probabilidade de que a diferen\u00e7a observada entre os grupos seja ao acaso, ent\u00e3o, voc\u00ea considera que <code>n\u00e3o h\u00e1 diferen\u00e7a significativa</code> entre os grupos.</p> <p>Na explica\u00e7\u00e3o acima, usamos \u201cdiferen\u00e7a entre os grupos\u201d como exemplo, que se aplica a an\u00e1lises como teste t e Anova.</p> <p>Para testes como correla\u00e7\u00e3o de Pearson e regress\u00e3o linear, passar\u00edamos a dizer \u201crela\u00e7\u00e3o entre as vari\u00e1veis\u201d.</p> <p>Refer\u00eancia: https://estatisticafacil.org/2020/10/06/valor_de_p/</p> <p>Atente-se para a informa\u00e7\u00e3o a seguir:</p> <p>As defini\u00e7\u00f5es, entendimentos e explica\u00e7\u00f5es que utilizamos aqui, s\u00e3o os mais gerais e amplamente utilizadas em disciplinas b\u00e1sicas de estat\u00edstica ou bioestat\u00edstica e livros texto.</p> <p>Sendo assim, nestes moldes, de forma geral, o entendimento dos significados se torna mais f\u00e1cil e l\u00f3gico para quem n\u00e3o \u00e9 ligado diretamente com a \u00e1rea de exatas.</p> <p>Este entendimento, no entanto, vem sendo criticado por alguns estat\u00edsticos e, por conta disto, a Associa\u00e7\u00e3o Americana de Estat\u00edstica publicou um editorial sobre a <code>\u201csignific\u00e2ncia estat\u00edstica e o valor de p\u201d</code>, com aspectos um pouco diferentes dos retratados aqui.</p> <p>Abaixo, uma defini\u00e7\u00e3o mais precisa, mas ao mesmo tempo menos intuitiva.</p> <p>O valor de p representa a probabilidade de obtermos um resultado igual (ou mais extremo) ao obtido a partir dos nossos dados, assumindo que a hip\u00f3tese nula \u00e9 verdadeira.</p> <p>Essa defini\u00e7\u00e3o ser\u00e1 discutida nos t\u00f3picos abaixo</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/#2-hipoteses-estatisticas","title":"2. Hip\u00f3teses Estat\u00edsticas","text":"<p>Quando fazemos um teste inferencial de hip\u00f3teses \u2014 como qui-quadrado, teste t, anova, correla\u00e7\u00e3o, regress\u00e3o, etc \u2014 temos basicamente duas hip\u00f3teses:</p> <ul> <li> <p>HIP\u00d3TESE nula (H0): A padr\u00e3o, mais simples, de que n\u00e3o h\u00e1 \u2018diferen\u00e7a entre os grupos\u2019 ou n\u00e3o h\u00e1 \u2018rela\u00e7\u00e3o entre as vari\u00e1veis\u2019.</p> </li> <li> <p>HIP\u00d3TESE alternativa (H1): Estado alternativo, complementar a H0, de que h\u00e1 \u2018diferen\u00e7as entre grupos\u2019 ou h\u00e1 \u2018rela\u00e7\u00e3o entre as vari\u00e1veis\u2019.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/#3-nivel-de-significancia-e-valor-de-p","title":"3. N\u00edvel de Signific\u00e2ncia e Valor de P","text":"<p>O objetivo b\u00e1sico de todo e qualquer teste de hip\u00f3teses \u00e9 definir se rejeitaremos ou n\u00e3o a hip\u00f3tese nula (H0) \u2014 e essa defini\u00e7\u00e3o depender\u00e1 de dois fatores fundamentais:</p> <ul> <li> <p>1. N\u00cdVEL DE SIGNIFIC\u00c2NCIA (\u03b1): Representa um valor de corte, um crit\u00e9rio que definimos para rejeitar H0 ou n\u00e3o. A defini\u00e7\u00e3o de seu valor \u2014 normalmente 1% ou 5% \u2014 deve ser feita anteriormente ao teste.</p> </li> <li> <p>2. VALOR DE P (p): O valor de p representa uma probabilidade, e esse valor ser\u00e1 obtido sempre que executarmos um teste inferencial de hip\u00f3teses.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/#4-estatisticamente-significativo","title":"4. Estatisticamente Significativo?","text":"<p>Ao executar nossa an\u00e1lise e obtermos o valor de p, o pr\u00f3ximo passo ser\u00e1 compar\u00e1-lo com o n\u00edvel de signific\u00e2ncia (\u03b1) que definimos anteriormente.</p> <p>Como exemplo, considere que definimos um n\u00edvel de signific\u00e2ncia (\u03b1) de 0,05 (ou 5%), ter\u00edamos ent\u00e3o duas possibilidades ao compararmos esse \u03b1 com nosso valor de p obtido no teste:</p> <ol> <li> <p>Quando o valor de p \u00e9 menor ou igual ao n\u00edvel de signific\u00e2ncia \u03b1 <code>(p \u2264 0,05)</code>, devemos ent\u00e3o <code>rejeitar</code> a <code>hip\u00f3tese nula (H0)</code>. Aqui dizemos que nosso teste foi <code>estatisticamente significativo</code>.</p> </li> <li> <p>Quando o valor de p \u00e9 maior que o n\u00edvel de signific\u00e2ncia \u03b1 <code>(p &gt; 0,05)</code>, devemos ent\u00e3o <code>n\u00e3o rejeitar</code> a <code>hip\u00f3tese nula (H0)</code>. Aqui dizemos que nosso teste <code>n\u00e3o foi estatisticamente significativo</code>.</p> </li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4.%20p_valor/#5-o-que-significa-o-valor-de-p","title":"5. O que Significa o Valor de P?","text":"<p>Em termos t\u00e9cnicos o valor de p pode ser definido como:</p> <p>A probabilidade de obtermos um resultado igual (ou mais  extremo) ao obtido a partir dos nossos dados, assumindo que a hip\u00f3tese nula \u00e9 verdadeira.</p> <p>Se meu teste retornou, por exemplo, p = 2%, o que isso significa?</p> <p>Se considerarmos H0 verdadeira, a probabilidade de obtermos resultados iguais (ou mais extremos) que o nosso, ser\u00e1 de apenas 2%. Como foi menor que o \u03b1 = 5%, rejeitamos H0.</p> <p>Refer\u00eancia: https://estatisticafacil.org/2022/02/18/valor_de_p_retorno/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/","title":"Teste T Pareado: C\u00e1lculo Manual","text":"In\u00a0[\u00a0]: Copied! <p>Para testar se existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas das duas colunas <code>ks.scores1</code> e <code>ks.scores2</code>, podemos usar um <code>teste t pareado</code>. Este teste \u00e9 adequado para comparar as m\u00e9dias de duas amostras emparelhadas, assumindo que as diferen\u00e7as entre as amostras seguem uma distribui\u00e7\u00e3o normal.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nfrom scipy import stats\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\n\n# Criar o DataFrame\ndf = pd.DataFrame(data)\n\n# Calcular o teste T pareado\nt_statistic, p_value = stats.ttest_rel(df['ks.scores1'], df['ks.scores2'])\n\n# Exibir resultados\nprint(\"Estat\u00edstica t:\", t_statistic)\nprint(\"Valor p:\", p_value)\n\n# Avalia\u00e7\u00e3o do resultado\nif p_value &lt; 0.05:\n    print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\nelse:\n    print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\n</pre> import pandas as pd from scipy import stats  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] }  # Criar o DataFrame df = pd.DataFrame(data)  # Calcular o teste T pareado t_statistic, p_value = stats.ttest_rel(df['ks.scores1'], df['ks.scores2'])  # Exibir resultados print(\"Estat\u00edstica t:\", t_statistic) print(\"Valor p:\", p_value)  # Avalia\u00e7\u00e3o do resultado if p_value &lt; 0.05:     print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\") else:     print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")  <pre>Estat\u00edstica t: 4.378132332736648\nValor p: 0.011892242763488443\nRejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\n</pre>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#teste-t-pareado-calculo-manual","title":"Teste T Pareado: C\u00e1lculo Manual\u00b6","text":"<p>Este documento explica como realizar um teste t pareado manualmente para determinar se h\u00e1 uma diferen\u00e7a significativa entre as m\u00e9dias de duas amostras emparelhadas. Neste exemplo, utilizamos duas colunas de dados representando m\u00e9tricas de KS scores.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#dados","title":"Dados\u00b6","text":"<p>Vamos utilizar os seguintes dados:</p> <ul> <li><code>ks.scores1</code>: [0.583983, 0.576596, 0.556730, 0.595138, 0.584564]</li> <li><code>ks.scores2</code>: [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#passo-a-passo-para-o-teste-t-pareado-manualmente","title":"Passo a Passo para o Teste T Pareado Manualmente\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#1-calcular-as-diferencas","title":"1. Calcular as Diferen\u00e7as\u00b6","text":"<p>Primeiro, calculamos a diferen\u00e7a entre as duas colunas para cada par de valores:</p> <p>$$ \\text{Diferen\u00e7a} = \\text{ks.scores1} - \\text{ks.scores2} $$</p> <p>$$ \\begin{align*}  0.583983 - 0.490242 &amp;= 0.093741\\\\\\\\ 0.576596 - 0.551584 &amp;= 0.025012\\\\\\\\ 0.556730 - 0.514383 &amp;= 0.042347\\\\\\\\ 0.595138 - 0.535587 &amp;= 0.059551\\\\\\\\ 0.584564 - 0.546064 &amp;= 0.038500\\\\\\\\ \\end{align*} $$</p> <p>Ent\u00e3o, as diferen\u00e7as s\u00e3o:</p> <p>$$ \\text{Diferen\u00e7as} = [0.093741, 0.025012, 0.042347, 0.059551, 0.038500] $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#2-calcular-a-media-das-diferencas","title":"2. Calcular a M\u00e9dia das Diferen\u00e7as\u00b6","text":"<p>Agora, calculamos a m\u00e9dia das diferen\u00e7as ($\\bar{d}$):</p> <p>$$ \\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i = \\frac{0.093741 + 0.025012 + 0.042347 + 0.059551 + 0.038500}{5} $$</p> <p>$$ \\bar{d} = \\frac{0.259151}{5} = 0.0518302 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#3-calcular-o-desvio-padrao-das-diferencas","title":"3. Calcular o Desvio Padr\u00e3o das Diferen\u00e7as\u00b6","text":"<p>Para calcular o desvio padr\u00e3o ($s_d$), usamos a f\u00f3rmula do desvio padr\u00e3o de uma amostra:</p> <p>$$ s_d = \\sqrt{\\frac{\\sum_{i=1}^{n} (d_i - \\bar{d})^2}{n-1}} $$</p> <p>$$ \\begin{align*} (d_1 - \\bar{d})^2 &amp;= (0.093741 - 0.0518302)^2 = 0.001749 \\\\\\\\ (d_2 - \\bar{d})^2 &amp;= (0.025012 - 0.0518302)^2 = 0.000712 \\\\\\\\ (d_3 - \\bar{d})^2 &amp;= (0.042347 - 0.0518302)^2 = 0.000090 \\\\\\\\ (d_4 - \\bar{d})^2 &amp;= (0.059551 - 0.0518302)^2 = 0.000059 \\\\\\\\ (d_5 - \\bar{d})^2 &amp;= (0.038500 - 0.0518302)^2 = 0.000177 \\\\\\\\ \\end{align*} $$</p> <p>Agora, somamos essas diferen\u00e7as quadradas e dividimos pelo n\u00famero de pares menos um:</p> <p>$$ \\sum (d_i - \\bar{d})^2 = 0.001749 + 0.000712 + 0.000090 + 0.000059 + 0.000177 = 0.002787 $$</p> <p>$$ s_d = \\sqrt{\\frac{0.002787}{5-1}} = \\sqrt{\\frac{0.002787}{4}} = \\sqrt{0.00069675} = 0.026396 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#4-calcular-a-estatistica-t","title":"4. Calcular a Estat\u00edstica t\u00b6","text":"<p>A estat\u00edstica t \u00e9 calculada usando a m\u00e9dia das diferen\u00e7as, o desvio padr\u00e3o das diferen\u00e7as e o n\u00famero de pares:</p> <p>$$ t = \\frac{\\bar{d}}{s_d / \\sqrt{n}} $$</p> <p>Onde:</p> <ul> <li>($\\bar{d}$) \u00e9 a m\u00e9dia das diferen\u00e7as.</li> <li>($s_d$) \u00e9 o desvio padr\u00e3o das diferen\u00e7as.</li> <li>($n$) \u00e9 o n\u00famero de pares.</li> </ul> <p>Substituindo os valores:</p> <p>$$ t = \\frac{0.0518302}{0.026396 / \\sqrt{5}} = \\frac{0.0518302}{0.011804} = 4.389 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#5-determinar-o-valor-p","title":"5. Determinar o Valor p\u00b6","text":"<p>Para determinar o valor p, utilizamos a tabela de distribui\u00e7\u00e3o t de Student. Com $n - 1 = 4$ graus de liberdade e uma estat\u00edstica $t$ de $4.389$, vamos buscar o valor p correspondente.</p> <ul> <li>Para $t = 4.389$ e $df = 4$, o valor p \u00e9 geralmente menor que $0.05$, indicando que existe uma diferen\u00e7a significativa.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#51-determinar-a-regiao-critica","title":"5.1 Determinar a Regi\u00e3o Cr\u00edtica\u00b6","text":"<p>Para um teste t, a regi\u00e3o cr\u00edtica depende do n\u00edvel de signific\u00e2ncia ($\ud835\udefc$) e do tipo de teste (unilateral ou bilateral). Para um teste t bilateral, a regi\u00e3o cr\u00edtica est\u00e1 nas duas extremidades da distribui\u00e7\u00e3o t.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#exemplo-pratico","title":"Exemplo Pr\u00e1tico\u00b6","text":"<ul> <li><p>Localize a estat\u00edstica t calculada: 4.389</p> </li> <li><p>Localize a coluna com o n\u00edvel de signific\u00e2ncia desejado (por exemplo, $\ud835\udefc=0.05$ para um teste de duas caudas).</p> </li> <li><p>Compare o valor da estat\u00edstica t com os valores cr\u00edticos da tabela:</p> <p>Para $\ud835\udefc=0.05$ em um teste de duas caudas e 4 graus de liberdade, o valor cr\u00edtico geralmente \u00e9 cerca de 2.776. Como $t=4.389$ \u00e9 maior que o valor cr\u00edtico de 2.776, isso indica que a estat\u00edstica t est\u00e1 na regi\u00e3o cr\u00edtica e o valor p \u00e9 menor que 0.05.</p> </li> </ul> <p>Se a sua estat\u00edstica t calculada (t = 4.389) exceder o valor cr\u00edtico da tabela t para o n\u00edvel de signific\u00e2ncia escolhido, <code>voc\u00ea rejeita a hip\u00f3tese nula</code>. Para testes de duas caudas, voc\u00ea precisa comparar a estat\u00edstica t com o valor cr\u00edtico para a regi\u00e3o cr\u00edtica em ambas as extremidades da distribui\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#conclusao","title":"Conclus\u00e3o\u00b6","text":"<ul> <li>Valor de t calculado: 4.389</li> <li>Graus de liberdade (df): 4</li> <li>Valor p: Aproximadamente $0.0053$ (menor que $0.05$)</li> </ul> <p>Com base nos c\u00e1lculos, <code>podemos rejeitar a hip\u00f3tese nula</code> e concluir que existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas <code>ks.scores1</code> e <code>ks.scores2</code>.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#resumo-do-teste-t-pareado","title":"Resumo do Teste T Pareado:\u00b6","text":"<ul> <li>Hip\u00f3tese Nula (H0): A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero.</li> <li>Hip\u00f3tese Alternativa (H1): A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas n\u00e3o \u00e9 zero.</li> <li>Resultado: <code>Rejeitamos a hip\u00f3tese nula</code>. Existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#teste-t-pareado-usando-python","title":"Teste T Pareado usando Python\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#passos-para-realizar-o-teste-t-pareado","title":"Passos para realizar o Teste T Pareado:\u00b6","text":"<p>1. Formula\u00e7\u00e3o das Hip\u00f3teses:</p> <ul> <li><code>H0 (Hip\u00f3tese Nula):</code> A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero ($\ud835\udf07_1 \u2212\ud835\udf07_2 = 0$).</li> <li><code>H1 (Hip\u00f3tese Alternativa):</code> A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas n\u00e3o \u00e9 zero ($\ud835\udf07_1 \u2212\ud835\udf07_2$ != $0$).</li> </ul> <p>2. C\u00e1lculo da Diferen\u00e7a das M\u00e9tricas:</p> <ul> <li>Para cada par de valores das duas colunas, calcule a diferen\u00e7a.</li> </ul> <p>3. Aplica\u00e7\u00e3o do Teste T Pareado:</p> <ul> <li>Utilize a diferen\u00e7a calculada para aplicar o <code>teste t pareado</code>.</li> <li>Calcule o <code>valor p</code> para determinar se as diferen\u00e7as s\u00e3o estatisticamente significativas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5.%20t_student_teste_t/#implementacao-em-python","title":"Implementa\u00e7\u00e3o em Python:\u00b6","text":"<p>Vou demonstrar como voc\u00ea pode implementar isso usando a biblioteca <code>scipy.stats</code> para calcular o teste t pareado.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/","title":"1.1.6. Notebook - Permutation teste","text":"<p>Para realizar um teste de permuta\u00e7\u00e3o junto e um teste t no cen\u00e1rio em que voc\u00ea possui duas colunas de m\u00e9tricas ks.scores1 e ks.scores2, podemos seguir os seguintes passos:</p> <p>1. <code>Teste T Pareado:</code> \u00c9 um teste param\u00e9trico que assume que os dados seguem uma distribui\u00e7\u00e3o normal (para grandes amostras, isso \u00e9 menos cr\u00edtico devido ao Teorema Central do Limite). Ele \u00e9 mais eficiente com amostras grandes e pode ser mais f\u00e1cil de interpretar em muitos casos. Como j\u00e1 discutido, o teste t pareado \u00e9 apropriado para amostras emparelhadas e verifica se a diferen\u00e7a m\u00e9dia \u00e9 significativamente diferente de zero.</p> <p>2. <code>Teste de Permuta\u00e7\u00e3o:</code> \u00c9 um teste n\u00e3o-param\u00e9trico que n\u00e3o faz suposi\u00e7\u00f5es sobre a distribui\u00e7\u00e3o dos dados. Ele avalia a diferen\u00e7a entre as m\u00e9dias das amostras ao permutar os dados entre as duas amostras para gerar uma distribui\u00e7\u00e3o nula.\u00c9 especialmente \u00fatil quando voc\u00ea tem uma amostra pequena ou quando n\u00e3o pode assumir a normalidade dos dados.</p> <p>O <code>teste de permuta\u00e7\u00e3o</code> \u00e9 um m\u00e9todo de <code>resampling</code> que permite testar a hip\u00f3tese nula de que duas amostras n\u00e3o apresentam diferen\u00e7as estat\u00edsticas significativas. Isso \u00e9 feito atrav\u00e9s da permuta\u00e7\u00e3o repetida dos dados, calculando a diferen\u00e7a nas m\u00e9dias a cada permuta\u00e7\u00e3o, para criar uma distribui\u00e7\u00e3o nula.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\n\n# Criar o DataFrame\ndf = pd.DataFrame(data)\n\n# N\u00famero de permuta\u00e7\u00f5es\nnum_permutations = 10000\n\n# Calcular a diferen\u00e7a observada entre as m\u00e9dias\nobserved_diff = np.mean(df['ks.scores1']) - np.mean(df['ks.scores2'])\n\n# Combinar as duas amostras\ncombined = np.hstack((df['ks.scores1'], df['ks.scores2']))\n\n# Inicializar contador para permuta\u00e7\u00f5es onde a diferen\u00e7a \u00e9 maior ou igual \u00e0 diferen\u00e7a observada\ncount = 0\n\n# Permuta\u00e7\u00e3o\nfor _ in range(num_permutations):\n    # Embaralhar os dados\n    np.random.shuffle(combined)\n    # Separar novamente em dois grupos\n    permuted1 = combined[:len(df['ks.scores1'])]\n    permuted2 = combined[len(df['ks.scores1']):]\n    # Calcular a diferen\u00e7a de m\u00e9dias nas amostras permutadas\n    permuted_diff = np.mean(permuted1) - np.mean(permuted2)\n    # Verificar se a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada\n    if abs(permuted_diff) &gt;= abs(observed_diff):\n        count += 1\n\n# Calcular o valor p\np_value_permutation = count / num_permutations\n\n# Exibir resultados\nprint(\"Diferen\u00e7a observada:\", observed_diff)\nprint(\"Valor p do teste de permuta\u00e7\u00e3o:\", p_value_permutation)\n\n# Avalia\u00e7\u00e3o do resultado\nif p_value_permutation &lt; 0.05:\n    print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\nelse:\n    print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\n</pre> import numpy as np import pandas as pd  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] }  # Criar o DataFrame df = pd.DataFrame(data)  # N\u00famero de permuta\u00e7\u00f5es num_permutations = 10000  # Calcular a diferen\u00e7a observada entre as m\u00e9dias observed_diff = np.mean(df['ks.scores1']) - np.mean(df['ks.scores2'])  # Combinar as duas amostras combined = np.hstack((df['ks.scores1'], df['ks.scores2']))  # Inicializar contador para permuta\u00e7\u00f5es onde a diferen\u00e7a \u00e9 maior ou igual \u00e0 diferen\u00e7a observada count = 0  # Permuta\u00e7\u00e3o for _ in range(num_permutations):     # Embaralhar os dados     np.random.shuffle(combined)     # Separar novamente em dois grupos     permuted1 = combined[:len(df['ks.scores1'])]     permuted2 = combined[len(df['ks.scores1']):]     # Calcular a diferen\u00e7a de m\u00e9dias nas amostras permutadas     permuted_diff = np.mean(permuted1) - np.mean(permuted2)     # Verificar se a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada     if abs(permuted_diff) &gt;= abs(observed_diff):         count += 1  # Calcular o valor p p_value_permutation = count / num_permutations  # Exibir resultados print(\"Diferen\u00e7a observada:\", observed_diff) print(\"Valor p do teste de permuta\u00e7\u00e3o:\", p_value_permutation)  # Avalia\u00e7\u00e3o do resultado if p_value_permutation &lt; 0.05:     print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\") else:     print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")  <pre>Diferen\u00e7a observada: 0.05183019999999994\nValor p do teste de permuta\u00e7\u00e3o: 0.0053\nRejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\n</pre> In\u00a0[3]: Copied! <pre>from typing import Dict, List, Tuple\ndef permutation_test(\n    array1: List[float],\n    array2: List[float],\n    anscreen: bool = True,\n    alpha: float = 0.05\n) -&gt; Tuple[float, List[float], float, List[str]]:\n    \"\"\"\n    Realiza um teste de permuta\u00e7\u00e3o para comparar as m\u00e9dias de dois arrays.\n\n    Args:\n        array1 (List[float]): O primeiro array de dados.\n        array2 (List[float]): O segundo array de dados.\n        anscreen (bool): Se True, imprime os resultados na tela. Default \u00e9 False.\n        alpha (float): N\u00edvel de signific\u00e2ncia para o teste (p-valor). Default \u00e9 0.05.\n\n    Returns:\n        Tuple[float, List[float], float, List[str]]:\n            - p_val (float): Valor p do teste de permuta\u00e7\u00e3o.\n            - mean_lst (List[float]): Lista das diferen\u00e7as m\u00e9dias permutadas.\n            - mean_diff (float): Diferen\u00e7a m\u00e9dia observada entre os dois arrays.\n            - text_lst (List[str]): Lista de mensagens interpretativas sobre o teste.\n    \"\"\"\n    # Garantindo a entrada com numpy array\n    array1 = np.array(array1)\n    array2 = np.array(array2)\n    \n    # C\u00e1lculo das m\u00e9dias de cada vetor\n    avg_array1 = array1.mean()\n    avg_array2 = array2.mean()\n    \n    # Diferen\u00e7a entre as m\u00e9dias\n    mean_diff = avg_array1 - avg_array2\n    full_array = np.concatenate([array1, array2])\n    mean_lst = []\n    # Defina a semente aleat\u00f3ria para reprodutibilidade\n    np.random.seed(42)\n    for i in range(10000):\n        # Com reposi\u00e7\u00e3o: bootstrapping\n        avg1 = np.random.choice(full_array, size=len(array1), replace=True).mean()\n        avg2 = np.random.choice(full_array, size=len(array2), replace=True).mean()\n        # reprece = True, Assume que qualquer valor pode vir de uma das duas listas, converg\u00cancia para Normal.\n        mean_lst.append(avg1 - avg2)\n    \n    if mean_diff &gt; 0:\n        p_val = np.sum(np.array(mean_lst) &gt; mean_diff) / len(mean_lst) \n    else:\n        p_val = np.sum(np.array(mean_lst) &lt; mean_diff) / len(mean_lst) \n    \n    text_lst = [\"\\n Teste de Significancia \", \n                \"**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \\n\",\n                f\" Arrays sizes: {len(array1)}, {len(array2)} \",\n                \"* Difference between averages: %.4f - %.4f = %.4f\" % (avg_array1, avg_array2, mean_diff),\n                \"* p_val = %.4f \" %p_val]\n    \n    if p_val &gt; alpha:\n        text_lst.append(f'The model seems to produce similar results with CI-{1 - alpha} (fail to reject H0).\\n')\n    else:\n        text_lst.append(f'The model seems to produce different results with CI-{1 - alpha} (reject H0).\\n')\n    \n    if anscreen:\n        for line in text_lst:\n            print(line)   \n    return p_val, mean_lst, mean_diff, text_lst\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\np_val, mean_lst, mean_diff, text_lst = permutation_test(array1 = data[\"ks.scores1\"], array2 = data[\"ks.scores2\"], alpha  = 0.05)\n</pre> from typing import Dict, List, Tuple def permutation_test(     array1: List[float],     array2: List[float],     anscreen: bool = True,     alpha: float = 0.05 ) -&gt; Tuple[float, List[float], float, List[str]]:     \"\"\"     Realiza um teste de permuta\u00e7\u00e3o para comparar as m\u00e9dias de dois arrays.      Args:         array1 (List[float]): O primeiro array de dados.         array2 (List[float]): O segundo array de dados.         anscreen (bool): Se True, imprime os resultados na tela. Default \u00e9 False.         alpha (float): N\u00edvel de signific\u00e2ncia para o teste (p-valor). Default \u00e9 0.05.      Returns:         Tuple[float, List[float], float, List[str]]:             - p_val (float): Valor p do teste de permuta\u00e7\u00e3o.             - mean_lst (List[float]): Lista das diferen\u00e7as m\u00e9dias permutadas.             - mean_diff (float): Diferen\u00e7a m\u00e9dia observada entre os dois arrays.             - text_lst (List[str]): Lista de mensagens interpretativas sobre o teste.     \"\"\"     # Garantindo a entrada com numpy array     array1 = np.array(array1)     array2 = np.array(array2)          # C\u00e1lculo das m\u00e9dias de cada vetor     avg_array1 = array1.mean()     avg_array2 = array2.mean()          # Diferen\u00e7a entre as m\u00e9dias     mean_diff = avg_array1 - avg_array2     full_array = np.concatenate([array1, array2])     mean_lst = []     # Defina a semente aleat\u00f3ria para reprodutibilidade     np.random.seed(42)     for i in range(10000):         # Com reposi\u00e7\u00e3o: bootstrapping         avg1 = np.random.choice(full_array, size=len(array1), replace=True).mean()         avg2 = np.random.choice(full_array, size=len(array2), replace=True).mean()         # reprece = True, Assume que qualquer valor pode vir de uma das duas listas, converg\u00cancia para Normal.         mean_lst.append(avg1 - avg2)          if mean_diff &gt; 0:         p_val = np.sum(np.array(mean_lst) &gt; mean_diff) / len(mean_lst)      else:         p_val = np.sum(np.array(mean_lst) &lt; mean_diff) / len(mean_lst)           text_lst = [\"\\n Teste de Significancia \",                  \"**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \\n\",                 f\" Arrays sizes: {len(array1)}, {len(array2)} \",                 \"* Difference between averages: %.4f - %.4f = %.4f\" % (avg_array1, avg_array2, mean_diff),                 \"* p_val = %.4f \" %p_val]          if p_val &gt; alpha:         text_lst.append(f'The model seems to produce similar results with CI-{1 - alpha} (fail to reject H0).\\n')     else:         text_lst.append(f'The model seems to produce different results with CI-{1 - alpha} (reject H0).\\n')          if anscreen:         for line in text_lst:             print(line)        return p_val, mean_lst, mean_diff, text_lst  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] } p_val, mean_lst, mean_diff, text_lst = permutation_test(array1 = data[\"ks.scores1\"], array2 = data[\"ks.scores2\"], alpha  = 0.05) <pre>\n Teste de Significancia \n**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \n\n Arrays sizes: 5, 5 \n* Difference between averages: 0.5794 - 0.5276 = 0.0518\n* p_val = 0.0049 \nThe model seems to produce different results with CI-0.95 (reject H0).\n\n</pre>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#teste-de-permutacao","title":"Teste de permuta\u00e7\u00e3o\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#implementacao-do-teste-t-pareado","title":"Implementa\u00e7\u00e3o do Teste T Pareado\u00b6","text":"<p>Antes de implementarmos o teste de permuta\u00e7\u00e3o, vamos relembrar como implementar o teste t pareado:</p> <ul> <li>Notebook -Teste T Calculo</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#implementacao-do-teste-de-permutacao","title":"Implementa\u00e7\u00e3o do Teste de Permuta\u00e7\u00e3o\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#passo-a-passo-para-o-teste-de-permutacao","title":"Passo a Passo para o Teste de Permuta\u00e7\u00e3o\u00b6","text":"<p>1. Formula\u00e7\u00e3o das Hip\u00f3teses:</p> <ul> <li><code>H0 (Hip\u00f3tese Nula):</code>  As duas amostras v\u00eam da mesma distribui\u00e7\u00e3o (N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias).</li> <li><code>H1 (Hip\u00f3tese Alternativa):</code> As duas amostras v\u00eam de distribui\u00e7\u00f5es diferentes (H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias).</li> </ul> <p>2. Passos do Teste de Permuta\u00e7\u00e3o:</p> <ul> <li>Calcule a diferen\u00e7a observada entre as m\u00e9dias das duas amostras.</li> <li>Combine as amostras em um \u00fanico conjunto de dados.</li> <li>Embaralhe (permute) aleatoriamente os dados e separe-os novamente em dois grupos.</li> <li>Calcule a diferen\u00e7a entre as m\u00e9dias dos grupos permutados.</li> <li>Repita o processo de permuta\u00e7\u00e3o v\u00e1rias vezes (por exemplo, 10.000 vezes) para construir a distribui\u00e7\u00e3o nula.</li> <li>Compare a diferen\u00e7a observada com a distribui\u00e7\u00e3o nula para determinar o valor p.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#teste-de-permutacao-codigo-1","title":"Teste de Permuta\u00e7\u00e3o: C\u00f3digo 1:\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#explicacao-do-codigo-do-teste-de-permutacao","title":"Explica\u00e7\u00e3o do C\u00f3digo do Teste de Permuta\u00e7\u00e3o\u00b6","text":"<ul> <li><code>Combina\u00e7\u00e3o e Permuta\u00e7\u00e3o:</code> Combina as duas amostras em um array e embaralha repetidamente para criar distribui\u00e7\u00f5es permutadas.</li> <li><code>Contagem:</code> Conta o n\u00famero de permuta\u00e7\u00f5es onde a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada.</li> <li><code>C\u00e1lculo do Valor p:</code> O valor p \u00e9 calculado dividindo o n\u00famero de permuta\u00e7\u00f5es em que a diferen\u00e7a permutada foi maior ou igual \u00e0 diferen\u00e7a observada pelo total de permuta\u00e7\u00f5es.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#resultado-esperado","title":"Resultado Esperado\u00b6","text":"<p>Ao executar ambos os testes, voc\u00ea ter\u00e1 duas an\u00e1lises complementares sobre a diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas:</p> <ul> <li>1. <code>Teste T Pareado:</code> Verifica se a diferen\u00e7a m\u00e9dia \u00e9 significativa sob a suposi\u00e7\u00e3o de normalidade.</li> <li>2. <code>Teste de Permuta\u00e7\u00e3o:</code> Oferece uma abordagem n\u00e3o-param\u00e9trica para testar a mesma hip\u00f3tese.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#consideracoes","title":"Considera\u00e7\u00f5es\u00b6","text":"<p>O teste t assume que as diferen\u00e7as entre as amostras seguem uma distribui\u00e7\u00e3o normal. Se essa suposi\u00e7\u00e3o n\u00e3o for v\u00e1lida, o teste de permuta\u00e7\u00e3o \u00e9 uma boa alternativa. O teste de permuta\u00e7\u00e3o \u00e9 computacionalmente intensivo, mas n\u00e3o depende de suposi\u00e7\u00f5es sobre a distribui\u00e7\u00e3o dos dados, tornando-o \u00fatil para casos em que a normalidade \u00e9 question\u00e1vel.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#teste-de-permutacao-codigo-2","title":"Teste de Permuta\u00e7\u00e3o: C\u00f3digo 2 ()\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#comparando-os-codigos-de-permutacao","title":"Comparando os c\u00f3digos de Permuta\u00e7\u00e3o\u00b6","text":"<p>O <code>c\u00f3digo 1</code>  e a fun\u00e7\u00e3o <code>permutation_test</code> compartilham a mesma l\u00f3gica b\u00e1sica para realizar um teste de permuta\u00e7\u00e3o, mas existem algumas diferen\u00e7as sutis na implementa\u00e7\u00e3o e no tipo de an\u00e1lise.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#codigo-fornecido","title":"C\u00f3digo Fornecido\u00b6","text":"<p>1. Processo de Permuta\u00e7\u00e3o:</p> <ul> <li>Combina as duas amostras.</li> <li>Embaralha aleatoriamente os dados combinados.</li> <li>Separa os dados embaralhados novamente em duas amostras.</li> <li>Calcula a diferen\u00e7a entre as m\u00e9dias das amostras permutadas e compara com a diferen\u00e7a observada.</li> </ul> <p>2. Valor p:</p> <ul> <li>O <code>valor p</code> \u00e9 calculado como a propor\u00e7\u00e3o das diferen\u00e7as permutadas que s\u00e3o maiores ou iguais \u00e0 diferen\u00e7a observada.</li> </ul> <p>3. Teste de Hip\u00f3teses:</p> <p>Se o <code>valor p for menor que 0.05</code>, <code>rejeita a hip\u00f3tese nula</code>, indicando que h\u00e1 uma diferen\u00e7a significativa entre as m\u00e9dias.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#funcao-permutation_test","title":"Fun\u00e7\u00e3o permutation_test\u00b6","text":"<p>1. Processo de Permuta\u00e7\u00e3o:</p> <ul> <li>Em vez de combinar e embaralhar os dados, utiliza a t\u00e9cnica de <code>bootstrapping</code> (amostragem com reposi\u00e7\u00e3o) para gerar as diferen\u00e7as de m\u00e9dias. Calcula a diferen\u00e7a entre as m\u00e9dias de amostras bootstrapped e compara com a diferen\u00e7a observada.</li> </ul> <p>2. Valor p:</p> <ul> <li>O valor p \u00e9 calculado comparando a diferen\u00e7a m\u00e9dia observada com as diferen\u00e7as m\u00e9dias obtidas nas amostras bootstrapped.</li> </ul> <p>3. Teste de Hip\u00f3teses:</p> <ul> <li>A fun\u00e7\u00e3o oferece uma descri\u00e7\u00e3o mais detalhada do teste, incluindo mensagens interpretativas.</li> <li>Permite definir um n\u00edvel de signific\u00e2ncia (alpha) e imprime resultados na tela se o argumento anscreen for True.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6.%20Permutacion_test/#principais-diferencas","title":"Principais Diferen\u00e7as\u00b6","text":"<ul> <li><code>Combina\u00e7\u00e3o de Dados:</code> O c\u00f3digo 1 combina as amostras e embaralha, enquanto a fun\u00e7\u00e3o permutation_test utiliza <code>bootstrapping</code>.</li> <li><code>Tipo de Permuta\u00e7\u00e3o:</code> O c\u00f3digo 1 usa permuta\u00e7\u00e3o direta, enquanto a fun\u00e7\u00e3o permutation_test usa amostragem com reposi\u00e7\u00e3o.</li> <li><code>Sa\u00edda:</code> A fun\u00e7\u00e3o permutation_test retorna um conjunto mais detalhado de informa\u00e7\u00f5es e permite a impress\u00e3o dos resultados.</li> </ul> <p>Ambos os m\u00e9todos t\u00eam o mesmo objetivo: comparar as m\u00e9dias de duas amostras para determinar se h\u00e1 uma diferen\u00e7a significativa. A escolha entre eles pode depender da prefer\u00eancia ou do contexto espec\u00edfico do problema.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/Readme/","title":"Readme","text":"<ul> <li>1. O que s\u00e3o Testes de Hip\u00f3teses</li> <li>1.1. Hip\u00f3teses</li> <li>1.2. Passos para Realizar um Teste de Hip\u00f3teses</li> <li>1.3. Tipos de Teste de hip\u00f3teses:</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/Readme/#1-o-que-sao-testes-de-hipoteses","title":"1. O que s\u00e3o Testes de Hip\u00f3teses","text":"<p>Testes de hip\u00f3teses s\u00e3o procedimentos estat\u00edsticos usados para tomar decis\u00f5es ou infer\u00eancias sobre popula\u00e7\u00f5es com base em amostras de dados. A ideia b\u00e1sica \u00e9 formular duas hip\u00f3teses mutuamente exclusivas: a hip\u00f3tese nula (H<sub>0</sub>) e a hip\u00f3tese alternativa (H<sub>a</sub>).</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/Readme/#11-hipoteses","title":"1.1. Hip\u00f3teses","text":"<ul> <li>Hip\u00f3tese Nula (H<sub>0</sub>): Assume que n\u00e3o h\u00e1 efeito ou diferen\u00e7a significativa. \u00c9 a hip\u00f3tese que voc\u00ea tenta refutar.</li> <li>Hip\u00f3tese Alternativa (H<sub>a</sub>): Assume que h\u00e1 um efeito ou diferen\u00e7a significativa. \u00c9 a hip\u00f3tese que voc\u00ea tenta provar.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/Readme/#12-passos-para-realizar-um-teste-de-hipoteses","title":"1.2. Passos para Realizar um Teste de Hip\u00f3teses","text":"<ol> <li>Formular as Hip\u00f3teses: Definir H<sub>0</sub> e H<sub>a</sub>.</li> <li>Escolher o N\u00edvel de Signific\u00e2ncia (\u03b1): Geralmente, 0,05 ou 0,01.</li> <li>Coletar Dados: Obter uma amostra representativa da popula\u00e7\u00e3o.</li> <li>Calcular a Estat\u00edstica de Teste: Utilizar a f\u00f3rmula apropriada para a estat\u00edstica de teste (por exemplo, t-teste, teste z, etc.).</li> <li>Tomar a Decis\u00e3o: Comparar a estat\u00edstica de teste com o valor cr\u00edtico ou calcular o p-valor e compar\u00e1-lo com \u03b1.</li> <li>Conclus\u00e3o: Se o p-valor for menor que \u03b1, rejeite H<sub>0</sub> em favor de H<sub>a</sub>. Caso contr\u00e1rio, n\u00e3o rejeite H<sub>0</sub>.</li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/Readme/#13-tipos-de-teste-de-hipoteses","title":"1.3. Tipos de Teste de hip\u00f3teses:","text":"<ul> <li>Teste t</li> </ul>"},{"location":"Estudos_machine_learning/Page/KS/","title":"KS","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\ndiretorio_atual = os.getcwd()\nprint(f\"Logado no diret\u00f3rio: {diretorio_atual}\")\nsys.path.append('/home/jovyan/work')\n</pre> import os import sys  diretorio_atual = os.getcwd() print(f\"Logado no diret\u00f3rio: {diretorio_atual}\") sys.path.append('/home/jovyan/work') <pre>Logado no diret\u00f3rio: /home/jovyan/work\n</pre> In\u00a0[2]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[3]: Copied! <pre># Salvando a base de teste em formato CSV\ntrain_data_experimento = pd.read_csv('./data/processed/train_data_experimento.csv')\ntest_data_experimento  = pd.read_csv('./data/processed/test_data_experimento.csv')\n</pre> # Salvando a base de teste em formato CSV train_data_experimento = pd.read_csv('./data/processed/train_data_experimento.csv') test_data_experimento  = pd.read_csv('./data/processed/test_data_experimento.csv') In\u00a0[5]: Copied! <pre>train_data_experimento.head(3)\n</pre> train_data_experimento.head(3) Out[5]: PassengerId Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Survived y_predi_forest_clf y_proba_forest_clf y_predi_svm_clf y_proba_svm_clf 0 446 1 Dodge, Master. Washington male 4.0 0 2 33638 81.8583 A34 S 1 1 0.71 1 0.810786 1 651 3 Mitkoff, Mr. Mito male NaN 0 0 349221 7.8958 NaN S 0 0 0.00 0 0.140404 2 173 3 Johnson, Miss. Eleanor Ileen female 1.0 1 1 347742 11.1333 NaN S 1 1 0.74 1 0.780057 In\u00a0[8]: Copied! <pre>import numpy as np\nfrom scipy.stats import ks_2samp\n\n# Gerar duas amostras\namostra1 = np.random.normal(0, 1, 100)\namostra2 = np.random.normal(0, 1.5, 100)\n\n# Calcular o teste KS\nstatistic, p_value = ks_2samp(amostra1, amostra2)\n\nprint(f\"Estat\u00edstica KS: {statistic}\")\nprint(f\"Valor p: {p_value}\")\n</pre> import numpy as np from scipy.stats import ks_2samp  # Gerar duas amostras amostra1 = np.random.normal(0, 1, 100) amostra2 = np.random.normal(0, 1.5, 100)  # Calcular o teste KS statistic, p_value = ks_2samp(amostra1, amostra2)  print(f\"Estat\u00edstica KS: {statistic}\") print(f\"Valor p: {p_value}\") <pre>Estat\u00edstica KS: 0.19\nValor p: 0.05390207893129876\n</pre> In\u00a0[\u00a0]: Copied! <pre>from scipy.stats import ks_2samp\ndf = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\")\nks_2samp(df.loc[df.y==0,\"p\"], df.loc[df.y==1,\"p\"])\n</pre> from scipy.stats import ks_2samp df = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\") ks_2samp(df.loc[df.y==0,\"p\"], df.loc[df.y==1,\"p\"]) In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom scipy.stats import ks_2samp\n\nnp.random.seed(42)\n# Criar um DataFrame de exemplo\ndata = {\n    'score': np.random.random(100),\n    'label': np.random.randint(2, size=100)\n}\ndf = pd.DataFrame(data)\n\n# Separar os scores em duas amostras com base nos r\u00f3tulos\namostra1 = df[df['label'] == 0]['score']\namostra2 = df[df['label'] == 1]['score']\n\n# Calcular a m\u00e9trica KS usando scipy\nks_statistic, p_value = ks_2samp(amostra1, amostra2)\n\nprint(f\"M\u00e9trica KS: {ks_statistic}\")\nprint(f\"Valor p: {p_value}\")\n</pre> import pandas as pd import numpy as np from scipy.stats import ks_2samp  np.random.seed(42) # Criar um DataFrame de exemplo data = {     'score': np.random.random(100),     'label': np.random.randint(2, size=100) } df = pd.DataFrame(data)  # Separar os scores em duas amostras com base nos r\u00f3tulos amostra1 = df[df['label'] == 0]['score'] amostra2 = df[df['label'] == 1]['score']  # Calcular a m\u00e9trica KS usando scipy ks_statistic, p_value = ks_2samp(amostra1, amostra2)  print(f\"M\u00e9trica KS: {ks_statistic}\") print(f\"Valor p: {p_value}\") In\u00a0[7]: Copied! <pre>df = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\")\n# Calculando a tabela KS e o valor KS\nkstable = utils.ks(data=df, target=\"y\", prob=\"p\")\n</pre> df = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\") # Calculando a tabela KS e o valor KS kstable = utils.ks(data=df, target=\"y\", prob=\"p\") <pre>M\u00e9trica KS: 0.1336812525090325\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Estudos_machine_learning/Page/KS/#teste-estatistico-de-kolmogorov-smirnov","title":"Teste Estat\u00edstico de Kolmogorov-Smirnov\u00b6","text":""},{"location":"Estudos_machine_learning/Page/KS/#metrica-de-performance-kolmogorov-smirnov-ks","title":"M\u00e9trica de Performance Kolmogorov-Smirnov (KS)\u00b6","text":""},{"location":"exemplos/Learning_curve_1/","title":"Titanic data","text":"In\u00a0[1]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>#-----------------------------------------------------------\n# Step 01: load data using panda\n#-----------------------------------------------------------\ntrain_df = pd.read_csv('Bases/Titanic_train.csv')  # train set\ntest_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set\ncombine  = [train_df, test_df]\n</pre> #----------------------------------------------------------- # Step 01: load data using panda #----------------------------------------------------------- train_df = pd.read_csv('Bases/Titanic_train.csv')  # train set test_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set combine  = [train_df, test_df] In\u00a0[3]: Copied! <pre>#-----------------------------------------------------------\n# Step 02: Acquire and clean data\n#-----------------------------------------------------------\ntrain_df.head(5)\n</pre> #----------------------------------------------------------- # Step 02: Acquire and clean data #----------------------------------------------------------- train_df.head(5) Out[3]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S In\u00a0[4]: Copied! <pre>train_df.info()\n</pre> train_df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n</pre> In\u00a0[5]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[5]: PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 In\u00a0[6]: Copied! <pre>train_df.describe(include=['O'])\n</pre> train_df.describe(include=['O']) Out[6]: Name Sex Ticket Cabin Embarked count 891 891 891 204 889 unique 891 2 681 147 3 top Braund, Mr. Owen Harris male 347082 B96 B98 S freq 1 577 7 4 644 <p>Training data statistics:</p> <ul> <li>891 training samples</li> <li>Age, Cabin, Embarked: incomplete data</li> <li>Data type:<ul> <li>object: Name, Sex, Ticket, Cabin, Embarked</li> <li>int64: PassengerId, Survived, Pclass, SibSp, Parch</li> <li>float64: Age, Fare</li> </ul> </li> <li>Survive rate: 0.383838</li> </ul> <p>Estat\u00edsticas dos dados de treinamento:</p> <ul> <li>891 amostras de treinamento</li> <li>Idade, Cabine, Embarque: dados incompletos</li> <li>Tipo de dados:<ul> <li>objeto: Nome, Sexo, Bilhete, Cabine, Embarque</li> <li>int64: PassengerId, Sobreviveu, Classe, SibSp, Parch</li> <li>float64: Idade, Tarifa</li> <li>Taxa de sobreviv\u00eancia: 0.383838</li> </ul> </li> </ul> In\u00a0[7]: Copied! <pre> # remove Features: Ticket, Cabin\n#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n#test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1)\n#combine  = [train_df, test_df]\n# aplica a logica para ambos os datasets\nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].fillna('U')\n    dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\n    \nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0, \n                                            'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)\n    \ntrain_df.head()\n    \n</pre>  # remove Features: Ticket, Cabin #train_df = train_df.drop(['Ticket', 'Cabin'], axis=1) #test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1) #combine  = [train_df, test_df] # aplica a logica para ambos os datasets for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].fillna('U')     dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)      for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0,                                              'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)      train_df.head()      Out[7]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 1 S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 0 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 1 S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 0 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 1 S In\u00a0[8]: Copied! <pre>train_df = train_df.drop(['Ticket'], axis=1)\ntest_df  = test_df.drop(['Ticket'], axis=1)\ncombine  = [train_df, test_df]\n\n\n# survival rate distribtion as a function of Pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> train_df = train_df.drop(['Ticket'], axis=1) test_df  = test_df.drop(['Ticket'], axis=1) combine  = [train_df, test_df]   # survival rate distribtion as a function of Pclass train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[8]: Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 In\u00a0[9]: Copied! <pre># obtain Title from name (Mr, Mrs, Miss etc)\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')\n    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')\n    dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'\n    dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'\n\n#: count survived rate for different titles\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> # obtain Title from name (Mr, Mrs, Miss etc) for dataset in combine:     dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)   for dataset in combine:     dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')     dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')     dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')     dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')     dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')     dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'     dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'  #: count survived rate for different titles train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[9]: Title Survived 3 Mrs 0.795276 1 Miss 0.702703 5 Royalty 0.600000 0 Master 0.575000 4 Officer 0.181818 2 Mr 0.158700 In\u00a0[10]: Copied! <pre>train_df.head(5)\n</pre> train_df.head(5) Out[10]: PassengerId Survived Pclass Name Sex Age SibSp Parch Fare Cabin Embarked Title 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 7.2500 1 S Mr 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 71.2833 0 C Mrs 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 7.9250 1 S Miss 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 53.1000 0 S Mrs 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 8.0500 1 S Mr In\u00a0[11]: Copied! <pre># Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...)\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\n# if age &lt; 16, set 'Sex' to Child\nfor dataset in combine:\n    dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'\n    \n# Covert 'Sex' to numbers (female:1, male:2)\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...) title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6} for dataset in combine:     dataset['Title'] = dataset['Title'].map(title_mapping)     dataset['Title'] = dataset['Title'].fillna(0)  # Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data train_df = train_df.drop(['Name', 'PassengerId'], axis=1) test_df = test_df.drop(['Name'], axis=1) combine = [train_df, test_df]  # if age &lt; 16, set 'Sex' to Child for dataset in combine:     dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'      # Covert 'Sex' to numbers (female:1, male:2) for dataset in combine:     dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)  train_df.head() Out[11]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 22.0 1 0 7.2500 1 S 1 1 1 1 1 38.0 1 0 71.2833 0 C 3 2 1 3 1 26.0 0 0 7.9250 1 S 2 3 1 1 1 35.0 1 0 53.1000 0 S 3 4 0 3 0 35.0 0 0 8.0500 1 S 1 In\u00a0[12]: Copied! <pre># Age distribution for different values of Pclass and gender\n#grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n#grid.map(plt.hist, 'Age', bins=20)\n#grid.add_legend()\n</pre> # Age distribution for different values of Pclass and gender #grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6) #grid.map(plt.hist, 'Age', bins=20) #grid.add_legend() In\u00a0[13]: Copied! <pre># Guess age values using median values for age across set of Pclass and gender frature combinations\nfor dataset in combine:\n    dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)\n\n# create Age bands and determine correlations with Survived\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> # Guess age values using median values for age across set of Pclass and gender frature combinations for dataset in combine:     dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)  # create Age bands and determine correlations with Survived train_df['AgeBand'] = pd.cut(train_df['Age'], 5) train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True) <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\4175406704.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> Out[13]: AgeBand Survived 0 (-0.08, 16.0] 0.550000 1 (16.0, 32.0] 0.339506 2 (32.0, 48.0] 0.404444 3 (48.0, 64.0] 0.434783 4 (64.0, 80.0] 0.090909 In\u00a0[14]: Copied! <pre>for dataset in combine:\n    dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> for dataset in combine:     dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0     dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1     dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2     dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3     dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4  train_df = train_df.drop(['AgeBand'], axis=1) combine = [train_df, test_df] train_df.head() Out[14]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 1 1 0 7.2500 1 S 1 1 1 1 1 2 1 0 71.2833 0 C 3 2 1 3 1 1 0 0 7.9250 1 S 2 3 1 1 1 2 1 0 53.1000 0 S 3 4 0 3 0 2 0 0 8.0500 1 S 1 In\u00a0[15]: Copied! <pre># Create family size from 'sibsq + parch + 1'\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\n#create another feature called IsAlone\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n    dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2\n\ntrain_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()\n\n#drop Parch, SibSp, and FamilySize features in favor of IsAlone\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # Create family size from 'sibsq + parch + 1' for dataset in combine:     dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1  train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)  #create another feature called IsAlone for dataset in combine:     dataset['IsAlone'] = 0     dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1     dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2  train_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()  #drop Parch, SibSp, and FamilySize features in favor of IsAlone train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) combine = [train_df, test_df] train_df.head() Out[15]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone 0 0 3 0 1 7.2500 1 S 1 0 1 1 1 1 2 71.2833 0 C 3 0 2 1 3 1 1 7.9250 1 S 2 1 3 1 1 1 2 53.1000 0 S 3 0 4 0 3 0 2 8.0500 1 S 1 1 In\u00a0[16]: Copied! <pre># Create an artfical feature combinbing PClass and Age.\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()\n</pre> # Create an artfical feature combinbing PClass and Age. for dataset in combine:     dataset['Age*Class'] = dataset.Age * dataset.Pclass  train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head() Out[16]: Age*Class Age Pclass 0 3 1 3 1 2 2 1 2 3 1 3 3 2 2 1 4 6 2 3 In\u00a0[17]: Copied! <pre># fill the missing values of Embarked feature with the most common occurance\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # fill the missing values of Embarked feature with the most common occurance freq_port = train_df.Embarked.dropna().mode()[0] for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].fillna(freq_port) train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)  for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)  train_df.head() Out[17]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 7.2500 1 0 1 0 3 1 1 1 1 2 71.2833 0 1 3 0 2 2 1 3 1 1 7.9250 1 0 2 1 3 3 1 1 1 2 53.1000 0 0 3 0 2 4 0 3 0 2 8.0500 1 0 1 1 6 In\u00a0[18]: Copied! <pre># fill the missing values of Fare\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n\n# Create FareBand\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n\n# Convert the Fare feature to ordinal values based on the FareBand\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # fill the missing values of Fare test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)  # Create FareBand train_df['FareBand'] = pd.qcut(train_df['Fare'], 4) train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)  # Convert the Fare feature to ordinal values based on the FareBand for dataset in combine:     dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0     dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1     dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2     dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3     dataset['Fare'] = dataset['Fare'].astype(int)  train_df = train_df.drop(['FareBand'], axis=1) combine = [train_df, test_df] train_df.head() <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\nC:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n</pre> Out[18]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 0 1 0 1 0 3 1 1 1 1 2 3 0 1 3 0 2 2 1 3 1 1 1 1 0 2 1 3 3 1 1 1 2 3 0 0 3 0 2 4 0 3 0 2 1 1 0 1 1 6 In\u00a0[19]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[19]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 mean 0.383838 2.308642 0.490460 1.332211 1.505051 0.771044 0.361392 1.711560 0.741863 2.785634 std 0.486592 0.836071 0.660838 0.822210 1.118148 0.420397 0.635673 1.036888 0.575364 1.755907 min 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 25% 0.000000 2.000000 0.000000 1.000000 0.500000 1.000000 0.000000 1.000000 0.000000 2.000000 50% 0.000000 3.000000 0.000000 1.000000 2.000000 1.000000 0.000000 1.000000 1.000000 3.000000 75% 1.000000 3.000000 1.000000 2.000000 2.000000 1.000000 1.000000 2.000000 1.000000 3.000000 max 1.000000 3.000000 2.000000 4.000000 3.000000 1.000000 2.000000 6.000000 2.000000 12.000000 In\u00a0[20]: Copied! <pre>#correlation matrix\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(train_df.corr(), vmax=.8, square=True);\n</pre> #correlation matrix f, ax = plt.subplots(figsize=(12, 9)) sns.heatmap(train_df.corr(), vmax=.8, square=True); In\u00a0[21]: Copied! <pre>train_df.to_csv('Bases_tratadas/Titanic_train_df.csv')\ntest_df.to_csv('Bases_tratadas/Titanic_test_df.csv')\n</pre> train_df.to_csv('Bases_tratadas/Titanic_train_df.csv') test_df.to_csv('Bases_tratadas/Titanic_test_df.csv')"},{"location":"exemplos/Learning_curve_1/#titanic-data","title":"Titanic data\u00b6","text":"<p>Tarefa: Prever a sobreviv\u00eancia de um passageiro(a) dado sua classe de ticket, nome, g\u00eanero, idade, n\u00famero de irm\u00e3os/c\u00f4njuges a bordo, n\u00famero de pais/filhos a bordo, n\u00famero do ticket, n\u00famero da cabine e Porto de embarque.</p>"},{"location":"exemplos/Learning_curve_1/#parte-i-analise-exploratoria-de-dados","title":"Parte I: An\u00e1lise Explorat\u00f3ria de Dados\u00b6","text":""},{"location":"exemplos/Learning_curve_1/#step-1-carrega-base-de-dados","title":"Step 1: Carrega Base de Dados\u00b6","text":""},{"location":"exemplos/Learning_curve_1/#step-2-limpeza-dos-dados","title":"Step 2: Limpeza dos Dados\u00b6","text":""},{"location":"exemplos/Learning_curve_1/#salvando-as-bases-tratadas","title":"Salvando as bases tratadas\u00b6","text":""},{"location":"exemplos/Teste/","title":"Configura\u00e7\u00e3o do Teste","text":""},{"location":"exemplos/codigo/","title":"Exemplos de C\u00f3digo","text":""},{"location":"exemplos/codigo/#python","title":"Python","text":"<pre><code>def hello_world():\n    print(\"Ol\u00e1, mundo!\")\n</code></pre>"},{"location":"exemplos/markdown/","title":"Exemplos de Markdown","text":""},{"location":"exemplos/markdown/#cabecalhos","title":"Cabe\u00e7alhos","text":"<p>```markdown</p>"},{"location":"exemplos/markdown/#titulo-1","title":"T\u00edtulo 1","text":""},{"location":"exemplos/markdown/#titulo-2","title":"T\u00edtulo 2","text":""},{"location":"exemplos/markdown/#titulo-3","title":"T\u00edtulo 3","text":""},{"location":"guias/configuracao/","title":"Configura\u00e7\u00e3o","text":"<p>Aqui est\u00e3o algumas dicas para configurar o MkDocs.</p>"},{"location":"guias/configuracao/#tema","title":"Tema","text":"<p>Use o tema <code>material</code> para uma apar\u00eancia moderna:</p> <pre><code>theme:\n  name: material\n</code></pre>"},{"location":"guias/guia-rapido/","title":"Guia R\u00e1pido","text":"<p>Este \u00e9 um guia r\u00e1pido para come\u00e7ar a usar o MkDocs.</p>"},{"location":"guias/guia-rapido/#passos-basicos","title":"Passos B\u00e1sicos","text":"<ol> <li>Instale o MkDocs: <code>pip install mkdocs</code>.</li> <li>Crie um novo projeto: <code>mkdocs new .</code>.</li> <li>Inicie o servidor: <code>mkdocs serve</code>.</li> <li>Acesse <code>http://localhost:8000</code> no navegador.</li> </ol>"},{"location":"machine_learning/","title":"Index","text":"<ul> <li>Desenvolvimento de Modelo de Machine Learning</li> <li><code>Pr\u00e9-Treinamento</code></li> <li><code>Treinamento</code></li> <li><code>P\u00f3s-Treinamento</code></li> <li>Vis\u00e3o Geral da Metodologia CRISP-DM</li> </ul>"},{"location":"machine_learning/#desenvolvimento-de-modelo-de-machine-learning","title":"Desenvolvimento de Modelo de Machine Learning","text":"<p>Este projeto segue uma abordagem estruturada para o desenvolvimento de modelos de Machine Learning, utilizando  a metodologia do CRISP-DM dentro de tr\u00eas grandes grupos:</p>"},{"location":"machine_learning/#pre-treinamento","title":"<code>Pr\u00e9-Treinamento</code>","text":""},{"location":"machine_learning/#treinamento","title":"<code>Treinamento</code>","text":""},{"location":"machine_learning/#pos-treinamento","title":"<code>P\u00f3s-Treinamento</code>","text":"<p>As etapas do processo do <code>CRISP-DM</code> ser\u00e3o inseridas entre esses grupos.</p>"},{"location":"machine_learning/#visao-geral-da-metodologia-crisp-dm","title":"Vis\u00e3o Geral da Metodologia CRISP-DM","text":"<p>A metodologia CRISP-DM (Cross-Industry Standard Process for Data Mining) \u00e9 um estrutura abrangente que tem se destacado na abordagem de projetos de Ci\u00eancia de Dados, essa metodologia \u00e9 composta por seis fases interativas que guiam os profissionais de ci\u00eancia de dados durante todo o processo de descoberta de conhecimento a partir de dados. Vamos explorar cada uma dessas fases em detalhes:</p> <ol> <li> <p>Compreens\u00e3o do Neg\u00f3cio (Business Understanding) Antes de iniciar um projeto de an\u00e1lise de dados, \u00e9 essencial compreender o contexto e os objetivos do neg\u00f3cio. Nesta fase, definimos claramente as metas do projeto e as alinhamos aos objetivos estrat\u00e9gicos da organiza\u00e7\u00e3o.</p> </li> <li> <p>Compreens\u00e3o dos Dados (Data Understanding) Coletar dados relevantes \u00e9 fundamental para o sucesso do projeto. Nessa fase, exploramos e nos familiarizamos com os dados dispon\u00edveis, identificamos lacunas e problemas potenciais, e avaliamos a qualidade e a adequa\u00e7\u00e3o dos dados para o projeto.</p> </li> <li> <p>Prepara\u00e7\u00e3o dos Dados (Data Preparation) Os dados brutos raramente est\u00e3o prontos para a an\u00e1lise. Nesta fase, realizamos a limpeza dos dados, tratamos valores ausentes ou inconsistentes e integramos diferentes fontes de dados. O objetivo \u00e9 criar um conjunto de dados preparado para as etapas subsequentes.</p> </li> <li> <p>Modelagem (Modeling) A fase de modelagem envolve a aplica\u00e7\u00e3o de t\u00e9cnicas e algoritmos de modelagem de dados aos dados preparados. Selecionamos as t\u00e9cnicas mais adequadas, como regress\u00e3o, classifica\u00e7\u00e3o ou agrupamento, e ajustamos e avaliamos os modelos para garantir sua precis\u00e3o e efic\u00e1cia.</p> </li> <li> <p>Avalia\u00e7\u00e3o (Evaluation) A avalia\u00e7\u00e3o dos modelos desenvolvidos \u00e9 crucial para medir sua qualidade e desempenho. Nesta fase, utilizamos m\u00e9todos como valida\u00e7\u00e3o cruzada e m\u00e9tricas de desempenho para avaliar o qu\u00e3o bem os modelos se saem em dados n\u00e3o vistos. Com base nessa avalia\u00e7\u00e3o, podemos ajustar e aprimorar os modelos, se necess\u00e1rio.</p> </li> <li> <p>Implanta\u00e7\u00e3o (Deployment) A fase final da metodologia CRISP-DM \u00e9 a implanta\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o. Integramos o modelo aos sistemas existentes, monitoramos seu desempenho cont\u00ednuo e garantimos a ado\u00e7\u00e3o pela equipe de neg\u00f3cios.</p> </li> </ol> <p></p>"},{"location":"machine_learning/1_Pre_treinamento/","title":"1 Pre treinamento","text":"<ul> <li>1. Compreens\u00e3o do Neg\u00f3cio (Business Understanding)</li> <li>2. Compreens\u00e3o dos Dados (Data Understanding)</li> <li>2.1 An\u00e1lise Explorat\u00f3ria de Dados (EDA)</li> <li>3. Prepara\u00e7\u00e3o dos Dados (Data Preparation)</li> <li>3.1 - Normaliza\u00e7\u00e3o, Padroniza\u00e7\u00e3o e Transforma\u00e7\u00f5es<ul> <li>3.1.1 Normaliza\u00e7\u00e3o (Normalization or Scaling)</li> <li>3.1.2 Padroniza\u00e7\u00e3o (Standardization)</li> <li>3.1.2 Transforma\u00e7\u00f5es (Transformations)</li> </ul> </li> <li>Refer\u00eancias</li> </ul>"},{"location":"machine_learning/1_Pre_treinamento/#1-compreensao-do-negocio-business-understanding","title":"1. Compreens\u00e3o do Neg\u00f3cio (Business Understanding)","text":""},{"location":"machine_learning/1_Pre_treinamento/#2-compreensao-dos-dados-data-understanding","title":"2. Compreens\u00e3o dos Dados (Data Understanding)","text":""},{"location":"machine_learning/1_Pre_treinamento/#21-analise-exploratoria-de-dados-eda","title":"2.1 An\u00e1lise Explorat\u00f3ria de Dados (EDA)","text":"<p>Explorar os dados para entender suas caracter\u00edsticas, distribui\u00e7\u00f5es e rela\u00e7\u00f5es.</p>"},{"location":"machine_learning/1_Pre_treinamento/#3-preparacao-dos-dados-data-preparation","title":"3. Prepara\u00e7\u00e3o dos Dados (Data Preparation)","text":"<p>Os dados brutos raramente est\u00e3o prontos para a an\u00e1lise. Nesta fase, realizamos a limpeza dos dados, tratamos valores ausentes ou inconsistentes e integramos diferentes fontes de dados. O objetivo \u00e9 criar um conjunto de dados preparado para as etapas subsequentes.</p>"},{"location":"machine_learning/1_Pre_treinamento/#31-normalizacao-padronizacao-e-transformacoes","title":"3.1 - Normaliza\u00e7\u00e3o, Padroniza\u00e7\u00e3o e Transforma\u00e7\u00f5es","text":"<p>Uma atividade muito rotineira de um cientista de dados dentro do pr\u00e9-processamento, \u00e9 a transforma\u00e7\u00e3o de seus dados num\u00e9ricos com o objetivo de que todos eles fiquem com a mesma ordem de grandeza. Isso evita que o modelo fique enviesado, dando maior peso para as vari\u00e1veis de maior grandeza.</p> <p></p>"},{"location":"machine_learning/1_Pre_treinamento/#311-normalizacao-normalization-or-scaling","title":"3.1.1 Normaliza\u00e7\u00e3o (Normalization or Scaling)","text":"<p>A normaliza\u00e7\u00e3o coloca os dados dentro do intervalo de 0 a 1 (ou -1 a 1 se houver valores negativos) sem distorcer as diferen\u00e7as nos intervalos de valores. Ele n\u00e3o remove outliers (valores extremos), mas garante que todos os pontos de dados estejam em uma escala comum.</p> <p>Normalizar os dados usando Min-Max:</p> <p>$$ x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} $$</p> <p>Se a distribui\u00e7\u00e3o n\u00e3o \u00e9 Gaussiana ou o desvio padr\u00e3o \u00e9 muito pequeno, normalizar os dados \u00e9 uma escolha a ser tomada.</p>"},{"location":"machine_learning/1_Pre_treinamento/#312-padronizacao-standardization","title":"3.1.2 Padroniza\u00e7\u00e3o (Standardization)","text":"<p>J\u00e1 a padroniza\u00e7\u00e3o ir\u00e1 transformar as vari\u00e1veis fazendo com que elas resultem em uma m\u00e9dia igual a 0 e desvio padr\u00e3o igual a 1. Padronizar os dados normalmente \u00e9 feita usando a f\u00f3rmula z-score: $$ z = \\frac{x - \\mu}{\\sigma} $$</p>"},{"location":"machine_learning/1_Pre_treinamento/#312-transformacoes-transformations","title":"3.1.2 Transforma\u00e7\u00f5es (Transformations)","text":"<p>Estes envolvem a aplica\u00e7\u00e3o de fun\u00e7\u00f5es logar\u00edtmicas (como o logaritmo natural) aos dados. Eles s\u00e3o \u00fateis para lidar com distribui\u00e7\u00f5es assim\u00e9tricas e comprimir grandes faixas de valores. Leia mais: Transformacoes Veja alguns exemplos: Notebooks</p>"},{"location":"machine_learning/1_Pre_treinamento/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Normalizar ou Padronizar as Vari\u00e1veis?</li> <li>Normaliza\u00e7\u00e3o x Padroniza\u00e7\u00e3o: Qual a Diferen\u00e7a?</li> <li>O escalonamento dos dados: Normaliza\u00e7\u00e3o ou Padroniza\u00e7\u00e3o?</li> </ul>"},{"location":"machine_learning/2_Treinamento/","title":"4.0 Modelagem (Modeling)","text":"<p>A fase de modelagem envolve a aplica\u00e7\u00e3o de t\u00e9cnicas e algoritmos de modelagem de dados aos dados preparados. Selecionamos as t\u00e9cnicas mais adequadas, como regress\u00e3o, classifica\u00e7\u00e3o ou agrupamento, e ajustamos e avaliamos os modelos para garantir sua precis\u00e3o e efic\u00e1cia.</p>"},{"location":"machine_learning/3_Pos_treinamento/","title":"3 Pos treinamento","text":"<ul> <li>5 - Avalia\u00e7\u00e3o (Evaluation)</li> <li>Avalia\u00e7\u00e3o de M\u00e9tricas e Interpreta\u00e7\u00e3o do Modelo</li> <li>Fun\u00e7\u00e3o <code>learning_curve</code><ul> <li>Par\u00e2metros Principais:</li> <li>Sa\u00edda:</li> <li>Utilidade:</li> </ul> </li> <li>Interpreta\u00e7\u00e3o da Curva de Aprendizado<ul> <li>Curva de Treinamento (Vermelha):</li> <li>Curva de Valida\u00e7\u00e3o (Verde):</li> <li>Subajustamento (Underfitting):</li> <li>Superajustamento (Overfitting):</li> <li>Conclus\u00e3o</li> <li><code>Exemplifica\u00e7\u00e3o de Plateau</code></li> </ul> </li> <li>Leia mais</li> <li>6.0 Implanta\u00e7\u00e3o (Deployment)</li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#5-avaliacao-evaluation","title":"5 - Avalia\u00e7\u00e3o (Evaluation)","text":"<p>A avalia\u00e7\u00e3o dos modelos desenvolvidos \u00e9 crucial para medir sua qualidade e desempenho. Nesta fase, utilizamos m\u00e9todos como valida\u00e7\u00e3o cruzada e m\u00e9tricas de desempenho para avaliar o qu\u00e3o bem os modelos se saem em dados n\u00e3o vistos. Com base nessa avalia\u00e7\u00e3o, podemos ajustar e aprimorar os modelos, se necess\u00e1rio.</p>"},{"location":"machine_learning/3_Pos_treinamento/#avaliacao-de-metricas-e-interpretacao-do-modelo","title":"Avalia\u00e7\u00e3o de M\u00e9tricas e Interpreta\u00e7\u00e3o do Modelo","text":"<ol> <li> <p>Calcular m\u00e9tricas de desempenho, como precis\u00e3o, recall, F1-score, etc., no conjunto de teste para avaliar o desempenho do modelo.</p> </li> <li> <p>Interpreta\u00e7\u00e3o do Modelo: Compreender como o modelo est\u00e1 tomando decis\u00f5es, quais caracter\u00edsticas s\u00e3o importantes e se est\u00e1 seguindo padr\u00f5es esperados.</p> </li> </ol>"},{"location":"machine_learning/3_Pos_treinamento/#funcao-learning_curve","title":"Fun\u00e7\u00e3o <code>learning_curve</code>","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 uma ferramenta do scikit-learn que permite visualizar como o desempenho de um modelo varia com o tamanho do conjunto de treinamento. Ela \u00e9 \u00fatil para entender como o modelo se comporta \u00e0 medida que \u00e9 treinado com mais dados e para identificar problemas de <code>underfitting</code> ou <code>overfitting</code>.</p>"},{"location":"machine_learning/3_Pos_treinamento/#parametros-principais","title":"Par\u00e2metros Principais:","text":"<ul> <li> <p>Estimator: O estimador ou modelo de machine learning a ser avaliado. Deve ser um objeto que implementa os m\u00e9todos <code>fit</code> e <code>predict</code>.</p> </li> <li> <p>X: O conjunto de caracter\u00edsticas de entrada.</p> </li> <li> <p>y: O vetor alvo.</p> </li> <li> <p>Train_sizes: Os tamanhos relativos dos conjuntos de treinamento a serem usados. Pode ser especificado como uma lista de porcentagens ou como uma lista de n\u00fameros inteiros representando tamanhos absolutos.</p> </li> <li> <p>cv: O esquema de valida\u00e7\u00e3o cruzada a ser usado. Pode ser um objeto <code>KFold</code>, <code>StratifiedKFold</code>, ou um inteiro especificando o n\u00famero de folds.</p> </li> <li> <p>Scoring: A m\u00e9trica de avalia\u00e7\u00e3o a ser usada. Pode ser uma string representando uma m\u00e9trica integrada do scikit-learn (como 'accuracy', 'precision', 'recall', etc.) ou uma fun\u00e7\u00e3o de pontua\u00e7\u00e3o personalizada.</p> </li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#saida","title":"Sa\u00edda:","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> retorna cinco arrays:</p> <ul> <li> <p>Train_sizes_abs: O n\u00famero de amostras usadas em cada fold de treinamento.</p> </li> <li> <p>Train_scores: O desempenho do modelo no conjunto de treinamento para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>Test_scores: O desempenho do modelo no conjunto de teste (ou valida\u00e7\u00e3o) para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>fit_times: O tempo necess\u00e1rio para treinar o modelo para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>score_times: O tempo necess\u00e1rio para avaliar o modelo para cada tamanho de conjunto de treinamento.</p> </li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#utilidade","title":"Utilidade:","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 \u00fatil para:</p> <ul> <li>Visualizar como o desempenho do modelo muda com o tamanho do conjunto de treinamento.</li> <li>Identificar se o modelo est\u00e1 sofrendo de underfitting (baixo desempenho em conjuntos de treinamento pequenos) ou overfitting (alta varia\u00e7\u00e3o entre os conjuntos de treinamento e teste).</li> <li>Determinar se coletar mais dados de treinamento pode melhorar o desempenho do modelo.</li> </ul> <p>Em resumo, a fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 uma ferramenta valiosa para entender a capacidade de generaliza\u00e7\u00e3o do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento e para orientar decis\u00f5es importantes de modelagem em machine learning.</p>"},{"location":"machine_learning/3_Pos_treinamento/#interpretacao-da-curva-de-aprendizado","title":"Interpreta\u00e7\u00e3o da Curva de Aprendizado","text":""},{"location":"machine_learning/3_Pos_treinamento/#curva-de-treinamento-vermelha","title":"Curva de Treinamento (Vermelha):","text":"<ul> <li>Inicialmente Alta e Est\u00e1vel: Se a curva de treinamento come\u00e7a alta e permanece est\u00e1vel, isso indica que o modelo est\u00e1 aprendendo bem com os dados de treinamento.</li> <li>Decl\u00ednio Inicial: Pode haver um decl\u00ednio inicial na acur\u00e1cia de treinamento \u00e0 medida que o tamanho do conjunto de treinamento aumenta, o que \u00e9 normal pois mais dados aumentam a complexidade do problema.</li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#curva-de-validacao-verde","title":"Curva de Valida\u00e7\u00e3o (Verde):","text":"<ul> <li>Inicialmente Baixa e Crescendo: Se a curva de valida\u00e7\u00e3o come\u00e7a baixa e sobe, isso indica que o modelo est\u00e1 melhorando com mais dados de treinamento, o que \u00e9 um bom sinal.</li> <li>Plateau: Se a curva de valida\u00e7\u00e3o atinge um plateau e n\u00e3o melhora com mais dados, isso pode indicar que mais dados n\u00e3o v\u00e3o melhorar o desempenho e pode ser necess\u00e1rio ajustar os hiperpar\u00e2metros do modelo.</li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#subajustamento-underfitting","title":"Subajustamento (Underfitting):","text":"<ul> <li>Ambas as Curvas Baixas: Se tanto a curva de treinamento quanto a curva de valida\u00e7\u00e3o s\u00e3o baixas e pr\u00f3ximas uma da outra, o modelo n\u00e3o est\u00e1 capturando bem os padr\u00f5es dos dados. Pode ser necess\u00e1rio um modelo mais complexo.</li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#superajustamento-overfitting","title":"Superajustamento (Overfitting):","text":"<ul> <li>Curva de Treinamento Alta e Curva de Valida\u00e7\u00e3o Baixa: Se a curva de treinamento \u00e9 alta e a curva de valida\u00e7\u00e3o \u00e9 significativamente mais baixa, o modelo est\u00e1 se ajustando demais aos dados de treinamento e n\u00e3o est\u00e1 generalizando bem. T\u00e9cnicas como regulariza\u00e7\u00e3o, redu\u00e7\u00e3o da complexidade do modelo ou aumento do conjunto de dados podem ajudar.</li> </ul>"},{"location":"machine_learning/3_Pos_treinamento/#conclusao","title":"Conclus\u00e3o","text":"<p>A an\u00e1lise da curva de aprendizado ajuda a identificar o comportamento do modelo e decidir os pr\u00f3ximos passos para melhorar seu desempenho. Dependendo do padr\u00e3o observado nas curvas de treinamento e valida\u00e7\u00e3o, voc\u00ea pode ajustar o modelo, coletar mais dados ou alterar a abordagem de pr\u00e9-processamento e engenharia de caracter\u00edsticas.</p>"},{"location":"machine_learning/3_Pos_treinamento/#exemplificacao-de-plateau","title":"<code>Exemplifica\u00e7\u00e3o de Plateau</code>","text":"<p>Imagine que voc\u00ea est\u00e1 treinando um modelo de regress\u00e3o log\u00edstica e est\u00e1 monitorando a acur\u00e1cia da valida\u00e7\u00e3o ao longo do tempo ou conforme voc\u00ea aumenta a quantidade de dados de treinamento. Inicialmente, a acur\u00e1cia da valida\u00e7\u00e3o melhora \u00e0 medida que voc\u00ea adiciona mais dados, mas eventualmente, ela come\u00e7a a se estabilizar e atinge um ponto onde n\u00e3o h\u00e1 mais melhorias significativas, mesmo com a adi\u00e7\u00e3o de mais dados. Esse ponto de estabiliza\u00e7\u00e3o \u00e9 chamado de plateau.</p>"},{"location":"machine_learning/3_Pos_treinamento/#leia-mais","title":"Leia mais","text":"<p>Learning_Curves Notebook: Learning_Curves_2</p>"},{"location":"machine_learning/3_Pos_treinamento/#60-implantacao-deployment","title":"6.0 Implanta\u00e7\u00e3o (Deployment)","text":"<p>A fase final da metodologia CRISP-DM \u00e9 a implanta\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o. Integramos o modelo aos sistemas existentes, monitoramos seu desempenho cont\u00ednuo e garantimos a ado\u00e7\u00e3o pela equipe de neg\u00f3cios.</p>"},{"location":"machine_learning/teste/","title":"Machine Learning","text":"<p>```rust,editable fn main() {     let number = 5;     print!(\"{}\", number); }</p> <pre><code># Exemplo de C\u00f3digo Python\n\nAqui est\u00e1 um exemplo de c\u00f3digo Python dentro de um arquivo Markdown:\n\n```python, editable\ndef saudacao(nome):\n    return f\"Ol\u00e1, {nome}!\"\n\nnome = \"Mundo\"\nprint(saudacao(nome))\n</code></pre>"},{"location":"machine_learning/Page/Transformacoes/","title":"Transformacoes","text":"<ul> <li>Principais T\u00e9cnicas de Transforma\u00e7\u00e3o de Dados para Machine Learning</li> <li>Transforma\u00e7\u00f5es Logar\u00edtmicas</li> <li>Outras Transforma\u00e7\u00f5es</li> <li>Binning (Discretiza\u00e7\u00e3o)</li> <li>Encoding de Vari\u00e1veis Categ\u00f3ricas</li> <li>Feature Engineering</li> <li>Import\u00e2ncia das Transforma\u00e7\u00f5es de Dados na Regress\u00e3o Log\u00edstica</li> <li>Refer\u00eancias</li> </ul>"},{"location":"machine_learning/Page/Transformacoes/#principais-tecnicas-de-transformacao-de-dados-para-machine-learning","title":"Principais T\u00e9cnicas de Transforma\u00e7\u00e3o de Dados para Machine Learning","text":""},{"location":"machine_learning/Page/Transformacoes/#transformacoes-logaritmicas","title":"Transforma\u00e7\u00f5es Logar\u00edtmicas","text":"<p>As transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis para:</p> <ol> <li>Redu\u00e7\u00e3o de Varia\u00e7\u00e3o: Reduz a dispers\u00e3o em dados com ampla gama de valores.</li> <li>Lineariza\u00e7\u00e3o de Rela\u00e7\u00f5es N\u00e3o Lineares: Torna rela\u00e7\u00f5es n\u00e3o lineares mais lineares, \u00fatil em dados de crescimento exponencial.</li> <li>Estabiliza\u00e7\u00e3o de Vari\u00e2ncia: Especialmente em s\u00e9ries temporais e dados financeiros.</li> <li>Modelos Multiplicativos: Converte modelos multiplicativos em aditivos.</li> </ol>"},{"location":"machine_learning/Page/Transformacoes/#outras-transformacoes","title":"Outras Transforma\u00e7\u00f5es","text":"<ul> <li>Box-Cox: Estabiliza a vari\u00e2ncia e aproxima os dados a uma distribui\u00e7\u00e3o normal.</li> <li>Raiz Quadrada: Reduz a assimetria dos dados com cauda longa \u00e0 direita.</li> <li>Pot\u00eancia: Inclui transforma\u00e7\u00f5es como raiz c\u00fabica ou quadrada, melhora a linearidade em modelos de regress\u00e3o.</li> </ul>"},{"location":"machine_learning/Page/Transformacoes/#binning-discretizacao","title":"Binning (Discretiza\u00e7\u00e3o)","text":"<p>Agrupa valores cont\u00ednuos em intervalos discretos, transformando vari\u00e1veis cont\u00ednuas em categ\u00f3ricas.</p>"},{"location":"machine_learning/Page/Transformacoes/#encoding-de-variaveis-categoricas","title":"Encoding de Vari\u00e1veis Categ\u00f3ricas","text":"<p>Essencial para algoritmos de machine learning. T\u00e9cnicas incluem:</p> <ul> <li>One-hot encoding</li> <li>Label encoding</li> <li>Target encoding</li> </ul>"},{"location":"machine_learning/Page/Transformacoes/#feature-engineering","title":"Feature Engineering","text":"<p>Cria\u00e7\u00e3o de novas vari\u00e1veis a partir das existentes, incluindo combina\u00e7\u00f5es, derivadas e intera\u00e7\u00f5es.</p>"},{"location":"machine_learning/Page/Transformacoes/#importancia-das-transformacoes-de-dados-na-regressao-logistica","title":"Import\u00e2ncia das Transforma\u00e7\u00f5es de Dados na Regress\u00e3o Log\u00edstica","text":"<p>Transforma\u00e7\u00f5es s\u00e3o cruciais para melhorar a performance da regress\u00e3o log\u00edstica por v\u00e1rias raz\u00f5es:</p> <ol> <li>Linearidade: Torna a rela\u00e7\u00e3o entre vari\u00e1veis mais linear.</li> <li>Normaliza\u00e7\u00e3o de Escala: Garante que todas as vari\u00e1veis tenham a mesma ordem de grandeza.</li> <li>Redu\u00e7\u00e3o de Assimetria: Reduz a distor\u00e7\u00e3o dos dados.</li> <li>Estabiliza\u00e7\u00e3o da Vari\u00e2ncia: Garante vari\u00e2ncia constante.</li> <li>Melhoria da Separabilidade: Aumenta a separa\u00e7\u00e3o entre classes.</li> <li>Tratamento de Outliers: Mitiga o impacto de valores extremos.</li> <li>Melhoria na Converg\u00eancia do Algoritmo: Acelera a converg\u00eancia de algoritmos de otimiza\u00e7\u00e3o.</li> <li>Interpreta\u00e7\u00e3o dos Coeficientes: Facilita a interpreta\u00e7\u00e3o dos coeficientes do modelo.</li> </ol> <p>Aplicar transforma\u00e7\u00f5es antes da regress\u00e3o log\u00edstica melhora a performance, a estabilidade e a interpretabilidade dos resultados.</p>"},{"location":"machine_learning/Page/Transformacoes/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Normalizar ou Padronizar as Vari\u00e1veis?</li> <li>Normaliza\u00e7\u00e3o x Padroniza\u00e7\u00e3o: Qual a Diferen\u00e7a?</li> </ul>"},{"location":"machine_learning/Page/learning_curves/","title":"Learning curves","text":"<ul> <li>Tipos de curvas para avalia\u00e7\u00e3o</li> <li>Curva de Valida\u00e7\u00e3o</li> <li>Curva de Desempenho(curva de aprendizado)</li> <li>Scikit-learn: Curvas de Avalia\u00e7\u00e3o e Aprendizagem</li> <li>Curvas Adicionais de Aprendizado em Machine Learning<ul> <li>Curva de Aprendizado Incremental</li> <li>Curva de Aprendizado de Converg\u00eancia</li> <li>Curva de Aprendizado de Regulariza\u00e7\u00e3o</li> <li>Curva de Aprendizado de Aprendizado Ativo</li> </ul> </li> </ul>"},{"location":"machine_learning/Page/learning_curves/#tipos-de-curvas-para-avaliacao","title":"Tipos de curvas para avalia\u00e7\u00e3o","text":""},{"location":"machine_learning/Page/learning_curves/#curva-de-validacao","title":"Curva de Valida\u00e7\u00e3o","text":"<ul> <li>A curva de valida\u00e7\u00e3o \u00e9 uma ferramenta usada para avaliar o desempenho de um modelo de machine learning variando diferentes hiperpar\u00e2metros.</li> <li>Ela representa o desempenho do modelo em um conjunto de valida\u00e7\u00e3o em rela\u00e7\u00e3o a diferentes configura\u00e7\u00f5es de hiperpar\u00e2metros, permitindo a sele\u00e7\u00e3o da combina\u00e7\u00e3o \u00f3tima de hiperpar\u00e2metros para o modelo.</li> <li>A curva de valida\u00e7\u00e3o geralmente mostra o desempenho do modelo em rela\u00e7\u00e3o a um \u00fanico hiperpar\u00e2metro, mantendo os outros constantes. Isso ajuda a identificar como mudan\u00e7as nos hiperpar\u00e2metros afetam o desempenho do modelo.</li> </ul>"},{"location":"machine_learning/Page/learning_curves/#curva-de-desempenhocurva-de-aprendizado","title":"Curva de Desempenho(curva de aprendizado)","text":"<ul> <li>A curva de desempenho, tamb\u00e9m conhecida como <code>curva de aprendizado</code>, mostra como o desempenho do modelo varia com a quantidade de dados de treinamento.</li> <li>Ela representa a precis\u00e3o ou outra m\u00e9trica de desempenho do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento.</li> <li>A curva de desempenho \u00e9 \u00fatil para entender se o modelo est\u00e1 sofrendo de subajuste (underfitting) ou sobreajuste (overfitting). No subajuste, o desempenho permanece baixo mesmo com mais dados de treinamento, enquanto no sobreajuste, o desempenho no conjunto de treinamento \u00e9 muito melhor do que no conjunto de valida\u00e7\u00e3o.</li> <li>Analisar a curva de desempenho ajuda a decidir se \u00e9 necess\u00e1rio coletar mais dados, ajustar a complexidade do modelo ou melhorar outras t\u00e9cnicas de regulariza\u00e7\u00e3o para otimizar o desempenho do modelo.</li> </ul> <p>Ambas as curvas s\u00e3o ferramentas poderosas para entender e otimizar modelos de machine learning, ajudando a encontrar configura\u00e7\u00f5es ideais de hiperpar\u00e2metros e melhorando a capacidade de generaliza\u00e7\u00e3o do modelo para novos dados.</p>"},{"location":"machine_learning/Page/learning_curves/#scikit-learn-curvas-de-avaliacao-e-aprendizagem","title":"Scikit-learn: Curvas de Avalia\u00e7\u00e3o e Aprendizagem","text":"<p>As fun\u00e7\u00f5es <code>validation_curve</code> e <code>learning_curve</code> do scikit-learn s\u00e3o duas ferramentas importantes para avaliar o desempenho de modelos de machine learning, mas t\u00eam prop\u00f3sitos ligeiramente diferentes. Aqui est\u00e3o as principais diferen\u00e7as entre elas:</p> <p>Objetivo:</p> <p><code>validation_curve:</code> A fun\u00e7\u00e3o validation_curve \u00e9 usada para avaliar como uma \u00fanica hiperpar\u00e2metro afeta o desempenho do modelo. Ela plota o desempenho do modelo em rela\u00e7\u00e3o a diferentes valores de um hiperpar\u00e2metro espec\u00edfico, permitindo que voc\u00ea identifique o valor ideal desse hiperpar\u00e2metro.</p> <p><code>learning_curve:</code> A fun\u00e7\u00e3o learning_curve, por outro lado, \u00e9 usada para avaliar o desempenho do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Ela mostra como o desempenho do modelo varia \u00e0 medida que o tamanho do conjunto de treinamento aumenta, ajudando a entender se o modelo se beneficiaria de mais dados de treinamento.</p> <p>Par\u00e2metros:</p> <p><code>validation_curve:</code> A fun\u00e7\u00e3o validation_curve requer a especifica\u00e7\u00e3o do modelo, o conjunto de treinamento, o conjunto de teste (ou valida\u00e7\u00e3o cruzada) e o hiperpar\u00e2metro que se deseja avaliar.</p> <p><code>learning_curve:</code> A fun\u00e7\u00e3o learning_curve requer a especifica\u00e7\u00e3o do modelo, o conjunto de treinamento e uma m\u00e9trica de avalia\u00e7\u00e3o (como precis\u00e3o, erro ou outra m\u00e9trica de desempenho). Geralmente, ela tamb\u00e9m requer a especifica\u00e7\u00e3o de uma estrat\u00e9gia de valida\u00e7\u00e3o cruzada.</p> <p>Sa\u00edda:</p> <p><code>validation_curve:</code> A sa\u00edda da fun\u00e7\u00e3o validation_curve \u00e9 um gr\u00e1fico que mostra como o desempenho do modelo varia em rela\u00e7\u00e3o aos valores do hiperpar\u00e2metro especificado.</p> <p><code>learning_curve:</code> A sa\u00edda da fun\u00e7\u00e3o learning_curve \u00e9 um gr\u00e1fico que mostra como o desempenho do modelo varia em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Pode mostrar o erro de treinamento e/ou valida\u00e7\u00e3o em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento.</p> <p>Em resumo, enquanto a validation_curve ajuda a otimizar hiperpar\u00e2metros de modelos, a learning_curve fornece insights sobre a capacidade de generaliza\u00e7\u00e3o do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Ambas s\u00e3o ferramentas valiosas para aprimorar modelos de machine learning, mas t\u00eam prop\u00f3sitos distintos.</p>"},{"location":"machine_learning/Page/learning_curves/#curvas-adicionais-de-aprendizado-em-machine-learning","title":"Curvas Adicionais de Aprendizado em Machine Learning","text":"<p>Al\u00e9m das fun\u00e7\u00f5es <code>validation_curve</code> e <code>learning_curve</code>, o scikit-learn oferece outras curvas de aprendizado que fornecem insights adicionais sobre o desempenho e comportamento de modelos de machine learning. Abaixo est\u00e3o algumas dessas curvas adicionais:</p>"},{"location":"machine_learning/Page/learning_curves/#curva-de-aprendizado-incremental","title":"Curva de Aprendizado Incremental","text":"<p>Esta curva mostra como o desempenho do modelo evolui \u00e0 medida que novos exemplos de treinamento s\u00e3o adicionados incrementalmente. \u00c9 \u00fatil para entender como o modelo se comporta com o aumento do tamanho do conjunto de dados de treinamento. </p>"},{"location":"machine_learning/Page/learning_curves/#curva-de-aprendizado-de-convergencia","title":"Curva de Aprendizado de Converg\u00eancia","text":"<p>Esta curva avalia como as medidas de desempenho do modelo (como erro ou precis\u00e3o) mudam ao longo do tempo ou do n\u00famero de itera\u00e7\u00f5es do algoritmo de treinamento. Ajuda a determinar se o modelo est\u00e1 convergindo para uma solu\u00e7\u00e3o est\u00e1vel ou se precisa de mais itera\u00e7\u00f5es para melhorar.</p>"},{"location":"machine_learning/Page/learning_curves/#curva-de-aprendizado-de-regularizacao","title":"Curva de Aprendizado de Regulariza\u00e7\u00e3o","text":"<p>Esta curva mostra como diferentes valores de regulariza\u00e7\u00e3o afetam o desempenho do modelo. \u00c9 \u00fatil para determinar o impacto da regulariza\u00e7\u00e3o nos resultados do modelo e encontrar o melhor valor de regulariza\u00e7\u00e3o para evitar overfitting.</p>"},{"location":"machine_learning/Page/learning_curves/#curva-de-aprendizado-de-aprendizado-ativo","title":"Curva de Aprendizado de Aprendizado Ativo","text":"<p>Esta curva demonstra como o desempenho do modelo melhora \u00e0 medida que o algoritmo de aprendizado ativo seleciona ativamente os exemplos mais informativos para treinamento. \u00c9 \u00fatil para entender como o modelo se beneficia de uma estrat\u00e9gia de aprendizado ativo em compara\u00e7\u00e3o com uma estrat\u00e9gia de aprendizado passivo.</p> <p>Essas curvas adicionais fornecem uma vis\u00e3o mais abrangente do comportamento do modelo durante o treinamento e s\u00e3o \u00fateis para an\u00e1lise detalhada e refinamento de modelos de machine learning.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/","title":"Cross validacion skShuffle","text":"In\u00a0[11]: Copied! <pre>from sklearn.model_selection import ShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n</pre> from sklearn.model_selection import ShuffleSplit from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_iris from sklearn.model_selection import cross_val_score  # Carregar dados de exemplo data = load_iris() X, y = data.data, data.target  # Definir o modelo model = RandomForestClassifier() In\u00a0[12]: Copied! <pre># Definir o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)\n\n# Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit\nscores = cross_val_score(model, X, y, cv=shuffle_split)\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</pre> # Definir o ShuffleSplit shuffle_split = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)  # Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit scores = cross_val_score(model, X, y, cv=shuffle_split)  # Exibir os resultados print(\"Scores de valida\u00e7\u00e3o cruzada:\", scores) print(\"M\u00e9dia dos scores:\", scores.mean()) print(\"Desvio padr\u00e3o dos scores:\", scores.std()) <pre>Scores de valida\u00e7\u00e3o cruzada: [1.         0.96666667 0.96666667 0.93333333]\nM\u00e9dia dos scores: 0.9666666666666668\nDesvio padr\u00e3o dos scores: 0.02357022603955158\n</pre> In\u00a0[13]: Copied! <pre>shuffle_split\n</pre> shuffle_split Out[13]: <pre>ShuffleSplit(n_splits=4, random_state=42, test_size=0.2, train_size=None)</pre> In\u00a0[14]: Copied! <pre># Executar valida\u00e7\u00e3o cruzada\nscores = cross_val_score(model, X, y, cv=4)  # cv=5 define 5 folds\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</pre> # Executar valida\u00e7\u00e3o cruzada scores = cross_val_score(model, X, y, cv=4)  # cv=5 define 5 folds  # Exibir os resultados print(\"Scores de valida\u00e7\u00e3o cruzada:\", scores) print(\"M\u00e9dia dos scores:\", scores.mean()) print(\"Desvio padr\u00e3o dos scores:\", scores.std())  <pre>Scores de valida\u00e7\u00e3o cruzada: [0.97368421 0.94736842 0.94594595 1.        ]\nM\u00e9dia dos scores: 0.9667496443812233\nDesvio padr\u00e3o dos scores: 0.02214779922867332\n</pre> <p>O <code>ShuffleSplit</code> em scikit-learn \u00e9 um gerador de indices de treinamento e teste para valida\u00e7\u00e3o cruzada. Ao contr\u00e1rio de m\u00e9todos que retornam os pr\u00f3prios dados divididos, ShuffleSplit gera \u00edndices que podem ser usados para selecionar subconjuntos de treinamento e teste diretamente dos dados originais.</p> <p>O que ShuffleSplit Retorna</p> <p>O objeto ShuffleSplit n\u00e3o retorna diretamente os dados de treinamento e teste. Em vez disso, ele gera pares de \u00edndices (um para treinamento e outro para teste) que voc\u00ea pode usar para dividir seus dados manualmente.</p> <p>Exemplo de Uso Aqui est\u00e1 um exemplo detalhado de como usar ShuffleSplit e entender o que ele retorna:</p> In\u00a0[23]: Copied! <pre>import pandas as pd\nfrom sklearn.model_selection import ShuffleSplit\nimport numpy as np\n\n# Criar dados de exemplo\ndata = {\n    'feature1': np.arange(5),\n    'feature2': np.arange(5, 10),\n    'label': [0, 1, 0, 1, 0]\n}\ndf = pd.DataFrame(data)\nX = df[['feature1', 'feature2']]\ny = df['label']\n\n# Configurar o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n\n# Mostrar DataFrame e labels\nprint('DataFrame:')\nprint(df)\nprint('Labels:')\nprint(y.values)\n\n# Mostrar \u00edndices gerados\nfor train_index, test_index in shuffle_split.split(X):\n    print('################################')\n    print(\"\u00cdndices de treino:\", train_index)\n    print(\"\u00cdndices de teste:\", test_index)\n    print('-----')\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    print(\"Dados de treino:\")\n    print(X_train)\n    print(y_train.values)\n    print(\"Dados de teste:\")\n    print(X_test)\n    print(y_test.values)\n\n    \n</pre> import pandas as pd from sklearn.model_selection import ShuffleSplit import numpy as np  # Criar dados de exemplo data = {     'feature1': np.arange(5),     'feature2': np.arange(5, 10),     'label': [0, 1, 0, 1, 0] } df = pd.DataFrame(data) X = df[['feature1', 'feature2']] y = df['label']  # Configurar o ShuffleSplit shuffle_split = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)  # Mostrar DataFrame e labels print('DataFrame:') print(df) print('Labels:') print(y.values)  # Mostrar \u00edndices gerados for train_index, test_index in shuffle_split.split(X):     print('################################')     print(\"\u00cdndices de treino:\", train_index)     print(\"\u00cdndices de teste:\", test_index)     print('-----')     X_train, X_test = X.iloc[train_index], X.iloc[test_index]     y_train, y_test = y.iloc[train_index], y.iloc[test_index]     print(\"Dados de treino:\")     print(X_train)     print(y_train.values)     print(\"Dados de teste:\")     print(X_test)     print(y_test.values)        <pre>DataFrame:\n   feature1  feature2  label\n0         0         5      0\n1         1         6      1\n2         2         7      0\n3         3         8      1\n4         4         9      0\nLabels:\n[0 1 0 1 0]\n################################\n\u00cdndices de treino: [4 2 0 3]\n\u00cdndices de teste: [1]\n-----\nDados de treino:\n   feature1  feature2\n4         4         9\n2         2         7\n0         0         5\n3         3         8\n[0 0 0 1]\nDados de teste:\n   feature1  feature2\n1         1         6\n[1]\n################################\n\u00cdndices de treino: [1 2 0 4]\n\u00cdndices de teste: [3]\n-----\nDados de treino:\n   feature1  feature2\n1         1         6\n2         2         7\n0         0         5\n4         4         9\n[1 0 0 0]\nDados de teste:\n   feature1  feature2\n3         3         8\n[1]\n################################\n\u00cdndices de treino: [0 3 4 2]\n\u00cdndices de teste: [1]\n-----\nDados de treino:\n   feature1  feature2\n0         0         5\n3         3         8\n4         4         9\n2         2         7\n[0 1 0 0]\nDados de teste:\n   feature1  feature2\n1         1         6\n[1]\n</pre>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#validacao-cruzada-com-shufflesplit","title":"Valida\u00e7\u00e3o Cruzada com ShuffleSplit\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#entendendo-o-shuffle_split","title":"Entendendo o <code>shuffle_split</code>\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/","title":"Cross validacion skShuffle","text":"<ul> <li>Ferramentas para Cross-Validation</li> <li>Fun\u00e7\u00e3o <code>ShuffleSplit</code><ul> <li>Quando Usar ShuffleSplit</li> </ul> </li> <li>Fun\u00e7\u00e3o <code>cross_val_score</code></li> </ul>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#ferramentas-para-cross-validation","title":"Ferramentas para Cross-Validation","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#funcao-shufflesplit","title":"Fun\u00e7\u00e3o <code>ShuffleSplit</code>","text":"<p>A fun\u00e7\u00e3o ShuffleSplit no pacote scikit-learn \u00e9 uma ferramenta de valida\u00e7\u00e3o cruzada que permite criar divis\u00f5es aleat\u00f3rias dos dados em conjuntos de treinamento e teste. \u00c9 especialmente \u00fatil quando voc\u00ea deseja um controle mais flex\u00edvel sobre o processo de divis\u00e3o dos dados, em compara\u00e7\u00e3o com outras estrat\u00e9gias de valida\u00e7\u00e3o cruzada.</p> <p>Funcionalidades Principais Divis\u00f5es Aleat\u00f3rias: O ShuffleSplit cria divis\u00f5es aleat\u00f3rias dos dados, onde cada divis\u00e3o cont\u00e9m um subconjunto dos dados de treinamento e um subconjunto dos dados de teste. Controle de Tamanho: Voc\u00ea pode especificar o tamanho dos conjuntos de treinamento e teste, permitindo uma personaliza\u00e7\u00e3o fina. Repetibilidade: Voc\u00ea pode definir um seed para o gerador de n\u00fameros aleat\u00f3rios para obter resultados reprodut\u00edveis. Par\u00e2metros Principais n_splits: N\u00famero de reamostragens (divis\u00f5es) a serem geradas. O valor padr\u00e3o \u00e9 10. test_size: Propor\u00e7\u00e3o ou n\u00famero absoluto de amostras no conjunto de teste. Pode ser um float (representando uma propor\u00e7\u00e3o) ou um int (n\u00famero absoluto). train_size: Propor\u00e7\u00e3o ou n\u00famero absoluto de amostras no conjunto de treinamento. Similar ao test_size. random_state: Seed para o gerador de n\u00fameros aleat\u00f3rios para garantir que os resultados sejam reprodut\u00edveis.</p> <p>Exemplo de Uso Aqui est\u00e1 um exemplo de como usar ShuffleSplit:</p> <pre><code>from sklearn.model_selection import ShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n\n# Definir o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\n# Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit\nscores = cross_val_score(model, X, y, cv=shuffle_split)\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</code></pre>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#quando-usar-shufflesplit","title":"Quando Usar ShuffleSplit","text":"<p>Controle Fino: Use ShuffleSplit quando precisar de controle espec\u00edfico sobre o n\u00famero de amostras no conjunto de treinamento e teste. Dados Desbalanceados: Pode ser \u00fatil em conjuntos de dados desbalanceados, onde voc\u00ea quer garantir que cada divis\u00e3o tenha uma propor\u00e7\u00e3o espec\u00edfica de classes.</p> <p>Repetibilidade: \u00datil quando voc\u00ea precisa garantir que as divis\u00f5es sejam as mesmas entre diferentes execu\u00e7\u00f5es, utilizando o par\u00e2metro random_state. Compara\u00e7\u00e3o com Outras T\u00e9cnicas de Valida\u00e7\u00e3o Cruzada K-Fold: Divide os dados em K subconjuntos (folds) de forma sequencial e usa cada fold como conjunto de teste uma vez. ShuffleSplit oferece mais flexibilidade ao permitir divis\u00f5es aleat\u00f3rias repetidas. StratifiedKFold: Similar ao K-Fold, mas preserva a propor\u00e7\u00e3o das classes em cada fold. ShuffleSplit n\u00e3o garante a preserva\u00e7\u00e3o das propor\u00e7\u00f5es de classe por padr\u00e3o, a menos que seja configurado para isso. Em resumo, ShuffleSplit \u00e9 uma ferramenta flex\u00edvel e poderosa para criar divis\u00f5es aleat\u00f3rias dos dados, permitindo uma avalia\u00e7\u00e3o robusta e personalizada do desempenho dos modelos de aprendizado de m\u00e1quina.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validacion_skShuffle/#funcao-cross_val_score","title":"Fun\u00e7\u00e3o <code>cross_val_score</code>","text":"<p>A fun\u00e7\u00e3o cross_val_score \u00e9 uma ferramenta essencial no pacote scikit-learn do Python usada para avaliar a performance de um modelo de aprendizado de m\u00e1quina de forma robusta. Aqui est\u00e1 uma vis\u00e3o geral de suas principais funcionalidades:</p> <p>Valida\u00e7\u00e3o Cruzada: A cross_val_score executa a valida\u00e7\u00e3o cruzada, uma t\u00e9cnica usada para avaliar o desempenho de um modelo de aprendizado de m\u00e1quina. A valida\u00e7\u00e3o cruzada divide o conjunto de dados em v\u00e1rias partes, chamadas de folds. O modelo \u00e9 treinado em alguns desses folds (conjunto de treinamento) e avaliado nos folds restantes (conjunto de teste).</p> <p>Estimativa de Performance: A fun\u00e7\u00e3o calcula a performance do modelo em cada um dos folds e retorna uma lista de scores, que podem ser m\u00e9tricas como acur\u00e1cia, precis\u00e3o, recall, F1-score, entre outras, dependendo do problema e da m\u00e9trica escolhida.</p> <p>Redu\u00e7\u00e3o de Overfitting: Ao avaliar o modelo em diferentes subconjuntos dos dados, a valida\u00e7\u00e3o cruzada fornece uma estimativa mais realista de sua performance e ajuda a detectar overfitting, onde o modelo se ajusta excessivamente aos dados de treinamento.</p> <p>Como Usar Aqui est\u00e1 um exemplo b\u00e1sico de como usar a fun\u00e7\u00e3o cross_val_score:</p> <pre><code>from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n\n# Executar valida\u00e7\u00e3o cruzada\nscores = cross_val_score(model, X, y, cv=5)  # cv=5 define 5 folds\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</code></pre> <p>Par\u00e2metros Importantes estimator: O modelo de aprendizado de m\u00e1quina que voc\u00ea deseja avaliar (ex. RandomForestClassifier()). X: As caracter\u00edsticas dos dados de entrada. y: Os r\u00f3tulos ou targets dos dados de entrada. cv: N\u00famero de folds (divis\u00f5es) para a valida\u00e7\u00e3o cruzada. O valor padr\u00e3o \u00e9 5. scoring: M\u00e9trica de avalia\u00e7\u00e3o a ser utilizada (ex. 'accuracy', 'precision', 'recall', etc.). Se n\u00e3o for especificado, a m\u00e9trica padr\u00e3o do modelo ser\u00e1 usada. Retorno A fun\u00e7\u00e3o retorna um array com os scores obtidos em cada um dos folds. Voc\u00ea pode calcular a m\u00e9dia e o desvio padr\u00e3o desses scores para ter uma no\u00e7\u00e3o da variabilidade e performance geral do modelo.</p> <p>Em resumo, cross_val_score \u00e9 uma fun\u00e7\u00e3o poderosa para realizar a valida\u00e7\u00e3o cruzada e obter uma estimativa confi\u00e1vel do desempenho do modelo em diferentes subconjuntos dos dados, ajudando a assegurar que o modelo n\u00e3o est\u00e1 superajustado aos dados de treinamento.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Cross_validation_pyspark/","title":"Cross validation pyspark","text":"In\u00a0[\u00a0]: Copied! <pre>########################################\n## Title: Spark MLlib Linear Regression Script, with Cross-Validation and Parameter Sweep\n## Language: PySpark\n## Author: Colby T. Ford, Ph.D.\n########################################\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Create initial LinearRegression model\nlr = LinearRegression(labelCol=\"label\", featuresCol=\"features\")\n\n\n# Create ParamGrid for Cross Validation\nlrparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])\n             #  .addGrid(lr.regParam, [0.01, 0.1, 0.5])\n             .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n             #  .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10, 20, 50])\n             #  .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\n\n# Evaluate model\nlrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n\n# Create 5-fold CrossValidator\nlrcv = CrossValidator(estimator = lr,\n                    estimatorParamMaps = lrparamGrid,\n                    evaluator = lrevaluator,\n                    numFolds = 5)\n\n# Run cross validations\nlrcvModel = lrcv.fit(train)\nprint(lrcvModel)\n\n# Get Model Summary Statistics\nlrcvSummary = lrcvModel.bestModel.summary\nprint(\"Coefficient Standard Errors: \" + str(lrcvSummary.coefficientStandardErrors))\nprint(\"P Values: \" + str(lrcvSummary.pValues)) # Last element is the intercept\n\n# Use test set here so we can measure the accuracy of our model on new data\nlrpredictions = lrcvModel.transform(test)\n\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nprint('RMSE:', lrevaluator.evaluate(lrpredictions))\n</pre> ######################################## ## Title: Spark MLlib Linear Regression Script, with Cross-Validation and Parameter Sweep ## Language: PySpark ## Author: Colby T. Ford, Ph.D. ########################################  from pyspark.ml.regression import LinearRegression from pyspark.ml.tuning import ParamGridBuilder, CrossValidator from pyspark.ml.evaluation import RegressionEvaluator  # Create initial LinearRegression model lr = LinearRegression(labelCol=\"label\", featuresCol=\"features\")   # Create ParamGrid for Cross Validation lrparamGrid = (ParamGridBuilder()              .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])              #  .addGrid(lr.regParam, [0.01, 0.1, 0.5])              .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])              #  .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])              .addGrid(lr.maxIter, [1, 5, 10, 20, 50])              #  .addGrid(lr.maxIter, [1, 5, 10])              .build())  # Evaluate model lrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")  # Create 5-fold CrossValidator lrcv = CrossValidator(estimator = lr,                     estimatorParamMaps = lrparamGrid,                     evaluator = lrevaluator,                     numFolds = 5)  # Run cross validations lrcvModel = lrcv.fit(train) print(lrcvModel)  # Get Model Summary Statistics lrcvSummary = lrcvModel.bestModel.summary print(\"Coefficient Standard Errors: \" + str(lrcvSummary.coefficientStandardErrors)) print(\"P Values: \" + str(lrcvSummary.pValues)) # Last element is the intercept  # Use test set here so we can measure the accuracy of our model on new data lrpredictions = lrcvModel.transform(test)  # cvModel uses the best model found from the Cross Validation # Evaluate best model print('RMSE:', lrevaluator.evaluate(lrpredictions))"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/","title":"Titanic data","text":"In\u00a0[1]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>#-----------------------------------------------------------\n# Step 01: load data using panda\n#-----------------------------------------------------------\ntrain_df = pd.read_csv('Bases/Titanic_train.csv')  # train set\ntest_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set\ncombine  = [train_df, test_df]\n</pre> #----------------------------------------------------------- # Step 01: load data using panda #----------------------------------------------------------- train_df = pd.read_csv('Bases/Titanic_train.csv')  # train set test_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set combine  = [train_df, test_df] In\u00a0[3]: Copied! <pre>#-----------------------------------------------------------\n# Step 02: Acquire and clean data\n#-----------------------------------------------------------\ntrain_df.head(5)\n</pre> #----------------------------------------------------------- # Step 02: Acquire and clean data #----------------------------------------------------------- train_df.head(5) Out[3]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S In\u00a0[4]: Copied! <pre>train_df.info()\n</pre> train_df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n</pre> In\u00a0[5]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[5]: PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 In\u00a0[6]: Copied! <pre>train_df.describe(include=['O'])\n</pre> train_df.describe(include=['O']) Out[6]: Name Sex Ticket Cabin Embarked count 891 891 891 204 889 unique 891 2 681 147 3 top Braund, Mr. Owen Harris male 347082 B96 B98 S freq 1 577 7 4 644 <p>Training data statistics:</p> <ul> <li>891 training samples</li> <li>Age, Cabin, Embarked: incomplete data</li> <li>Data type:<ul> <li>object: Name, Sex, Ticket, Cabin, Embarked</li> <li>int64: PassengerId, Survived, Pclass, SibSp, Parch</li> <li>float64: Age, Fare</li> </ul> </li> <li>Survive rate: 0.383838</li> </ul> <p>Estat\u00edsticas dos dados de treinamento:</p> <ul> <li>891 amostras de treinamento</li> <li>Idade, Cabine, Embarque: dados incompletos</li> <li>Tipo de dados:<ul> <li>objeto: Nome, Sexo, Bilhete, Cabine, Embarque</li> <li>int64: PassengerId, Sobreviveu, Classe, SibSp, Parch</li> <li>float64: Idade, Tarifa</li> <li>Taxa de sobreviv\u00eancia: 0.383838</li> </ul> </li> </ul> In\u00a0[7]: Copied! <pre> # remove Features: Ticket, Cabin\n#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n#test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1)\n#combine  = [train_df, test_df]\n# aplica a logica para ambos os datasets\nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].fillna('U')\n    dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\n    \nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0, \n                                            'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)\n    \ntrain_df.head()\n    \n</pre>  # remove Features: Ticket, Cabin #train_df = train_df.drop(['Ticket', 'Cabin'], axis=1) #test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1) #combine  = [train_df, test_df] # aplica a logica para ambos os datasets for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].fillna('U')     dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)      for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0,                                              'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)      train_df.head()      Out[7]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 1 S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 0 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 1 S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 0 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 1 S In\u00a0[8]: Copied! <pre>train_df = train_df.drop(['Ticket'], axis=1)\ntest_df  = test_df.drop(['Ticket'], axis=1)\ncombine  = [train_df, test_df]\n\n\n# survival rate distribtion as a function of Pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> train_df = train_df.drop(['Ticket'], axis=1) test_df  = test_df.drop(['Ticket'], axis=1) combine  = [train_df, test_df]   # survival rate distribtion as a function of Pclass train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[8]: Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 In\u00a0[9]: Copied! <pre># obtain Title from name (Mr, Mrs, Miss etc)\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')\n    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')\n    dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'\n    dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'\n\n#: count survived rate for different titles\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> # obtain Title from name (Mr, Mrs, Miss etc) for dataset in combine:     dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)   for dataset in combine:     dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')     dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')     dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')     dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')     dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')     dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'     dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'  #: count survived rate for different titles train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[9]: Title Survived 3 Mrs 0.795276 1 Miss 0.702703 5 Royalty 0.600000 0 Master 0.575000 4 Officer 0.181818 2 Mr 0.158700 In\u00a0[10]: Copied! <pre>train_df.head(5)\n</pre> train_df.head(5) Out[10]: PassengerId Survived Pclass Name Sex Age SibSp Parch Fare Cabin Embarked Title 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 7.2500 1 S Mr 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 71.2833 0 C Mrs 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 7.9250 1 S Miss 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 53.1000 0 S Mrs 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 8.0500 1 S Mr In\u00a0[11]: Copied! <pre># Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...)\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\n# if age &lt; 16, set 'Sex' to Child\nfor dataset in combine:\n    dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'\n    \n# Covert 'Sex' to numbers (female:1, male:2)\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...) title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6} for dataset in combine:     dataset['Title'] = dataset['Title'].map(title_mapping)     dataset['Title'] = dataset['Title'].fillna(0)  # Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data train_df = train_df.drop(['Name', 'PassengerId'], axis=1) test_df = test_df.drop(['Name'], axis=1) combine = [train_df, test_df]  # if age &lt; 16, set 'Sex' to Child for dataset in combine:     dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'      # Covert 'Sex' to numbers (female:1, male:2) for dataset in combine:     dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)  train_df.head() Out[11]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 22.0 1 0 7.2500 1 S 1 1 1 1 1 38.0 1 0 71.2833 0 C 3 2 1 3 1 26.0 0 0 7.9250 1 S 2 3 1 1 1 35.0 1 0 53.1000 0 S 3 4 0 3 0 35.0 0 0 8.0500 1 S 1 In\u00a0[12]: Copied! <pre># Age distribution for different values of Pclass and gender\n#grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n#grid.map(plt.hist, 'Age', bins=20)\n#grid.add_legend()\n</pre> # Age distribution for different values of Pclass and gender #grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6) #grid.map(plt.hist, 'Age', bins=20) #grid.add_legend() In\u00a0[13]: Copied! <pre># Guess age values using median values for age across set of Pclass and gender frature combinations\nfor dataset in combine:\n    dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)\n\n# create Age bands and determine correlations with Survived\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> # Guess age values using median values for age across set of Pclass and gender frature combinations for dataset in combine:     dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)  # create Age bands and determine correlations with Survived train_df['AgeBand'] = pd.cut(train_df['Age'], 5) train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True) <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\4175406704.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> Out[13]: AgeBand Survived 0 (-0.08, 16.0] 0.550000 1 (16.0, 32.0] 0.339506 2 (32.0, 48.0] 0.404444 3 (48.0, 64.0] 0.434783 4 (64.0, 80.0] 0.090909 In\u00a0[14]: Copied! <pre>for dataset in combine:\n    dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> for dataset in combine:     dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0     dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1     dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2     dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3     dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4  train_df = train_df.drop(['AgeBand'], axis=1) combine = [train_df, test_df] train_df.head() Out[14]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 1 1 0 7.2500 1 S 1 1 1 1 1 2 1 0 71.2833 0 C 3 2 1 3 1 1 0 0 7.9250 1 S 2 3 1 1 1 2 1 0 53.1000 0 S 3 4 0 3 0 2 0 0 8.0500 1 S 1 In\u00a0[15]: Copied! <pre># Create family size from 'sibsq + parch + 1'\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\n#create another feature called IsAlone\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n    dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2\n\ntrain_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()\n\n#drop Parch, SibSp, and FamilySize features in favor of IsAlone\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # Create family size from 'sibsq + parch + 1' for dataset in combine:     dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1  train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)  #create another feature called IsAlone for dataset in combine:     dataset['IsAlone'] = 0     dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1     dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2  train_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()  #drop Parch, SibSp, and FamilySize features in favor of IsAlone train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) combine = [train_df, test_df] train_df.head() Out[15]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone 0 0 3 0 1 7.2500 1 S 1 0 1 1 1 1 2 71.2833 0 C 3 0 2 1 3 1 1 7.9250 1 S 2 1 3 1 1 1 2 53.1000 0 S 3 0 4 0 3 0 2 8.0500 1 S 1 1 In\u00a0[16]: Copied! <pre># Create an artfical feature combinbing PClass and Age.\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()\n</pre> # Create an artfical feature combinbing PClass and Age. for dataset in combine:     dataset['Age*Class'] = dataset.Age * dataset.Pclass  train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head() Out[16]: Age*Class Age Pclass 0 3 1 3 1 2 2 1 2 3 1 3 3 2 2 1 4 6 2 3 In\u00a0[17]: Copied! <pre># fill the missing values of Embarked feature with the most common occurance\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # fill the missing values of Embarked feature with the most common occurance freq_port = train_df.Embarked.dropna().mode()[0] for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].fillna(freq_port) train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)  for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)  train_df.head() Out[17]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 7.2500 1 0 1 0 3 1 1 1 1 2 71.2833 0 1 3 0 2 2 1 3 1 1 7.9250 1 0 2 1 3 3 1 1 1 2 53.1000 0 0 3 0 2 4 0 3 0 2 8.0500 1 0 1 1 6 In\u00a0[18]: Copied! <pre># fill the missing values of Fare\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n\n# Create FareBand\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n\n# Convert the Fare feature to ordinal values based on the FareBand\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # fill the missing values of Fare test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)  # Create FareBand train_df['FareBand'] = pd.qcut(train_df['Fare'], 4) train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)  # Convert the Fare feature to ordinal values based on the FareBand for dataset in combine:     dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0     dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1     dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2     dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3     dataset['Fare'] = dataset['Fare'].astype(int)  train_df = train_df.drop(['FareBand'], axis=1) combine = [train_df, test_df] train_df.head() <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\nC:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n</pre> Out[18]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 0 1 0 1 0 3 1 1 1 1 2 3 0 1 3 0 2 2 1 3 1 1 1 1 0 2 1 3 3 1 1 1 2 3 0 0 3 0 2 4 0 3 0 2 1 1 0 1 1 6 In\u00a0[19]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[19]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 mean 0.383838 2.308642 0.490460 1.332211 1.505051 0.771044 0.361392 1.711560 0.741863 2.785634 std 0.486592 0.836071 0.660838 0.822210 1.118148 0.420397 0.635673 1.036888 0.575364 1.755907 min 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 25% 0.000000 2.000000 0.000000 1.000000 0.500000 1.000000 0.000000 1.000000 0.000000 2.000000 50% 0.000000 3.000000 0.000000 1.000000 2.000000 1.000000 0.000000 1.000000 1.000000 3.000000 75% 1.000000 3.000000 1.000000 2.000000 2.000000 1.000000 1.000000 2.000000 1.000000 3.000000 max 1.000000 3.000000 2.000000 4.000000 3.000000 1.000000 2.000000 6.000000 2.000000 12.000000 In\u00a0[20]: Copied! <pre>#correlation matrix\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(train_df.corr(), vmax=.8, square=True);\n</pre> #correlation matrix f, ax = plt.subplots(figsize=(12, 9)) sns.heatmap(train_df.corr(), vmax=.8, square=True); In\u00a0[21]: Copied! <pre>train_df.to_csv('Bases_tratadas/Titanic_train_df.csv')\ntest_df.to_csv('Bases_tratadas/Titanic_test_df.csv')\n</pre> train_df.to_csv('Bases_tratadas/Titanic_train_df.csv') test_df.to_csv('Bases_tratadas/Titanic_test_df.csv')"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/#titanic-data","title":"Titanic data\u00b6","text":"<p>Tarefa: Prever a sobreviv\u00eancia de um passageiro(a) dado sua classe de ticket, nome, g\u00eanero, idade, n\u00famero de irm\u00e3os/c\u00f4njuges a bordo, n\u00famero de pais/filhos a bordo, n\u00famero do ticket, n\u00famero da cabine e Porto de embarque.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/#parte-i-analise-exploratoria-de-dados","title":"Parte I: An\u00e1lise Explorat\u00f3ria de Dados\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/#step-1-carrega-base-de-dados","title":"Step 1: Carrega Base de Dados\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/#step-2-limpeza-dos-dados","title":"Step 2: Limpeza dos Dados\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_1/#salvando-as-bases-tratadas","title":"Salvando as bases tratadas\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/","title":"Titanic data","text":"In\u00a0[3]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#Learning curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import validation_curve\n\n\n# Essa n\u00e3o \u00e9 uma boa pratica minha\n# No futuro seria interessante removre para avaliar os avisos\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\n# Suprimir os avisos de converg\u00eancia\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\n\n%load_ext autoreload\n%autoreload 2\n\nimport utils.learning_curve as curve\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt  #machine learning from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC, LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.linear_model import Perceptron from sklearn.linear_model import SGDClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.model_selection import cross_val_score from sklearn.ensemble import VotingClassifier from sklearn.model_selection import GridSearchCV  #Learning curve from sklearn.model_selection import learning_curve from sklearn.model_selection import ShuffleSplit from sklearn.model_selection import cross_val_predict from sklearn.model_selection import validation_curve   # Essa n\u00e3o \u00e9 uma boa pratica minha # No futuro seria interessante removre para avaliar os avisos import warnings from sklearn.exceptions import ConvergenceWarning  # Suprimir os avisos de converg\u00eancia warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)   %load_ext autoreload %autoreload 2  import utils.learning_curve as curve <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[5]: Copied! <pre>train_df = pd.read_csv('Results/Titanic_train_df.csv')\ntest_df = pd.read_csv('Results/Titanic_test_df.csv')\n</pre> train_df = pd.read_csv('Results/Titanic_train_df.csv') test_df = pd.read_csv('Results/Titanic_test_df.csv') In\u00a0[6]: Copied! <pre>#------------------------------------------------------------------\n# Step 03: Learning model\n#------------------------------------------------------------------\n\nX_data = train_df.drop(\"Survived\", axis=1)          # data: Features\nY_data = train_df[\"Survived\"]                       # data: Labels\nX_test_kaggle  = test_df.drop(\"PassengerId\", axis=1).copy() # test data (kaggle)\n\n# Cria varios conjuntos de Treino e Teste\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n</pre> #------------------------------------------------------------------ # Step 03: Learning model #------------------------------------------------------------------  X_data = train_df.drop(\"Survived\", axis=1)          # data: Features Y_data = train_df[\"Survived\"]                       # data: Labels X_test_kaggle  = test_df.drop(\"PassengerId\", axis=1).copy() # test data (kaggle)  # Cria varios conjuntos de Treino e Teste cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0) <p>O <code>ShuffleSplit</code> \u00e9 uma classe no m\u00f3dulo model_selection do scikit-learn que gera divis\u00f5es aleat\u00f3rias dos dados em conjuntos de treinamento e teste.</p> <p><code>n_splits=100:</code> O n\u00famero de divis\u00f5es (ou splits) que ser\u00e3o criadas. Neste caso, 100 diferentes divis\u00f5es ser\u00e3o geradas.</p> <p><code>test_size=0.2:</code> A propor\u00e7\u00e3o do conjunto de dados que ser\u00e1 usada como conjunto de teste. Aqui, 20% dos dados ser\u00e3o reservados para o conjunto de teste em cada split.</p> <p><code>random_state=0: </code>Um valor de semente para o gerador de n\u00fameros aleat\u00f3rios. Isso garante que os splits gerados sejam reprodut\u00edveis; ou seja, se voc\u00ea executar o c\u00f3digo novamente com o mesmo random_state, voc\u00ea obter\u00e1 exatamente os mesmos splits.</p> <p>O <code>ShuffleSplit</code> divide aleatoriamente os dados em conjuntos de treinamento e teste mantendo a propor\u00e7\u00e3o especificada. \u00c9 particularmente \u00fatil quando voc\u00ea quer avaliar a performance de um modelo em v\u00e1rias divis\u00f5es diferentes dos dados, para obter uma estimativa mais robusta da sua performance.</p> In\u00a0[7]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[8]: Copied! <pre>#grid search: Logistic Regression\nmodel = LogisticRegression()\nif search_param==1:\n    param_range = np.logspace(-6, 5, 12)\n    param_grid = dict(C=param_range)\n    curve.grid_search_model(X_data, Y_data, model, param_grid, cv)\n# Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0}\n</pre> #grid search: Logistic Regression model = LogisticRegression() if search_param==1:     param_range = np.logspace(-6, 5, 12)     param_grid = dict(C=param_range)     curve.grid_search_model(X_data, Y_data, model, param_grid, cv) # Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0} <pre>Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0}\n</pre> In\u00a0[9]: Copied! <pre>#Validation Curve: Logistic Regression\nif plot_vc == 1:\n    param_range = np.logspace(-6, 3, 10)\n    param_name=\"C\"\n    ylim=[0.55, 0.9]\n    curve.validation_curve_model(X_data, Y_data, model, \"C\", param_range, cv, ylim)\n</pre> #Validation Curve: Logistic Regression if plot_vc == 1:     param_range = np.logspace(-6, 3, 10)     param_name=\"C\"     ylim=[0.55, 0.9]     curve.validation_curve_model(X_data, Y_data, model, \"C\", param_range, cv, ylim) In\u00a0[10]: Copied! <pre>#learn curve\nlogreg  = LogisticRegression(C=1000)\n\nif plot_lc==1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, logreg, cv, train_size)\n</pre> #learn curve logreg  = LogisticRegression(C=1000)  if plot_lc==1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, logreg, cv, train_size) In\u00a0[11]: Copied! <pre># Logistic Regression \nacc_log = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_Logistic.csv')\n</pre> # Logistic Regression  acc_log = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_Logistic.csv') In\u00a0[12]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[13]: Copied! <pre>#grid search: SVM\nif search_param==1:\n    param_range = np.linspace(0.5, 5, 9)\n    param_grid = dict(C=param_range)\n\n    curve.grid_search_model(X_data, Y_data, SVC(), param_grid, cv)\n# Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5}\n</pre> #grid search: SVM if search_param==1:     param_range = np.linspace(0.5, 5, 9)     param_grid = dict(C=param_range)      curve.grid_search_model(X_data, Y_data, SVC(), param_grid, cv) # Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5} <pre>Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5}\n</pre> In\u00a0[14]: Copied! <pre>#Validation Curve: SVC\nif plot_vc == 1:\n    param_range = np.linspace(0.1, 10, 10)\n    param_name=\"C\"\n    ylim=[0.78, 0.90]\n    curve.validation_curve_model(X_data, Y_data, SVC(), \"C\", param_range, cv, ylim, log=False)\n</pre> #Validation Curve: SVC if plot_vc == 1:     param_range = np.linspace(0.1, 10, 10)     param_name=\"C\"     ylim=[0.78, 0.90]     curve.validation_curve_model(X_data, Y_data, SVC(), \"C\", param_range, cv, ylim, log=False) In\u00a0[15]: Copied! <pre>#learn curve: SVC\nsvc = SVC(C=1, probability=True)\n\nif plot_lc == 1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, svc, cv, train_size)\n</pre> #learn curve: SVC svc = SVC(C=1, probability=True)  if plot_lc == 1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, svc, cv, train_size) In\u00a0[16]: Copied! <pre># Support Vector Machines\nacc_svc = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_SVM.csv')\n</pre> # Support Vector Machines acc_svc = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_SVM.csv') In\u00a0[17]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[18]: Copied! <pre>#grid search: KNN\nif search_param==1:\n    param_range = (np.linspace(1, 10, 10)).astype(int)\n    param_grid = dict(n_neighbors=param_range)\n\n    curve.grid_search_model(X_data, Y_data, KNeighborsClassifier(), param_grid, cv)\n# Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2}\n</pre> #grid search: KNN if search_param==1:     param_range = (np.linspace(1, 10, 10)).astype(int)     param_grid = dict(n_neighbors=param_range)      curve.grid_search_model(X_data, Y_data, KNeighborsClassifier(), param_grid, cv) # Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2} <pre>Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2}\n</pre> In\u00a0[19]: Copied! <pre>#Validation Curve: KNN\nif plot_vc==1:\n    param_range = np.linspace(2, 20, 10).astype(int)\n    param_name=\"n_neighbors\"\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, KNeighborsClassifier(), \"n_neighbors\", param_range, cv, ylim, log=False)\n</pre> #Validation Curve: KNN if plot_vc==1:     param_range = np.linspace(2, 20, 10).astype(int)     param_name=\"n_neighbors\"     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, KNeighborsClassifier(), \"n_neighbors\", param_range, cv, ylim, log=False) In\u00a0[20]: Copied! <pre>#learn curve: KNN\nknn = KNeighborsClassifier(n_neighbors = 10)\n\nif plot_lc==1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, knn, cv, train_size)\n</pre> #learn curve: KNN knn = KNeighborsClassifier(n_neighbors = 10)  if plot_lc==1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, knn, cv, train_size) In\u00a0[21]: Copied! <pre># KNN\nacc_knn = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_KNN.csv')\n</pre> # KNN acc_knn = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_KNN.csv') In\u00a0[22]: Copied! <pre># Lista de modelos e nomes de arquivo de submiss\u00e3o correspondentes\nmodels = [\n    (GaussianNB(), 'Gaussian_Naive_Bayes'),\n    (Perceptron(), 'Perceptron'),\n    (LinearSVC(), 'Linear_SVC'),\n    (SGDClassifier(), 'Stochastic_Gradient_Descent'),\n    (DecisionTreeClassifier(), 'Decision_Tree')\n]\n\ndic_acc = {}\n# Iterar sobre os modelos\nfor model, filename in models:\n    acc = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_{filename}.csv'\n    )\n    dic_acc[filename] = acc\n    print(f'Accuracy for {filename}')\n</pre> # Lista de modelos e nomes de arquivo de submiss\u00e3o correspondentes models = [     (GaussianNB(), 'Gaussian_Naive_Bayes'),     (Perceptron(), 'Perceptron'),     (LinearSVC(), 'Linear_SVC'),     (SGDClassifier(), 'Stochastic_Gradient_Descent'),     (DecisionTreeClassifier(), 'Decision_Tree') ]  dic_acc = {} # Iterar sobre os modelos for model, filename in models:     acc = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_{filename}.csv'     )     dic_acc[filename] = acc     print(f'Accuracy for {filename}')  <pre>Accuracy for Gaussian_Naive_Bayes\nAccuracy for Perceptron\nAccuracy for Linear_SVC\nAccuracy for Stochastic_Gradient_Descent\nAccuracy for Decision_Tree\n</pre> In\u00a0[23]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[24]: Copied! <pre>#grid search: KNN (This step is very slow)\nparam_range = (np.linspace(10, 110, 10)).astype(int)\nparam_leaf = (np.linspace(1, 2, 2)).astype(int)\nparam_grid = {'n_estimators':param_range, 'min_samples_leaf':param_leaf}\n\ncurve.grid_search_model(X_data, Y_data, RandomForestClassifier(), param_grid, cv)\n# Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10}\n</pre> #grid search: KNN (This step is very slow) param_range = (np.linspace(10, 110, 10)).astype(int) param_leaf = (np.linspace(1, 2, 2)).astype(int) param_grid = {'n_estimators':param_range, 'min_samples_leaf':param_leaf}  curve.grid_search_model(X_data, Y_data, RandomForestClassifier(), param_grid, cv) # Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10} <pre>Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10}\n</pre> In\u00a0[25]: Copied! <pre>if plot_vc==1:\n    param_range = np.linspace(10, 110, 10).astype(int)\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(min_samples_leaf=12), \"n_estimators\", param_range, cv, ylim, log=False)\n</pre> if plot_vc==1:     param_range = np.linspace(10, 110, 10).astype(int)     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(min_samples_leaf=12), \"n_estimators\", param_range, cv, ylim, log=False) In\u00a0[26]: Copied! <pre>if plot_vc==1:\n    param_range = np.linspace(1, 21, 10).astype(int)\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(n_estimators=80), \"min_samples_leaf\", param_range, cv, ylim, log=False)\n</pre> if plot_vc==1:     param_range = np.linspace(1, 21, 10).astype(int)     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(n_estimators=80), \"min_samples_leaf\", param_range, cv, ylim, log=False) In\u00a0[27]: Copied! <pre># Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=80, random_state =0, min_samples_leaf = 12)\nacc_random_forest = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_random_forest.csv'\n    )\n</pre> # Random Forest random_forest = RandomForestClassifier(n_estimators=80, random_state =0, min_samples_leaf = 12) acc_random_forest = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_random_forest.csv'     ) In\u00a0[28]: Copied! <pre>#ensemble votring\nensemble_voting = VotingClassifier(estimators=[('lg', logreg), ('sv', svc), ('rf', random_forest),('kn',knn)], voting='soft')\nacc_ensemble_voting = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_ensemble_voting.csv'\n    )\n</pre> #ensemble votring ensemble_voting = VotingClassifier(estimators=[('lg', logreg), ('sv', svc), ('rf', random_forest),('kn',knn)], voting='soft') acc_ensemble_voting = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_ensemble_voting.csv'     ) In\u00a0[29]: Copied! <pre>dic_acc.keys()\n</pre> dic_acc.keys() Out[29]: <pre>dict_keys(['Gaussian_Naive_Bayes', 'Perceptron', 'Linear_SVC', 'Stochastic_Gradient_Descent', 'Decision_Tree'])</pre> In\u00a0[30]: Copied! <pre>acc_gaussian = dic_acc['Gaussian_Naive_Bayes']\nacc_perceptron = dic_acc['Perceptron']\nacc_sgd = dic_acc['Stochastic_Gradient_Descent']\nacc_linear_svc = dic_acc['Linear_SVC']\nacc_decision_tree = dic_acc['Decision_Tree']\n</pre> acc_gaussian = dic_acc['Gaussian_Naive_Bayes'] acc_perceptron = dic_acc['Perceptron'] acc_sgd = dic_acc['Stochastic_Gradient_Descent'] acc_linear_svc = dic_acc['Linear_SVC'] acc_decision_tree = dic_acc['Decision_Tree'] In\u00a0[31]: Copied! <pre>models = pd.DataFrame(\n    {\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Random Forest', \n              'Naive Bayes', 'Perceptron','Stochastic Gradient Decent', 'Linear SVC',\n              'Decision Tree', 'ensemble_voting'],\n    'KFoldScore': [acc_svc.mean(), acc_knn.mean(), acc_log.mean(), acc_random_forest.mean(), \n                acc_gaussian.mean(), acc_perceptron.mean(), acc_sgd.mean(), acc_linear_svc.mean(), \n                acc_decision_tree.mean(), acc_ensemble_voting.mean()],\n    'Std': [acc_svc.std(), acc_knn.std(), acc_log.std(), acc_random_forest.std(), \n            acc_gaussian.std(), acc_perceptron.std(), acc_sgd.std(), acc_linear_svc.std(), \n            acc_decision_tree.std(), acc_ensemble_voting.std()]})\n\nmodels.sort_values(by='KFoldScore', ascending=False)\n</pre> models = pd.DataFrame(     {     'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Random Forest',                'Naive Bayes', 'Perceptron','Stochastic Gradient Decent', 'Linear SVC',               'Decision Tree', 'ensemble_voting'],     'KFoldScore': [acc_svc.mean(), acc_knn.mean(), acc_log.mean(), acc_random_forest.mean(),                  acc_gaussian.mean(), acc_perceptron.mean(), acc_sgd.mean(), acc_linear_svc.mean(),                  acc_decision_tree.mean(), acc_ensemble_voting.mean()],     'Std': [acc_svc.std(), acc_knn.std(), acc_log.std(), acc_random_forest.std(),              acc_gaussian.std(), acc_perceptron.std(), acc_sgd.std(), acc_linear_svc.std(),              acc_decision_tree.std(), acc_ensemble_voting.std()]})  models.sort_values(by='KFoldScore', ascending=False) Out[31]: Model KFoldScore Std 7 Linear SVC 0.802961 0.029316 0 Support Vector Machines 0.790559 0.029808 1 KNN 0.790559 0.029808 2 Logistic Regression 0.790559 0.029808 8 Decision Tree 0.747486 0.036634 9 ensemble_voting 0.747486 0.035394 3 Random Forest 0.746927 0.036638 4 Naive Bayes 0.746816 0.032111 6 Stochastic Gradient Decent 0.562291 0.112604 5 Perceptron 0.542961 0.121304"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#titanic-data","title":"Titanic data\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#part-ii-learning-model","title":"Part II : Learning Model\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#logistic-regression","title":"Logistic Regression\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#support-vector-machines","title":"Support Vector Machines\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#knn","title":"KNN\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#predictions-list","title":"Predictions List\u00b6","text":"<ul> <li>Naive Bayes</li> <li>Perceptron</li> <li>Linear SVC</li> <li>Stochastic Gradient Descent</li> <li>Decision Tree\u00b6</li> </ul>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#random-forest","title":"Random Forest\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Learning_curve_2/#ensemble-votring","title":"Ensemble votring\u00b6","text":""},{"location":"machine_learning/_Notebooks_teoria_aplicada/Transformacoes/","title":"Transformacoes","text":"In\u00a0[22]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as plt\nimport matplotlib.pyplot as plt\n</pre> import numpy as np import pandas as pd import seaborn as sns import matplotlib as plt import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre>diamonds = sns.load_dataset(\"diamonds\")\ndiamonds.head()\n</pre> diamonds = sns.load_dataset(\"diamonds\") diamonds.head() Out[2]: carat cut color clarity depth table price x y z 0 0.23 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 1 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 2 0.23 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 3 0.29 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 4 0.31 Good J SI2 63.3 58.0 335 4.34 4.35 2.75 In\u00a0[3]: Copied! <pre>diamonds.hist(figsize=(16, 16))\n</pre> diamonds.hist(figsize=(16, 16)) Out[3]: <pre>array([[&lt;Axes: title={'center': 'carat'}&gt;,\n        &lt;Axes: title={'center': 'depth'}&gt;,\n        &lt;Axes: title={'center': 'table'}&gt;],\n       [&lt;Axes: title={'center': 'price'}&gt;, &lt;Axes: title={'center': 'x'}&gt;,\n        &lt;Axes: title={'center': 'y'}&gt;],\n       [&lt;Axes: title={'center': 'z'}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]], dtype=object)</pre> In\u00a0[9]: Copied! <pre>diamonds['price_log'] = np.log(diamonds['price'])\ndiamonds['carat_log'] = np.log(diamonds['carat'])\n</pre> diamonds['price_log'] = np.log(diamonds['price']) diamonds['carat_log'] = np.log(diamonds['carat']) In\u00a0[20]: Copied! <pre>f, axs = plt.subplots(2, 2, figsize=(8, 4), gridspec_kw=dict(width_ratios=[8, 6]))\n# Transforme axs em uma lista unidimensional\naxs = axs.flatten()\nsns.histplot(data=diamonds, x=\"price\", ax=axs[0])\nsns.histplot(data=diamonds, x=\"price_log\", ax=axs[1])\nsns.histplot(data=diamonds, x=\"carat\", ax=axs[2])\nsns.histplot(data=diamonds, x=\"carat_log\", ax=axs[3])\nf.tight_layout()\n\n\n# Calcule a assimetria\nskewness_price = diamonds[\"price\"].skew()\nskewness_price_log = diamonds[\"price_log\"].skew()\nskewness_carat = diamonds[\"carat\"].skew()\nskewness_carat_log = diamonds[\"carat_log\"].skew()\n# Atualize os t\u00edtulos dos gr\u00e1ficos\naxs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\")\naxs[1].set_title(f\"Assimetria (price_log): {skewness_price_log:.2f}\")\naxs[2].set_title(f\"Assimetria (carat): {skewness_carat:.2f}\")\naxs[3].set_title(f\"Assimetria (carat_log): {skewness_carat_log:.2f}\")\n\nplt.show()\n</pre> f, axs = plt.subplots(2, 2, figsize=(8, 4), gridspec_kw=dict(width_ratios=[8, 6])) # Transforme axs em uma lista unidimensional axs = axs.flatten() sns.histplot(data=diamonds, x=\"price\", ax=axs[0]) sns.histplot(data=diamonds, x=\"price_log\", ax=axs[1]) sns.histplot(data=diamonds, x=\"carat\", ax=axs[2]) sns.histplot(data=diamonds, x=\"carat_log\", ax=axs[3]) f.tight_layout()   # Calcule a assimetria skewness_price = diamonds[\"price\"].skew() skewness_price_log = diamonds[\"price_log\"].skew() skewness_carat = diamonds[\"carat\"].skew() skewness_carat_log = diamonds[\"carat_log\"].skew() # Atualize os t\u00edtulos dos gr\u00e1ficos axs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\") axs[1].set_title(f\"Assimetria (price_log): {skewness_price_log:.2f}\") axs[2].set_title(f\"Assimetria (carat): {skewness_carat:.2f}\") axs[3].set_title(f\"Assimetria (carat_log): {skewness_carat_log:.2f}\")  plt.show()  In\u00a0[32]: Copied! <pre>df = pd.DataFrame([1, 10, 20, 25, 30, 40, 100, 110, 200, 300, 500, 800, 1000, 1050, 2000, 10000, 500000], columns=['price'])\ndf['price_log_e'] = np.log(df['price'])\ndf['price_log10'] = np.log10(df['price'])\ndf['price_log2'] = np.log2(df['price'])\n# Exibindo as primeiras linhas do DataFrame\ndf\n</pre> df = pd.DataFrame([1, 10, 20, 25, 30, 40, 100, 110, 200, 300, 500, 800, 1000, 1050, 2000, 10000, 500000], columns=['price']) df['price_log_e'] = np.log(df['price']) df['price_log10'] = np.log10(df['price']) df['price_log2'] = np.log2(df['price']) # Exibindo as primeiras linhas do DataFrame df Out[32]: price price_log_e price_log10 price_log2 0 1 0.000000 0.000000 0.000000 1 10 2.302585 1.000000 3.321928 2 20 2.995732 1.301030 4.321928 3 25 3.218876 1.397940 4.643856 4 30 3.401197 1.477121 4.906891 5 40 3.688879 1.602060 5.321928 6 100 4.605170 2.000000 6.643856 7 110 4.700480 2.041393 6.781360 8 200 5.298317 2.301030 7.643856 9 300 5.703782 2.477121 8.228819 10 500 6.214608 2.698970 8.965784 11 800 6.684612 2.903090 9.643856 12 1000 6.907755 3.000000 9.965784 13 1050 6.956545 3.021189 10.036174 14 2000 7.600902 3.301030 10.965784 15 10000 9.210340 4.000000 13.287712 16 500000 13.122363 5.698970 18.931569 In\u00a0[36]: Copied! <pre>f, axs = plt.subplots(2, 2, figsize=(8, 6), gridspec_kw=dict(width_ratios=[8, 6]))\n# Transforme axs em uma lista unidimensional\naxs = axs.flatten()\nsns.histplot(data=df, x=\"price\", ax=axs[0])\nsns.histplot(data=df, x=\"price_log_e\", ax=axs[1])\nsns.histplot(data=df, x=\"price_log10\", ax=axs[2])\nsns.histplot(data=df, x=\"price_log2\", ax=axs[3])\nf.tight_layout()\n\n\n# Calcule a assimetria\nskewness_price = df[\"price\"].skew()\nskewness_price_log = df[\"price_log_e\"].skew()\nskewness_carat = df[\"price_log10\"].skew()\nskewness_carat_log = df[\"price_log2\"].skew()\n# Atualize os t\u00edtulos dos gr\u00e1ficos\naxs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\")\naxs[1].set_title(f\"Assimetria (price_log_e): {skewness_price_log:.2f}\")\naxs[2].set_title(f\"Assimetria (price_log10): {skewness_carat:.2f}\")\naxs[3].set_title(f\"Assimetria (price_log2): {skewness_carat_log:.2f}\")\n\nplt.show()\n</pre> f, axs = plt.subplots(2, 2, figsize=(8, 6), gridspec_kw=dict(width_ratios=[8, 6])) # Transforme axs em uma lista unidimensional axs = axs.flatten() sns.histplot(data=df, x=\"price\", ax=axs[0]) sns.histplot(data=df, x=\"price_log_e\", ax=axs[1]) sns.histplot(data=df, x=\"price_log10\", ax=axs[2]) sns.histplot(data=df, x=\"price_log2\", ax=axs[3]) f.tight_layout()   # Calcule a assimetria skewness_price = df[\"price\"].skew() skewness_price_log = df[\"price_log_e\"].skew() skewness_carat = df[\"price_log10\"].skew() skewness_carat_log = df[\"price_log2\"].skew() # Atualize os t\u00edtulos dos gr\u00e1ficos axs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\") axs[1].set_title(f\"Assimetria (price_log_e): {skewness_price_log:.2f}\") axs[2].set_title(f\"Assimetria (price_log10): {skewness_carat:.2f}\") axs[3].set_title(f\"Assimetria (price_log2): {skewness_carat_log:.2f}\")  plt.show()"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Transformacoes/#propriedades-da-funcao-logaritmica","title":"Propriedades da Fun\u00e7\u00e3o Logar\u00edtmica:\u00b6","text":"<p>Em resumo, as transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis quando se deseja lidar com varia\u00e7\u00e3o excessiva, linearizar rela\u00e7\u00f5es n\u00e3o lineares ou estabilizar a vari\u00e2ncia em dados.</p> <ul> <li>A fun\u00e7\u00e3o logar\u00edtmica \u00e9 a inversa da fun\u00e7\u00e3o exponencial. Ela se apresenta na forma geral: $$ y = \\log_b(x) $$</li> <li>Aqui, (x) \u00e9 o valor original e (y)  \u00e9 o logaritmo desse valor na base (b).</li> <li>A base (b) pode ser qualquer n\u00famero maior que 1, mas as bases mais comuns s\u00e3o 10 (logaritmo comum) e  (e) (logaritmo natural).</li> </ul>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Transformacoes/#compressao-e-expansao-de-intervalos","title":"Compress\u00e3o e Expans\u00e3o de Intervalos:\u00b6","text":"<p>A fun\u00e7\u00e3o logar\u00edtmica comprime o intervalo de grandes n\u00fameros e expande o intervalo de pequenos n\u00fameros. Por exemplo, um intervalo entre 100 e 1000 \u00e9 comprimido para um intervalo entre 2 e 3 quando aplicamos o logaritmo na base 10.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Transformacoes/#visualizacao-de-padroes","title":"Visualiza\u00e7\u00e3o de Padr\u00f5es:\u00b6","text":"<p>As transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis para facilitar a visualiza\u00e7\u00e3o de padr\u00f5es nos dados. Elas transformam rela\u00e7\u00f5es exponenciais em rela\u00e7\u00f5es mais compreens\u00edveis.</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/Transformacoes/#aplicacoes-praticas","title":"Aplica\u00e7\u00f5es Pr\u00e1ticas:\u00b6","text":"<p>Na ci\u00eancia de dados, usamos transforma\u00e7\u00f5es logar\u00edtmicas quando:</p> <ul> <li>A vari\u00e1vel tem uma distribui\u00e7\u00e3o assim\u00e9trica.</li> <li>A vari\u00e2ncia dos dados \u00e9 grande.</li> </ul> <p>A transforma\u00e7\u00e3o logar\u00edtmica \u00e9 definida como: $$ y = \\log(x) $$</p>"},{"location":"machine_learning/_Notebooks_teoria_aplicada/utils/learning_curve/","title":"Learning curve","text":"In\u00a0[\u00a0]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd In\u00a0[\u00a0]: Copied! <pre># visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>#machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n</pre> #machine learning from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC, LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.linear_model import Perceptron from sklearn.linear_model import SGDClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.model_selection import cross_val_score from sklearn.ensemble import VotingClassifier from sklearn.model_selection import GridSearchCV In\u00a0[\u00a0]: Copied! <pre>#Learning curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import validation_curve\n</pre> #Learning curve from sklearn.model_selection import learning_curve from sklearn.model_selection import ShuffleSplit from sklearn.model_selection import cross_val_predict from sklearn.model_selection import validation_curve In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00f5es para type hints\nfrom typing import Any, Dict, Union, List, Optional, Tuple\nfrom sklearn.base import BaseEstimator\n</pre> # Fun\u00e7\u00f5es para type hints from typing import Any, Dict, Union, List, Optional, Tuple from sklearn.base import BaseEstimator In\u00a0[\u00a0]: Copied! <pre>def grid_search_model(X: np.ndarray, \n                      Y: np.ndarray, \n                      model: BaseEstimator, \n                      parameters: Dict[str, Any], \n                      cv: Union[int, Any]) -&gt; None:\n    \"\"\"\n    Realiza uma busca em grade para encontrar os melhores hiperpar\u00e2metros para um modelo de Machine Learning.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser treinado.\n        parameters (Dict[str, Any]): Dicion\u00e1rio de par\u00e2metros a serem testados na busca em grade.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n\n    Returns:\n        None: A fun\u00e7\u00e3o imprime o melhor score e os melhores par\u00e2metros encontrados.\n    \"\"\"\n    CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=cv)\n    CV_model.fit(X, Y)\n    print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)\n\n # Usar BaseEstimator como type hint significa que voc\u00ea pode passar qualquer \n # modelo de aprendizado de m\u00e1quina do scikit-learn para a fun\u00e7\u00e3o, \n # seja ele uma regress\u00e3o linear, uma \u00e1rvore de decis\u00e3o, uma m\u00e1quina de vetores de suporte (SVM), uma rede neural, etc.\n</pre> def grid_search_model(X: np.ndarray,                        Y: np.ndarray,                        model: BaseEstimator,                        parameters: Dict[str, Any],                        cv: Union[int, Any]) -&gt; None:     \"\"\"     Realiza uma busca em grade para encontrar os melhores hiperpar\u00e2metros para um modelo de Machine Learning.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser treinado.         parameters (Dict[str, Any]): Dicion\u00e1rio de par\u00e2metros a serem testados na busca em grade.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.      Returns:         None: A fun\u00e7\u00e3o imprime o melhor score e os melhores par\u00e2metros encontrados.     \"\"\"     CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=cv)     CV_model.fit(X, Y)     print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)   # Usar BaseEstimator como type hint significa que voc\u00ea pode passar qualquer   # modelo de aprendizado de m\u00e1quina do scikit-learn para a fun\u00e7\u00e3o,   # seja ele uma regress\u00e3o linear, uma \u00e1rvore de decis\u00e3o, uma m\u00e1quina de vetores de suporte (SVM), uma rede neural, etc. In\u00a0[\u00a0]: Copied! <pre># validacion curv\ndef validation_curve_model(X: np.ndarray, \n                           Y: np.ndarray, \n                           model: BaseEstimator, \n                           param_name: str, \n                           parameters: List[Any], \n                           cv: Union[int, Any], \n                           ylim: Optional[Tuple[float, float]] = None, \n                           log: bool = True) -&gt; plt.Figure:\n    \"\"\"\n    Plota a curva de valida\u00e7\u00e3o para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser avaliado.\n        param_name (str): Nome do hiperpar\u00e2metro a ser testado.\n        parameters (List[Any]): Lista de valores para o hiperpar\u00e2metro.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n        ylim (Optional[Tuple[float, float]]): Limites para o eixo y no gr\u00e1fico (opcional).\n        log (bool): Se verdadeiro, usa escala logar\u00edtmica para o eixo x.\n\n    Returns:\n        plt.Figure: O objeto de figura do matplotlib contendo a curva de valida\u00e7\u00e3o.\n    \"\"\"\n    train_scores, test_scores = validation_curve(\n        model, X, Y, param_name=param_name, param_range=parameters, cv=cv, scoring=\"accuracy\"\n    )\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.figure()\n    plt.title(\"Curva de Valida\u00e7\u00e3o\")\n    plt.fill_between(parameters, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(parameters, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\n    if log:\n        plt.semilogx(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n        plt.semilogx(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n    else:\n        plt.plot(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n        plt.plot(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n\n    if ylim is not None:\n        plt.ylim(*ylim)\n\n    plt.ylabel('Pontua\u00e7\u00e3o')\n    plt.xlabel(f'Par\u00e2metro {param_name}')\n    plt.legend(loc=\"best\")\n\n    return plt\n</pre> # validacion curv def validation_curve_model(X: np.ndarray,                             Y: np.ndarray,                             model: BaseEstimator,                             param_name: str,                             parameters: List[Any],                             cv: Union[int, Any],                             ylim: Optional[Tuple[float, float]] = None,                             log: bool = True) -&gt; plt.Figure:     \"\"\"     Plota a curva de valida\u00e7\u00e3o para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser avaliado.         param_name (str): Nome do hiperpar\u00e2metro a ser testado.         parameters (List[Any]): Lista de valores para o hiperpar\u00e2metro.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.         ylim (Optional[Tuple[float, float]]): Limites para o eixo y no gr\u00e1fico (opcional).         log (bool): Se verdadeiro, usa escala logar\u00edtmica para o eixo x.      Returns:         plt.Figure: O objeto de figura do matplotlib contendo a curva de valida\u00e7\u00e3o.     \"\"\"     train_scores, test_scores = validation_curve(         model, X, Y, param_name=param_name, param_range=parameters, cv=cv, scoring=\"accuracy\"     )          train_scores_mean = np.mean(train_scores, axis=1)     train_scores_std = np.std(train_scores, axis=1)     test_scores_mean = np.mean(test_scores, axis=1)     test_scores_std = np.std(test_scores, axis=1)      plt.figure()     plt.title(\"Curva de Valida\u00e7\u00e3o\")     plt.fill_between(parameters, train_scores_mean - train_scores_std,                      train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")     plt.fill_between(parameters, test_scores_mean - test_scores_std,                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")      if log:         plt.semilogx(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")         plt.semilogx(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")     else:         plt.plot(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")         plt.plot(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")      if ylim is not None:         plt.ylim(*ylim)      plt.ylabel('Pontua\u00e7\u00e3o')     plt.xlabel(f'Par\u00e2metro {param_name}')     plt.legend(loc=\"best\")      return plt In\u00a0[\u00a0]: Copied! <pre># Learning curve\ndef Learning_curve_model(X: np.ndarray, \n                         Y: np.ndarray, \n                         model: BaseEstimator, \n                         cv: Union[int, Any], \n                         train_sizes: Union[np.ndarray, List[int]]) -&gt; plt.Figure:\n    \"\"\"\n    Plota a curva de aprendizado para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o\n    em diferentes tamanhos de conjunto de treinamento.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser avaliado.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n        train_sizes (Union[np.ndarray, List[int]]): Tamanhos dos conjuntos de treinamento a serem usados para gerar a curva de aprendizado.\n\n    Returns:\n        plt.Figure: O objeto de figura do matplotlib contendo a curva de aprendizado.\n    \"\"\"\n    plt.figure()\n    plt.title(\"Curva de Aprendizado\")\n    plt.xlabel(\"Exemplos de Treinamento\")\n    plt.ylabel(\"Pontua\u00e7\u00e3o\")\n\n    train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std  = np.std(train_scores, axis=1)\n    test_scores_mean  = np.mean(test_scores, axis=1)\n    test_scores_std   = np.std(test_scores, axis=1)\n    plt.grid()\n    \n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n                     \n    plt.legend(loc=\"best\")\n    return plt\n</pre> # Learning curve def Learning_curve_model(X: np.ndarray,                           Y: np.ndarray,                           model: BaseEstimator,                           cv: Union[int, Any],                           train_sizes: Union[np.ndarray, List[int]]) -&gt; plt.Figure:     \"\"\"     Plota a curva de aprendizado para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o     em diferentes tamanhos de conjunto de treinamento.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser avaliado.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.         train_sizes (Union[np.ndarray, List[int]]): Tamanhos dos conjuntos de treinamento a serem usados para gerar a curva de aprendizado.      Returns:         plt.Figure: O objeto de figura do matplotlib contendo a curva de aprendizado.     \"\"\"     plt.figure()     plt.title(\"Curva de Aprendizado\")     plt.xlabel(\"Exemplos de Treinamento\")     plt.ylabel(\"Pontua\u00e7\u00e3o\")      train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)      train_scores_mean = np.mean(train_scores, axis=1)     train_scores_std  = np.std(train_scores, axis=1)     test_scores_mean  = np.mean(test_scores, axis=1)     test_scores_std   = np.std(test_scores, axis=1)     plt.grid()          plt.fill_between(train_sizes, train_scores_mean - train_scores_std,                      train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")                           plt.legend(loc=\"best\")     return plt In\u00a0[\u00a0]: Copied! <pre># lrearning, prediction and printing results\ndef predict_model(X: np.ndarray, \n                  Y: np.ndarray, \n                  model: BaseEstimator, \n                  Xtest: np.ndarray, \n                  submit_name: str, \n                  test_df: pd.DataFrame, \n                  cv: Union[int, Any] = 5) -&gt; np.ndarray:\n    \"\"\"\n    Treina o modelo, faz previs\u00f5es e salva os resultados em um arquivo CSV.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser treinado.\n        Xtest (np.ndarray): Dados de entrada (features) para o teste.\n        submit_name (str): Nome do arquivo CSV para salvar as previs\u00f5es.\n        test_df (pd.DataFrame): DataFrame contendo os dados de teste, incluindo o 'PassengerId'.\n        cv (Union[int, Any], optional): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada. Default \u00e9 5.\n\n    Returns:\n        np.ndarray: Array contendo as pontua\u00e7\u00f5es de valida\u00e7\u00e3o cruzada.\n    \"\"\"\n    model.fit(X, Y)\n    Y_pred = model.predict(Xtest)\n    score = cross_val_score(model, X, Y, cv=cv)\n\n    submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n    submission.to_csv(submit_name, index=False)\n    \n    return score\n</pre> # lrearning, prediction and printing results def predict_model(X: np.ndarray,                    Y: np.ndarray,                    model: BaseEstimator,                    Xtest: np.ndarray,                    submit_name: str,                    test_df: pd.DataFrame,                    cv: Union[int, Any] = 5) -&gt; np.ndarray:     \"\"\"     Treina o modelo, faz previs\u00f5es e salva os resultados em um arquivo CSV.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser treinado.         Xtest (np.ndarray): Dados de entrada (features) para o teste.         submit_name (str): Nome do arquivo CSV para salvar as previs\u00f5es.         test_df (pd.DataFrame): DataFrame contendo os dados de teste, incluindo o 'PassengerId'.         cv (Union[int, Any], optional): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada. Default \u00e9 5.      Returns:         np.ndarray: Array contendo as pontua\u00e7\u00f5es de valida\u00e7\u00e3o cruzada.     \"\"\"     model.fit(X, Y)     Y_pred = model.predict(Xtest)     score = cross_val_score(model, X, Y, cv=cv)      submission = pd.DataFrame({         \"PassengerId\": test_df[\"PassengerId\"],         \"Survived\": Y_pred     })     submission.to_csv(submit_name, index=False)          return score"},{"location":"python/01_Funcion_Built-in/","title":"Important Built-in Functions","text":"<p>https://docs.python.org/3/tutorial/datastructures.html</p> <p>Documenta\u00e7\u00e3o: https://docs.python.org/pt-br/3/library/functions.html</p>  Important Built-in Functions <p>A list comprehension \u00e9 uma forma concisa e elegante de criar listas em Python. Ela permite que voc\u00ea crie uma nova lista aplicando uma express\u00e3o a cada elemento de uma sequ\u00eancia (como uma lista, tupla ou conjunto).</p> <ol> <li>Sintaxe<ul> <li>A sintaxe geral de uma list comprehension \u00e9: <code>[express\u00e3o for elemento in sequ\u00eancia]</code>.</li> <li>Voc\u00ea pode adicionar uma cl\u00e1usula if para filtrar elementos: <code>[express\u00e3o for elemento in sequ\u00eancia if condi\u00e7\u00e3o]</code>.</li> </ul> </li> </ol> <ul> <li>Outro op\u00e7\u00e3o de Formato padr\u00e3o:<pre>[express\u00e3o for item in lista]\n[expr for item in lista if cond]\n</pre> </li> </ul> <ol> <li>Exemplos</li> </ol> In\u00a0[2]: Copied! <pre># Criando uma lista de quadrados para\nnumeros = [1, 2, 3, 4, 5]\nquadrados = [x**2 for x in numeros]\nprint(quadrados)  # Output: [1, 4, 9, 16, 25]\n</pre> # Criando uma lista de quadrados para numeros = [1, 2, 3, 4, 5] quadrados = [x**2 for x in numeros] print(quadrados)  # Output: [1, 4, 9, 16, 25]  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[3]: Copied! <pre># Filtrando n\u00fameros pares\nnumeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nnumeros_pares = [x for x in numeros if x % 2 == 0]\nprint(numeros_pares)\n</pre> # Filtrando n\u00fameros pares numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] numeros_pares = [x for x in numeros if x % 2 == 0] print(numeros_pares) <pre>[2, 4, 6, 8, 10]\n</pre> In\u00a0[4]: Copied! <pre># Criando uma lista de strings em mai\u00fasculas\npalavras = ['python', '\u00e9', 'incr\u00edvel']\nmaiusculas = [palavra.upper() for palavra in palavras]\nprint(maiusculas)\n</pre> # Criando uma lista de strings em mai\u00fasculas palavras = ['python', '\u00e9', 'incr\u00edvel'] maiusculas = [palavra.upper() for palavra in palavras] print(maiusculas) <pre>['PYTHON', '\u00c9', 'INCR\u00cdVEL']\n</pre> In\u00a0[5]: Copied! <pre># Gerando uma lista de tuplas\nnumeros = [1,2,3]\ntuplas = [(x, x**2) for x in numeros]\nprint(tuplas)\n</pre> # Gerando uma lista de tuplas numeros = [1,2,3] tuplas = [(x, x**2) for x in numeros] print(tuplas) <pre>[(1, 1), (2, 4), (3, 9)]\n</pre> <p>As fun\u00e7\u00f5es lambda em Python s\u00e3o fun\u00e7\u00f5es an\u00f4nimas que podem ser definidas em uma \u00fanica linha de c\u00f3digo. Elas s\u00e3o \u00fateis para criar pequenas fun\u00e7\u00f5es sem a necessidade de dar um nome a elas.</p> <p>https://docs.python.org/pt-br/3/reference/expressions.html?#lambda</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral de uma fun\u00e7\u00e3o lambda \u00e9: <code>lambda argumentos: express\u00e3o</code>.</li> <li>Voc\u00ea pode usar uma fun\u00e7\u00e3o lambda em qualquer lugar onde normalmente usaria uma fun\u00e7\u00e3o regular.</li> </ul> </li> </ol> <ul> <li>Outra op\u00e7\u00e3o de formato Geral<pre>lambda &lt;variavel_entrada&gt;: &lt;expressao&gt;\n</pre> </li> </ul> <ol> <li>Exemplos</li> </ol> In\u00a0[6]: Copied! <pre># Fun\u00e7\u00e3o que retorna o quadrado de um n\u00famero\ndobrar = lambda x_entrada: x_entrada * 2\nprint(dobrar(5))\n</pre> # Fun\u00e7\u00e3o que retorna o quadrado de um n\u00famero dobrar = lambda x_entrada: x_entrada * 2 print(dobrar(5)) <pre>10\n</pre> In\u00a0[7]: Copied! <pre># Fun\u00e7\u00e3o que verifica se um numero \u00e9 par\neh_par = lambda x_entrada: x_entrada % 2 == 0\nprint(eh_par(7))\n</pre> # Fun\u00e7\u00e3o que verifica se um numero \u00e9 par eh_par = lambda x_entrada: x_entrada % 2 == 0 print(eh_par(7)) <pre>False\n</pre> In\u00a0[8]: Copied! <pre># Fun\u00e7\u00e3o que soma 2 em cada elemento de uma lista\nsoma_dois = lambda lista_entrada: [x + 2 for x in lista_entrada]\n\n# Exemplo de uso:\nnumeros = [1, 3, 5, 7]\nresultado = soma_dois(numeros)\nprint(f\"Resultado: {resultado}\")\n</pre> # Fun\u00e7\u00e3o que soma 2 em cada elemento de uma lista soma_dois = lambda lista_entrada: [x + 2 for x in lista_entrada]  # Exemplo de uso: numeros = [1, 3, 5, 7] resultado = soma_dois(numeros) print(f\"Resultado: {resultado}\")  <pre>Resultado: [3, 5, 7, 9]\n</pre> In\u00a0[9]: Copied! <pre># Fun\u00e7\u00e3o para order um dicionario\nprodutos = [\n    {\"nome\": \"Ma\u00e7\u00e3\", \"preco\": 2.5},\n    {\"nome\": \"Banana\", \"preco\": 1.8},\n    {\"nome\": \"Laranja\", \"preco\": 0.1}\n]\nprodutos_ordenados = sorted(produtos, key=lambda preso_entrada: preso_entrada[\"preco\"])\nprodutos_ordenados\n</pre> # Fun\u00e7\u00e3o para order um dicionario produtos = [     {\"nome\": \"Ma\u00e7\u00e3\", \"preco\": 2.5},     {\"nome\": \"Banana\", \"preco\": 1.8},     {\"nome\": \"Laranja\", \"preco\": 0.1} ] produtos_ordenados = sorted(produtos, key=lambda preso_entrada: preso_entrada[\"preco\"]) produtos_ordenados Out[9]: <pre>[{'nome': 'Laranja', 'preco': 0.1},\n {'nome': 'Banana', 'preco': 1.8},\n {'nome': 'Ma\u00e7\u00e3', 'preco': 2.5}]</pre> In\u00a0[10]: Copied! <pre># Mapeamento de uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista\nnumeros = [1, 2, 3, 4, 5]\nquadrados = list(\n    map(lambda x_entrada: x_entrada**2, numeros)\n    )\nprint(quadrados)\n</pre> # Mapeamento de uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista numeros = [1, 2, 3, 4, 5] quadrados = list(     map(lambda x_entrada: x_entrada**2, numeros)     ) print(quadrados)  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[11]: Copied! <pre># Filtrando uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista\nnumeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nnumeros_pares = list(\n    filter(lambda x_entrada: x_entrada % 2 == 0, numeros )\n)\nnumeros_pares\n</pre> # Filtrando uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  numeros_pares = list(     filter(lambda x_entrada: x_entrada % 2 == 0, numeros ) ) numeros_pares Out[11]: <pre>[2, 4, 6, 8, 10]</pre> <p>A fun\u00e7\u00e3o map() em Python \u00e9 usada para aplicar uma fun\u00e7\u00e3o a cada elemento de uma sequ\u00eancia (como uma lista, tupla ou conjunto) e retornar um iterador com os resultados.</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral da fun\u00e7\u00e3o map() \u00e9: <code>map(funcao, sequencia)</code>.</li> <li>A fun\u00e7\u00e3o funcao \u00e9 aplicada a cada elemento da sequencia.</li> </ul> </li> </ol> <ul> <li>Outra o\u00e7\u00e3o de formato Geral:<pre>map(&lt;lambda function&gt;, &lt;iterador&gt;)\n</pre> </li> </ul> In\u00a0[12]: Copied! <pre># Eleva cada n\u00famero ao quadrado: Aplica uma fun\u00e7\u00e3o em cada element de uma lista\nnumeros = [1, 2, 3, 4, 5]\nquadrados = list(\n    map(lambda x_entrada: x_entrada**2, numeros)\n    )\nprint(quadrados)\n</pre> # Eleva cada n\u00famero ao quadrado: Aplica uma fun\u00e7\u00e3o em cada element de uma lista numeros = [1, 2, 3, 4, 5] quadrados = list(     map(lambda x_entrada: x_entrada**2, numeros)     ) print(quadrados)  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[13]: Copied! <pre>palavras = [\"python\", \"\u00e9\", \"incr\u00edvel\"]\nresultado = list(\n    map(lambda x_entrada: x_entrada.upper(), palavras)\n)\nprint(resultado)\n</pre> palavras = [\"python\", \"\u00e9\", \"incr\u00edvel\"] resultado = list(     map(lambda x_entrada: x_entrada.upper(), palavras) ) print(resultado) <pre>['PYTHON', '\u00c9', 'INCR\u00cdVEL']\n</pre> <p>A fun\u00e7\u00e3o <code>filter()</code> em Python \u00e9 usada para filtrar elementos de uma sequ\u00eancia (como uma lista, tupla ou conjunto) com base em uma condi\u00e7\u00e3o especificada. Ela retorna um iterador contendo apenas os elementos que atendem \u00e0 condi\u00e7\u00e3o</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral da fun\u00e7\u00e3o filter() \u00e9: <code>filter(funcao, sequencia)</code>.</li> <li>A fun\u00e7\u00e3o funcao deve retornar True ou False para cada elemento da sequencia.</li> </ul> </li> </ol> <p>2.Exemplo</p> In\u00a0[14]: Copied! <pre># Filtrando n\u00fameros pares: Aplicando a um filtro em uma lista de elementos\nnumeros = [1, 2, 3, 4, 5]\nnumeros_pares = list(\n    filter(lambda x: x % 2 == 0, numeros)\n    )\nprint(numeros_pares)\n</pre> # Filtrando n\u00fameros pares: Aplicando a um filtro em uma lista de elementos numeros = [1, 2, 3, 4, 5] numeros_pares = list(     filter(lambda x: x % 2 == 0, numeros)     ) print(numeros_pares)  <pre>[2, 4]\n</pre> <p>O zip() \u00e9 uma fun\u00e7\u00e3o embutida do Python que combina elementos de duas ou mais sequ\u00eancias, como listas ou tuplas. Ele cria um iterador que produz tuplas contendo um elemento de cada sequ\u00eancia. O zip() \u00e9 uma ferramenta poderosa para combinar e descompactar sequ\u00eancias.</p> <ol> <li>sintaxe: <code>zip(iter\u00e1vel1, iter\u00e1vel2, ...)</code></li> </ol> <ol> <li>Exemplo</li> </ol> In\u00a0[18]: Copied! <pre># Usando zip() para combinar as listas\nlista1 = [1, 2, 3]\nlista2 = ['a', 'b', 'c']\n\ncombinacao = list(\n    zip(lista1, lista2)\n)\n\nprint(combinacao) \n</pre> # Usando zip() para combinar as listas lista1 = [1, 2, 3] lista2 = ['a', 'b', 'c']  combinacao = list(     zip(lista1, lista2) )  print(combinacao)   <pre>[(1, 'a'), (2, 'b'), (3, 'c')]\n</pre> In\u00a0[22]: Copied! <pre># Descompactando uma lista de tuplas\n\ntuplas = [(1, 'a'), (2, 'b'), (3, 'c')]\n\n# Usando zip() para descompactar as tuplas\ndescompactado1, descompactado2 = zip(*tuplas)\n\nprint(descompactado1)\nprint(descompactado2)\n\nprint(\"--------------------------------\")\nprint(tuplas)\nprint(*tuplas)\n</pre> # Descompactando uma lista de tuplas  tuplas = [(1, 'a'), (2, 'b'), (3, 'c')]  # Usando zip() para descompactar as tuplas descompactado1, descompactado2 = zip(*tuplas)  print(descompactado1) print(descompactado2)  print(\"--------------------------------\") print(tuplas) print(*tuplas)  <pre>(1, 2, 3)\n('a', 'b', 'c')\n--------------------------------\n[(1, 'a'), (2, 'b'), (3, 'c')]\n(1, 'a') (2, 'b') (3, 'c')\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[16]: Copied! <pre>numeros = [1, 2, 3, 4, 5]\n\n# Eleva cada n\u00famero ao quadrado, e filtra baseado em uma condi\u00e7\u00e3o.\nquadrados = list(\n    filter(lambda x: x**2 == 4, numeros)\n    )\nprint(quadrados)\n</pre> numeros = [1, 2, 3, 4, 5]  # Eleva cada n\u00famero ao quadrado, e filtra baseado em uma condi\u00e7\u00e3o. quadrados = list(     filter(lambda x: x**2 == 4, numeros)     ) print(quadrados)  <pre>[2]\n</pre> In\u00a0[17]: Copied! <pre>numeros = [1, 2, 3, 4, 5]\n\n# Eleva cada n\u00famero ao quadrado e verifica uma condi\u00e7\u00e3o.\nquadrados = list(\n    map(lambda x: x**2 == 4, numeros)\n    )\nprint(quadrados)\n</pre> numeros = [1, 2, 3, 4, 5]  # Eleva cada n\u00famero ao quadrado e verifica uma condi\u00e7\u00e3o. quadrados = list(     map(lambda x: x**2 == 4, numeros)     ) print(quadrados)  <pre>[False, True, False, False, False]\n</pre>"},{"location":"python/01_Funcion_Built-in/#1-list-comprehension","title":"1. <code>list comprehension</code>\u00b6","text":""},{"location":"python/01_Funcion_Built-in/#2-lambda","title":"2. <code>Lambda</code>\u00b6","text":""},{"location":"python/01_Funcion_Built-in/#3-map","title":"3. <code>Map</code>\u00b6","text":""},{"location":"python/01_Funcion_Built-in/#3-filter","title":"3. <code>Filter</code>\u00b6","text":""},{"location":"python/01_Funcion_Built-in/#4-zip","title":"4. <code>Zip()</code>\u00b6","text":""},{"location":"python/01_Funcion_Built-in/#entendendo-algumas-diferencas-entre-map-e-filter","title":"Entendendo algumas diferen\u00e7as entre MAP e FILTER\u00b6","text":""},{"location":"python/01_Funcion_Built-in/","title":"01 Funcion Built in","text":""},{"location":"python/01_Funcion_Built-in/#funcoes-built-in-do-python","title":"Fun\u00e7\u00f5es Built-in do Python","text":"<p>O Python possui v\u00e1rias fun\u00e7\u00f5es built-in que est\u00e3o sempre dispon\u00edveis para uso. Aqui est\u00e3o algumas delas em ordem alfab\u00e9tica:</p> <ul> <li><code>abs(x)</code>: Retorna o valor absoluto de um n\u00famero (inteiro ou ponto flutuante).</li> <li><code>all(iterable)</code>: Retorna True se todos os elementos do iter\u00e1vel forem verdadeiros (ou se o iter\u00e1vel estiver vazio).</li> <li><code>any(iterable)</code>: Retorna True se qualquer elemento do iter\u00e1vel for verdadeiro.</li> <li><code>ascii(object)</code>: Retorna uma representa\u00e7\u00e3o imprim\u00edvel de um objeto, escapando caracteres n\u00e3o-ASCII.</li> <li><code>bin(x)</code>: Converte um n\u00famero inteiro para uma string de bin\u00e1rios prefixada com \u201c0b\u201d.</li> <li><code>bool(x)</code>: Retorna um valor booleano (True ou False).</li> <li><code>bytearray(source[, encoding[, errors]])</code>: Retorna um novo vetor de bytes mut\u00e1vel.</li> <li><code>bytes([source[, encoding[, errors]]])</code>: Retorna um objeto de bytes imut\u00e1vel.</li> <li><code>callable(object)</code>: Verifica se o objeto \u00e9 cham\u00e1vel (pode ser chamado como uma fun\u00e7\u00e3o).</li> <li><code>chr(i)</code>: Retorna uma string representando um caractere Unicode cujo c\u00f3digo \u00e9 i.</li> <li><code>complex(real[, imag])</code>: Retorna um n\u00famero complexo.</li> <li><code>delattr(object, name)</code>: Remove um atributo de um objeto.</li> <li><code>dict([iterable])</code>: Retorna um dicion\u00e1rio.</li> <li><code>divmod(a, b)</code>: Retorna o quociente e o resto da divis\u00e3o de a por b.</li> <li><code>enumerate(iterable, start=0)</code>: Retorna um objeto enumerado (pares \u00edndice-valor).</li> <li><code>filter(function, iterable)</code>: Filtra elementos do iter\u00e1vel com base em uma fun\u00e7\u00e3o.</li> <li><code>float(x)</code>: Converte um n\u00famero ou string para um ponto flutuante.</li> <li><code>format(value[, format_spec])</code>: Formata um valor de acordo com a especifica\u00e7\u00e3o de formato.</li> <li><code>frozenset([iterable])</code>: Retorna um conjunto imut\u00e1vel.</li> <li><code>getattr(object, name[, default])</code>: Retorna o valor de um atributo de um objeto.</li> <li><code>globals()</code>: Retorna um dicion\u00e1rio com as vari\u00e1veis globais.</li> <li><code>hasattr(object, name)</code>: Verifica se um objeto tem um atributo.</li> <li><code>hash(object)</code>: Retorna o valor hash de um objeto.</li> <li><code>hex(x)</code>: Converte um n\u00famero inteiro para uma string hexadecimal.</li> <li><code>id(object)</code>: Retorna o identificador \u00fanico de um objeto.</li> <li><code>input([prompt])</code>: L\u00ea uma linha da entrada padr\u00e3o.</li> <li><code>int(x[, base])</code>: Converte um n\u00famero ou string para um inteiro.</li> <li><code>isinstance(object, classinfo)</code>: Verifica se um objeto \u00e9 uma inst\u00e2ncia de uma classe.</li> <li><code>issubclass(class, classinfo)</code>: Verifica se uma classe \u00e9 subclasse de outra.</li> <li><code>iter(iterable[, sentinel])</code>: Retorna um iterador para o iter\u00e1vel.</li> <li><code>len(s)</code>: Retorna o n\u00famero de elementos em uma sequ\u00eancia (string, lista, tupla, etc.).</li> <li><code>list([iterable])</code>: Retorna uma lista.</li> <li><code>locals()</code>: Retorna um dicion\u00e1rio com as vari\u00e1veis locais.</li> <li><code>map(function, iterable, ...)</code>: Aplica uma fun\u00e7\u00e3o a cada elemento do iter\u00e1vel.</li> <li><code>max(iterable[, key])</code>: Retorna o maior elemento do iter\u00e1vel.</li> <li><code>memoryview(obj)</code>: Retorna uma vis\u00e3o de mem\u00f3ria de um objeto.</li> <li><code>min(iterable[, key])</code>: Retorna o menor elemento do iter\u00e1vel.</li> <li><code>next(iterator[, default])</code>: Retorna o pr\u00f3ximo elemento de um iterador.</li> <li><code>object()</code>: Retorna um novo objeto vazio.</li> <li><code>oct(x)</code>: Converte um n\u00famero inteiro para uma string octal.</li> <li><code>open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</code>: Abre um arquivo.</li> <li><code>ord(c)</code>: Retorna o valor Unicode do caractere.</li> <li><code>pow(x, y[, z])</code>: Calcula x elevado \u00e0 pot\u00eancia y (opcionalmente m\u00f3dulo z).</li> <li><code>print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)</code>: Imprime objetos na sa\u00edda padr\u00e3o.</li> <li><code>property([fget[, fset[, fdel[, doc]]]])</code>: Retorna uma propriedade.</li> <li><code>range(stop)</code>, <code>range(start, stop[, step])</code>: Retorna uma sequ\u00eancia de valores.</li> </ul>"},{"location":"python/02_Loc_Iloc/","title":"02 Loc Iloc","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import pandas as pd import numpy as np  import matplotlib.pyplot as plt import seaborn as sns In\u00a0[3]: Copied! <pre># Exemplo de DataFrame\ndata = {\n    'PassengerId': [1, 2, 3],\n    'Survived': [1, 0, 1],\n    'Pclass': [3, 1, 3],\n    'Name': ['Name1', 'Name2', 'Name3'],\n    'Sex': ['male', 'female', 'female']\n}\ndf_train = pd.DataFrame(data)\n</pre> # Exemplo de DataFrame data = {     'PassengerId': [1, 2, 3],     'Survived': [1, 0, 1],     'Pclass': [3, 1, 3],     'Name': ['Name1', 'Name2', 'Name3'],     'Sex': ['male', 'female', 'female'] } df_train = pd.DataFrame(data) In\u00a0[5]: Copied! <pre>df_train.loc[0:4, 'Survived':'Sex']\n</pre> df_train.loc[0:4, 'Survived':'Sex'] Out[5]: Survived Pclass Name Sex 0 1 3 Name1 male 1 0 1 Name2 female 2 1 3 Name3 female In\u00a0[6]: Copied! <pre>df_train.loc[0:4, 'Sex']\n</pre> df_train.loc[0:4, 'Sex'] Out[6]: <pre>0      male\n1    female\n2    female\nName: Sex, dtype: object</pre> In\u00a0[7]: Copied! <pre>df_train.loc[0:4]['Sex']\n</pre> df_train.loc[0:4]['Sex'] Out[7]: <pre>0      male\n1    female\n2    female\nName: Sex, dtype: object</pre> In\u00a0[9]: Copied! <pre>df_train.iloc[0:4, 2:4]\n</pre> df_train.iloc[0:4, 2:4] Out[9]: Pclass Name 0 3 Name1 1 1 Name2 2 3 Name3"},{"location":"python/datas_spark/","title":"Datas spark","text":"In\u00a0[2]: Copied! <pre>import os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"c:/spark/spark-3.3.2-bin-hadoop2/\"\n</pre> import os os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" os.environ[\"SPARK_HOME\"] = \"c:/spark/spark-3.3.2-bin-hadoop2/\" In\u00a0[3]: Copied! <pre>import findspark\nfindspark.init(\"C:/spark/spark-3.3.2-bin-hadoop2/\")\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master('teste').getOrCreate()\n</pre> import findspark findspark.init(\"C:/spark/spark-3.3.2-bin-hadoop2/\")  from pyspark.sql import SparkSession spark = SparkSession.builder.master('teste').getOrCreate() In\u00a0[\u00a0]: Copied! <pre>spark\n</pre> spark Out[\u00a0]: <p>SparkSession - in-memory</p> <p>SparkContext</p> <p>Spark UI</p> Version <code>v3.3.2</code> Master <code>local[*]</code> AppName <code>pyspark-shell</code> In\u00a0[\u00a0]: Copied! <pre>formatos_data_hora = [\n    # Formatos de data e hora\n    \"YYYY-MM-DD HH:MM:SS\",  # 2024-05-29 13:45:30 (ISO)\n    \"YYYY-MM-DD HH:MM:SS.sss\",  # 2024-05-29 13:45:30.123 (ISO)\n    \"DD-MM-YYYY HH:MM:SS\",  # 29-05-2024 13:45:30 (Brasileiro)\n    \"DD/MM/YYYY HH:MM:SS\",  # 29/05/2024 13:45:30 (Brasileiro)\n    \"MM-DD-YYYY HH:MM:SS\",  # 05-29-2024 13:45:30 (USA)\n    \"MM/DD/YYYY HH:MM:SS\",  # 05/29/2024 13:45:30 (USA)\n    \"YYYY/MM/DD HH:MM:SS\",  # 2024/05/29 13:45:30 (ISO)\n    \"YYYY.MM.DD HH:MM:SS\",  # 2024.05.29 13:45:30 (ISO)\n    \"DD.MM.YYYY HH:MM:SS\",  # 29.05.2024 13:45:30 (Europeu)\n    \"DD.MM.YYYY HH:MM:SS.sss\",  # 29.05.2024 13:45:30.123 (Europeu)\n    \"DD/MM/YYYY, HH:MM:SS\",  # 29/05/2024, 13:45:30 (Brasileiro)\n    \"YYYY-MM-DD'T'HH:MM:SS\",  # 2024-05-29T13:45:30 (ISO 8601)\n    \"YYYY-MM-DD'T'HH:MM:SS.sss\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)\n    \"YYYYMMDDTHHMMSS\",  # 20240529T134530 (ISO 8601 compacto)\n    \"YYYYMMDDHHMMSS\",  # 20240529134530 (Compacto)\n    \"YYYY/MM/DD HH:MM\",  # 2024/05/29 13:45 (ISO)\n    \"MM/DD/YYYY HH:MM\",  # 05/29/2024 13:45 (USA)\n    \"DD-MM-YYYY HH:MM\",  # 29-05-2024 13:45 (Brasileiro)\n    \"DD/MM/YYYY HH:MM\",  # 29/05/2024 13:45 (Brasileiro)\n    \"DD.MM.YYYY HH:MM\",  # 29.05.2024 13:45 (Europeu)\n    \"YYYY-MM-DD HH:MM\",  # 2024-05-29 13:45 (ISO)\n    \"DD/MM/YY HH:MM\",  # 29/05/24 13:45 (Brasileiro)\n    \"DD/MM/YY HH:MM:SS\",  # 29/05/24 13:45:30 (Brasileiro)\n    \"MM/DD/YY HH:MM\",  # 05/29/24 13:45 (USA)\n    \"MM/DD/YY HH:MM:SS\",  # 05/29/24 13:45:30 (USA)\n    \"DD.MM.YY HH:MM\",  # 29.05.24 13:45 (Europeu)\n    \"DD.MM.YY HH:MM:SS\",  # 29.05.24 13:45:30 (Europeu)\n    \"YYYY-MM-DD HH:MM:SS Z\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)\n    \"YYYY-MM-DD HH:MM:SSZZ\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)\n    \"YYYY-MM-DDTHH:MM:SSZZ\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"YYYY-MM-DDTHH:MM:SS.sssZZ\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)\n    \"YYYY/MM/DDTHH:MM:SSZZ\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"YYYY-MM-DDTHH:MM:SS.sssZ\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)\n    \"YYYY-MM-DDTHH:MM:SSZ\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)\n    \"YYYYMMDD HH:MM:SS\",  # 20240529 13:45:30 (Compacto)\n    \"YYYYMMDD HH:MM:SS.sss\",  # 20240529 13:45:30.123 (Compacto)\n    \"YYYYMMDD'T'HHMMSSZ\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)\n    \"YYYYMMDD'T'HHMMSS.sssZ\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)\n    \n    # Formatos de data e hora com AM/PM\n    \"YYYY-MM-DD hh:MM:SS AM/PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:MM:SS AM/PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM/DD/YYYY hh:MM:SS AM/PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)\n    \"YYYY/MM/DD hh:MM:SS AM/PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"DD-MM-YYYY hh:MM:SS AM/PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:MM:SS AM/PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \n    # Formatos de data sem hora\n    \"YYYY-MM-DD\",  # 2024-05-29 (ISO)\n    \"DD-MM-YYYY\",  # 29-05-2024 (Brasileiro)\n    \"DD/MM/YYYY\",  # 29/05/2024 (Brasileiro)\n    \"MM-DD-YYYY\",  # 05-29-2024 (USA)\n    \"MM/DD/YYYY\",  # 05/29/2024 (USA)\n    \"YYYY/MM/DD\",  # 2024/05/29 (ISO)\n    \"YYYY.MM.DD\",  # 2024.05.29 (ISO)\n    \"DD.MM.YYYY\",  # 29.05.2024 (Europeu)\n    \"DD/MM/YY\",  # 29/05/24 (Brasileiro)\n    \"MM/DD/YY\",  # 05/29/24 (USA)\n    \"DD.MM.YY\",  # 29.05.24 (Europeu)\n    \n    \"YYYY/MM/DD hh:mm:ss A\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:mm:ss A\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:mm:ss A\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \"YYYY/MM/DD hh:mm A\",  # 2024/05/29 01:45 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:mm A\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:mm A\",  # 05-29-2024 01:45 PM (USA com AM/PM)\n    \n    \"YYYYMMDD\",  # 20240529 (Compacto)\n    \"YYMMDD\",  # 240529 (Compacto curto)\n    \"YY/MM/DD\",  # 24/05/29 (Curto)\n    \"YY-MM-DD\",  # 24-05-29 (Curto)\n    \"YY.MM.DD\",  # 24.05.29 (Curto)\n    \n    \"DD MMM YYYY\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)\n    \"DD MMMM YYYY\",  # 29 May 2024 (Dia, m\u00eas completo e ano)\n    \"MMM DD, YYYY\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)\n    \"MMMM DD, YYYY\",  # May 29, 2024 (M\u00eas completo, dia e ano)\n    \"MMM DD YYYY\",  # May 29 2024 (M\u00eas abreviado, dia e ano)\n    \"MMMM DD YYYY\",  # May 29 2024 (M\u00eas completo, dia e ano)\n    \n    \"DD/MMM/YYYY\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)\n    \"DD-MMM-YYYY\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)\n    \"DD MMM, YYYY\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)\n    \n    \"E, MMM DD YYYY HH:MM:SS\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)\n    \"EEEE, MMMM DD, YYYY HH:MM:SS\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)\n    \n    \"E, DD MMM YYYY HH:MM:SS\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)\n    \"EEEE, DD MMMM YYYY HH:MM:SS\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)\n    \n    \"E, DD MMM YYYY hh:mm:ss A\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)\n    \"EEEE, DD MMMM YYYY hh:mm:ss A\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)\n    \n    \"E, MMM DD YYYY hh:mm:ss A\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)\n    \"EEEE, MMMM DD, YYYY hh:mm:ss A\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)\n    \n    \"E, MMM DD, YY HH:MM\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)\n    \"EEEE, MMMM DD, YY HH:MM\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)\n    \n    \"E, DD MMM, YY HH:MM\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)\n    \"EEEE, DD MMMM, YY HH:MM\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora)\n]\n</pre> formatos_data_hora = [     # Formatos de data e hora     \"YYYY-MM-DD HH:MM:SS\",  # 2024-05-29 13:45:30 (ISO)     \"YYYY-MM-DD HH:MM:SS.sss\",  # 2024-05-29 13:45:30.123 (ISO)     \"DD-MM-YYYY HH:MM:SS\",  # 29-05-2024 13:45:30 (Brasileiro)     \"DD/MM/YYYY HH:MM:SS\",  # 29/05/2024 13:45:30 (Brasileiro)     \"MM-DD-YYYY HH:MM:SS\",  # 05-29-2024 13:45:30 (USA)     \"MM/DD/YYYY HH:MM:SS\",  # 05/29/2024 13:45:30 (USA)     \"YYYY/MM/DD HH:MM:SS\",  # 2024/05/29 13:45:30 (ISO)     \"YYYY.MM.DD HH:MM:SS\",  # 2024.05.29 13:45:30 (ISO)     \"DD.MM.YYYY HH:MM:SS\",  # 29.05.2024 13:45:30 (Europeu)     \"DD.MM.YYYY HH:MM:SS.sss\",  # 29.05.2024 13:45:30.123 (Europeu)     \"DD/MM/YYYY, HH:MM:SS\",  # 29/05/2024, 13:45:30 (Brasileiro)     \"YYYY-MM-DD'T'HH:MM:SS\",  # 2024-05-29T13:45:30 (ISO 8601)     \"YYYY-MM-DD'T'HH:MM:SS.sss\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)     \"YYYYMMDDTHHMMSS\",  # 20240529T134530 (ISO 8601 compacto)     \"YYYYMMDDHHMMSS\",  # 20240529134530 (Compacto)     \"YYYY/MM/DD HH:MM\",  # 2024/05/29 13:45 (ISO)     \"MM/DD/YYYY HH:MM\",  # 05/29/2024 13:45 (USA)     \"DD-MM-YYYY HH:MM\",  # 29-05-2024 13:45 (Brasileiro)     \"DD/MM/YYYY HH:MM\",  # 29/05/2024 13:45 (Brasileiro)     \"DD.MM.YYYY HH:MM\",  # 29.05.2024 13:45 (Europeu)     \"YYYY-MM-DD HH:MM\",  # 2024-05-29 13:45 (ISO)     \"DD/MM/YY HH:MM\",  # 29/05/24 13:45 (Brasileiro)     \"DD/MM/YY HH:MM:SS\",  # 29/05/24 13:45:30 (Brasileiro)     \"MM/DD/YY HH:MM\",  # 05/29/24 13:45 (USA)     \"MM/DD/YY HH:MM:SS\",  # 05/29/24 13:45:30 (USA)     \"DD.MM.YY HH:MM\",  # 29.05.24 13:45 (Europeu)     \"DD.MM.YY HH:MM:SS\",  # 29.05.24 13:45:30 (Europeu)     \"YYYY-MM-DD HH:MM:SS Z\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)     \"YYYY-MM-DD HH:MM:SSZZ\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)     \"YYYY-MM-DDTHH:MM:SSZZ\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"YYYY-MM-DDTHH:MM:SS.sssZZ\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)     \"YYYY/MM/DDTHH:MM:SSZZ\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"YYYY-MM-DDTHH:MM:SS.sssZ\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)     \"YYYY-MM-DDTHH:MM:SSZ\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)     \"YYYYMMDD HH:MM:SS\",  # 20240529 13:45:30 (Compacto)     \"YYYYMMDD HH:MM:SS.sss\",  # 20240529 13:45:30.123 (Compacto)     \"YYYYMMDD'T'HHMMSSZ\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)     \"YYYYMMDD'T'HHMMSS.sssZ\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)          # Formatos de data e hora com AM/PM     \"YYYY-MM-DD hh:MM:SS AM/PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:MM:SS AM/PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM/DD/YYYY hh:MM:SS AM/PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)     \"YYYY/MM/DD hh:MM:SS AM/PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"DD-MM-YYYY hh:MM:SS AM/PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:MM:SS AM/PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)          # Formatos de data sem hora     \"YYYY-MM-DD\",  # 2024-05-29 (ISO)     \"DD-MM-YYYY\",  # 29-05-2024 (Brasileiro)     \"DD/MM/YYYY\",  # 29/05/2024 (Brasileiro)     \"MM-DD-YYYY\",  # 05-29-2024 (USA)     \"MM/DD/YYYY\",  # 05/29/2024 (USA)     \"YYYY/MM/DD\",  # 2024/05/29 (ISO)     \"YYYY.MM.DD\",  # 2024.05.29 (ISO)     \"DD.MM.YYYY\",  # 29.05.2024 (Europeu)     \"DD/MM/YY\",  # 29/05/24 (Brasileiro)     \"MM/DD/YY\",  # 05/29/24 (USA)     \"DD.MM.YY\",  # 29.05.24 (Europeu)          \"YYYY/MM/DD hh:mm:ss A\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:mm:ss A\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:mm:ss A\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)     \"YYYY/MM/DD hh:mm A\",  # 2024/05/29 01:45 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:mm A\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:mm A\",  # 05-29-2024 01:45 PM (USA com AM/PM)          \"YYYYMMDD\",  # 20240529 (Compacto)     \"YYMMDD\",  # 240529 (Compacto curto)     \"YY/MM/DD\",  # 24/05/29 (Curto)     \"YY-MM-DD\",  # 24-05-29 (Curto)     \"YY.MM.DD\",  # 24.05.29 (Curto)          \"DD MMM YYYY\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)     \"DD MMMM YYYY\",  # 29 May 2024 (Dia, m\u00eas completo e ano)     \"MMM DD, YYYY\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)     \"MMMM DD, YYYY\",  # May 29, 2024 (M\u00eas completo, dia e ano)     \"MMM DD YYYY\",  # May 29 2024 (M\u00eas abreviado, dia e ano)     \"MMMM DD YYYY\",  # May 29 2024 (M\u00eas completo, dia e ano)          \"DD/MMM/YYYY\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)     \"DD-MMM-YYYY\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)     \"DD MMM, YYYY\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)          \"E, MMM DD YYYY HH:MM:SS\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)     \"EEEE, MMMM DD, YYYY HH:MM:SS\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)          \"E, DD MMM YYYY HH:MM:SS\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)     \"EEEE, DD MMMM YYYY HH:MM:SS\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)          \"E, DD MMM YYYY hh:mm:ss A\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)     \"EEEE, DD MMMM YYYY hh:mm:ss A\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)          \"E, MMM DD YYYY hh:mm:ss A\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)     \"EEEE, MMMM DD, YYYY hh:mm:ss A\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)          \"E, MMM DD, YY HH:MM\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)     \"EEEE, MMMM DD, YY HH:MM\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)          \"E, DD MMM, YY HH:MM\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)     \"EEEE, DD MMMM, YY HH:MM\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora) ]  In\u00a0[\u00a0]: Copied! <pre>exemplos_formatos_data_hora = [\n    # Formatos de data e hora\n    \"2024-05-29 13:45:30\",  # 2024-05-29 13:45:30 (ISO)\n    \"2024-05-29 13:45:30.123\",  # 2024-05-29 13:45:30.123 (ISO)\n    \"29-05-2024 13:45:30\",  # 29-05-2024 13:45:30 (Brasileiro)\n    \"29/05/2024 13:45:30\",  # 29/05/2024 13:45:30 (Brasileiro)\n    \"05-29-2024 13:45:30\",  # 05-29-2024 13:45:30 (USA)\n    \"05/29/2024 13:45:30\",  # 05/29/2024 13:45:30 (USA)\n    \"2024/05/29 13:45:30\",  # 2024/05/29 13:45:30 (ISO)\n    \"2024.05.29 13:45:30\",  # 2024.05.29 13:45:30 (ISO)\n    \"29.05.2024 13:45:30\",  # 29.05.2024 13:45:30 (Europeu)\n    \"29.05.2024 13:45:30.123\",  # 29.05.2024 13:45:30.123 (Europeu)\n    \"29/05/2024, 13:45:30\",  # 29/05/2024, 13:45:30 (Brasileiro)\n    \"2024-05-29T13:45:30\",  # 2024-05-29T13:45:30 (ISO 8601)\n    \"2024-05-29T13:45:30.123\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)\n    \"20240529T134530\",  # 20240529T134530 (ISO 8601 compacto)\n    \"20240529134530\",  # 20240529134530 (Compacto)\n    \"2024/05/29 13:45\",  # 2024/05/29 13:45 (ISO)\n    \"05/29/2024 13:45\",  # 05/29/2024 13:45 (USA)\n    \"29-05-2024 13:45\",  # 29-05-2024 13:45 (Brasileiro)\n    \"29/05/2024 13:45\",  # 29/05/2024 13:45 (Brasileiro)\n    \"29.05.2024 13:45\",  # 29.05.2024 13:45 (Europeu)\n    \"2024-05-29 13:45\",  # 2024-05-29 13:45 (ISO)\n    \"29/05/24 13:45\",  # 29/05/24 13:45 (Brasileiro)\n    \"29/05/24 13:45:30\",  # 29/05/24 13:45:30 (Brasileiro)\n    \"05/29/24 13:45\",  # 05/29/24 13:45 (USA)\n    \"05/29/24 13:45:30\",  # 05/29/24 13:45:30 (USA)\n    \"29.05.24 13:45\",  # 29.05.24 13:45 (Europeu)\n    \"29.05.24 13:45:30\",  # 29.05.24 13:45:30 (Europeu)\n    \"2024-05-29 13:45:30 +0000\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)\n    \"2024-05-29 13:45:30+0000\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)\n    \"2024-05-29T13:45:30+0000\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"2024-05-29T13:45:30.123+0000\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)\n    \"2024/05/29T13:45:30+0000\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"2024-05-29T13:45:30.123Z\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)\n    \"2024-05-29T13:45:30Z\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)\n    \"20240529 13:45:30\",  # 20240529 13:45:30 (Compacto)\n    \"20240529 13:45:30.123\",  # 20240529 13:45:30.123 (Compacto)\n    \"20240529T134530Z\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)\n    \"20240529T134530.123Z\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)\n    \n    # Formatos de data e hora com AM/PM\n    \"2024-05-29 01:45:30 PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)\n    \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05/29/2024 01:45:30 PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)\n    \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"29-05-2024 01:45:30 PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \n    # Formatos de data sem hora\n    \"2024-05-29\",  # 2024-05-29 (ISO)\n    \"29-05-2024\",  # 29-05-2024 (Brasileiro)\n    \"29/05/2024\",  # 29/05/2024 (Brasileiro)\n    \"05-29-2024\",  # 05-29-2024 (USA)\n    \"05/29/2024\",  # 05/29/2024 (USA)\n    \"2024/05/29\",  # 2024/05/29 (ISO)\n    \"2024.05.29\",  # 2024.05.29 (ISO)\n    \"29.05.2024\",  # 29.05.2024 (Europeu)\n    \"29/05/24\",  # 29/05/24 (Brasileiro)\n    \"05/29/24\",  # 05/29/24 (USA)\n    \"29.05.24\",  # 29.05.24 (Europeu)\n    \n    \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \"2024/05/29 01:45 PM\",  # 2024/05/29 01:45 PM (ISO com AM/PM)\n    \"29/05/2024 01:45 PM\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45 PM\",  # 05-29-2024 01:45 PM (USA com AM/PM)\n    \n    \"20240529\",  # 20240529 (Compacto)\n    \"240529\",  # 240529 (Compacto curto)\n    \"24/05/29\",  # 24/05/29 (Curto)\n    \"24-05-29\",  # 24-05-29 (Curto)\n    \"24.05.29\",  # 24.05.29 (Curto)\n    \n    \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)\n    \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas completo e ano)\n    \"May 29, 2024\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)\n    \"May 29, 2024\",  # May 29, 2024 (M\u00eas completo, dia e ano)\n    \"May 29 2024\",  # May 29 2024 (M\u00eas abreviado, dia e ano)\n    \"May 29 2024\",  # May 29 2024 (M\u00eas completo, dia e ano)\n    \n    \"29/May/2024\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)\n    \"29-May-2024\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)\n    \"29 May, 2024\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)\n    \n    \"Wed, May 29 2024 13:45:30\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)\n    \"Wednesday, May 29, 2024 13:45:30\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)\n    \n    \"Wed, 29 May 2024 13:45:30\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)\n    \"Wednesday, 29 May 2024 13:45:30\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)\n    \n    \"Wed, 29 May 2024 01:45:30 PM\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)\n    \"Wednesday, 29 May 2024 01:45:30 PM\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)\n    \n    \"Wed, May 29 2024 01:45:30 PM\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)\n    \"Wednesday, May 29, 2024 01:45:30 PM\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)\n    \n    \"Wed, May 29, 24 13:45\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)\n    \"Wednesday, May 29, 24 13:45\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)\n    \n    \"Wed, 29 May, 24 13:45\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)\n    \"Wednesday, 29 May, 24 13:45\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora)\n]\n</pre> exemplos_formatos_data_hora = [     # Formatos de data e hora     \"2024-05-29 13:45:30\",  # 2024-05-29 13:45:30 (ISO)     \"2024-05-29 13:45:30.123\",  # 2024-05-29 13:45:30.123 (ISO)     \"29-05-2024 13:45:30\",  # 29-05-2024 13:45:30 (Brasileiro)     \"29/05/2024 13:45:30\",  # 29/05/2024 13:45:30 (Brasileiro)     \"05-29-2024 13:45:30\",  # 05-29-2024 13:45:30 (USA)     \"05/29/2024 13:45:30\",  # 05/29/2024 13:45:30 (USA)     \"2024/05/29 13:45:30\",  # 2024/05/29 13:45:30 (ISO)     \"2024.05.29 13:45:30\",  # 2024.05.29 13:45:30 (ISO)     \"29.05.2024 13:45:30\",  # 29.05.2024 13:45:30 (Europeu)     \"29.05.2024 13:45:30.123\",  # 29.05.2024 13:45:30.123 (Europeu)     \"29/05/2024, 13:45:30\",  # 29/05/2024, 13:45:30 (Brasileiro)     \"2024-05-29T13:45:30\",  # 2024-05-29T13:45:30 (ISO 8601)     \"2024-05-29T13:45:30.123\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)     \"20240529T134530\",  # 20240529T134530 (ISO 8601 compacto)     \"20240529134530\",  # 20240529134530 (Compacto)     \"2024/05/29 13:45\",  # 2024/05/29 13:45 (ISO)     \"05/29/2024 13:45\",  # 05/29/2024 13:45 (USA)     \"29-05-2024 13:45\",  # 29-05-2024 13:45 (Brasileiro)     \"29/05/2024 13:45\",  # 29/05/2024 13:45 (Brasileiro)     \"29.05.2024 13:45\",  # 29.05.2024 13:45 (Europeu)     \"2024-05-29 13:45\",  # 2024-05-29 13:45 (ISO)     \"29/05/24 13:45\",  # 29/05/24 13:45 (Brasileiro)     \"29/05/24 13:45:30\",  # 29/05/24 13:45:30 (Brasileiro)     \"05/29/24 13:45\",  # 05/29/24 13:45 (USA)     \"05/29/24 13:45:30\",  # 05/29/24 13:45:30 (USA)     \"29.05.24 13:45\",  # 29.05.24 13:45 (Europeu)     \"29.05.24 13:45:30\",  # 29.05.24 13:45:30 (Europeu)     \"2024-05-29 13:45:30 +0000\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)     \"2024-05-29 13:45:30+0000\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)     \"2024-05-29T13:45:30+0000\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"2024-05-29T13:45:30.123+0000\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)     \"2024/05/29T13:45:30+0000\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"2024-05-29T13:45:30.123Z\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)     \"2024-05-29T13:45:30Z\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)     \"20240529 13:45:30\",  # 20240529 13:45:30 (Compacto)     \"20240529 13:45:30.123\",  # 20240529 13:45:30.123 (Compacto)     \"20240529T134530Z\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)     \"20240529T134530.123Z\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)          # Formatos de data e hora com AM/PM     \"2024-05-29 01:45:30 PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)     \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"05/29/2024 01:45:30 PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)     \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"29-05-2024 01:45:30 PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)          # Formatos de data sem hora     \"2024-05-29\",  # 2024-05-29 (ISO)     \"29-05-2024\",  # 29-05-2024 (Brasileiro)     \"29/05/2024\",  # 29/05/2024 (Brasileiro)     \"05-29-2024\",  # 05-29-2024 (USA)     \"05/29/2024\",  # 05/29/2024 (USA)     \"2024/05/29\",  # 2024/05/29 (ISO)     \"2024.05.29\",  # 2024.05.29 (ISO)     \"29.05.2024\",  # 29.05.2024 (Europeu)     \"29/05/24\",  # 29/05/24 (Brasileiro)     \"05/29/24\",  # 05/29/24 (USA)     \"29.05.24\",  # 29.05.24 (Europeu)          \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)     \"2024/05/29 01:45 PM\",  # 2024/05/29 01:45 PM (ISO com AM/PM)     \"29/05/2024 01:45 PM\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45 PM\",  # 05-29-2024 01:45 PM (USA com AM/PM)          \"20240529\",  # 20240529 (Compacto)     \"240529\",  # 240529 (Compacto curto)     \"24/05/29\",  # 24/05/29 (Curto)     \"24-05-29\",  # 24-05-29 (Curto)     \"24.05.29\",  # 24.05.29 (Curto)          \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)     \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas completo e ano)     \"May 29, 2024\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)     \"May 29, 2024\",  # May 29, 2024 (M\u00eas completo, dia e ano)     \"May 29 2024\",  # May 29 2024 (M\u00eas abreviado, dia e ano)     \"May 29 2024\",  # May 29 2024 (M\u00eas completo, dia e ano)          \"29/May/2024\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)     \"29-May-2024\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)     \"29 May, 2024\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)          \"Wed, May 29 2024 13:45:30\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)     \"Wednesday, May 29, 2024 13:45:30\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)          \"Wed, 29 May 2024 13:45:30\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)     \"Wednesday, 29 May 2024 13:45:30\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)          \"Wed, 29 May 2024 01:45:30 PM\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)     \"Wednesday, 29 May 2024 01:45:30 PM\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)          \"Wed, May 29 2024 01:45:30 PM\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)     \"Wednesday, May 29, 2024 01:45:30 PM\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)          \"Wed, May 29, 24 13:45\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)     \"Wednesday, May 29, 24 13:45\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)          \"Wed, 29 May, 24 13:45\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)     \"Wednesday, 29 May, 24 13:45\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora) ]"}]}