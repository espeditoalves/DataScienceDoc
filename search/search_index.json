{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. Projeto Ci\u00eancia de Dados","text":"<p>Este reposit\u00f3rio tem como objetivo centralizar e organizar todo o conhecimento em Ci\u00eancia de Dados que venho acumulando ao longo da minha carreira. Aqui, voc\u00ea encontrar\u00e1 materiais estruturados sobre estat\u00edstica, machine learning, engenharia de machine learning e outras \u00e1reas essenciais para o desenvolvimento de solu\u00e7\u00f5es baseadas em dados.</p> <p>O conte\u00fado \u00e9 disponibilizado de forma did\u00e1tica, contemplando desde conceitos fundamentais at\u00e9 t\u00e9cnicas avan\u00e7adas, com exemplos pr\u00e1ticos e refer\u00eancias para aprofundamento. Este projeto est\u00e1 em constante evolu\u00e7\u00e3o, refletindo meu compromisso com aprendizado cont\u00ednuo e compartilhamento de conhecimento.</p> <p></p> <p>Autor</p> <ul> <li>Email: espedito.ferreira.alves@outlook.com</li> <li>Linkdin: Espedito Ferreira Alves</li> <li>GitHub: espeditoalves</li> </ul>"},{"location":"#2-organizacao-do-repositorio","title":"2. Organiza\u00e7\u00e3o do Reposit\u00f3rio","text":""},{"location":"#21-sumario","title":"2.1. Sum\u00e1rio","text":"<p>O reposit\u00f3rio est\u00e1 organizado nos seguintes cap\u00edtulos:</p> <ul> <li>\ud83d\udcca 1. Estat\u00edstica</li> </ul> <p>Introdu\u00e7\u00e3o \u00e0 Estat\u00edstica (Conceitos b\u00e1sicos, distribui\u00e7\u00f5es, testes de hip\u00f3teses e an\u00e1lise explorat\u00f3ria de dados)</p> <ul> <li>\ud83e\udd16 2. Machine Learning</li> </ul> <p>Em constru\u00e7\u00e3o (Abordagem supervisionada/n\u00e3o supervisionada, modelos de classifica\u00e7\u00e3o e regress\u00e3o, avalia\u00e7\u00e3o de desempenho)</p> <ul> <li>\u2699\ufe0f 3. Machine Learning Engineer</li> </ul> <p>Em constru\u00e7\u00e3o (Deploy de modelos, pipelines de dados, monitoramento e escalabilidade em produ\u00e7\u00e3o)</p> <p>Objetivo</p> <p>Servir como um reposit\u00f3rio de conhecimento pessoal, podendo ser utilizado como refer\u00eancia para profissionais de dados, estudantes e entusiastas, combinando teoria e pr\u00e1tica em um formato acess\u00edvel.</p> <p>Principais t\u00f3picos de estudos:</p> <p>Assuntos e t\u00f3picos para estudar em ci\u00eancia de dados Resumo.</p>"},{"location":"0_resumo/Resumo/","title":"1. Mapeamento de assuntos sobre ciencia de dados","text":""},{"location":"0_resumo/Resumo/#2-profissional-basico-ciencia-de-dados","title":"2. PROFISSIONAL B\u00c1SICO - CI\u00caNCIA DE DADOS","text":""},{"location":"0_resumo/Resumo/#21-i-matematica","title":"2.1. I - MATEM\u00c1TICA:","text":""},{"location":"0_resumo/Resumo/#211-calculo-basico","title":"2.1.1. C\u00e1lculo B\u00e1sico:","text":"<ul> <li>fun\u00e7\u00f5es; </li> <li>limites; </li> <li>derivadas; </li> <li>derivadas parciais; </li> <li>m\u00e1ximos e m\u00ednimos; integrais.  </li> </ul>"},{"location":"0_resumo/Resumo/#212-algebra-linear","title":"2.1.2. \u00c1lgebra Linear:","text":"<ul> <li>vetores e matrizes; </li> <li>opera\u00e7\u00f5es com vetores e matrizes; </li> <li>tipos de matrizes; </li> <li>transforma\u00e7\u00f5es lineares; </li> <li>espa\u00e7os e subespa\u00e7os vetoriais de Rn; </li> <li>sistemas de equa\u00e7\u00f5es lineares; </li> <li>normas (L1, L2, infinita, p-generalizada, Minkowksi e Chebyshev), autovalores e autovetores; </li> <li>decomposi\u00e7\u00e3o matricial (Cholesky e Singular Value Decomposition (SVD)). </li> </ul>"},{"location":"0_resumo/Resumo/#213-otimizacao-matematica","title":"2.1.3. Otimiza\u00e7\u00e3o Matem\u00e1tica:","text":"<ul> <li>programa\u00e7\u00e3o linear inteira e mista; </li> <li>problemas de otimiza\u00e7\u00e3o unidimensionais e multidimensionais, com e sem restri\u00e7\u00f5es; </li> <li>otimiza\u00e7\u00e3o convexa; </li> <li>programa\u00e7\u00e3o din\u00e2mica. </li> </ul>"},{"location":"0_resumo/Resumo/#22-ii-probabilidade-e-estatistica","title":"2.2. II - PROBABILIDADE E ESTAT\u00cdSTICA:","text":""},{"location":"0_resumo/Resumo/#221-fundamentos-de-probabilidade","title":"2.2.1. Fundamentos de probabilidade:","text":"<ul> <li>defini\u00e7\u00f5es b\u00e1sicas de probabilidade; </li> <li>axiomas; </li> <li>probabilidade condicional. </li> </ul>"},{"location":"0_resumo/Resumo/#222-variaveis-aleatorias-e-distribuicoes-de-probabilidades","title":"2.2.2. Vari\u00e1veis aleat\u00f3rias e distribui\u00e7\u00f5es de probabilidades:","text":"<ul> <li>vari\u00e1veis aleat\u00f3rias; </li> <li>fun\u00e7\u00f5es de probabilidade; </li> <li>principais distribui\u00e7\u00f5es discretas e cont\u00ednuas (Uniforme, Binomial, Normal, Poisson, Bernoulli e Exponencial). </li> </ul>"},{"location":"0_resumo/Resumo/#223-estatisticas-descritivas","title":"2.2.3. Estat\u00edsticas Descritivas:","text":"<ul> <li>medidas de tend\u00eancia central (m\u00e9dia, mediana e moda);</li> <li>medidas de dispers\u00e3o (vari\u00e2ncia, desvio padr\u00e3o e amplitude); </li> <li>medidas de posi\u00e7\u00e3o (percentis e quartis). </li> </ul>"},{"location":"0_resumo/Resumo/#224-teoremas-fundamentais-da-probabilidade","title":"2.2.4. Teoremas fundamentais da probabilidade:","text":"<ul> <li>independ\u00eancia de eventos; </li> <li>teorema de Bayes; </li> <li>teorema da probabilidade total; </li> <li>lei dos grandes n\u00fameros; </li> <li>teorema central do limite. </li> </ul>"},{"location":"0_resumo/Resumo/#225-distribuicoes-amostrais","title":"2.2.5. Distribui\u00e7\u00f5es amostrais:","text":"<ul> <li>distribui\u00e7\u00e3o amostral da m\u00e9dia; </li> <li>distribui\u00e7\u00e3o amostral da propor\u00e7\u00e3o; </li> <li>distribui\u00e7\u00e3o qui-quadrado; </li> <li>distribui\u00e7\u00e3o t de Student; </li> <li>distribui\u00e7\u00e3o F. </li> </ul>"},{"location":"0_resumo/Resumo/#226-inferencia-estatistica","title":"2.2.6. Infer\u00eancia estat\u00edstica:","text":"<ul> <li>estima\u00e7\u00e3o pontual e intervalar; </li> <li>intervalos de confian\u00e7a; </li> <li>testes de hip\u00f3teses (formula\u00e7\u00e3o, tipos de erros, e poder do teste); </li> <li>testes z e t para m\u00e9dias; </li> <li>testes de propor\u00e7\u00f5es; </li> <li>testes qui-quadrado para independ\u00eancia e ajuste de Goodness-of-Fit; </li> <li>teste A/B. </li> </ul>"},{"location":"0_resumo/Resumo/#227-correlacao","title":"2.2.7. Correla\u00e7\u00e3o:","text":"<ul> <li>correla\u00e7\u00e3o e causalidade; </li> <li>correla\u00e7\u00e3o de Pearson; </li> <li>correla\u00e7\u00e3o de Spearman; </li> <li>correla\u00e7\u00e3o parcial. </li> </ul>"},{"location":"0_resumo/Resumo/#228-inferencia-bayesiana","title":"2.2.8. Infer\u00eancia Bayesiana:","text":"<ul> <li>distribui\u00e7\u00f5es a priori e a posteriori; </li> <li>estimativa pontual e intervalar; </li> <li>predi\u00e7\u00e3o e testes de hip\u00f3teses bayesianos; </li> <li>crit\u00e9rios de sele\u00e7\u00e3o de modelos; </li> <li>m\u00e9todos MCMC.</li> </ul>"},{"location":"0_resumo/Resumo/#23-iii-financas-quantitativas","title":"2.3. III - FINAN\u00c7AS QUANTITATIVAS:","text":""},{"location":"0_resumo/Resumo/#231-matematica-financeira","title":"2.3.1. Matem\u00e1tica financeira:","text":"<ul> <li>Conven\u00e7\u00f5es de C\u00e1lculo de Juros; </li> <li>Valor Presente L\u00edquido; </li> <li>Taxa Interna de Retorno; </li> <li>proje\u00e7\u00e3o de fluxos de caixa futuros. </li> </ul>"},{"location":"0_resumo/Resumo/#232-mercados-de-taxas-de-juros","title":"2.3.2. Mercados de Taxas de Juros:","text":"<ul> <li>Instrumentos de Renda Fixa; </li> <li>Taxa Spot; </li> <li>Taxa Foward; </li> <li>Rela\u00e7\u00f5es B\u00e1sicas de N\u00e3o Arbitragem no Mercado de Juros;</li> <li>Curvas de Juros; </li> <li>Bootstraping de Curvas de Juros; </li> <li>Duration; </li> <li>Convexidade; </li> <li>t\u00e9cnicas de interpola\u00e7\u00e3o de taxas de juros; </li> <li>modelos de Svenson e de Nelson-Siegel. </li> </ul>"},{"location":"0_resumo/Resumo/#233-medidas-de-desempenho-e-de-riscos","title":"2.3.3. Medidas de Desempenho e de Riscos:","text":"<ul> <li>Volatilidade; </li> <li>Value At Risk; </li> <li>Conditional Value at Risk; </li> <li>Backtesting de Modelos de Risco; </li> <li>Maximum Drawdown; </li> <li>Sharpe Ratio; </li> <li>Information Ratio. </li> </ul>"},{"location":"0_resumo/Resumo/#234-otimizacao-de-carteiras","title":"2.3.4. Otimiza\u00e7\u00e3o de carteiras:","text":"<ul> <li>modelo de m\u00e9dia-vari\u00e2ncia com e sem restri\u00e7\u00f5es; </li> <li>modelos de paridade de riscos; </li> <li>modelos de paridade de riscos hier\u00e1rquica (HRP). </li> </ul>"},{"location":"0_resumo/Resumo/#235-simulacao-de-monte-carlo-em-financas","title":"2.3.5. Simula\u00e7\u00e3o de Monte Carlo em Finan\u00e7as:","text":"<ul> <li>principais aplica\u00e7\u00f5es em precifica\u00e7\u00e3o e an\u00e1lise de riscos.</li> </ul>"},{"location":"0_resumo/Resumo/#236-derivativos","title":"2.3.6. Derivativos:","text":"<ul> <li>conceitos gerais; </li> <li>derivativos de renda vari\u00e1vel; </li> <li>derivativos de renda fixa; </li> <li>modelo de Black-Scholes. </li> </ul>"},{"location":"0_resumo/Resumo/#24-iv-dados-e-bases-de-dados","title":"2.4. IV- DADOS E BASES DE DADOS:","text":""},{"location":"0_resumo/Resumo/#241-conceitos-fundamentais-de-dados","title":"2.4.1. Conceitos fundamentais de dados:","text":"<ul> <li>o que s\u00e3o dados; </li> <li>processos geradores de dados; </li> <li>tipos e classes de dados; </li> <li>formatos de arquivos de dados comuns (txt, csv, xlsx, xml, json e parquet). </li> </ul>"},{"location":"0_resumo/Resumo/#242-introducao-a-bases-de-dados","title":"2.4.2. Introdu\u00e7\u00e3o a Bases de Dados:","text":"<ul> <li>o que s\u00e3o bases de dados; </li> <li>tipos de bases de dados; </li> <li>metadados; </li> <li>tidy data. </li> </ul>"},{"location":"0_resumo/Resumo/#243-introducao-ao-armazenamento-de-dados","title":"2.4.3. Introdu\u00e7\u00e3o ao armazenamento de dados:","text":"<ul> <li>armazenamento de arquivos; </li> <li>principais estruturas de armazenamento de dados anal\u00edticos (data warehouse, data mart, data lake data lakehouse, vector stores), suas diferen\u00e7as conceituais e casos de uso;</li> <li>armazenamento na nuvem. </li> </ul>"},{"location":"0_resumo/Resumo/#244-sistemas-gerenciadores-de-base-de-dados-sgbd","title":"2.4.4. Sistemas Gerenciadores de Base de Dados (SGBD):","text":"<ul> <li>defini\u00e7\u00e3o de SGBD; </li> <li>principais fun\u00e7\u00f5es; </li> <li>principais tipos de SGBDs (SQL e NoSQL) e suas diferen\u00e7as; transa\u00e7\u00f5es e \u00edndices.</li> </ul>"},{"location":"0_resumo/Resumo/#245-5modelo-de-dados","title":"2.4.5. 5.Modelo de dados:","text":"<ul> <li>modelo de entidade-relacionamento (ER); </li> <li>modelo relacional:</li> <li>tabelas, </li> <li>esquemas, </li> <li>chaves, </li> <li>consultas; </li> <li>dados estruturados, semiestruturados e n\u00e3o estruturados;</li> <li>modelo chave-valor; </li> <li>modelo colunar; </li> <li>modelo orientado a documentos; </li> <li>modelo orientado a grafos. </li> </ul>"},{"location":"0_resumo/Resumo/#246-ingestao-e-armazenamento-de-dados","title":"2.4.6. Ingest\u00e3o e armazenamento de dados;","text":"<ul> <li>defini\u00e7\u00e3o de ingest\u00e3o em lote (batch) e em tempo real (stream). </li> </ul>"},{"location":"0_resumo/Resumo/#247-big-data","title":"2.4.7. Big Data:","text":"<ul> <li>conceito de big data; </li> <li>conceitos gerais sobre t\u00e9cnicas e ferramentas para lidar com grandes volumes de dados (Spark, Hadoop, HDFS e MapReduce). </li> </ul>"},{"location":"0_resumo/Resumo/#25-v-gestao-de-projetos-de-ciencia-de-dados","title":"2.5. V - GEST\u00c3O DE PROJETOS DE CI\u00caNCIA DE DADOS:","text":""},{"location":"0_resumo/Resumo/#251-ciclo-de-vida-de-projetos-de-ciencia-de-dados","title":"2.5.1. Ciclo de vida de projetos de ci\u00eancia de dados.","text":""},{"location":"0_resumo/Resumo/#252-metodologias-de-gestao-de-projetos-de-ciencia-de-dados","title":"2.5.2. Metodologias de gest\u00e3o de projetos de ci\u00eancia de dados:","text":"<ul> <li>CRISP-DM; </li> <li>Microsoft Team Data Science Process (TDSP); </li> <li>princ\u00edpios de m\u00e9todos \u00e1geis (Scrum/Kanban); </li> <li>fundamentos de design thinking. </li> </ul>"},{"location":"0_resumo/Resumo/#253-principais-papeis-envolvidos-em-projetos-de-ciencia-de-dados","title":"2.5.3. Principais pap\u00e9is envolvidos em projetos de ci\u00eancia de dados.","text":""},{"location":"0_resumo/Resumo/#26-vi-qualidade-e-preparacao-de-dados","title":"2.6. VI - QUALIDADE E PREPARA\u00c7\u00c3O DE DADOS:","text":""},{"location":"0_resumo/Resumo/#261-metadados","title":"2.6.1. Metadados:","text":"<ul> <li>a sua import\u00e2ncia para avalia\u00e7\u00e3o da qualidade de dados; </li> <li>linhagem de dados; </li> </ul>"},{"location":"0_resumo/Resumo/#262-coleta-de-dados","title":"2.6.2. Coleta de dados:","text":"<ul> <li>fontes comuns de dados (internas e externas); </li> <li>interface de programa\u00e7\u00e3o de aplica\u00e7\u00e3o (API); </li> <li>t\u00e9cnicas de web scraping. </li> </ul>"},{"location":"0_resumo/Resumo/#263-problemas-comuns-de-qualidade-de-dados","title":"2.6.3. Problemas comuns de qualidade de dados:","text":"<ul> <li>valores ausentes; </li> <li>duplicatas; </li> <li>outliers; </li> <li>desbalanceamento; </li> <li>erros de imputa\u00e7\u00e3o. </li> </ul>"},{"location":"0_resumo/Resumo/#264-preparacao-de-dados","title":"2.6.4. Prepara\u00e7\u00e3o de dados:","text":"<ul> <li>t\u00e9cnicas de tratamento e limpeza de dados; </li> <li>t\u00e9cnicas detec\u00e7\u00e3o de vieses; </li> <li>data profiling. </li> </ul>"},{"location":"0_resumo/Resumo/#265-pre-processamento-de-dados","title":"2.6.5. Pr\u00e9-processamento de dados:","text":"<ul> <li>t\u00e9cnicas de normaliza\u00e7\u00e3o e padroniza\u00e7\u00e3o; </li> <li>discretiza\u00e7\u00e3o; </li> <li>metodologias de codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas (encoding). </li> </ul>"},{"location":"0_resumo/Resumo/#266-feature-engineering","title":"2.6.6. Feature engineering:","text":"<ul> <li>processos para enriquecimento de dados, com cria\u00e7\u00e3o e sele\u00e7\u00e3o de features relevantes; </li> <li>transforma\u00e7\u00f5es matem\u00e1ticas e estat\u00edsticas comuns em vari\u00e1veis. </li> </ul>"},{"location":"0_resumo/Resumo/#267-divisao-de-dados","title":"2.6.7. Divis\u00e3o de dados:","text":"<ul> <li>t\u00e9cnicas de amostragem; </li> <li>divis\u00e3o entre treinamento, valida\u00e7\u00e3o e teste; </li> <li>abordagens para cross-validation.</li> </ul>"},{"location":"0_resumo/Resumo/#27-vii-modelagem","title":"2.7. VII - MODELAGEM:","text":""},{"location":"0_resumo/Resumo/#271-pipeline-de-treinamento-de-modelos-e-suas-etapas","title":"2.7.1. Pipeline de treinamento de modelos e suas etapas.","text":""},{"location":"0_resumo/Resumo/#272-otimizacao-de-hiperparametros","title":"2.7.2. Otimiza\u00e7\u00e3o de hiperpar\u00e2metros:","text":"<ul> <li>grid search; </li> <li>random search; </li> <li>algoritmos de otimiza\u00e7\u00e3o avan\u00e7ados; </li> <li>automl; </li> <li>autotuning; </li> <li>autofeature engineering. </li> </ul>"},{"location":"0_resumo/Resumo/#273-metricas-para-avaliacao-e-selecao-de-modelos","title":"2.7.3. M\u00e9tricas para avalia\u00e7\u00e3o e sele\u00e7\u00e3o de modelos:","text":"<ul> <li>m\u00e9tricas para regress\u00e3o (MSE; RMSE; MAE; R\u00b2; R\u00b2 ajustado);</li> <li>m\u00e9tricas para classifica\u00e7\u00e3o (accuracy, precision, recall, F1-score e ROC-AUC); </li> <li>an\u00e1lise de matriz de confus\u00e3o; </li> <li>trade-off entre vi\u00e9s e vari\u00e2ncia; </li> <li>detec\u00e7\u00e3o de overfitting e underfitting. </li> </ul>"},{"location":"0_resumo/Resumo/#274-tecnicas-de-regularizacao","title":"2.7.4. T\u00e9cnicas de regulariza\u00e7\u00e3o:","text":"<ul> <li>lasso; </li> <li>ridge; </li> <li>elastic net; </li> <li>dropout; </li> <li>early stopping; </li> <li>batch normalization. </li> </ul>"},{"location":"0_resumo/Resumo/#275-dados-desbalanceados","title":"2.7.5. Dados desbalanceados:","text":"<ul> <li>t\u00e9cnicas para lidar com dados desbalanceados;</li> <li>oversampling; </li> <li>undersampling; </li> <li>dados sint\u00e9ticos; </li> <li>ajuste de pesos. </li> </ul>"},{"location":"0_resumo/Resumo/#276-validacao-de-modelos","title":"2.7.6. Valida\u00e7\u00e3o de Modelos:","text":"<ul> <li>K-fold cross-validation; </li> <li>leave-one-out cross-validation; </li> <li>bootstrap. </li> </ul>"},{"location":"0_resumo/Resumo/#277-modelagem-de-ia-centrada-em-dados-data-centric","title":"2.7.7. Modelagem de IA centrada em dados (data-centric).","text":""},{"location":"0_resumo/Resumo/#278-interpretabilidade-de-modelos","title":"2.7.8. Interpretabilidade de modelos:","text":"<ul> <li>feature importance; </li> <li>valores de Shapley (SHAP) e LIME. </li> </ul>"},{"location":"0_resumo/Resumo/#279-implantacao-de-modelos-em-producao","title":"2.7.9. Implanta\u00e7\u00e3o de modelos em produ\u00e7\u00e3o:","text":"<ul> <li>exporta\u00e7\u00e3o de modelos (pickle, PMML e ONNX); </li> <li>modelos como servi\u00e7o (APIs; microsservi\u00e7os); </li> <li>integra\u00e7\u00e3o com sistemas existentes; </li> <li>APIs e servi\u00e7os web; </li> <li>conceitos de MLOps; </li> <li>implanta\u00e7\u00e3o local (on premise) e na nuvem. </li> </ul>"},{"location":"0_resumo/Resumo/#2710-monitoramento-de-modelos","title":"2.7.10. Monitoramento de modelos:","text":"<ul> <li>monitoramento de desempenho; </li> <li>data drift; </li> <li>concept drift; </li> <li>detec\u00e7\u00e3o de drifts; </li> <li>retreino e atualiza\u00e7\u00e3o de modelos. </li> </ul>"},{"location":"0_resumo/Resumo/#28-viii-classes-de-modelos","title":"2.8. VIII - CLASSES DE MODELOS:","text":""},{"location":"0_resumo/Resumo/#281-reducao-de-dimensionalidade","title":"2.8.1. Redu\u00e7\u00e3o de dimensionalidade:","text":"<ul> <li>Principal Component Analysis (PCA); </li> <li>LDA; </li> <li>ICA; </li> <li>T-SNE; </li> <li>uso de autoencoders. </li> </ul>"},{"location":"0_resumo/Resumo/#282-tecnicas-de-clusterizacao","title":"2.8.2. T\u00e9cnicas de clusteriza\u00e7\u00e3o:","text":"<ul> <li>K-Means; </li> <li>agrupamento hier\u00e1rquico; </li> <li>Gaussian Mixture Models; </li> <li>DBSCAN. </li> </ul>"},{"location":"0_resumo/Resumo/#283-tecnicas-de-classificacao","title":"2.8.3. T\u00e9cnicas de classifica\u00e7\u00e3o:","text":"<ul> <li>Regress\u00e3o log\u00edstica; </li> <li>K-Nearest Neighbors (KNN); </li> <li>Suport Vector Machines (SVM); </li> <li>Decision Trees (CART); </li> <li>classificadores Naive-Bayes (Binomial-Beta, Poisson-Gama, Normal-Normal); </li> <li>Florestas Aleat\u00f3rias (Random Forest). </li> </ul>"},{"location":"0_resumo/Resumo/#284-introducao-a-regressao","title":"2.8.4. Introdu\u00e7\u00e3o \u00e0 regress\u00e3o:","text":"<ul> <li>regress\u00e3o linear simples e m\u00faltipla; </li> <li>hip\u00f3teses cl\u00e1ssicas, m\u00e9todo dos m\u00ednimos quadrados, diagn\u00f3stico e avalia\u00e7\u00e3o de modelos de regress\u00e3o (F-test, coeficiente de determina\u00e7\u00e3o, an\u00e1lise de res\u00edduos e demais), testes de signific\u00e2ncia, intervalos de confian\u00e7a, an\u00e1lise ANOVA, modelos n\u00e3o lineares (log-log, lin-log, log-lin e inverso). </li> </ul>"},{"location":"0_resumo/Resumo/#285-ensembling-de-modelos","title":"2.8.5. Ensembling de modelos:","text":"<ul> <li>Bagging; </li> <li>boosting (AdaBoost, Gradient Boosting, XGBoost, LightGBM e CatBoost); </li> <li>stacking. </li> </ul>"},{"location":"0_resumo/Resumo/#286-sistemas-de-recomendacao","title":"2.8.6. Sistemas de recomenda\u00e7\u00e3o:","text":"<ul> <li>Filtragem colaborativa (baseadas em usu\u00e1rios ou itens);</li> <li>filtragem baseada em conte\u00fado; sistemas h\u00edbridos;</li> <li>problemas comuns (cold start, escalabilidade, data sparsity). </li> </ul>"},{"location":"0_resumo/Resumo/#287-modelos-de-series-temporais","title":"2.8.7. Modelos de s\u00e9ries temporais:","text":"<ul> <li>defini\u00e7\u00e3o; </li> <li>componentes (tend\u00eancia, sazonalidade, ciclos e ru\u00eddo);</li> <li>autocorrela\u00e7\u00e3o e autocorrela\u00e7\u00e3o parcial; </li> <li>conceito e testes de estacionaridade; </li> <li>cointegra\u00e7\u00e3o; </li> <li>modelos AR, ARMA e ARIMA; </li> <li>modelos de suaviza\u00e7\u00e3o exponencial; </li> <li>modelos de decomposi\u00e7\u00e3o; </li> <li>modelos de regress\u00e3o com vari\u00e1veis temporais (ARIMAX). </li> </ul>"},{"location":"0_resumo/Resumo/#288-topicos-em-regressao","title":"2.8.8. T\u00f3picos em regress\u00e3o:","text":"<ul> <li>modelos de dados em painel; </li> <li>GLM; </li> <li>regress\u00e3o espacial; </li> <li>regress\u00e3o quant\u00edlica; </li> <li>regress\u00e3o de Poisson; </li> <li>modelos VAR; </li> <li>ECM e GARCH. </li> </ul>"},{"location":"0_resumo/Resumo/#289-introducao-a-modelos-causais","title":"2.8.9. Introdu\u00e7\u00e3o a modelos causais:","text":"<ul> <li>fundamentos de causalidade estat\u00edstica, experimentos e quase-experimentos, desenho de descontinuidade de regress\u00e3o, modelos de vari\u00e1veis instrumentais, diferen\u00e7as em diferen\u00e7as, modelos de equa\u00e7\u00f5es estruturais (SEM), m\u00e9todos de pareamento.</li> </ul>"},{"location":"0_resumo/Resumo/#2810-redes-neurais","title":"2.8.10. Redes neurais:","text":"<ul> <li>Introdu\u00e7\u00e3o a Redes Neurais Artificiais (arquitetura, fun\u00e7\u00f5es de ativa\u00e7\u00e3o, treinamento, forward pass, backpropagation, loss functions, algoritmos de otimiza\u00e7\u00e3o, \u00e9pocas, batch size e demais); </li> <li>embeddings; </li> <li>redes profundas (deep learning); </li> <li>Redes Neurais Convolucionais (CNNs) e Recorrentes (RNNs);</li> <li>LSTM; </li> <li>GRU; </li> <li>GAN; </li> <li>modelos multimodais. </li> </ul>"},{"location":"0_resumo/Resumo/#2811-modelos-de-aprendizado-por-reforco","title":"2.8.11. Modelos de aprendizado por refor\u00e7o:","text":"<ul> <li>Q-Learning; </li> <li>Deep Q-Networks (DQN); </li> <li>Policy Gradient Methods; </li> <li>multi-armed bandit. </li> </ul>"},{"location":"0_resumo/Resumo/#2812-visao-computacional","title":"2.8.12. Vis\u00e3o Computacional:","text":"<ul> <li>t\u00e9cnicas de pr\u00e9-processamento de imagem; </li> <li>OCR; </li> <li>segmenta\u00e7\u00e3o e extra\u00e7\u00e3o de caracter\u00edsticas de imagens;</li> <li>detec\u00e7\u00e3o; </li> <li>segmenta\u00e7\u00e3o e reconhecimento de objetos; </li> <li>classifica\u00e7\u00e3o de imagens. </li> </ul>"},{"location":"0_resumo/Resumo/#2813-modelos-multi-modais","title":"2.8.13. Modelos multi-modais:","text":"<ul> <li>principais aplica\u00e7\u00f5es. </li> </ul>"},{"location":"0_resumo/Resumo/#2814-quantificacao-de-incertezas-em-modelos-preditivos","title":"2.8.14. Quantifica\u00e7\u00e3o de incertezas em modelos preditivos:","text":"<ul> <li>Programa\u00e7\u00e3o Probabil\u00edstica; </li> <li>Amostragem de Gibbs; </li> <li>Infer\u00eancia Variacional; </li> <li>Hamiltonian Monte Carlo; </li> <li>Modelos de Markov Ocultos; </li> <li>Aprendizado Profundo Probabil\u00edstico; </li> <li>Conformal Prediction. </li> </ul>"},{"location":"0_resumo/Resumo/#29-ix-processamento-de-linguagem-natural-nlp","title":"2.9. IX - PROCESSAMENTO DE LINGUAGEM NATURAL (NLP):","text":""},{"location":"0_resumo/Resumo/#291-tecnicas-de-pre-processamento-de-texto","title":"2.9.1. T\u00e9cnicas de pr\u00e9-processamento de texto:","text":"<ul> <li>limpeza; </li> <li>normaliza\u00e7\u00e3o; </li> <li>remo\u00e7\u00e3o de stop words; </li> <li>stemming; </li> <li>lematiza\u00e7\u00e3o e demais. </li> </ul>"},{"location":"0_resumo/Resumo/#292-representacao-de-texto","title":"2.9.2. Representa\u00e7\u00e3o de texto:","text":"<ul> <li>N-grams; </li> <li>CBoW; </li> <li>FTD-IDF; </li> <li>word embeddings (Word2Vec, GloVe e demais) e document embeddings (Doc2Vec, BERT, ELMo e demais). </li> </ul>"},{"location":"0_resumo/Resumo/#293-modelagem-de-topicos","title":"2.9.3. Modelagem de t\u00f3picos:","text":"<ul> <li>latent dirichlet allocation (LDA); </li> <li>non-negative matrix factorization (NMF). </li> </ul>"},{"location":"0_resumo/Resumo/#294-modelos-de-linguagem","title":"2.9.4. Modelos de linguagem:","text":"<ul> <li>modelos de linguagem tradicionais; </li> <li>redes neurais recorrentes; </li> <li>redes neurais convolucionais; </li> <li>transformers. </li> </ul>"},{"location":"0_resumo/Resumo/#295-tarefas-basicas-em-nlp","title":"2.9.5. Tarefas b\u00e1sicas em NLP:","text":"<ul> <li>classifica\u00e7\u00e3o de texto; </li> <li>an\u00e1lise de sentimento; </li> <li>extra\u00e7\u00e3o de informa\u00e7\u00e3o (NER; REL); </li> <li>similaridade textual; </li> <li>sumariza\u00e7\u00e3o de texto; </li> <li>rotula\u00e7\u00e3o de partes do discurso (POS-tagging) e tradu\u00e7\u00e3o autom\u00e1tica. </li> </ul>"},{"location":"0_resumo/Resumo/#296-aplicacoes-relacionadas-a-modelos-de-nlp","title":"2.9.6. Aplica\u00e7\u00f5es relacionadas a modelos de NLP:","text":"<ul> <li>gera\u00e7\u00e3o de texto; </li> <li>question answering e di\u00e1logo conversacional; </li> <li>retrieval augmented generation (RAG); </li> <li>chatbots; </li> <li>extra\u00e7\u00e3o estruturada de informa\u00e7\u00f5es; </li> <li>agentes de IA (IA agents). </li> </ul>"},{"location":"0_resumo/Resumo/#210-x-programacao-e-ferramentas","title":"2.10. X - PROGRAMA\u00c7\u00c3O E FERRAMENTAS:","text":""},{"location":"0_resumo/Resumo/#2101-linguagem-de-programacao-python","title":"2.10.1. Linguagem de programa\u00e7\u00e3o Python:","text":"<ul> <li>sintaxe b\u00e1sica; </li> <li>operadores; </li> <li>vari\u00e1veis; </li> <li>estruturas de dados (dataframes, listas, matrizes, dicion\u00e1rios e conjuntos); </li> <li>estruturas de controle de fluxo; </li> <li>fun\u00e7\u00f5es; </li> <li>escopo; </li> <li>m\u00e9todo; </li> <li>paraleliza\u00e7\u00e3o de rotinas; </li> <li>serializa\u00e7\u00e3o e desserializa\u00e7\u00e3o. </li> </ul>"},{"location":"0_resumo/Resumo/#2102-bibliotecas-python","title":"2.10.2. Bibliotecas Python:","text":"<ul> <li>Pandas (manipula\u00e7\u00e3o; limpeza; transforma\u00e7\u00e3o e pr\u00e9-processamento de dado); </li> <li>NumPy (opera\u00e7\u00f5es de arrays); </li> <li>Matplotlib e Seaborn (visualiza\u00e7\u00e3o de dados); </li> <li>TensorFlow; </li> <li>Keras e PyTorch (redes neurais); </li> <li>Scikit-learn e XGBoost (aprendizado de m\u00e1quina); </li> <li>NLTK e spaCy (processamento de linguagem natural);</li> <li>huggingface (LLM); </li> <li>PySpark (Big data); </li> <li>Beautiful Soup (web scraping); </li> <li>Streamlit (data apps). </li> </ul>"},{"location":"0_resumo/Resumo/#2103-linguagem-sql-structured-query-language","title":"2.10.3. Linguagem SQL (Structured Query Language):","text":"<ul> <li>conceitos introdut\u00f3rios; </li> <li>comandos b\u00e1sicos para consultas (inser\u00e7\u00e3o, atualiza\u00e7\u00e3o e exclus\u00e3o de dados) e para an\u00e1lise de dados (como fun\u00e7\u00f5es de agrega\u00e7\u00e3o, filtros, joins, subconsultas e demais). </li> </ul>"},{"location":"0_resumo/Resumo/#2104-gestao-de-codigo","title":"2.10.4. Gest\u00e3o de C\u00f3digo:","text":"<ul> <li>qualidade de c\u00f3digo; </li> <li>testes automatizados; </li> <li>versionamento (Git). </li> </ul>"},{"location":"0_resumo/Resumo/#2105-ambientes-de-programacao","title":"2.10.5. Ambientes de programa\u00e7\u00e3o:","text":"<ul> <li>Jupyterhub e Jupyter Notebooks; </li> <li>linha de comando (navega\u00e7\u00e3o em diret\u00f3rios, manipula\u00e7\u00e3o de arquivos e dados);</li> <li>gerenciamento de processos; </li> <li>configura\u00e7\u00e3o de ambientes e vari\u00e1veis de ambiente;</li> <li>gerenciamento de pacotes Python (pip); </li> <li>ambientes virtuais Python. </li> </ul>"},{"location":"0_resumo/Resumo/#2106-microsoft-power-bi","title":"2.10.6. Microsoft Power BI:","text":"<ul> <li>conex\u00e3o e importa\u00e7\u00e3o de dados; </li> <li>modelagem de dados; </li> <li>cria\u00e7\u00e3o de medidas e colunas calculadas; </li> <li>visualiza\u00e7\u00f5es e gr\u00e1ficos; </li> <li>intera\u00e7\u00f5es entre visualiza\u00e7\u00f5es; </li> <li>cria\u00e7\u00e3o de relat\u00f3rios e pain\u00e9is. </li> </ul>"},{"location":"0_resumo/Resumo/#211-xi-visualizacao","title":"2.11. XI - VISUALIZA\u00c7\u00c3O;","text":""},{"location":"0_resumo/Resumo/#storytelling-e-comunicacao-corporativa","title":"STORYTELLING E COMUNICA\u00c7\u00c3O CORPORATIVA:","text":""},{"location":"0_resumo/Resumo/#2111-principais-tipos-de-visualizacoes-e-graficos","title":"2.11.1. Principais tipos de visualiza\u00e7\u00f5es e gr\u00e1ficos:","text":"<ul> <li>tabela; </li> <li>gr\u00e1fico de barras; </li> <li>linhas; </li> <li>pizza; </li> <li>dispers\u00e3o; </li> <li>histograma; </li> <li>\u00e1rea; </li> <li>boxplot; </li> <li>bolhas; </li> <li>radar; </li> <li>mapas cartogr\u00e1ficos; </li> <li>mapa de calor. </li> </ul>"},{"location":"0_resumo/Resumo/#2112-visualizacao-de-dados","title":"2.11.2. Visualiza\u00e7\u00e3o de dados:","text":"<ul> <li>princ\u00edpios de design de gr\u00e1ficos efetivos; </li> <li>principais conceitos de codifica\u00e7\u00e3o visual;</li> <li>interatividade; </li> <li>acessibilidade em gr\u00e1ficos. </li> </ul>"},{"location":"0_resumo/Resumo/#2113-dashboards","title":"2.11.3. Dashboards:","text":"<ul> <li>t\u00e9cnicas para constru\u00e7\u00e3o de interfaces e layout;</li> <li>abordagens para escolha de designs; </li> <li>organiza\u00e7\u00e3o de elementos visuais e gr\u00e1ficos; </li> <li>sele\u00e7\u00e3o de gr\u00e1ficos e visualiza\u00e7\u00f5es; </li> <li>interatividades e drill-downs; </li> <li>acessibilidade. </li> </ul>"},{"location":"0_resumo/Resumo/#2114-storytelling-com-dados","title":"2.11.4. Storytelling com dados:","text":"<ul> <li>constru\u00e7\u00e3o de narrativas visuais e contextualiza\u00e7\u00f5es;</li> <li>componentes de um storytelling efetivo. </li> </ul>"},{"location":"0_resumo/Resumo/#2115-reportes-executivos","title":"2.11.5. Reportes executivos:","text":"<ul> <li>princ\u00edpios de comunica\u00e7\u00e3o corporativa; </li> <li>interpreta\u00e7\u00e3o e apresenta\u00e7\u00e3o de dados de resultados de an\u00e1lises e de insights. </li> </ul>"},{"location":"0_resumo/Resumo/#212-xii-governanca-e-seguranca-de-dados","title":"2.12. XII - GOVERNAN\u00c7A E SEGURAN\u00c7A DE DADOS:","text":""},{"location":"0_resumo/Resumo/#2121-nocoes-de-governanca-de-dados-dmbok","title":"2.12.1. No\u00e7\u00f5es de governan\u00e7a de dados (DMBOK):","text":"<ul> <li>conceitos e objetivos da governan\u00e7a de dados; </li> <li>principais t\u00e9cnicas de qualidade e integridade de dados;</li> <li>princ\u00edpios de privacidade e prote\u00e7\u00e3o a dados. </li> </ul>"},{"location":"0_resumo/Resumo/#213-xiii-governanca-seguranca-e-aplicacao-responsavel-de-ia","title":"2.13. XIII - GOVERNAN\u00c7A, SEGURAN\u00c7A E APLICA\u00c7\u00c3O RESPONS\u00c1VEL DE IA:","text":""},{"location":"0_resumo/Resumo/#2131-nocoes-de-governanca-de-ia","title":"2.13.1. No\u00e7\u00f5es de governan\u00e7a de IA:","text":"<ul> <li>conceitos e objetivos da governan\u00e7a de IA; </li> <li>gest\u00e3o de riscos em IA; </li> <li>gest\u00e3o de ciclo de vida de modelos. </li> </ul>"},{"location":"0_resumo/Resumo/#2132-principais-riscos-e-vulnerabilidades-relacionados-a-ia","title":"2.13.2. Principais riscos e vulnerabilidades relacionados a IA:","text":"<ul> <li>vi\u00e9s algor\u00edtmico; </li> <li>exposi\u00e7\u00e3o de dados sens\u00edveis; </li> <li>envenenamento de dados de treinamento; </li> <li>ataques adversariais; </li> <li>ataques de manipula\u00e7\u00e3o de modelos; </li> <li>roubo de modelos; </li> <li>ataque de infer\u00eancia; </li> <li>alucina\u00e7\u00f5es. </li> </ul>"},{"location":"0_resumo/Resumo/#2133-aplicacao-de-ia-responsavel","title":"2.13.3. Aplica\u00e7\u00e3o de IA respons\u00e1vel:","text":"<ul> <li>defini\u00e7\u00e3o; </li> <li>\u00e9tica; </li> <li>transpar\u00eancia; </li> <li>justi\u00e7a e equidade; </li> <li>responsabiliza\u00e7\u00e3o; </li> <li>seguran\u00e7a cibern\u00e9tica; </li> <li>compliance regulat\u00f3rio.</li> </ul>"},{"location":"0_resumo/Resumo/#3-proximo-assunto","title":"3. Proximo assunto:","text":"<ul> <li>teste</li> </ul>"},{"location":"1_estatistica/Introducao_estatistica/","title":"1. Introdu\u00e7\u00e3o","text":"<p>Bem-vindo \u00e0 se\u00e7\u00e3o de Estat\u00edstica. Aqui voc\u00ea encontrar\u00e1 diversos conceitos importantes sobre an\u00e1lise de dados.</p>"},{"location":"1_estatistica/Introducao_estatistica/#11-conteudos-disponiveis","title":"1.1. Conte\u00fados dispon\u00edveis:","text":"<ul> <li>1.1.1 Testes de Hip\u00f3teses</li> <li>1.1.2 O que s\u00e3o os ts</li> <li>1.1.3 Aplicacao: Testes de hipotese e T-Studant</li> <li>1.1.3 Aplicacao: Intervalos de Confian\u00e7a e T-Studant</li> <li>1.1.5 O que \u00e9 P-valor</li> <li>1.1.6 Aplicacao: Permutacion teste</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1_Teste_Hipoteses/","title":"1. O que s\u00e3o Testes de Hip\u00f3teses?","text":"<p>Testes de hip\u00f3teses s\u00e3o procedimentos estat\u00edsticos usados para tomar decis\u00f5es ou infer\u00eancias sobre popula\u00e7\u00f5es com base em amostras de dados. A ideia b\u00e1sica \u00e9 formular duas hip\u00f3teses mutuamente exclusivas: a hip\u00f3tese nula (H<sub>0</sub>) e a hip\u00f3tese alternativa (H<sub>a</sub>).</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1_Teste_Hipoteses/#11-hipoteses","title":"1.1. Hip\u00f3teses","text":"<ul> <li>Hip\u00f3tese Nula (H<sub>0</sub>): Assume que n\u00e3o h\u00e1 efeito ou diferen\u00e7a significativa. \u00c9 a hip\u00f3tese que voc\u00ea tenta refutar.</li> <li>Hip\u00f3tese Alternativa (H<sub>a</sub>): Assume que h\u00e1 um efeito ou diferen\u00e7a significativa. \u00c9 a hip\u00f3tese que voc\u00ea tenta provar.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1_Teste_Hipoteses/#12-passos-para-realizar-um-teste-de-hipoteses","title":"1.2. Passos para Realizar um Teste de Hip\u00f3teses","text":"<ol> <li>Formular as Hip\u00f3teses: Definir H<sub>0</sub> e H<sub>a</sub>.</li> <li>Escolher o N\u00edvel de Signific\u00e2ncia (\u03b1): Geralmente, 0,05 ou 0,01.</li> <li>Coletar Dados: Obter uma amostra representativa da popula\u00e7\u00e3o.</li> <li>Calcular a Estat\u00edstica de Teste: Utilizar a f\u00f3rmula apropriada para a estat\u00edstica de teste (por exemplo, t-teste, teste z, etc.).</li> <li>Tomar a Decis\u00e3o: Comparar a estat\u00edstica de teste com o valor cr\u00edtico ou calcular o p-valor e compar\u00e1-lo com \u03b1.</li> <li>Conclus\u00e3o: Se o p-valor for menor que \u03b1, rejeite H<sub>0</sub> em favor de H<sub>a</sub>. Caso contr\u00e1rio, n\u00e3o rejeite H<sub>0</sub>.</li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.1_Teste_Hipoteses/#13-tipos-de-teste-de-hipoteses","title":"1.3. Tipos de Teste de hip\u00f3teses:","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/","title":"1. O que s\u00e3o os ts","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#11-o-que-e-estatistica-t-teste-t-e-distribuicao-t","title":"1.1. O que \u00e9 Estat\u00edstica t, Teste t e Distribui\u00e7\u00e3o t?","text":"<p>A estat\u00edstica \u00e9 a espinha dorsal da an\u00e1lise de dados, e a estat\u00edstica t, oriunda da distribui\u00e7\u00e3o t, \u00e9 um dos seus pilares fundamentais.</p> <p>Essa ferramenta n\u00e3o apenas desempenha um papel vital em testes de hip\u00f3teses, particularmente nos testes t, mas tamb\u00e9m \u00e9 a chave para entender como e por que certas conclus\u00f5es s\u00e3o retiradas de conjuntos de dados.</p> <p>Dominar a estat\u00edstica t \u00e9 mais do que uma mera habilidade acad\u00eamica; \u00e9 uma necessidade para qualquer um que queira analisar dados com precis\u00e3o e confian\u00e7a.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#12-pontos-chave","title":"1.2. Pontos-chave","text":"<ul> <li>Testes t avaliam diferen\u00e7as entre m\u00e9dias amostrais.</li> <li>A estat\u00edstica t considera desvio padr\u00e3o e tamanho da amostra.</li> <li>Testes t requerem a verifica\u00e7\u00e3o de premissas como normalidade.</li> <li><code>P-valores baixos sugerem diferen\u00e7as estatisticamente significativas</code>.</li> <li>Erros comuns incluem assumir normalidade e ignorar premissas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#13-estatistica-t","title":"1.3. Estat\u00edstica t","text":"<p>A estat\u00edstica t, tamb\u00e9m conhecida como valor t ou t de Student, \u00e9 uma medida que nos ajuda a determinar qu\u00e3o grande \u00e9 a diferen\u00e7a entre as m\u00e9dias de duas amostras, considerando a variabilidade nos dados.</p> <p>Em outras palavras, ela compara a diferen\u00e7a observada entre as m\u00e9dias das amostras com o que poder\u00edamos esperar por acaso. Se essa diferen\u00e7a for significativamente grande, conclu\u00edmos que as m\u00e9dias das popula\u00e7\u00f5es das quais as amostras foram retiradas provavelmente s\u00e3o diferentes.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#14-distribuicao-t","title":"1.4. Distribui\u00e7\u00e3o t","text":"<p>A distribui\u00e7\u00e3o t, tamb\u00e9m conhecida como distribui\u00e7\u00e3o de Student, \u00e9 uma das distribui\u00e7\u00f5es de probabilidade mais importantes no campo da estat\u00edstica, especialmente quando se trata de inferir sobre uma popula\u00e7\u00e3o a partir de uma amostra pequena.</p> <p><code>Origem:</code> A distribui\u00e7\u00e3o t foi introduzida por William Sealy Gosset sob o pseud\u00f4nimo \u201cStudent\u201d em 1908. Ele estava trabalhando na empresa de cervejaria Guinness e desenvolveu esta distribui\u00e7\u00e3o para lidar com problemas estat\u00edsticos envolvendo pequenas amostras.</p> <p></p> <p>Refer\u00eancia: https://estatisticafacil.org/estatistica-t/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#15-teste-t","title":"1.5. Teste t","text":"<p>O teste t \u00e9 um instrumento refinado de an\u00e1lise que se vale da estat\u00edstica t para confrontar as m\u00e9dias de dois conjuntos de dados. O que ele busca discernir \u00e9 a natureza da varia\u00e7\u00e3o entre esses conjuntos: \u00e9 uma diferen\u00e7a genuinamente significativa? Ou poderia essa varia\u00e7\u00e3o ser atribu\u00edda simplesmente ao capricho do acaso?</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#151-ha-tres-tipos-de-teste-t","title":"1.5.1. H\u00e1 tr\u00eas tipos de teste t:","text":"<p><code>Teste t de Uma Amostra:</code> O teste t de uma amostra confronta a m\u00e9dia de uma \u00fanica amostra com uma m\u00e9dia populacional j\u00e1 conhecida. Este tipo de teste \u00e9 frequentemente adotado quando os pesquisadores desejam verificar se a m\u00e9dia da amostra diverge de maneira significativa de um valor hipotetizado. Aqui, a estat\u00edstica t \u00e9 determinada comparando-se a m\u00e9dia da amostra com a m\u00e9dia da popula\u00e7\u00e3o, levando em considera\u00e7\u00e3o o tamanho da amostra e seu desvio padr\u00e3o.</p> <p><code>Teste t para Amostras Independentes:</code> Este teste, tamb\u00e9m conhecido como teste t de duas amostras, \u00e9 aplicado ao se comparar as m\u00e9dias de duas amostras independentes. O principal objetivo \u00e9 averiguar se existe uma diferen\u00e7a significativa entre as m\u00e9dias das popula\u00e7\u00f5es das quais as amostras foram extra\u00eddas. Para este teste, a estat\u00edstica t \u00e9 calculada considerando-se a discrep\u00e2ncia entre as m\u00e9dias das amostras, suas vari\u00e2ncias e os respectivos tamanhos das amostras.</p> <p><code>Teste t para Amostras Emparelhadas:</code> O teste t para amostras emparelhadas, ou teste t para amostras dependentes, \u00e9 indicado para compara\u00e7\u00e3o das m\u00e9dias de duas amostras relacionadas. Este teste \u00e9 utilizado quando as observa\u00e7\u00f5es s\u00e3o feitas em pares, como medi\u00e7\u00f5es antes e depois de um tratamento, ou sujeitos pareados em designs experimentais. Para este teste, a estat\u00edstica t \u00e9 derivada considerando-se as diferen\u00e7as entre as observa\u00e7\u00f5es emparelhadas e suas m\u00e9dias, bem como o desvio padr\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#16-premissas-do-teste-t","title":"1.6. Premissas do Teste t","text":"<p>Garantir que as premissas abaixo sejam atendidas permite aplicar os testes t e a estat\u00edstica t em suas pesquisas e an\u00e1lises de dados, conduzindo a conclus\u00f5es v\u00e1lidas e confi\u00e1veis.</p> <p><code>Dados em Escala de Intervalo ou Raz\u00e3o:</code> Os testes t s\u00e3o projetados para dados cont\u00ednuos que podem ser medidos em uma escala de raz\u00e3o ou intervalo. Estes tipos de dados possuem intervalos iguais entre os valores e um ponto zero significativo.</p> <p><code>Independ\u00eancia das Observa\u00e7\u00f5es:</code> As observa\u00e7\u00f5es nas amostras devem ser independentes entre si. Isso implica que a ocorr\u00eancia de uma observa\u00e7\u00e3o n\u00e3o deve influenciar a probabilidade de outra observa\u00e7\u00e3o acontecer. No teste t para amostras independentes, as amostras devem ser selecionadas de forma aleat\u00f3ria e n\u00e3o relacionadas entre si. Para o teste t de amostras emparelhadas, cada par de observa\u00e7\u00f5es deve ser independente dos outros pares. </p> <p><code>Normalidade:</code> Os dados devem ter uma distribui\u00e7\u00e3o aproximadamente normal, especialmente para tamanhos de amostras pequenos. Este pressuposto sugere que a distribui\u00e7\u00e3o de amostragem das m\u00e9dias segue uma distribui\u00e7\u00e3o normal ou quase normal. Embora os testes t sejam considerados robustos a desvios moderados da normalidade, viola\u00e7\u00f5es graves podem afetar a precis\u00e3o dos resultados do teste.</p> <p><code>Homogeneidade das Vari\u00e2ncias:</code> No teste t para amostras independentes, as vari\u00e2ncias das duas popula\u00e7\u00f5es comparadas devem ser iguais ou, pelo menos, aproximadamente iguais. Esse pressuposto \u00e9 conhecido como homogeneidade das vari\u00e2ncias. Se esse pressuposto for violado, testes alternativos, como o teste t de Welch, podem ser empregados, pois este \u00faltimo n\u00e3o exige vari\u00e2ncias iguais.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#17-graus-de-liberdade","title":"1.7. Graus de Liberdade","text":"<p>Os graus de liberdade representam um conceito fundamental na estat\u00edstica e t\u00eam implica\u00e7\u00f5es profundas no c\u00e1lculo da estat\u00edstica t e na determina\u00e7\u00e3o dos valores cr\u00edticos em testes t.</p> <p>Mas, o que s\u00e3o exatamente os graus de liberdade? S\u00e3o o n\u00famero de valores numa an\u00e1lise que t\u00eam a liberdade de variar sem infringir qualquer regra estabelecida \u2014 em outras palavras, s\u00e3o as observa\u00e7\u00f5es independentes que podem ser usadas para estimar um par\u00e2metro.</p> <p>Exemplo:</p> <p>Imagine que voc\u00ea tem cinco amigos e est\u00e1 tentando calcular a m\u00e9dia das idades deles. Voc\u00ea sabe que a m\u00e9dia de suas idades \u00e9 25 anos. Se voc\u00ea souber a idade de quatro desses amigos, voc\u00ea poder\u00e1 facilmente calcular a idade do quinto amigo, mesmo sem ningu\u00e9m te dizer qual \u00e9.</p> <p>Por exemplo: Amigo 1: 24 anos; Amigo 2: 25 anos; Amigo 3: 26 anos; e Amigo 4: 23 anos.</p> <p>Usando a informa\u00e7\u00e3o de que a m\u00e9dia \u00e9 25 anos, podemos calcular a idade do Amigo 5. Se somarmos as idades dos quatro primeiros amigos, obtemos um total de 98 anos. Para que a m\u00e9dia das cinco idades seja 25 anos, o total combinado deve ser 125 anos (25 anos x 5 amigos). Isso significa que o Amigo 5 tem 27 anos (125 \u2013 98 = 27).</p> <p>Neste exemplo, os graus de liberdade s\u00e3o 4. Isso porque podemos escolher qualquer idade para os primeiros quatro amigos, mas depois que essas idades forem determinadas, a idade do quinto amigo \u00e9 fixada pela m\u00e9dia que conhecemos. Portanto, s\u00f3 temos \u201cliberdade\u201d para variar as idades de 4 dos 5 amigos. </p> <p>No universo dos testes t, os graus de liberdade determinam a forma espec\u00edfica da distribui\u00e7\u00e3o t, essencial para calcular os valores p e tomar decis\u00f5es estat\u00edsticas sobre as diferen\u00e7as entre grupos.</p> <p>Como calculamos os graus de liberdade para diferentes testes t:</p> <p><code>Teste t de Uma Amostra:</code> Simplesmente subtrai-se um do tamanho total da amostra. Matematicamente falando: gl = n \u2013 1.</p> <p><code>Teste t para Amostras Independentes:</code> Neste cen\u00e1rio, temos duas amostras diferentes. A f\u00f3rmula considera o tamanho de ambas as amostras: gl = n1 + n2 \u2013 2.</p> <p><code>Teste t para Amostras Emparelhadas:</code> Aqui, comparamos dois conjuntos de observa\u00e7\u00f5es do mesmo grupo, como um \u201cantes e depois\u201d. Os graus de liberdade s\u00e3o calculados subtraindo um do n\u00famero total de pares: gl = n \u2013 1.</p> <p>A correta compreens\u00e3o e aplica\u00e7\u00e3o dos graus de liberdade n\u00e3o apenas asseguram a precis\u00e3o da sua an\u00e1lise, mas tamb\u00e9m a confiabilidade das conclus\u00f5es extra\u00eddas dela.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#18-estatistica-t-valor-de-p-e-intervalos-de-confianca","title":"1.8. Estat\u00edstica t, Valor de p e Intervalos de Confian\u00e7a","text":"<p>Estes tr\u00eas componentes formam a espinha dorsal da infer\u00eancia estat\u00edstica, permitindo aos pesquisadores e analistas de dados n\u00e3o apenas identificar diferen\u00e7as significativas em seus conjuntos de dados, mas tamb\u00e9m entender o contexto e a relev\u00e2ncia dessas diferen\u00e7as.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#181-estatistica-t","title":"1.8.1. Estat\u00edstica t:","text":"<p>Defini\u00e7\u00e3o: Originada da distribui\u00e7\u00e3o t, a estat\u00edstica-t quantifica a diferen\u00e7a entre m\u00e9dias amostrais, levando em considera\u00e7\u00e3o o desvio padr\u00e3o e o tamanho da amostra.</p> <p>Aplica\u00e7\u00e3o: Usada principalmente em testes t para contrastar m\u00e9dias amostrais, ela serve como um \u00edndice para avaliar o qu\u00e3o longe a nossa amostra est\u00e1 da popula\u00e7\u00e3o sob a hip\u00f3tese nula.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#182-valor-de-p","title":"1.8.2. Valor de p:","text":"<p>Defini\u00e7\u00e3o: Uma m\u00e9trica que indica a probabilidade de observar um resultado, como o obtido (ou mais extremo), assumindo que a hip\u00f3tese nula (H0) \u00e9 verdadeira.</p> <p>Interpreta\u00e7\u00e3o: Um <code>p-valor pequeno</code> \u2014 frequentemente, menor que 0.05 \u2014 sugere que os dados observados s\u00e3o <code>inconsistentes com a hip\u00f3tese nula (H0)</code>, permitindo-nos <code>rejeit\u00e1-la</code> em favor da hip\u00f3tese alternativa (H1). Portanto, <code>um p-valor baixo sinaliza uma diferen\u00e7a estatisticamente significativa.</code></p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#183-intervalos-de-confianca","title":"1.8.3. Intervalos de Confian\u00e7a:","text":"<p>Defini\u00e7\u00e3o: Uma estimativa de intervalo que indica a faixa dentro da qual esperamos que o verdadeiro valor da popula\u00e7\u00e3o esteja, com uma certa confian\u00e7a (como 95%).</p> <p>Interpreta\u00e7\u00e3o: Em testes t, esses intervalos nos oferecem uma faixa de valores prov\u00e1veis para as diferen\u00e7as entre as m\u00e9dias populacionais ou a m\u00e9dia da popula\u00e7\u00e3o em si. A amplitude desse intervalo \u00e9 influenciada por fatores como a estat\u00edstica-t, o tamanho da amostra e a variabilidade dos dados.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.2_O_que_sao_os_ts/#184-relacao-integrada","title":"1.8.4. Rela\u00e7\u00e3o Integrada:","text":"<p>A estat\u00edstica-t nos fornece uma m\u00e9trica de diferen\u00e7a que \u00e9, ent\u00e3o, avaliada em termos de sua probabilidade sob a hip\u00f3tese nula \u2014 da\u00ed surge o p-valor.</p> <p>Ao mesmo tempo, a estat\u00edstica-t alimenta a constru\u00e7\u00e3o dos intervalos de confian\u00e7a, proporcionando uma vis\u00e3o mais ampla da diferen\u00e7a, n\u00e3o apenas em termos de signific\u00e2ncia, mas tamb\u00e9m de magnitude e relev\u00e2ncia pr\u00e1tica.</p> <p>Em suma, ao combinar a estat\u00edstica-t, o p-valor e os intervalos de confian\u00e7a, obtemos uma imagem completa e multidimensional da diferen\u00e7a observada, auxiliando na tomada de decis\u00f5es informadas e na interpreta\u00e7\u00e3o precisa dos resultados.</p> <p>Refer\u00eancia: https://estatisticafacil.org/estatistica-t/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/","title":"1.1.3 Aplica\u00e7\u00e3o - Testes de Hip\u00f3tese","text":"<p>A baixo segue as principais etapas para se conduzir um teste de hip\u00f3teses com a Estat\u00edstica-t</p> <p>1. Estabele\u00e7a as hip\u00f3teses:</p> <ul> <li>Hip\u00f3tese nula (H0): Sugere que n\u00e3o existe uma diferen\u00e7a significativa entre as m\u00e9dias populacionais ou que a m\u00e9dia da amostra \u00e9 a mesma do valor proposto.</li> <li>Hip\u00f3tese alternativa (H1): Prop\u00f5e que pode existir uma diferen\u00e7a significativa entre as m\u00e9dias.</li> </ul> <p>2. Sele\u00e7\u00e3o do teste t correto:</p> <ul> <li>Escolha o tipo de teste t que se alinha com o design da sua pesquisa, seja ele para uma \u00fanica amostra, amostras independentes ou amostras pareadas.</li> </ul> <p>3. Confirma\u00e7\u00e3o das premissas:</p> <ul> <li>Assegure-se de que os dados atendam \u00e0s premissas necess\u00e1rias, como independ\u00eancia das observa\u00e7\u00f5es, normalidade e, quando aplic\u00e1vel, homogeneidade das vari\u00e2ncias.</li> </ul> <p>4. Computa\u00e7\u00e3o da estat\u00edstica-t:</p> <ul> <li>Utilizando os dados da amostra, calcule a estat\u00edstica-t conforme a formula\u00e7\u00e3o espec\u00edfica do teste t selecionado.</li> </ul> <p>5. Determina\u00e7\u00e3o dos graus de liberdade (df):</p> <ul> <li>Baseie-se no tamanho da amostra ou amostras para calcular os graus de liberdade.</li> </ul> <p>6. Obten\u00e7\u00e3o do p-valor:</p> <ul> <li>Utilize a estat\u00edstica-t e os graus de liberdade para identificar o p-valor correspondente na distribui\u00e7\u00e3o t.</li> </ul> <p>7. Compara\u00e7\u00e3o com o n\u00edvel de signific\u00e2ncia (\u03b1):</p> <ul> <li>Se o p-valor for menor que o n\u00edvel de signific\u00e2ncia definido (comumente 0,05), rejeite a hip\u00f3tese nula.</li> </ul> In\u00a0[1]: Copied! <pre>import pandas as pd\nfrom scipy import stats\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\n\n# Criar o DataFrame\ndf = pd.DataFrame(data)\n\n# Calcular o teste T pareado\nt_statistic, p_value = stats.ttest_rel(df['ks.scores1'], df['ks.scores2'])\n\n# Exibir resultados\nprint(\"Estat\u00edstica t:\", t_statistic)\nprint(\"Valor p:\", p_value)\n\n# Avalia\u00e7\u00e3o do resultado\nif p_value &lt; 0.05:\n    print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\nelse:\n    print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\n</pre> import pandas as pd from scipy import stats  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] }  # Criar o DataFrame df = pd.DataFrame(data)  # Calcular o teste T pareado t_statistic, p_value = stats.ttest_rel(df['ks.scores1'], df['ks.scores2'])  # Exibir resultados print(\"Estat\u00edstica t:\", t_statistic) print(\"Valor p:\", p_value)  # Avalia\u00e7\u00e3o do resultado if p_value &lt; 0.05:     print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\") else:     print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")  <pre>Estat\u00edstica t: 4.378132332736648\nValor p: 0.011892242763488443\nRejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\n</pre>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#1-testes-de-hipoteses-com-estatistica-t","title":"1. Testes de Hip\u00f3teses com Estat\u00edstica t\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#11-ilustracao-pratica","title":"1.1. Ilustra\u00e7\u00e3o Pr\u00e1tica:\u00b6","text":"<ul> <li>Estat\u00edstica F\u00e1cil - Estat\u00edstica T</li> </ul> <p>Imagine que deseja avaliar se um novo m\u00e9todo de ensino eleva as notas dos alunos.</p> <p>Coleta-se uma amostra de 25 alunos submetidos ao novo m\u00e9todo e compara-se a m\u00e9dia das suas notas \u00e0 m\u00e9dia populacional reconhecida de 80.</p> <p>Para esta situa\u00e7\u00e3o, utiliza-se o teste t para uma amostra.</p> <ol> <li>H0: \u03bc = 80; H1: \u03bc \u2260 80.</li> <li>Selecionado o teste t para uma \u00fanica amostra.</li> <li>Verificadas e validadas as premissas.</li> <li>Resultado da estat\u00edstica-t \u00e9 de 2,5.</li> <li>Graus de liberdade determinados como: df = 24.</li> <li>Com base na estat\u00edstica-t e df, o <code>p-valor</code> \u00e9 de <code>0,019</code>.</li> <li>Dado que <code>0,019</code> \u00e9 menor que 0,05, <code>rejeitamos H0</code>.</li> <li>Conclus\u00e3o: As evid\u00eancias apontam para uma melhoria significativa nas notas dos alunos devido ao novo m\u00e9todo de ensino. Refer\u00eancia:</li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#2-teste-t-pareado-calculo-manual","title":"2. Teste T Pareado: C\u00e1lculo Manual\u00b6","text":"<p>Este documento explica como realizar um teste t pareado manualmente para determinar se h\u00e1 uma diferen\u00e7a significativa entre as m\u00e9dias de duas amostras emparelhadas. Neste exemplo, utilizamos duas colunas de dados representando m\u00e9tricas de KS scores.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#21-dados","title":"2.1. Dados\u00b6","text":"<p>Vamos utilizar os seguintes dados:</p> <ul> <li><code>ks.scores1</code>: [0.583983, 0.576596, 0.556730, 0.595138, 0.584564]</li> <li><code>ks.scores2</code>: [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#22-passo-a-passo-para-o-teste-t-pareado-manualmente","title":"2.2. Passo a Passo para o Teste T Pareado Manualmente\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#221-calcular-as-diferencas","title":"2.2.1. Calcular as Diferen\u00e7as\u00b6","text":"<p>Primeiro, calculamos a diferen\u00e7a entre as duas colunas para cada par de valores:</p> <p>$$ \\text{Diferen\u00e7a} = \\text{ks.scores1} - \\text{ks.scores2} $$</p> <p>$$ \\begin{align*}  0.583983 - 0.490242 &amp;= 0.093741\\\\\\\\ 0.576596 - 0.551584 &amp;= 0.025012\\\\\\\\ 0.556730 - 0.514383 &amp;= 0.042347\\\\\\\\ 0.595138 - 0.535587 &amp;= 0.059551\\\\\\\\ 0.584564 - 0.546064 &amp;= 0.038500\\\\\\\\ \\end{align*} $$</p> <p>Ent\u00e3o, as diferen\u00e7as s\u00e3o:</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#textdiferencas-0093741-0025012-0042347-0059551-0038500-3","title":"$$ \\text{Diferen\u00e7as} = [0.093741, 0.025012, 0.042347, 0.059551, 0.038500] 3. $$\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#222-calcular-a-media-das-diferencas","title":"2.2.2. Calcular a M\u00e9dia das Diferen\u00e7as\u00b6","text":"<p>Agora, calculamos a m\u00e9dia das diferen\u00e7as ($\\bar{d}$):</p> <p>$$ \\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i = \\frac{0.093741 + 0.025012 + 0.042347 + 0.059551 + 0.038500}{5} $$</p> <p>$$ \\bar{d} = \\frac{0.259151}{5} = 0.0518302 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#223-calcular-o-desvio-padrao-das-diferencas","title":"2.2.3. Calcular o Desvio Padr\u00e3o das Diferen\u00e7as\u00b6","text":"<p>Para calcular o desvio padr\u00e3o ($s_d$), usamos a f\u00f3rmula do desvio padr\u00e3o de uma amostra:</p> <p>$$ s_d = \\sqrt{\\frac{\\sum_{i=1}^{n} (d_i - \\bar{d})^2}{n-1}} $$</p> <p>$$ \\begin{align*} (d_1 - \\bar{d})^2 &amp;= (0.093741 - 0.0518302)^2 = 0.001749 \\\\\\\\ (d_2 - \\bar{d})^2 &amp;= (0.025012 - 0.0518302)^2 = 0.000712 \\\\\\\\ (d_3 - \\bar{d})^2 &amp;= (0.042347 - 0.0518302)^2 = 0.000090 \\\\\\\\ (d_4 - \\bar{d})^2 &amp;= (0.059551 - 0.0518302)^2 = 0.000059 \\\\\\\\ (d_5 - \\bar{d})^2 &amp;= (0.038500 - 0.0518302)^2 = 0.000177 \\\\\\\\ \\end{align*} $$</p> <p>Agora, somamos essas diferen\u00e7as quadradas e dividimos pelo n\u00famero de pares menos um:</p> <p>$$ \\sum (d_i - \\bar{d})^2 = 0.001749 + 0.000712 + 0.000090 + 0.000059 + 0.000177 = 0.002787 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#s_d-sqrtfrac00027875-1-sqrtfrac00027874-sqrt000069675-0026396-4","title":"$$ s_d = \\sqrt{\\frac{0.002787}{5-1}} = \\sqrt{\\frac{0.002787}{4}} = \\sqrt{0.00069675} = 0.026396 4. $$\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#224-calcular-a-estatistica-t","title":"2.2.4. Calcular a Estat\u00edstica t\u00b6","text":"<p>A estat\u00edstica t \u00e9 calculada usando a m\u00e9dia das diferen\u00e7as, o desvio padr\u00e3o das diferen\u00e7as e o n\u00famero de pares:</p> <p>$$ t = \\frac{\\bar{d}}{s_d / \\sqrt{n}} $$</p> <p>Onde:</p> <ul> <li>($\\bar{d}$) \u00e9 a m\u00e9dia das diferen\u00e7as.</li> <li>($s_d$) \u00e9 o desvio padr\u00e3o das diferen\u00e7as.</li> <li>($n$) \u00e9 o n\u00famero de pares.</li> </ul> <p>Substituindo os valores:</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#t-frac005183020026396-sqrt5-frac005183020011804-4389-5","title":"$$ t = \\frac{0.0518302}{0.026396 / \\sqrt{5}} = \\frac{0.0518302}{0.011804} = 4.389 5. $$\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#225-determinar-o-valor-p","title":"2.2.5. Determinar o Valor p\u00b6","text":"<p>Para determinar o valor p, utilizamos a tabela de distribui\u00e7\u00e3o t de Student. Com $n - 1 = 4$ graus de liberdade e uma estat\u00edstica $t$ de $4.389$, vamos buscar o valor p correspondente.</p> <ul> <li>Para $t = 4.389$ e $df = 4$, o valor p \u00e9 geralmente menor que $0.05$, indicando que existe uma diferen\u00e7a significativa.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#226-determinar-a-regiao-critica","title":"2.2.6. Determinar a Regi\u00e3o Cr\u00edtica\u00b6","text":"<p>Para um teste t, a regi\u00e3o cr\u00edtica depende do n\u00edvel de signific\u00e2ncia ($\ud835\udefc$) e do tipo de teste (unilateral ou bilateral). Para um teste t bilateral, a regi\u00e3o cr\u00edtica est\u00e1 nas duas extremidades da distribui\u00e7\u00e3o t.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#227-exemplo-pratico","title":"2.2.7. Exemplo Pr\u00e1tico\u00b6","text":"<ul> <li><p>Localize a estat\u00edstica t calculada: 4.389</p> </li> <li><p>Localize a coluna com o n\u00edvel de signific\u00e2ncia desejado (por exemplo, $\ud835\udefc=0.05$ para um teste de duas caudas).</p> </li> <li><p>Compare o valor da estat\u00edstica t com os valores cr\u00edticos da tabela:</p> <p>Para $\ud835\udefc=0.05$ em um teste de duas caudas e 4 graus de liberdade, o valor cr\u00edtico geralmente \u00e9 cerca de 2.776. Como $t=4.389$ \u00e9 maior que o valor cr\u00edtico de 2.776, isso indica que a estat\u00edstica t est\u00e1 na regi\u00e3o cr\u00edtica e o valor p \u00e9 menor que 0.05.</p> </li> </ul> <p>Se a sua estat\u00edstica t calculada (t = 4.389) exceder o valor cr\u00edtico da tabela t para o n\u00edvel de signific\u00e2ncia escolhido, <code>voc\u00ea rejeita a hip\u00f3tese nula</code>. Para testes de duas caudas, voc\u00ea precisa comparar a estat\u00edstica t com o valor cr\u00edtico para a regi\u00e3o cr\u00edtica em ambas as extremidades da distribui\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#228-conclusao","title":"2.2.8. Conclus\u00e3o\u00b6","text":"<ul> <li>Valor de t calculado: 4.389</li> <li>Graus de liberdade (df): 4</li> <li>Valor p: Aproximadamente $0.0053$ (menor que $0.05$)</li> </ul> <p>Com base nos c\u00e1lculos, <code>podemos rejeitar a hip\u00f3tese nula</code> e concluir que existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas <code>ks.scores1</code> e <code>ks.scores2</code>.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#229-resumo-do-teste-t-pareado","title":"2.2.9. Resumo do Teste T Pareado:\u00b6","text":"<ul> <li>Hip\u00f3tese Nula (H0): A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero.</li> <li>Hip\u00f3tese Alternativa (H1): A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas n\u00e3o \u00e9 zero.</li> <li>Resultado: <code>Rejeitamos a hip\u00f3tese nula</code>. Existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#23-teste-t-pareado-usando-python","title":"2.3. Teste T Pareado usando Python\u00b6","text":"<p>Para testar se existe uma diferen\u00e7a significativa entre as m\u00e9dias das m\u00e9tricas das duas colunas <code>ks.scores1</code> e <code>ks.scores2</code>, podemos usar um <code>teste t pareado</code>. Este teste \u00e9 adequado para comparar as m\u00e9dias de duas amostras emparelhadas, assumindo que as diferen\u00e7as entre as amostras seguem uma distribui\u00e7\u00e3o normal.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#231-passos-para-realizar-o-teste-t-pareado","title":"2.3.1. Passos para realizar o Teste T Pareado:\u00b6","text":"<p>1. Formula\u00e7\u00e3o das Hip\u00f3teses:</p> <ul> <li><code>H0 (Hip\u00f3tese Nula):</code> A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero ($\ud835\udf07_1 \u2212\ud835\udf07_2 = 0$).</li> <li><code>H1 (Hip\u00f3tese Alternativa):</code> A diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas n\u00e3o \u00e9 zero ($\ud835\udf07_1 \u2212\ud835\udf07_2$ != $0$).</li> </ul> <p>2. C\u00e1lculo da Diferen\u00e7a das M\u00e9tricas:</p> <ul> <li>Para cada par de valores das duas colunas, calcule a diferen\u00e7a.</li> </ul> <p>3. Aplica\u00e7\u00e3o do Teste T Pareado:</p> <ul> <li>Utilize a diferen\u00e7a calculada para aplicar o <code>teste t pareado</code>.</li> <li>Calcule o <code>valor p</code> para determinar se as diferen\u00e7as s\u00e3o estatisticamente significativas.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.3_Aplicacao_teste_hipotese/#24-implementacao-em-python","title":"2.4. Implementa\u00e7\u00e3o em Python:\u00b6","text":"<p>Vou demonstrar como voc\u00ea pode implementar isso usando a biblioteca <code>scipy.stats</code> para calcular o teste t pareado.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/","title":"1.1.4 Aplica\u00e7\u00e3o - Intervalo de Confian\u00e7a","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#1-calculo-de-intervalo-de-confianca-usando-t-student","title":"1. C\u00e1lculo de Intervalo de Confian\u00e7a Usando t-Student\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#11-dados-fornecidos","title":"1.1. Dados Fornecidos\u00b6","text":"<p>Os dados fornecidos s\u00e3o do AUC_PR:</p> <ul> <li>$x_1 = 0.769682$</li> <li>$x_2 = 0.758596$</li> <li>$x_3 = 0.762273$</li> <li>$x_4 = 0.776236$</li> <li>$x_5 = 0.760402$</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#12-passo-1-calcular-a-media-amostral-barx","title":"1.2. Passo 1: Calcular a M\u00e9dia Amostral ($\\bar{x}$)\u00b6","text":"<p>A m\u00e9dia amostral ## Passo 1: Calcular a M\u00e9dia Amostral ($\\bar{x}$) \u00e9 calculada somando todos os valores e dividindo pelo n\u00famero total de observa\u00e7\u00f5es ($n$):</p> <p>$$ \\bar{x} = \\frac{x_1 + x_2 + x_3 + x_4 + x_5}{5} $$</p> <p>$$ \\bar{x} = \\frac{0.769682 + 0.758596 + 0.762273 + 0.776236 + 0.760402}{5} $$</p> <p>$$ \\bar{x} = \\frac{3.827189}{5} $$</p> <p>$$ \\bar{x} = 0.765438 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#13-passo-2-calcular-o-desvio-padrao-amostral-s","title":"1.3. Passo 2: Calcular o Desvio Padr\u00e3o Amostral ($s$)\u00b6","text":"<p>Para calcular o desvio padr\u00e3o amostral, utilizamos a f\u00f3rmula:</p> <p>$$ s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n - 1}} $$</p> <p>Primeiro, calculamos cada termo $(x_i - \\bar{x})^2$:</p> <p>\\begin{align*} (x_1 - \\bar{x})^2 &amp;= (0.769682 - 0.765438)^2 = 0.00001806 \\\\ (x_2 - \\bar{x})^2 &amp;= (0.758596 - 0.765438)^2 = 0.00004683 \\\\ (x_3 - \\bar{x})^2 &amp;= (0.762273 - 0.765438)^2 = 0.00000998 \\\\ (x_4 - \\bar{x})^2 &amp;= (0.776236 - 0.765438)^2 = 0.00011589 \\\\ (x_5 - \\bar{x})^2 &amp;= (0.760402 - 0.765438)^2 = 0.00002534 \\end{align*}</p> <p>Agora, somamos os quadrados das diferen\u00e7as:</p> <p>$$ \\sum_{i=1}^{n}(x_i - \\bar{x})^2 = 0.00001806 + 0.00004683 + 0.00000998 + 0.00011589 + 0.00002534 = 0.0002161 $$</p> <p>Calculando o desvio padr\u00e3o amostral ((s)):</p> <p>$$ s = \\sqrt{\\frac{0.0002161}{5 - 1}} = \\sqrt{\\frac{0.0002161}{4}} = \\sqrt{0.00005403} \\approx 0.00735 $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#14-passo-3-calcular-o-intervalo-de-confianca","title":"1.4. Passo 3: Calcular o Intervalo de Confian\u00e7a\u00b6","text":"<p>O intervalo de confian\u00e7a para a m\u00e9dia de uma amostra, usando a distribui\u00e7\u00e3o <code>t-Student</code>, \u00e9 dado por:</p> <p>$$ IC = \\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#2-entendendo-o","title":"2. Entendendo o $\ud835\udefc$\u00b6","text":"<p>Para um intervalo de confian\u00e7a de 95%, o valor de  $\ud835\udefc$ representa a probabilidade de erro, ou seja, a \u00e1rea das caudas da distribui\u00e7\u00e3o <code>t-Student</code> que n\u00e3o \u00e9 coberta pelo intervalo de confian\u00e7a. Neste caso, $\ud835\udefc=1\u22120.95=0.05$, ou 5%. Isso significa que h\u00e1 uma chance de 5% de que a m\u00e9dia verdadeira n\u00e3o esteja dentro do intervalo calculado.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#3-divisao-de-entre-as-caudas","title":"3. Divis\u00e3o de $\ud835\udefc$ entre as Caudas\u00b6","text":"<p>Como o intervalo de confian\u00e7a \u00e9 sim\u00e9trico em torno da m\u00e9dia amostral, o valor de $\ud835\udefc$ \u00e9 dividido igualmente entre as duas caudas da distribui\u00e7\u00e3o. Portanto, cada cauda tem uma \u00e1rea de $\ud835\udefc/2=0.025$.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#31-escolha-do-valor-de-t_alpha2-n-1","title":"3.1. Escolha do valor de $t_{\\alpha/2, n-1}$\u00b6","text":"<p>O valor de $t_{\\alpha/2, n-1}$ \u00e9 obtido da tabela t-Student para $n\u22121=4$ graus de liberdade, correspondendo a uma cauda de 2.5% em cada lado da distribui\u00e7\u00e3o. O valor t\u00edpico para um n\u00edvel de confian\u00e7a de 95% e 4 graus de liberdade \u00e9 aproximadamente 2.776.</p> <p>Substituindo os valores:</p> <ul> <li>$\\bar{x} = 0.765438$</li> <li>$s = 0.00735$</li> <li>$n = 5$</li> <li>$t_{0.025, 4} \\approx 2.776$</li> </ul> <p>O erro padr\u00e3o da m\u00e9dia (SEM) \u00e9 calculado como:</p> <p>$$ \\frac{s}{\\sqrt{n}} = \\frac{0.00735}{\\sqrt{5}} = \\frac{0.00735}{2.236} \\approx 0.003285 $$</p> <ul> <li>$s$: Desvio padr\u00e3o da amostra, que mede a dispers\u00e3o dos dados em rela\u00e7\u00e3o \u00e0 m\u00e9dia amostral.</li> <li>$\ud835\udc5b$: Tamanho da amostra, ou seja, o n\u00famero total de observa\u00e7\u00f5es na amostra.</li> </ul> <p>Agora, calculamos o intervalo de confian\u00e7a:</p> <p>$$ IC = 0.765438 \\pm 2.776 \\times 0.003285 $$</p> <p>$$ IC = 0.765438 \\pm 0.009113 $$</p> <p>$$ IC = [0.756325, 0.774551] $$</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#4-resultado-final","title":"4. Resultado Final\u00b6","text":"<p>O intervalo de confian\u00e7a de 95% para os dados fornecidos \u00e9 aproximadamente:</p> <p>$$ IC = [0.756325, 0.774551] $$</p> <ol> <li>Ou seja, com 95% de confian\u00e7a, podemos afirmar que a m\u00e9dia verdadeira dos dados est\u00e1 entre 0.756325 e 0.774551.</li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#5-interpretacao-do-intervalo-de-confianca","title":"5. Interpreta\u00e7\u00e3o do Intervalo de Confian\u00e7a\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#51-significado-do-intervalo-de-confianca","title":"5.1. Significado do Intervalo de Confian\u00e7a\u00b6","text":"<ul> <li><p>Intervalo Calculado: $[0.756325,0.774551]$.</p> <p>Isso significa que, com 95% de confian\u00e7a, a m\u00e9dia verdadeira da popula\u00e7\u00e3o da qual a amostra foi retirada est\u00e1 entre 0.756325 e 0.774551.</p> </li> <li><p>M\u00e9dia Amostral ($\\bar{x}$): 0.765438.</p> <p>A m\u00e9dia amostral \u00e9 a melhor estimativa pontual da m\u00e9dia verdadeira da popula\u00e7\u00e3o. O intervalo de confian\u00e7a fornece uma faixa ao redor dessa m\u00e9dia, refletindo a incerteza da estimativa.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#52-nivel-de-confianca-de-95","title":"5.2. N\u00edvel de Confian\u00e7a de 95%\u00b6","text":"<p>O n\u00edvel de confian\u00e7a de 95% implica que, se repet\u00edssemos o processo de amostragem muitas vezes (com diferentes amostras do mesmo tamanho), em 95% das vezes, o intervalo calculado conteria a verdadeira m\u00e9dia da popula\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#53-interpretacao-do-erro-padrao-da-media-sem","title":"5.3. Interpreta\u00e7\u00e3o do Erro Padr\u00e3o da M\u00e9dia (SEM)\u00b6","text":"<ul> <li><p>Erro Padr\u00e3o da M\u00e9dia (SEM): $0.003285$</p> <p>O SEM nos diz o quanto a m\u00e9dia amostral ($\\bar{x}$) pode variar de uma amostra para outra. Nesse caso, o SEM de $0.003285$ indica que a m\u00e9dia das amostras tende a variar em torno de $0.003285$ unidades em rela\u00e7\u00e3o \u00e0 m\u00e9dia verdadeira da popula\u00e7\u00e3o.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#54-precisao-da-estimativa","title":"5.4. Precis\u00e3o da Estimativa\u00b6","text":"<ul> <li><p>Intervalo Estreito: O intervalo relativamente estreito ($[0.756325,0.774551]$) indica que a estimativa da m\u00e9dia amostral \u00e9 bastante precisa. Isso ocorre porque o desvio padr\u00e3o \u00e9 pequeno e o tamanho da amostra \u00e9 adequado para garantir uma boa estimativa.</p> </li> <li><p>Implica\u00e7\u00f5es Pr\u00e1ticas: Em contextos pr\u00e1ticos, como an\u00e1lise financeira ou pesquisa cient\u00edfica, essa precis\u00e3o significa que podemos confiar que a m\u00e9dia da popula\u00e7\u00e3o real est\u00e1 dentro do intervalo calculado com um alto n\u00edvel de confian\u00e7a.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.4_Aplicacao_intervalos_de_confianca/#6-interpretacao-generica-do-intervalo-de-confianca","title":"6. Interpreta\u00e7\u00e3o Generica do Intervalo de Confian\u00e7a\u00b6","text":"<p>Um intervalo de confian\u00e7a de 95% para uma m\u00e9dia amostral significa que, se coletarmos 100 amostras diferentes e calcularmos um intervalo de confian\u00e7a para cada uma, esperamos que 95 desses intervalos contenham a verdadeira m\u00e9dia da popula\u00e7\u00e3o.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/","title":"1.1.5 O que \u00e9 p-valor","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/#1-o-que-e-p-valor","title":"1. O que \u00e9 P VALOR?","text":"<p>O valor de p representa a probabilidade de a diferen\u00e7a detectada entre os grupos analisados ter ocorrido ao acaso. </p> <p>Ent\u00e3o,</p> <p>\u2013 Um pequeno valor de p (p \u2264 0,05, ou seja, probabilidade menor ou igual a 5%):  indica que h\u00e1 uma pequena probabilidade de que a diferen\u00e7a observada entre os grupos seja ao acaso, ent\u00e3o, voc\u00ea considera que <code>h\u00e1 diferen\u00e7a significativa</code> entre os grupos.</p> <p>\u2013 Um grande valor de p (p &gt; 0,05, ou seja, probabilidade maior que 5%):  indica que h\u00e1 uma grande probabilidade de que a diferen\u00e7a observada entre os grupos seja ao acaso, ent\u00e3o, voc\u00ea considera que <code>n\u00e3o h\u00e1 diferen\u00e7a significativa</code> entre os grupos.</p> <p>Na explica\u00e7\u00e3o acima, usamos \u201cdiferen\u00e7a entre os grupos\u201d como exemplo, que se aplica a an\u00e1lises como teste t e Anova.</p> <p>Para testes como correla\u00e7\u00e3o de Pearson e regress\u00e3o linear, passar\u00edamos a dizer \u201crela\u00e7\u00e3o entre as vari\u00e1veis\u201d.</p> <p>Refer\u00eancia: https://estatisticafacil.org/2020/10/06/valor_de_p/</p> <p>Atente-se para a informa\u00e7\u00e3o a seguir:</p> <p>As defini\u00e7\u00f5es, entendimentos e explica\u00e7\u00f5es que utilizamos aqui, s\u00e3o os mais gerais e amplamente utilizadas em disciplinas b\u00e1sicas de estat\u00edstica ou bioestat\u00edstica e livros texto.</p> <p>Sendo assim, nestes moldes, de forma geral, o entendimento dos significados se torna mais f\u00e1cil e l\u00f3gico para quem n\u00e3o \u00e9 ligado diretamente com a \u00e1rea de exatas.</p> <p>Este entendimento, no entanto, vem sendo criticado por alguns estat\u00edsticos e, por conta disto, a Associa\u00e7\u00e3o Americana de Estat\u00edstica publicou um editorial sobre a <code>\u201csignific\u00e2ncia estat\u00edstica e o valor de p\u201d</code>, com aspectos um pouco diferentes dos retratados aqui.</p> <p>Abaixo, uma defini\u00e7\u00e3o mais precisa, mas ao mesmo tempo menos intuitiva.</p> <p>O valor de p representa a probabilidade de obtermos um resultado igual (ou mais extremo) ao obtido a partir dos nossos dados, assumindo que a hip\u00f3tese nula \u00e9 verdadeira.</p> <p>Essa defini\u00e7\u00e3o ser\u00e1 discutida nos t\u00f3picos abaixo</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/#2-hipoteses-estatisticas","title":"2. Hip\u00f3teses Estat\u00edsticas","text":"<p>Quando fazemos um teste inferencial de hip\u00f3teses \u2014 como qui-quadrado, teste t, anova, correla\u00e7\u00e3o, regress\u00e3o, etc \u2014 temos basicamente duas hip\u00f3teses:</p> <ul> <li> <p>HIP\u00d3TESE nula (H0): A padr\u00e3o, mais simples, de que n\u00e3o h\u00e1 \u2018diferen\u00e7a entre os grupos\u2019 ou n\u00e3o h\u00e1 \u2018rela\u00e7\u00e3o entre as vari\u00e1veis\u2019.</p> </li> <li> <p>HIP\u00d3TESE alternativa (H1): Estado alternativo, complementar a H0, de que h\u00e1 \u2018diferen\u00e7as entre grupos\u2019 ou h\u00e1 \u2018rela\u00e7\u00e3o entre as vari\u00e1veis\u2019.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/#3-nivel-de-significancia-e-valor-de-p","title":"3. N\u00edvel de Signific\u00e2ncia e Valor de P","text":"<p>O objetivo b\u00e1sico de todo e qualquer teste de hip\u00f3teses \u00e9 definir se rejeitaremos ou n\u00e3o a hip\u00f3tese nula (H0) \u2014 e essa defini\u00e7\u00e3o depender\u00e1 de dois fatores fundamentais:</p> <ul> <li> <p>1. N\u00cdVEL DE SIGNIFIC\u00c2NCIA (\u03b1): Representa um valor de corte, um crit\u00e9rio que definimos para rejeitar H0 ou n\u00e3o. A defini\u00e7\u00e3o de seu valor \u2014 normalmente 1% ou 5% \u2014 deve ser feita anteriormente ao teste.</p> </li> <li> <p>2. VALOR DE P (p): O valor de p representa uma probabilidade, e esse valor ser\u00e1 obtido sempre que executarmos um teste inferencial de hip\u00f3teses.</p> </li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/#4-estatisticamente-significativo","title":"4. Estatisticamente Significativo?","text":"<p>Ao executar nossa an\u00e1lise e obtermos o valor de p, o pr\u00f3ximo passo ser\u00e1 compar\u00e1-lo com o n\u00edvel de signific\u00e2ncia (\u03b1) que definimos anteriormente.</p> <p>Como exemplo, considere que definimos um n\u00edvel de signific\u00e2ncia (\u03b1) de 0,05 (ou 5%), ter\u00edamos ent\u00e3o duas possibilidades ao compararmos esse \u03b1 com nosso valor de p obtido no teste:</p> <ol> <li> <p>Quando o valor de p \u00e9 menor ou igual ao n\u00edvel de signific\u00e2ncia \u03b1 <code>(p \u2264 0,05)</code>, devemos ent\u00e3o <code>rejeitar</code> a <code>hip\u00f3tese nula (H0)</code>. Aqui dizemos que nosso teste foi <code>estatisticamente significativo</code>.</p> </li> <li> <p>Quando o valor de p \u00e9 maior que o n\u00edvel de signific\u00e2ncia \u03b1 <code>(p &gt; 0,05)</code>, devemos ent\u00e3o <code>n\u00e3o rejeitar</code> a <code>hip\u00f3tese nula (H0)</code>. Aqui dizemos que nosso teste <code>n\u00e3o foi estatisticamente significativo</code>.</p> </li> </ol>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.5_O_que_e_p_valor/#5-o-que-significa-o-valor-de-p","title":"5. O que Significa o Valor de P?","text":"<p>Em termos t\u00e9cnicos o valor de p pode ser definido como:</p> <p>A probabilidade de obtermos um resultado igual (ou mais  extremo) ao obtido a partir dos nossos dados, assumindo que a hip\u00f3tese nula \u00e9 verdadeira.</p> <p>Se meu teste retornou, por exemplo, p = 2%, o que isso significa?</p> <p>Se considerarmos H0 verdadeira, a probabilidade de obtermos resultados iguais (ou mais extremos) que o nosso, ser\u00e1 de apenas 2%. Como foi menor que o \u03b1 = 5%, rejeitamos H0.</p> <p>Refer\u00eancia: https://estatisticafacil.org/2022/02/18/valor_de_p_retorno/</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/","title":"1.1.6 Aplica\u00e7\u00e3o Permutacional Test","text":"<p>Para realizar um teste de permuta\u00e7\u00e3o junto e um teste t no cen\u00e1rio em que voc\u00ea possui duas colunas de m\u00e9tricas ks.scores1 e ks.scores2, podemos seguir os seguintes passos:</p> <p>1. <code>Teste T Pareado:</code> \u00c9 um teste param\u00e9trico que assume que os dados seguem uma distribui\u00e7\u00e3o normal (para grandes amostras, isso \u00e9 menos cr\u00edtico devido ao Teorema Central do Limite). Ele \u00e9 mais eficiente com amostras grandes e pode ser mais f\u00e1cil de interpretar em muitos casos. Como j\u00e1 discutido, o teste t pareado \u00e9 apropriado para amostras emparelhadas e verifica se a diferen\u00e7a m\u00e9dia \u00e9 significativamente diferente de zero.</p> <p>2. <code>Teste de Permuta\u00e7\u00e3o:</code> \u00c9 um teste n\u00e3o-param\u00e9trico que n\u00e3o faz suposi\u00e7\u00f5es sobre a distribui\u00e7\u00e3o dos dados. Ele avalia a diferen\u00e7a entre as m\u00e9dias das amostras ao permutar os dados entre as duas amostras para gerar uma distribui\u00e7\u00e3o nula.\u00c9 especialmente \u00fatil quando voc\u00ea tem uma amostra pequena ou quando n\u00e3o pode assumir a normalidade dos dados.</p> <p>O <code>teste de permuta\u00e7\u00e3o</code> \u00e9 um m\u00e9todo de <code>resampling</code> que permite testar a hip\u00f3tese nula de que duas amostras n\u00e3o apresentam diferen\u00e7as estat\u00edsticas significativas. Isso \u00e9 feito atrav\u00e9s da permuta\u00e7\u00e3o repetida dos dados, calculando a diferen\u00e7a nas m\u00e9dias a cada permuta\u00e7\u00e3o, para criar uma distribui\u00e7\u00e3o nula.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\n\n# Criar o DataFrame\ndf = pd.DataFrame(data)\n\n# N\u00famero de permuta\u00e7\u00f5es\nnum_permutations = 10000\n\n# Calcular a diferen\u00e7a observada entre as m\u00e9dias\nobserved_diff = np.mean(df['ks.scores1']) - np.mean(df['ks.scores2'])\n\n# Combinar as duas amostras\ncombined = np.hstack((df['ks.scores1'], df['ks.scores2']))\n\n# Inicializar contador para permuta\u00e7\u00f5es onde a diferen\u00e7a \u00e9 maior ou igual \u00e0 diferen\u00e7a observada\ncount = 0\n\n# Permuta\u00e7\u00e3o\nfor _ in range(num_permutations):\n    # Embaralhar os dados\n    np.random.shuffle(combined)\n    # Separar novamente em dois grupos\n    permuted1 = combined[:len(df['ks.scores1'])]\n    permuted2 = combined[len(df['ks.scores1']):]\n    # Calcular a diferen\u00e7a de m\u00e9dias nas amostras permutadas\n    permuted_diff = np.mean(permuted1) - np.mean(permuted2)\n    # Verificar se a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada\n    if abs(permuted_diff) &gt;= abs(observed_diff):\n        count += 1\n\n# Calcular o valor p\np_value_permutation = count / num_permutations\n\n# Exibir resultados\nprint(\"Diferen\u00e7a observada:\", observed_diff)\nprint(\"Valor p do teste de permuta\u00e7\u00e3o:\", p_value_permutation)\n\n# Avalia\u00e7\u00e3o do resultado\nif p_value_permutation &lt; 0.05:\n    print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\nelse:\n    print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")\n</pre> import numpy as np import pandas as pd  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] }  # Criar o DataFrame df = pd.DataFrame(data)  # N\u00famero de permuta\u00e7\u00f5es num_permutations = 10000  # Calcular a diferen\u00e7a observada entre as m\u00e9dias observed_diff = np.mean(df['ks.scores1']) - np.mean(df['ks.scores2'])  # Combinar as duas amostras combined = np.hstack((df['ks.scores1'], df['ks.scores2']))  # Inicializar contador para permuta\u00e7\u00f5es onde a diferen\u00e7a \u00e9 maior ou igual \u00e0 diferen\u00e7a observada count = 0  # Permuta\u00e7\u00e3o for _ in range(num_permutations):     # Embaralhar os dados     np.random.shuffle(combined)     # Separar novamente em dois grupos     permuted1 = combined[:len(df['ks.scores1'])]     permuted2 = combined[len(df['ks.scores1']):]     # Calcular a diferen\u00e7a de m\u00e9dias nas amostras permutadas     permuted_diff = np.mean(permuted1) - np.mean(permuted2)     # Verificar se a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada     if abs(permuted_diff) &gt;= abs(observed_diff):         count += 1  # Calcular o valor p p_value_permutation = count / num_permutations  # Exibir resultados print(\"Diferen\u00e7a observada:\", observed_diff) print(\"Valor p do teste de permuta\u00e7\u00e3o:\", p_value_permutation)  # Avalia\u00e7\u00e3o do resultado if p_value_permutation &lt; 0.05:     print(\"Rejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\") else:     print(\"N\u00e3o rejeitamos a hip\u00f3tese nula: N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\")  <pre>Diferen\u00e7a observada: 0.05183019999999994\nValor p do teste de permuta\u00e7\u00e3o: 0.0053\nRejeitamos a hip\u00f3tese nula: H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias.\n</pre> In\u00a0[3]: Copied! <pre>from typing import Dict, List, Tuple\ndef permutation_test(\n    array1: List[float],\n    array2: List[float],\n    anscreen: bool = True,\n    alpha: float = 0.05\n) -&gt; Tuple[float, List[float], float, List[str]]:\n    \"\"\"\n    Realiza um teste de permuta\u00e7\u00e3o para comparar as m\u00e9dias de dois arrays.\n\n    Args:\n        array1 (List[float]): O primeiro array de dados.\n        array2 (List[float]): O segundo array de dados.\n        anscreen (bool): Se True, imprime os resultados na tela. Default \u00e9 False.\n        alpha (float): N\u00edvel de signific\u00e2ncia para o teste (p-valor). Default \u00e9 0.05.\n\n    Returns:\n        Tuple[float, List[float], float, List[str]]:\n            - p_val (float): Valor p do teste de permuta\u00e7\u00e3o.\n            - mean_lst (List[float]): Lista das diferen\u00e7as m\u00e9dias permutadas.\n            - mean_diff (float): Diferen\u00e7a m\u00e9dia observada entre os dois arrays.\n            - text_lst (List[str]): Lista de mensagens interpretativas sobre o teste.\n    \"\"\"\n    # Garantindo a entrada com numpy array\n    array1 = np.array(array1)\n    array2 = np.array(array2)\n    \n    # C\u00e1lculo das m\u00e9dias de cada vetor\n    avg_array1 = array1.mean()\n    avg_array2 = array2.mean()\n    \n    # Diferen\u00e7a entre as m\u00e9dias\n    mean_diff = avg_array1 - avg_array2\n    full_array = np.concatenate([array1, array2])\n    mean_lst = []\n    # Defina a semente aleat\u00f3ria para reprodutibilidade\n    np.random.seed(42)\n    for i in range(10000):\n        # Com reposi\u00e7\u00e3o: bootstrapping\n        avg1 = np.random.choice(full_array, size=len(array1), replace=True).mean()\n        avg2 = np.random.choice(full_array, size=len(array2), replace=True).mean()\n        # reprece = True, Assume que qualquer valor pode vir de uma das duas listas, converg\u00cancia para Normal.\n        mean_lst.append(avg1 - avg2)\n    \n    if mean_diff &gt; 0:\n        p_val = np.sum(np.array(mean_lst) &gt; mean_diff) / len(mean_lst) \n    else:\n        p_val = np.sum(np.array(mean_lst) &lt; mean_diff) / len(mean_lst) \n    \n    text_lst = [\"\\n Teste de Significancia \", \n                \"**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \\n\",\n                f\" Arrays sizes: {len(array1)}, {len(array2)} \",\n                \"* Difference between averages: %.4f - %.4f = %.4f\" % (avg_array1, avg_array2, mean_diff),\n                \"* p_val = %.4f \" %p_val]\n    \n    if p_val &gt; alpha:\n        text_lst.append(f'The model seems to produce similar results with CI-{1 - alpha} (fail to reject H0).\\n')\n    else:\n        text_lst.append(f'The model seems to produce different results with CI-{1 - alpha} (reject H0).\\n')\n    \n    if anscreen:\n        for line in text_lst:\n            print(line)   \n    return p_val, mean_lst, mean_diff, text_lst\n\n# Dados fornecidos: ks.scores\ndata = {\n    \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],\n    \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064]\n}\np_val, mean_lst, mean_diff, text_lst = permutation_test(array1 = data[\"ks.scores1\"], array2 = data[\"ks.scores2\"], alpha  = 0.05)\n</pre> from typing import Dict, List, Tuple def permutation_test(     array1: List[float],     array2: List[float],     anscreen: bool = True,     alpha: float = 0.05 ) -&gt; Tuple[float, List[float], float, List[str]]:     \"\"\"     Realiza um teste de permuta\u00e7\u00e3o para comparar as m\u00e9dias de dois arrays.      Args:         array1 (List[float]): O primeiro array de dados.         array2 (List[float]): O segundo array de dados.         anscreen (bool): Se True, imprime os resultados na tela. Default \u00e9 False.         alpha (float): N\u00edvel de signific\u00e2ncia para o teste (p-valor). Default \u00e9 0.05.      Returns:         Tuple[float, List[float], float, List[str]]:             - p_val (float): Valor p do teste de permuta\u00e7\u00e3o.             - mean_lst (List[float]): Lista das diferen\u00e7as m\u00e9dias permutadas.             - mean_diff (float): Diferen\u00e7a m\u00e9dia observada entre os dois arrays.             - text_lst (List[str]): Lista de mensagens interpretativas sobre o teste.     \"\"\"     # Garantindo a entrada com numpy array     array1 = np.array(array1)     array2 = np.array(array2)          # C\u00e1lculo das m\u00e9dias de cada vetor     avg_array1 = array1.mean()     avg_array2 = array2.mean()          # Diferen\u00e7a entre as m\u00e9dias     mean_diff = avg_array1 - avg_array2     full_array = np.concatenate([array1, array2])     mean_lst = []     # Defina a semente aleat\u00f3ria para reprodutibilidade     np.random.seed(42)     for i in range(10000):         # Com reposi\u00e7\u00e3o: bootstrapping         avg1 = np.random.choice(full_array, size=len(array1), replace=True).mean()         avg2 = np.random.choice(full_array, size=len(array2), replace=True).mean()         # reprece = True, Assume que qualquer valor pode vir de uma das duas listas, converg\u00cancia para Normal.         mean_lst.append(avg1 - avg2)          if mean_diff &gt; 0:         p_val = np.sum(np.array(mean_lst) &gt; mean_diff) / len(mean_lst)      else:         p_val = np.sum(np.array(mean_lst) &lt; mean_diff) / len(mean_lst)           text_lst = [\"\\n Teste de Significancia \",                  \"**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \\n\",                 f\" Arrays sizes: {len(array1)}, {len(array2)} \",                 \"* Difference between averages: %.4f - %.4f = %.4f\" % (avg_array1, avg_array2, mean_diff),                 \"* p_val = %.4f \" %p_val]          if p_val &gt; alpha:         text_lst.append(f'The model seems to produce similar results with CI-{1 - alpha} (fail to reject H0).\\n')     else:         text_lst.append(f'The model seems to produce different results with CI-{1 - alpha} (reject H0).\\n')          if anscreen:         for line in text_lst:             print(line)        return p_val, mean_lst, mean_diff, text_lst  # Dados fornecidos: ks.scores data = {     \"ks.scores1\": [0.583983, 0.576596, 0.556730, 0.595138, 0.584564],     \"ks.scores2\": [0.490242, 0.551584, 0.514383, 0.535587, 0.546064] } p_val, mean_lst, mean_diff, text_lst = permutation_test(array1 = data[\"ks.scores1\"], array2 = data[\"ks.scores2\"], alpha  = 0.05) <pre>\n Teste de Significancia \n**$H_0$:** Diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas \u00e9 zero. \n\n Arrays sizes: 5, 5 \n* Difference between averages: 0.5794 - 0.5276 = 0.0518\n* p_val = 0.0049 \nThe model seems to produce different results with CI-0.95 (reject H0).\n\n</pre>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#teste-de-permutacao","title":"Teste de permuta\u00e7\u00e3o\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#implementacao-do-teste-t-pareado","title":"Implementa\u00e7\u00e3o do Teste T Pareado\u00b6","text":"<p>Antes de implementarmos o teste de permuta\u00e7\u00e3o, vamos relembrar como implementar o teste t pareado:</p> <ul> <li>Notebook -Teste T Calculo</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#implementacao-do-teste-de-permutacao","title":"Implementa\u00e7\u00e3o do Teste de Permuta\u00e7\u00e3o\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#passo-a-passo-para-o-teste-de-permutacao","title":"Passo a Passo para o Teste de Permuta\u00e7\u00e3o\u00b6","text":"<p>1. Formula\u00e7\u00e3o das Hip\u00f3teses:</p> <ul> <li><code>H0 (Hip\u00f3tese Nula):</code>  As duas amostras v\u00eam da mesma distribui\u00e7\u00e3o (N\u00e3o h\u00e1 diferen\u00e7a significativa entre as m\u00e9dias).</li> <li><code>H1 (Hip\u00f3tese Alternativa):</code> As duas amostras v\u00eam de distribui\u00e7\u00f5es diferentes (H\u00e1 diferen\u00e7a significativa entre as m\u00e9dias).</li> </ul> <p>2. Passos do Teste de Permuta\u00e7\u00e3o:</p> <ul> <li>Calcule a diferen\u00e7a observada entre as m\u00e9dias das duas amostras.</li> <li>Combine as amostras em um \u00fanico conjunto de dados.</li> <li>Embaralhe (permute) aleatoriamente os dados e separe-os novamente em dois grupos.</li> <li>Calcule a diferen\u00e7a entre as m\u00e9dias dos grupos permutados.</li> <li>Repita o processo de permuta\u00e7\u00e3o v\u00e1rias vezes (por exemplo, 10.000 vezes) para construir a distribui\u00e7\u00e3o nula.</li> <li>Compare a diferen\u00e7a observada com a distribui\u00e7\u00e3o nula para determinar o valor p.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#teste-de-permutacao-codigo-1","title":"Teste de Permuta\u00e7\u00e3o: C\u00f3digo 1:\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#explicacao-do-codigo-do-teste-de-permutacao","title":"Explica\u00e7\u00e3o do C\u00f3digo do Teste de Permuta\u00e7\u00e3o\u00b6","text":"<ul> <li><code>Combina\u00e7\u00e3o e Permuta\u00e7\u00e3o:</code> Combina as duas amostras em um array e embaralha repetidamente para criar distribui\u00e7\u00f5es permutadas.</li> <li><code>Contagem:</code> Conta o n\u00famero de permuta\u00e7\u00f5es onde a diferen\u00e7a permutada \u00e9 maior ou igual \u00e0 diferen\u00e7a observada.</li> <li><code>C\u00e1lculo do Valor p:</code> O valor p \u00e9 calculado dividindo o n\u00famero de permuta\u00e7\u00f5es em que a diferen\u00e7a permutada foi maior ou igual \u00e0 diferen\u00e7a observada pelo total de permuta\u00e7\u00f5es.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#resultado-esperado","title":"Resultado Esperado\u00b6","text":"<p>Ao executar ambos os testes, voc\u00ea ter\u00e1 duas an\u00e1lises complementares sobre a diferen\u00e7a entre as m\u00e9dias das m\u00e9tricas:</p> <ul> <li>1. <code>Teste T Pareado:</code> Verifica se a diferen\u00e7a m\u00e9dia \u00e9 significativa sob a suposi\u00e7\u00e3o de normalidade.</li> <li>2. <code>Teste de Permuta\u00e7\u00e3o:</code> Oferece uma abordagem n\u00e3o-param\u00e9trica para testar a mesma hip\u00f3tese.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#consideracoes","title":"Considera\u00e7\u00f5es\u00b6","text":"<p>O teste t assume que as diferen\u00e7as entre as amostras seguem uma distribui\u00e7\u00e3o normal. Se essa suposi\u00e7\u00e3o n\u00e3o for v\u00e1lida, o teste de permuta\u00e7\u00e3o \u00e9 uma boa alternativa. O teste de permuta\u00e7\u00e3o \u00e9 computacionalmente intensivo, mas n\u00e3o depende de suposi\u00e7\u00f5es sobre a distribui\u00e7\u00e3o dos dados, tornando-o \u00fatil para casos em que a normalidade \u00e9 question\u00e1vel.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#teste-de-permutacao-codigo-2","title":"Teste de Permuta\u00e7\u00e3o: C\u00f3digo 2 ()\u00b6","text":""},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#comparando-os-codigos-de-permutacao","title":"Comparando os c\u00f3digos de Permuta\u00e7\u00e3o\u00b6","text":"<p>O <code>c\u00f3digo 1</code>  e a fun\u00e7\u00e3o <code>permutation_test</code> compartilham a mesma l\u00f3gica b\u00e1sica para realizar um teste de permuta\u00e7\u00e3o, mas existem algumas diferen\u00e7as sutis na implementa\u00e7\u00e3o e no tipo de an\u00e1lise.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#codigo-fornecido","title":"C\u00f3digo Fornecido\u00b6","text":"<p>1. Processo de Permuta\u00e7\u00e3o:</p> <ul> <li>Combina as duas amostras.</li> <li>Embaralha aleatoriamente os dados combinados.</li> <li>Separa os dados embaralhados novamente em duas amostras.</li> <li>Calcula a diferen\u00e7a entre as m\u00e9dias das amostras permutadas e compara com a diferen\u00e7a observada.</li> </ul> <p>2. Valor p:</p> <ul> <li>O <code>valor p</code> \u00e9 calculado como a propor\u00e7\u00e3o das diferen\u00e7as permutadas que s\u00e3o maiores ou iguais \u00e0 diferen\u00e7a observada.</li> </ul> <p>3. Teste de Hip\u00f3teses:</p> <p>Se o <code>valor p for menor que 0.05</code>, <code>rejeita a hip\u00f3tese nula</code>, indicando que h\u00e1 uma diferen\u00e7a significativa entre as m\u00e9dias.</p>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#funcao-permutation_test","title":"Fun\u00e7\u00e3o permutation_test\u00b6","text":"<p>1. Processo de Permuta\u00e7\u00e3o:</p> <ul> <li>Em vez de combinar e embaralhar os dados, utiliza a t\u00e9cnica de <code>bootstrapping</code> (amostragem com reposi\u00e7\u00e3o) para gerar as diferen\u00e7as de m\u00e9dias. Calcula a diferen\u00e7a entre as m\u00e9dias de amostras bootstrapped e compara com a diferen\u00e7a observada.</li> </ul> <p>2. Valor p:</p> <ul> <li>O valor p \u00e9 calculado comparando a diferen\u00e7a m\u00e9dia observada com as diferen\u00e7as m\u00e9dias obtidas nas amostras bootstrapped.</li> </ul> <p>3. Teste de Hip\u00f3teses:</p> <ul> <li>A fun\u00e7\u00e3o oferece uma descri\u00e7\u00e3o mais detalhada do teste, incluindo mensagens interpretativas.</li> <li>Permite definir um n\u00edvel de signific\u00e2ncia (alpha) e imprime resultados na tela se o argumento anscreen for True.</li> </ul>"},{"location":"1_estatistica/1.1_testes_de_hipoteses/1.1.6_Aplicacao_Permutacion_test/#principais-diferencas","title":"Principais Diferen\u00e7as\u00b6","text":"<ul> <li><code>Combina\u00e7\u00e3o de Dados:</code> O c\u00f3digo 1 combina as amostras e embaralha, enquanto a fun\u00e7\u00e3o permutation_test utiliza <code>bootstrapping</code>.</li> <li><code>Tipo de Permuta\u00e7\u00e3o:</code> O c\u00f3digo 1 usa permuta\u00e7\u00e3o direta, enquanto a fun\u00e7\u00e3o permutation_test usa amostragem com reposi\u00e7\u00e3o.</li> <li><code>Sa\u00edda:</code> A fun\u00e7\u00e3o permutation_test retorna um conjunto mais detalhado de informa\u00e7\u00f5es e permite a impress\u00e3o dos resultados.</li> </ul> <p>Ambos os m\u00e9todos t\u00eam o mesmo objetivo: comparar as m\u00e9dias de duas amostras para determinar se h\u00e1 uma diferen\u00e7a significativa. A escolha entre eles pode depender da prefer\u00eancia ou do contexto espec\u00edfico do problema.</p>"},{"location":"2_machine_learning/Introducao_machine_learning/","title":"1. Introdu\u00e7\u00e3o ao Machine Learning","text":""},{"location":"2_machine_learning/Introducao_machine_learning/#11-o-que-e-machine-learning","title":"1.1. O Que \u00e9 Machine Learning?","text":"<p>Machine Learning (Aprendizado de M\u00e1quina) \u00e9 um subcampo da Intelig\u00eancia Artificial que utiliza algoritmos estat\u00edsticos para permitir que sistemas \"aprendam\" com dados, identificando padr\u00f5es e tomando decis\u00f5es com interven\u00e7\u00e3o humana m\u00ednima.</p>"},{"location":"2_machine_learning/Introducao_machine_learning/#12-relacao-com-a-estatistica","title":"1.2. Rela\u00e7\u00e3o com a Estat\u00edstica","text":"<p>O Machine Learning \u00e9 essencialmente Estat\u00edstica computacional em a\u00e7\u00e3o. Enquanto a Estat\u00edstica tradicional foca em infer\u00eancia e testes de hip\u00f3teses, o ML prioriza a predi\u00e7\u00e3o e a automatiza\u00e7\u00e3o. Ambas compartilham:</p> <ul> <li>Modelos de regress\u00e3o e classifica\u00e7\u00e3o  </li> <li>T\u00e9cnicas de valida\u00e7\u00e3o cruzada  </li> <li>M\u00e9tricas de desempenho (RMSE, AUC-ROC)  </li> <li>Tratamento de vi\u00e9s e vari\u00e2ncia</li> </ul>"},{"location":"2_machine_learning/Introducao_machine_learning/#13-principais-categorias","title":"1.3. Principais Categorias","text":"<ol> <li> <p>Aprendizado Supervisionado    (Dados rotulados - Regress\u00e3o/Classifica\u00e7\u00e3o)    Ex: Prever pre\u00e7os de im\u00f3veis (Regress\u00e3o Linear) ou diagnosticar doen\u00e7as (\u00c1rvores de Decis\u00e3o)</p> </li> <li> <p>Aprendizado N\u00e3o-Supervisionado    (Dados n\u00e3o rotulados - Clusteriza\u00e7\u00e3o)    Ex: Segmenta\u00e7\u00e3o de clientes (K-Means), Redu\u00e7\u00e3o de dimensionalidade (PCA)</p> </li> <li> <p>Aprendizado por Refor\u00e7o    (Sistemas que aprendem por tentativa e erro)    Ex: Jogos aut\u00f4nomos, Rob\u00f3tica</p> </li> </ol>"},{"location":"2_machine_learning/Introducao_machine_learning/#14-por-que-combinar-estatistica-e-ml","title":"1.4. Por Que Combinar Estat\u00edstica e ML?","text":"Estat\u00edstica Cl\u00e1ssica Machine Learning Foco em interpretabilidade Foco em performance preditiva Amostras menores Grandes volumes de dados Testes de signific\u00e2ncia Otimiza\u00e7\u00e3o de hiperpar\u00e2metros"},{"location":"2_machine_learning/Introducao_machine_learning/#15-aplicacoes-praticas","title":"1.5. Aplica\u00e7\u00f5es Pr\u00e1ticas","text":"<p>\ud83c\udfe5 Sa\u00fade: Diagn\u00f3stico de c\u00e2ncer com redes neurais</p> <p>\ud83c\udfe6 Finan\u00e7as: Detec\u00e7\u00e3o de fraudes em transa\u00e7\u00f5es</p> <p>\ud83d\uded2 Varejo: Sistemas de recomenda\u00e7\u00e3o (como os da Amazon/Netflix)</p> <p>\"Machine Learning \u00e9 estat\u00edstica em ester\u00f3ides, mas sem compreens\u00e3o &gt;estat\u00edstica, voc\u00ea estar\u00e1 apenas pressionando bot\u00f5es aleat\u00f3rios.\" \u2014 John Tukey</p>"},{"location":"2_machine_learning/Introducao_machine_learning/#2-topicos-de-machine-learning","title":"2. T\u00f3picos de Machine Learning","text":""},{"location":"2_machine_learning/Introducao_machine_learning/#21-classificacao-versus-regressao","title":"2.1. classifica\u00e7\u00e3o versus regress\u00e3o","text":"<p>Existem duas categorias de problemas que podem ser bem resolvidos com a utiliza\u00e7\u00e3o de Machine Learning: os de classifica\u00e7\u00e3o e os de regress\u00e3o.</p>"},{"location":"2_machine_learning/Introducao_machine_learning/#211-classificacao","title":"2.1.1. Classifica\u00e7\u00e3o","text":"<p>Quando precisamos prever a qual categoria pertence uma determinada amostra, trata-se de um problema de classifica\u00e7\u00e3o. Alguns exemplos que podemos citar s\u00e3o:</p> <p>Prever se um(a) determinado(a) paciente est\u00e1 com Covid. Se um(a) cliente est\u00e1 propenso(a) a desistir da compra. Se algum(a) usu\u00e1rio(a) web est\u00e1 propenso(a) a clicar em um an\u00fancio. Nesses casos mencionados, a previs\u00e3o se concentra em 0 ou 1 (Covid/n\u00e3o Covid, desistir/n\u00e3o desistir, clicar/n\u00e3o clicar) que \u00e9 denominada de classifica\u00e7\u00e3o bin\u00e1ria, na qual existem somente duas classes. H\u00e1 tamb\u00e9m casos em que a classifica\u00e7\u00e3o se d\u00e1 com mais duas classes, chamada de classifica\u00e7\u00e3o multiclasse, como a filtragem dos e-mails em \u201cprincipal\u201d, \u201csocial\u201d, \u201cpromo\u00e7\u00f5es\u201d, \u201cimportantes\u201d ou \u201cf\u00f3runs\u201d.</p> <p>Entre os algoritmos de classifica\u00e7\u00e3o podemos citar:</p> <ul> <li>K-Nearest Neighbors (KNN)</li> <li>Support Vector Machine (SVM)</li> <li>Decision Tree Classifier</li> <li>Random Forest Classifier</li> </ul>"},{"location":"2_machine_learning/Introducao_machine_learning/#212-regressao","title":"2.1.2. Regress\u00e3o","text":"<p>Quando precisamos prever um valor num\u00e9rico espec\u00edfico, isso indica que estamos lidando com um problema de regress\u00e3o. Alguns exemplos desses problemas est\u00e3o relacionados \u00e0 previs\u00e3o de:</p> <ul> <li>pre\u00e7os/custos futuros;</li> <li>estoque;</li> <li>receita futura.</li> </ul> <p>Nessas situa\u00e7\u00f5es, podemos utilizar algum modelo de regress\u00e3o para realizar essas previs\u00f5es e apresentar como resposta algum valor cont\u00ednuo relacionado ao problema. Existem diferentes tipos de algoritmos de machine learning utilizados para resolver esse tipo de problema:</p> <ul> <li>Linear Regression;</li> <li>Random Forest Regressor;</li> <li>Support Vector Regression (SVR).</li> </ul> <p>Fonte</p>"},{"location":"2_machine_learning/Introducao_machine_learning/#3-conteudos-disponiveis","title":"3. Conte\u00fados dispon\u00edveis","text":"<ul> <li>2.1. Crisp-DM</li> <li>2.2. Pr\u00e9 Treinamento</li> <li>2.3.Treinamento</li> <li>2.4. P\u00f3s Treinamento</li> </ul>"},{"location":"2_machine_learning/resumo_site/","title":"Resumo site","text":"<ul> <li>Regress\u00e3o Linear: Testando Rela\u00e7\u00f5es e Prevendo Resultados;</li> <li>Regress\u00e3o Linear: T\u00e9cnicas Avan\u00e7adas de Modelagem.</li> </ul> <p>Fonte</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.1_CRISP-DM/","title":"1. Desenvolvimento de Modelo de Machine Learning","text":"<p>Este projeto segue uma abordagem estruturada para o desenvolvimento de modelos de Machine Learning, utilizando  a metodologia do <code>CRISP-DM</code> dentro de tr\u00eas grandes grupos:</p> <ul> <li>1.1. Pr\u00e9-Treinamento</li> <li>1.2. Treinamento</li> <li>1.3. P\u00f3s-Treinamento</li> </ul> <p>As etapas do processo do <code>CRISP-DM</code> ser\u00e3o inseridas entre esses grupos.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.1_CRISP-DM/#2-visao-geral-da-metodologia-crisp-dm","title":"2. Vis\u00e3o Geral da Metodologia CRISP-DM","text":"<p>A metodologia CRISP-DM (Cross-Industry Standard Process for Data Mining) \u00e9 um estrutura abrangente que tem se destacado na abordagem de projetos de Ci\u00eancia de Dados, essa metodologia \u00e9 composta por seis fases interativas que guiam os profissionais de ci\u00eancia de dados durante todo o processo de descoberta de conhecimento a partir de dados. Vamos explorar cada uma dessas fases em detalhes:</p> <ol> <li> <p>Compreens\u00e3o do Neg\u00f3cio (Business Understanding) Antes de iniciar um projeto de an\u00e1lise de dados, \u00e9 essencial compreender o contexto e os objetivos do neg\u00f3cio. Nesta fase, definimos claramente as metas do projeto e as alinhamos aos objetivos estrat\u00e9gicos da organiza\u00e7\u00e3o.</p> </li> <li> <p>Compreens\u00e3o dos Dados (Data Understanding) Coletar dados relevantes \u00e9 fundamental para o sucesso do projeto. Nessa fase, exploramos e nos familiarizamos com os dados dispon\u00edveis, identificamos lacunas e problemas potenciais, e avaliamos a qualidade e a adequa\u00e7\u00e3o dos dados para o projeto.</p> </li> <li> <p>Prepara\u00e7\u00e3o dos Dados (Data Preparation) Os dados brutos raramente est\u00e3o prontos para a an\u00e1lise. Nesta fase, realizamos a limpeza dos dados, tratamos valores ausentes ou inconsistentes e integramos diferentes fontes de dados. O objetivo \u00e9 criar um conjunto de dados preparado para as etapas subsequentes.</p> </li> <li> <p>Modelagem (Modeling) A fase de modelagem envolve a aplica\u00e7\u00e3o de t\u00e9cnicas e algoritmos de modelagem de dados aos dados preparados. Selecionamos as t\u00e9cnicas mais adequadas, como regress\u00e3o, classifica\u00e7\u00e3o ou agrupamento, e ajustamos e avaliamos os modelos para garantir sua precis\u00e3o e efic\u00e1cia.</p> </li> <li> <p>Avalia\u00e7\u00e3o (Evaluation) A avalia\u00e7\u00e3o dos modelos desenvolvidos \u00e9 crucial para medir sua qualidade e desempenho. Nesta fase, utilizamos m\u00e9todos como valida\u00e7\u00e3o cruzada e m\u00e9tricas de desempenho para avaliar o qu\u00e3o bem os modelos se saem em dados n\u00e3o vistos. Com base nessa avalia\u00e7\u00e3o, podemos ajustar e aprimorar os modelos, se necess\u00e1rio.</p> </li> <li> <p>Implanta\u00e7\u00e3o (Deployment) A fase final da metodologia CRISP-DM \u00e9 a implanta\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o. Integramos o modelo aos sistemas existentes, monitoramos seu desempenho cont\u00ednuo e garantimos a ado\u00e7\u00e3o pela equipe de neg\u00f3cios.</p> </li> </ol> <p></p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/","title":"1. Principais conceitos do CRISP-DM: Pr\u00e9 Treinamento","text":""},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#11-compreensao-do-negocio-business-understanding","title":"1.1. Compreens\u00e3o do Neg\u00f3cio (Business Understanding)","text":""},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#12-compreensao-dos-dados-data-understanding","title":"1.2. Compreens\u00e3o dos Dados (Data Understanding)","text":""},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#121-analise-exploratoria-de-dados-eda","title":"1.2.1. An\u00e1lise Explorat\u00f3ria de Dados (EDA)","text":"<p>Explorar os dados para entender suas caracter\u00edsticas, distribui\u00e7\u00f5es e rela\u00e7\u00f5es.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#13-preparacao-dos-dados-data-preparation","title":"1.3. Prepara\u00e7\u00e3o dos Dados (Data Preparation)","text":"<p>Os dados brutos raramente est\u00e3o prontos para a an\u00e1lise. Nesta fase, realizamos a limpeza dos dados, tratamos valores ausentes ou inconsistentes e integramos diferentes fontes de dados. O objetivo \u00e9 criar um conjunto de dados preparado para as etapas subsequentes.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#131-normalizacao-padronizacao-e-transformacoes","title":"1.3.1. Normaliza\u00e7\u00e3o, Padroniza\u00e7\u00e3o e Transforma\u00e7\u00f5es","text":"<p>Uma atividade muito rotineira de um cientista de dados dentro do pr\u00e9-processamento, \u00e9 a transforma\u00e7\u00e3o de seus dados num\u00e9ricos com o objetivo de que todos eles fiquem com a mesma ordem de grandeza. Isso evita que o modelo fique enviesado, dando maior peso para as vari\u00e1veis de maior grandeza.</p> <p></p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#1311-normalizacao-normalization-or-scaling","title":"1.3.1.1. Normaliza\u00e7\u00e3o (Normalization or Scaling)","text":"<p>A normaliza\u00e7\u00e3o coloca os dados dentro do intervalo de 0 a 1 (ou -1 a 1 se houver valores negativos) sem distorcer as diferen\u00e7as nos intervalos de valores. Ele n\u00e3o remove outliers (valores extremos), mas garante que todos os pontos de dados estejam em uma escala comum.</p> <p>Normalizar os dados usando Min-Max:</p> <p>$$ x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} $$</p> <p>Se a distribui\u00e7\u00e3o n\u00e3o \u00e9 Gaussiana ou o desvio padr\u00e3o \u00e9 muito pequeno, normalizar os dados \u00e9 uma escolha a ser tomada.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#1312-padronizacao-standardization","title":"1.3.1.2. Padroniza\u00e7\u00e3o (Standardization)","text":"<p>J\u00e1 a padroniza\u00e7\u00e3o ir\u00e1 transformar as vari\u00e1veis fazendo com que elas resultem em uma m\u00e9dia igual a 0 e desvio padr\u00e3o igual a 1. Padronizar os dados normalmente \u00e9 feita usando a f\u00f3rmula z-score: $$ z = \\frac{x - \\mu}{\\sigma} $$</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#1313-transformacoes-transformations","title":"1.3.1.3. Transforma\u00e7\u00f5es (Transformations)","text":"<p>Estes envolvem a aplica\u00e7\u00e3o de fun\u00e7\u00f5es logar\u00edtmicas (como o logaritmo natural) aos dados. Eles s\u00e3o \u00fateis para lidar com distribui\u00e7\u00f5es assim\u00e9tricas e comprimir grandes faixas de valores. Leia mais: Transformacoes Veja alguns exemplos: Notebooks</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.2_Pre_treinamento/#14-referencias","title":"1.4. Refer\u00eancias","text":"<ul> <li>Normalizar ou Padronizar as Vari\u00e1veis?</li> <li>Normaliza\u00e7\u00e3o x Padroniza\u00e7\u00e3o: Qual a Diferen\u00e7a?</li> <li>O escalonamento dos dados: Normaliza\u00e7\u00e3o ou Padroniza\u00e7\u00e3o?</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.3_Treinamento/","title":"1. Modelagem (Modeling)","text":"<p>A fase de modelagem envolve a aplica\u00e7\u00e3o de t\u00e9cnicas e algoritmos de modelagem de dados aos dados preparados. Selecionamos as t\u00e9cnicas mais adequadas, como regress\u00e3o, classifica\u00e7\u00e3o ou agrupamento, e ajustamos e avaliamos os modelos para garantir sua precis\u00e3o e efic\u00e1cia.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/","title":"1. Avalia\u00e7\u00e3o (Evaluation)","text":"<p>A avalia\u00e7\u00e3o dos modelos desenvolvidos \u00e9 crucial para medir sua qualidade e desempenho. Nesta fase, utilizamos m\u00e9todos como valida\u00e7\u00e3o cruzada e m\u00e9tricas de desempenho para avaliar o qu\u00e3o bem os modelos se saem em dados n\u00e3o vistos. Com base nessa avalia\u00e7\u00e3o, podemos ajustar e aprimorar os modelos, se necess\u00e1rio.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#11-avaliacao-de-metricas-e-interpretacao-do-modelo","title":"1.1. Avalia\u00e7\u00e3o de M\u00e9tricas e Interpreta\u00e7\u00e3o do Modelo","text":"<ol> <li> <p>Calcular m\u00e9tricas de desempenho, como precis\u00e3o, recall, F1-score, etc., no conjunto de teste para avaliar o desempenho do modelo.</p> </li> <li> <p>Interpreta\u00e7\u00e3o do Modelo: Compreender como o modelo est\u00e1 tomando decis\u00f5es, quais caracter\u00edsticas s\u00e3o importantes e se est\u00e1 seguindo padr\u00f5es esperados.</p> </li> </ol>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#12-funcao-learning_curve","title":"1.2. Fun\u00e7\u00e3o <code>learning_curve</code>","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 uma ferramenta do scikit-learn que permite visualizar como o desempenho de um modelo varia com o tamanho do conjunto de treinamento. Ela \u00e9 \u00fatil para entender como o modelo se comporta \u00e0 medida que \u00e9 treinado com mais dados e para identificar problemas de <code>underfitting</code> ou <code>overfitting</code>.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#121-parametros-principais","title":"1.2.1. Par\u00e2metros Principais:","text":"<ul> <li> <p>Estimator: O estimador ou modelo de machine learning a ser avaliado. Deve ser um objeto que implementa os m\u00e9todos <code>fit</code> e <code>predict</code>.</p> </li> <li> <p>X: O conjunto de caracter\u00edsticas de entrada.</p> </li> <li> <p>y: O vetor alvo.</p> </li> <li> <p>Train_sizes: Os tamanhos relativos dos conjuntos de treinamento a serem usados. Pode ser especificado como uma lista de porcentagens ou como uma lista de n\u00fameros inteiros representando tamanhos absolutos.</p> </li> <li> <p>cv: O esquema de valida\u00e7\u00e3o cruzada a ser usado. Pode ser um objeto <code>KFold</code>, <code>StratifiedKFold</code>, ou um inteiro especificando o n\u00famero de folds.</p> </li> <li> <p>Scoring: A m\u00e9trica de avalia\u00e7\u00e3o a ser usada. Pode ser uma string representando uma m\u00e9trica integrada do scikit-learn (como 'accuracy', 'precision', 'recall', etc.) ou uma fun\u00e7\u00e3o de pontua\u00e7\u00e3o personalizada.</p> </li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#122-saida","title":"1.2.2. Sa\u00edda:","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> retorna cinco arrays:</p> <ul> <li> <p>Train_sizes_abs: O n\u00famero de amostras usadas em cada fold de treinamento.</p> </li> <li> <p>Train_scores: O desempenho do modelo no conjunto de treinamento para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>Test_scores: O desempenho do modelo no conjunto de teste (ou valida\u00e7\u00e3o) para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>fit_times: O tempo necess\u00e1rio para treinar o modelo para cada tamanho de conjunto de treinamento.</p> </li> <li> <p>score_times: O tempo necess\u00e1rio para avaliar o modelo para cada tamanho de conjunto de treinamento.</p> </li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#123-utilidade","title":"1.2.3. Utilidade:","text":"<p>A fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 \u00fatil para:</p> <ul> <li>Visualizar como o desempenho do modelo muda com o tamanho do conjunto de treinamento.</li> <li>Identificar se o modelo est\u00e1 sofrendo de underfitting (baixo desempenho em conjuntos de treinamento pequenos) ou overfitting (alta varia\u00e7\u00e3o entre os conjuntos de treinamento e teste).</li> <li>Determinar se coletar mais dados de treinamento pode melhorar o desempenho do modelo.</li> </ul> <p>Em resumo, a fun\u00e7\u00e3o <code>learning_curve</code> \u00e9 uma ferramenta valiosa para entender a capacidade de generaliza\u00e7\u00e3o do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento e para orientar decis\u00f5es importantes de modelagem em machine learning.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#13-interpretacao-da-curva-de-aprendizado","title":"1.3. Interpreta\u00e7\u00e3o da Curva de Aprendizado","text":""},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#131-curva-de-treinamento-vermelha","title":"1.3.1. Curva de Treinamento (Vermelha):","text":"<ul> <li>Inicialmente Alta e Est\u00e1vel: Se a curva de treinamento come\u00e7a alta e permanece est\u00e1vel, isso indica que o modelo est\u00e1 aprendendo bem com os dados de treinamento.</li> <li>Decl\u00ednio Inicial: Pode haver um decl\u00ednio inicial na acur\u00e1cia de treinamento \u00e0 medida que o tamanho do conjunto de treinamento aumenta, o que \u00e9 normal pois mais dados aumentam a complexidade do problema.</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#132-curva-de-validacao-verde","title":"1.3.2. Curva de Valida\u00e7\u00e3o (Verde):","text":"<ul> <li>Inicialmente Baixa e Crescendo: Se a curva de valida\u00e7\u00e3o come\u00e7a baixa e sobe, isso indica que o modelo est\u00e1 melhorando com mais dados de treinamento, o que \u00e9 um bom sinal.</li> <li>Plateau: Se a curva de valida\u00e7\u00e3o atinge um plateau e n\u00e3o melhora com mais dados, isso pode indicar que mais dados n\u00e3o v\u00e3o melhorar o desempenho e pode ser necess\u00e1rio ajustar os hiperpar\u00e2metros do modelo.</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#133-subajustamento-underfitting","title":"1.3.3. Subajustamento (Underfitting):","text":"<ul> <li>Ambas as Curvas Baixas: Se tanto a curva de treinamento quanto a curva de valida\u00e7\u00e3o s\u00e3o baixas e pr\u00f3ximas uma da outra, o modelo n\u00e3o est\u00e1 capturando bem os padr\u00f5es dos dados. Pode ser necess\u00e1rio um modelo mais complexo.</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#134-superajustamento-overfitting","title":"1.3.4. Superajustamento (Overfitting):","text":"<ul> <li>Curva de Treinamento Alta e Curva de Valida\u00e7\u00e3o Baixa: Se a curva de treinamento \u00e9 alta e a curva de valida\u00e7\u00e3o \u00e9 significativamente mais baixa, o modelo est\u00e1 se ajustando demais aos dados de treinamento e n\u00e3o est\u00e1 generalizando bem. T\u00e9cnicas como regulariza\u00e7\u00e3o, redu\u00e7\u00e3o da complexidade do modelo ou aumento do conjunto de dados podem ajudar.</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#135-conclusao","title":"1.3.5. Conclus\u00e3o","text":"<p>A an\u00e1lise da curva de aprendizado ajuda a identificar o comportamento do modelo e decidir os pr\u00f3ximos passos para melhorar seu desempenho. Dependendo do padr\u00e3o observado nas curvas de treinamento e valida\u00e7\u00e3o, voc\u00ea pode ajustar o modelo, coletar mais dados ou alterar a abordagem de pr\u00e9-processamento e engenharia de caracter\u00edsticas.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#1351-exemplificacao-de-plateau","title":"1.3.5.1. <code>Exemplifica\u00e7\u00e3o de Plateau</code>","text":"<p>Imagine que voc\u00ea est\u00e1 treinando um modelo de regress\u00e3o log\u00edstica e est\u00e1 monitorando a acur\u00e1cia da valida\u00e7\u00e3o ao longo do tempo ou conforme voc\u00ea aumenta a quantidade de dados de treinamento. Inicialmente, a acur\u00e1cia da valida\u00e7\u00e3o melhora \u00e0 medida que voc\u00ea adiciona mais dados, mas eventualmente, ela come\u00e7a a se estabilizar e atinge um ponto onde n\u00e3o h\u00e1 mais melhorias significativas, mesmo com a adi\u00e7\u00e3o de mais dados. Esse ponto de estabiliza\u00e7\u00e3o \u00e9 chamado de plateau.</p>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#14-leia-mais","title":"1.4. Leia mais","text":"<ul> <li>Learning_Curves</li> <li>Notebook: Learning_Curves_1</li> <li>Notebook: Learning_Curves_2</li> </ul>"},{"location":"2_machine_learning/2.1_CRISP-DM/2.1.4_Pos_treinamento/#2-implantacao-deployment","title":"2. Implanta\u00e7\u00e3o (Deployment)","text":"<p>A fase final da metodologia CRISP-DM \u00e9 a implanta\u00e7\u00e3o do modelo em um ambiente de produ\u00e7\u00e3o. Integramos o modelo aos sistemas existentes, monitoramos seu desempenho cont\u00ednuo e garantimos a ado\u00e7\u00e3o pela equipe de neg\u00f3cios.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/","title":"Transformacoes","text":"In\u00a0[22]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as plt\nimport matplotlib.pyplot as plt\n</pre> import numpy as np import pandas as pd import seaborn as sns import matplotlib as plt import matplotlib.pyplot as plt  In\u00a0[2]: Copied! <pre>diamonds = sns.load_dataset(\"diamonds\")\ndiamonds.head()\n</pre> diamonds = sns.load_dataset(\"diamonds\") diamonds.head() Out[2]: carat cut color clarity depth table price x y z 0 0.23 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 1 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 2 0.23 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 3 0.29 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 4 0.31 Good J SI2 63.3 58.0 335 4.34 4.35 2.75 In\u00a0[3]: Copied! <pre>diamonds.hist(figsize=(16, 16))\n</pre> diamonds.hist(figsize=(16, 16)) Out[3]: <pre>array([[&lt;Axes: title={'center': 'carat'}&gt;,\n        &lt;Axes: title={'center': 'depth'}&gt;,\n        &lt;Axes: title={'center': 'table'}&gt;],\n       [&lt;Axes: title={'center': 'price'}&gt;, &lt;Axes: title={'center': 'x'}&gt;,\n        &lt;Axes: title={'center': 'y'}&gt;],\n       [&lt;Axes: title={'center': 'z'}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]], dtype=object)</pre> In\u00a0[9]: Copied! <pre>diamonds['price_log'] = np.log(diamonds['price'])\ndiamonds['carat_log'] = np.log(diamonds['carat'])\n</pre> diamonds['price_log'] = np.log(diamonds['price']) diamonds['carat_log'] = np.log(diamonds['carat']) In\u00a0[20]: Copied! <pre>f, axs = plt.subplots(2, 2, figsize=(8, 4), gridspec_kw=dict(width_ratios=[8, 6]))\n# Transforme axs em uma lista unidimensional\naxs = axs.flatten()\nsns.histplot(data=diamonds, x=\"price\", ax=axs[0])\nsns.histplot(data=diamonds, x=\"price_log\", ax=axs[1])\nsns.histplot(data=diamonds, x=\"carat\", ax=axs[2])\nsns.histplot(data=diamonds, x=\"carat_log\", ax=axs[3])\nf.tight_layout()\n\n\n# Calcule a assimetria\nskewness_price = diamonds[\"price\"].skew()\nskewness_price_log = diamonds[\"price_log\"].skew()\nskewness_carat = diamonds[\"carat\"].skew()\nskewness_carat_log = diamonds[\"carat_log\"].skew()\n# Atualize os t\u00edtulos dos gr\u00e1ficos\naxs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\")\naxs[1].set_title(f\"Assimetria (price_log): {skewness_price_log:.2f}\")\naxs[2].set_title(f\"Assimetria (carat): {skewness_carat:.2f}\")\naxs[3].set_title(f\"Assimetria (carat_log): {skewness_carat_log:.2f}\")\n\nplt.show()\n</pre> f, axs = plt.subplots(2, 2, figsize=(8, 4), gridspec_kw=dict(width_ratios=[8, 6])) # Transforme axs em uma lista unidimensional axs = axs.flatten() sns.histplot(data=diamonds, x=\"price\", ax=axs[0]) sns.histplot(data=diamonds, x=\"price_log\", ax=axs[1]) sns.histplot(data=diamonds, x=\"carat\", ax=axs[2]) sns.histplot(data=diamonds, x=\"carat_log\", ax=axs[3]) f.tight_layout()   # Calcule a assimetria skewness_price = diamonds[\"price\"].skew() skewness_price_log = diamonds[\"price_log\"].skew() skewness_carat = diamonds[\"carat\"].skew() skewness_carat_log = diamonds[\"carat_log\"].skew() # Atualize os t\u00edtulos dos gr\u00e1ficos axs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\") axs[1].set_title(f\"Assimetria (price_log): {skewness_price_log:.2f}\") axs[2].set_title(f\"Assimetria (carat): {skewness_carat:.2f}\") axs[3].set_title(f\"Assimetria (carat_log): {skewness_carat_log:.2f}\")  plt.show()  In\u00a0[32]: Copied! <pre>df = pd.DataFrame([1, 10, 20, 25, 30, 40, 100, 110, 200, 300, 500, 800, 1000, 1050, 2000, 10000, 500000], columns=['price'])\ndf['price_log_e'] = np.log(df['price'])\ndf['price_log10'] = np.log10(df['price'])\ndf['price_log2'] = np.log2(df['price'])\n# Exibindo as primeiras linhas do DataFrame\ndf\n</pre> df = pd.DataFrame([1, 10, 20, 25, 30, 40, 100, 110, 200, 300, 500, 800, 1000, 1050, 2000, 10000, 500000], columns=['price']) df['price_log_e'] = np.log(df['price']) df['price_log10'] = np.log10(df['price']) df['price_log2'] = np.log2(df['price']) # Exibindo as primeiras linhas do DataFrame df Out[32]: price price_log_e price_log10 price_log2 0 1 0.000000 0.000000 0.000000 1 10 2.302585 1.000000 3.321928 2 20 2.995732 1.301030 4.321928 3 25 3.218876 1.397940 4.643856 4 30 3.401197 1.477121 4.906891 5 40 3.688879 1.602060 5.321928 6 100 4.605170 2.000000 6.643856 7 110 4.700480 2.041393 6.781360 8 200 5.298317 2.301030 7.643856 9 300 5.703782 2.477121 8.228819 10 500 6.214608 2.698970 8.965784 11 800 6.684612 2.903090 9.643856 12 1000 6.907755 3.000000 9.965784 13 1050 6.956545 3.021189 10.036174 14 2000 7.600902 3.301030 10.965784 15 10000 9.210340 4.000000 13.287712 16 500000 13.122363 5.698970 18.931569 In\u00a0[36]: Copied! <pre>f, axs = plt.subplots(2, 2, figsize=(8, 6), gridspec_kw=dict(width_ratios=[8, 6]))\n# Transforme axs em uma lista unidimensional\naxs = axs.flatten()\nsns.histplot(data=df, x=\"price\", ax=axs[0])\nsns.histplot(data=df, x=\"price_log_e\", ax=axs[1])\nsns.histplot(data=df, x=\"price_log10\", ax=axs[2])\nsns.histplot(data=df, x=\"price_log2\", ax=axs[3])\nf.tight_layout()\n\n\n# Calcule a assimetria\nskewness_price = df[\"price\"].skew()\nskewness_price_log = df[\"price_log_e\"].skew()\nskewness_carat = df[\"price_log10\"].skew()\nskewness_carat_log = df[\"price_log2\"].skew()\n# Atualize os t\u00edtulos dos gr\u00e1ficos\naxs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\")\naxs[1].set_title(f\"Assimetria (price_log_e): {skewness_price_log:.2f}\")\naxs[2].set_title(f\"Assimetria (price_log10): {skewness_carat:.2f}\")\naxs[3].set_title(f\"Assimetria (price_log2): {skewness_carat_log:.2f}\")\n\nplt.show()\n</pre> f, axs = plt.subplots(2, 2, figsize=(8, 6), gridspec_kw=dict(width_ratios=[8, 6])) # Transforme axs em uma lista unidimensional axs = axs.flatten() sns.histplot(data=df, x=\"price\", ax=axs[0]) sns.histplot(data=df, x=\"price_log_e\", ax=axs[1]) sns.histplot(data=df, x=\"price_log10\", ax=axs[2]) sns.histplot(data=df, x=\"price_log2\", ax=axs[3]) f.tight_layout()   # Calcule a assimetria skewness_price = df[\"price\"].skew() skewness_price_log = df[\"price_log_e\"].skew() skewness_carat = df[\"price_log10\"].skew() skewness_carat_log = df[\"price_log2\"].skew() # Atualize os t\u00edtulos dos gr\u00e1ficos axs[0].set_title(f\"Assimetria (price): {skewness_price:.2f}\") axs[1].set_title(f\"Assimetria (price_log_e): {skewness_price_log:.2f}\") axs[2].set_title(f\"Assimetria (price_log10): {skewness_carat:.2f}\") axs[3].set_title(f\"Assimetria (price_log2): {skewness_carat_log:.2f}\")  plt.show()"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#propriedades-da-funcao-logaritmica","title":"Propriedades da Fun\u00e7\u00e3o Logar\u00edtmica:\u00b6","text":"<p>Em resumo, as transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis quando se deseja lidar com varia\u00e7\u00e3o excessiva, linearizar rela\u00e7\u00f5es n\u00e3o lineares ou estabilizar a vari\u00e2ncia em dados.</p> <ul> <li>A fun\u00e7\u00e3o logar\u00edtmica \u00e9 a inversa da fun\u00e7\u00e3o exponencial. Ela se apresenta na forma geral: $$ y = \\log_b(x) $$</li> <li>Aqui, (x) \u00e9 o valor original e (y)  \u00e9 o logaritmo desse valor na base (b).</li> <li>A base (b) pode ser qualquer n\u00famero maior que 1, mas as bases mais comuns s\u00e3o 10 (logaritmo comum) e  (e) (logaritmo natural).</li> </ul>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#compressao-e-expansao-de-intervalos","title":"Compress\u00e3o e Expans\u00e3o de Intervalos:\u00b6","text":"<p>A fun\u00e7\u00e3o logar\u00edtmica comprime o intervalo de grandes n\u00fameros e expande o intervalo de pequenos n\u00fameros. Por exemplo, um intervalo entre 100 e 1000 \u00e9 comprimido para um intervalo entre 2 e 3 quando aplicamos o logaritmo na base 10.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#visualizacao-de-padroes","title":"Visualiza\u00e7\u00e3o de Padr\u00f5es:\u00b6","text":"<p>As transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis para facilitar a visualiza\u00e7\u00e3o de padr\u00f5es nos dados. Elas transformam rela\u00e7\u00f5es exponenciais em rela\u00e7\u00f5es mais compreens\u00edveis.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#aplicacoes-praticas","title":"Aplica\u00e7\u00f5es Pr\u00e1ticas:\u00b6","text":"<p>Na ci\u00eancia de dados, usamos transforma\u00e7\u00f5es logar\u00edtmicas quando:</p> <ul> <li>A vari\u00e1vel tem uma distribui\u00e7\u00e3o assim\u00e9trica.</li> <li>A vari\u00e2ncia dos dados \u00e9 grande.</li> </ul> <p>A transforma\u00e7\u00e3o logar\u00edtmica \u00e9 definida como: $$ y = \\log(x) $$</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/","title":"Transformacoes","text":"<ul> <li>Principais T\u00e9cnicas de Transforma\u00e7\u00e3o de Dados para Machine Learning</li> <li>Transforma\u00e7\u00f5es Logar\u00edtmicas</li> <li>Outras Transforma\u00e7\u00f5es</li> <li>Binning (Discretiza\u00e7\u00e3o)</li> <li>Encoding de Vari\u00e1veis Categ\u00f3ricas</li> <li>Feature Engineering</li> <li>Import\u00e2ncia das Transforma\u00e7\u00f5es de Dados na Regress\u00e3o Log\u00edstica</li> <li>Refer\u00eancias</li> </ul>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#principais-tecnicas-de-transformacao-de-dados-para-machine-learning","title":"Principais T\u00e9cnicas de Transforma\u00e7\u00e3o de Dados para Machine Learning","text":""},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#transformacoes-logaritmicas","title":"Transforma\u00e7\u00f5es Logar\u00edtmicas","text":"<p>As transforma\u00e7\u00f5es logar\u00edtmicas s\u00e3o \u00fateis para:</p> <ol> <li>Redu\u00e7\u00e3o de Varia\u00e7\u00e3o: Reduz a dispers\u00e3o em dados com ampla gama de valores.</li> <li>Lineariza\u00e7\u00e3o de Rela\u00e7\u00f5es N\u00e3o Lineares: Torna rela\u00e7\u00f5es n\u00e3o lineares mais lineares, \u00fatil em dados de crescimento exponencial.</li> <li>Estabiliza\u00e7\u00e3o de Vari\u00e2ncia: Especialmente em s\u00e9ries temporais e dados financeiros.</li> <li>Modelos Multiplicativos: Converte modelos multiplicativos em aditivos.</li> </ol>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#outras-transformacoes","title":"Outras Transforma\u00e7\u00f5es","text":"<ul> <li>Box-Cox: Estabiliza a vari\u00e2ncia e aproxima os dados a uma distribui\u00e7\u00e3o normal.</li> <li>Raiz Quadrada: Reduz a assimetria dos dados com cauda longa \u00e0 direita.</li> <li>Pot\u00eancia: Inclui transforma\u00e7\u00f5es como raiz c\u00fabica ou quadrada, melhora a linearidade em modelos de regress\u00e3o.</li> </ul>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#binning-discretizacao","title":"Binning (Discretiza\u00e7\u00e3o)","text":"<p>Agrupa valores cont\u00ednuos em intervalos discretos, transformando vari\u00e1veis cont\u00ednuas em categ\u00f3ricas.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#encoding-de-variaveis-categoricas","title":"Encoding de Vari\u00e1veis Categ\u00f3ricas","text":"<p>Essencial para algoritmos de machine learning. T\u00e9cnicas incluem:</p> <ul> <li>One-hot encoding</li> <li>Label encoding</li> <li>Target encoding</li> </ul>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#feature-engineering","title":"Feature Engineering","text":"<p>Cria\u00e7\u00e3o de novas vari\u00e1veis a partir das existentes, incluindo combina\u00e7\u00f5es, derivadas e intera\u00e7\u00f5es.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#importancia-das-transformacoes-de-dados-na-regressao-logistica","title":"Import\u00e2ncia das Transforma\u00e7\u00f5es de Dados na Regress\u00e3o Log\u00edstica","text":"<p>Transforma\u00e7\u00f5es s\u00e3o cruciais para melhorar a performance da regress\u00e3o log\u00edstica por v\u00e1rias raz\u00f5es:</p> <ol> <li>Linearidade: Torna a rela\u00e7\u00e3o entre vari\u00e1veis mais linear.</li> <li>Normaliza\u00e7\u00e3o de Escala: Garante que todas as vari\u00e1veis tenham a mesma ordem de grandeza.</li> <li>Redu\u00e7\u00e3o de Assimetria: Reduz a distor\u00e7\u00e3o dos dados.</li> <li>Estabiliza\u00e7\u00e3o da Vari\u00e2ncia: Garante vari\u00e2ncia constante.</li> <li>Melhoria da Separabilidade: Aumenta a separa\u00e7\u00e3o entre classes.</li> <li>Tratamento de Outliers: Mitiga o impacto de valores extremos.</li> <li>Melhoria na Converg\u00eancia do Algoritmo: Acelera a converg\u00eancia de algoritmos de otimiza\u00e7\u00e3o.</li> <li>Interpreta\u00e7\u00e3o dos Coeficientes: Facilita a interpreta\u00e7\u00e3o dos coeficientes do modelo.</li> </ol> <p>Aplicar transforma\u00e7\u00f5es antes da regress\u00e3o log\u00edstica melhora a performance, a estabilidade e a interpretabilidade dos resultados.</p>"},{"location":"2_machine_learning/2.2_Pre_treinamento/Transformacoes/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Normalizar ou Padronizar as Vari\u00e1veis?</li> <li>Normaliza\u00e7\u00e3o x Padroniza\u00e7\u00e3o: Qual a Diferen\u00e7a?</li> </ul>"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/","title":"Learning Curve I","text":"In\u00a0[\u00a0]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>#-----------------------------------------------------------\n# Step 01: load data using panda\n#-----------------------------------------------------------\ntrain_df = pd.read_csv('Bases/Titanic_train.csv')  # train set\ntest_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set\ncombine  = [train_df, test_df]\n</pre> #----------------------------------------------------------- # Step 01: load data using panda #----------------------------------------------------------- train_df = pd.read_csv('Bases/Titanic_train.csv')  # train set test_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set combine  = [train_df, test_df] In\u00a0[\u00a0]: Copied! <pre>#-----------------------------------------------------------\n# Step 02: Acquire and clean data\n#-----------------------------------------------------------\ntrain_df.head(5)\n</pre> #----------------------------------------------------------- # Step 02: Acquire and clean data #----------------------------------------------------------- train_df.head(5) Out[\u00a0]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S In\u00a0[\u00a0]: Copied! <pre>train_df.info()\n</pre> train_df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n</pre> In\u00a0[\u00a0]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[\u00a0]: PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 In\u00a0[\u00a0]: Copied! <pre>train_df.describe(include=['O'])\n</pre> train_df.describe(include=['O']) Out[\u00a0]: Name Sex Ticket Cabin Embarked count 891 891 891 204 889 unique 891 2 681 147 3 top Braund, Mr. Owen Harris male 347082 B96 B98 S freq 1 577 7 4 644 <p>Training data statistics:</p> <ul> <li>891 training samples</li> <li>Age, Cabin, Embarked: incomplete data</li> <li>Data type:<ul> <li>object: Name, Sex, Ticket, Cabin, Embarked</li> <li>int64: PassengerId, Survived, Pclass, SibSp, Parch</li> <li>float64: Age, Fare</li> </ul> </li> <li>Survive rate: 0.383838</li> </ul> <p>Estat\u00edsticas dos dados de treinamento:</p> <ul> <li>891 amostras de treinamento</li> <li>Idade, Cabine, Embarque: dados incompletos</li> <li>Tipo de dados:<ul> <li>objeto: Nome, Sexo, Bilhete, Cabine, Embarque</li> <li>int64: PassengerId, Sobreviveu, Classe, SibSp, Parch</li> <li>float64: Idade, Tarifa</li> <li>Taxa de sobreviv\u00eancia: 0.383838</li> </ul> </li> </ul> In\u00a0[\u00a0]: Copied! <pre> # remove Features: Ticket, Cabin\n#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n#test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1)\n#combine  = [train_df, test_df]\n# aplica a logica para ambos os datasets\nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].fillna('U')\n    dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\n    \nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0, \n                                            'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)\n    \ntrain_df.head()\n    \n</pre>  # remove Features: Ticket, Cabin #train_df = train_df.drop(['Ticket', 'Cabin'], axis=1) #test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1) #combine  = [train_df, test_df] # aplica a logica para ambos os datasets for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].fillna('U')     dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)      for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0,                                              'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)      train_df.head()      Out[\u00a0]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 1 S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 0 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 1 S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 0 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 1 S In\u00a0[\u00a0]: Copied! <pre>train_df = train_df.drop(['Ticket'], axis=1)\ntest_df  = test_df.drop(['Ticket'], axis=1)\ncombine  = [train_df, test_df]\n\n\n# survival rate distribtion as a function of Pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> train_df = train_df.drop(['Ticket'], axis=1) test_df  = test_df.drop(['Ticket'], axis=1) combine  = [train_df, test_df]   # survival rate distribtion as a function of Pclass train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[\u00a0]: Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 In\u00a0[\u00a0]: Copied! <pre># obtain Title from name (Mr, Mrs, Miss etc)\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')\n    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')\n    dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'\n    dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'\n\n#: count survived rate for different titles\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> # obtain Title from name (Mr, Mrs, Miss etc) for dataset in combine:     dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)   for dataset in combine:     dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')     dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')     dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')     dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')     dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')     dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'     dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'  #: count survived rate for different titles train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[\u00a0]: Title Survived 3 Mrs 0.795276 1 Miss 0.702703 5 Royalty 0.600000 0 Master 0.575000 4 Officer 0.181818 2 Mr 0.158700 In\u00a0[\u00a0]: Copied! <pre>train_df.head(5)\n</pre> train_df.head(5) Out[\u00a0]: PassengerId Survived Pclass Name Sex Age SibSp Parch Fare Cabin Embarked Title 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 7.2500 1 S Mr 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 71.2833 0 C Mrs 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 7.9250 1 S Miss 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 53.1000 0 S Mrs 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 8.0500 1 S Mr In\u00a0[\u00a0]: Copied! <pre># Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...)\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\n# if age &lt; 16, set 'Sex' to Child\nfor dataset in combine:\n    dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'\n    \n# Covert 'Sex' to numbers (female:1, male:2)\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...) title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6} for dataset in combine:     dataset['Title'] = dataset['Title'].map(title_mapping)     dataset['Title'] = dataset['Title'].fillna(0)  # Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data train_df = train_df.drop(['Name', 'PassengerId'], axis=1) test_df = test_df.drop(['Name'], axis=1) combine = [train_df, test_df]  # if age &lt; 16, set 'Sex' to Child for dataset in combine:     dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'      # Covert 'Sex' to numbers (female:1, male:2) for dataset in combine:     dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)  train_df.head() Out[\u00a0]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 22.0 1 0 7.2500 1 S 1 1 1 1 1 38.0 1 0 71.2833 0 C 3 2 1 3 1 26.0 0 0 7.9250 1 S 2 3 1 1 1 35.0 1 0 53.1000 0 S 3 4 0 3 0 35.0 0 0 8.0500 1 S 1 In\u00a0[\u00a0]: Copied! <pre># Age distribution for different values of Pclass and gender\n#grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n#grid.map(plt.hist, 'Age', bins=20)\n#grid.add_legend()\n</pre> # Age distribution for different values of Pclass and gender #grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6) #grid.map(plt.hist, 'Age', bins=20) #grid.add_legend() In\u00a0[\u00a0]: Copied! <pre># Guess age values using median values for age across set of Pclass and gender frature combinations\nfor dataset in combine:\n    dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)\n\n# create Age bands and determine correlations with Survived\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> # Guess age values using median values for age across set of Pclass and gender frature combinations for dataset in combine:     dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)  # create Age bands and determine correlations with Survived train_df['AgeBand'] = pd.cut(train_df['Age'], 5) train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True) <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\4175406704.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> Out[\u00a0]: AgeBand Survived 0 (-0.08, 16.0] 0.550000 1 (16.0, 32.0] 0.339506 2 (32.0, 48.0] 0.404444 3 (48.0, 64.0] 0.434783 4 (64.0, 80.0] 0.090909 In\u00a0[\u00a0]: Copied! <pre>for dataset in combine:\n    dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> for dataset in combine:     dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0     dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1     dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2     dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3     dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4  train_df = train_df.drop(['AgeBand'], axis=1) combine = [train_df, test_df] train_df.head() Out[\u00a0]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 1 1 0 7.2500 1 S 1 1 1 1 1 2 1 0 71.2833 0 C 3 2 1 3 1 1 0 0 7.9250 1 S 2 3 1 1 1 2 1 0 53.1000 0 S 3 4 0 3 0 2 0 0 8.0500 1 S 1 In\u00a0[\u00a0]: Copied! <pre># Create family size from 'sibsq + parch + 1'\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\n#create another feature called IsAlone\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n    dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2\n\ntrain_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()\n\n#drop Parch, SibSp, and FamilySize features in favor of IsAlone\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # Create family size from 'sibsq + parch + 1' for dataset in combine:     dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1  train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)  #create another feature called IsAlone for dataset in combine:     dataset['IsAlone'] = 0     dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1     dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2  train_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()  #drop Parch, SibSp, and FamilySize features in favor of IsAlone train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) combine = [train_df, test_df] train_df.head() Out[\u00a0]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone 0 0 3 0 1 7.2500 1 S 1 0 1 1 1 1 2 71.2833 0 C 3 0 2 1 3 1 1 7.9250 1 S 2 1 3 1 1 1 2 53.1000 0 S 3 0 4 0 3 0 2 8.0500 1 S 1 1 In\u00a0[\u00a0]: Copied! <pre># Create an artfical feature combinbing PClass and Age.\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()\n</pre> # Create an artfical feature combinbing PClass and Age. for dataset in combine:     dataset['Age*Class'] = dataset.Age * dataset.Pclass  train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head() Out[\u00a0]: Age*Class Age Pclass 0 3 1 3 1 2 2 1 2 3 1 3 3 2 2 1 4 6 2 3 In\u00a0[\u00a0]: Copied! <pre># fill the missing values of Embarked feature with the most common occurance\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # fill the missing values of Embarked feature with the most common occurance freq_port = train_df.Embarked.dropna().mode()[0] for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].fillna(freq_port) train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)  for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)  train_df.head() Out[\u00a0]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 7.2500 1 0 1 0 3 1 1 1 1 2 71.2833 0 1 3 0 2 2 1 3 1 1 7.9250 1 0 2 1 3 3 1 1 1 2 53.1000 0 0 3 0 2 4 0 3 0 2 8.0500 1 0 1 1 6 In\u00a0[\u00a0]: Copied! <pre># fill the missing values of Fare\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n\n# Create FareBand\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n\n# Convert the Fare feature to ordinal values based on the FareBand\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # fill the missing values of Fare test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)  # Create FareBand train_df['FareBand'] = pd.qcut(train_df['Fare'], 4) train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)  # Convert the Fare feature to ordinal values based on the FareBand for dataset in combine:     dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0     dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1     dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2     dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3     dataset['Fare'] = dataset['Fare'].astype(int)  train_df = train_df.drop(['FareBand'], axis=1) combine = [train_df, test_df] train_df.head() <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\nC:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n</pre> Out[\u00a0]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 0 1 0 1 0 3 1 1 1 1 2 3 0 1 3 0 2 2 1 3 1 1 1 1 0 2 1 3 3 1 1 1 2 3 0 0 3 0 2 4 0 3 0 2 1 1 0 1 1 6 In\u00a0[\u00a0]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[\u00a0]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 mean 0.383838 2.308642 0.490460 1.332211 1.505051 0.771044 0.361392 1.711560 0.741863 2.785634 std 0.486592 0.836071 0.660838 0.822210 1.118148 0.420397 0.635673 1.036888 0.575364 1.755907 min 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 25% 0.000000 2.000000 0.000000 1.000000 0.500000 1.000000 0.000000 1.000000 0.000000 2.000000 50% 0.000000 3.000000 0.000000 1.000000 2.000000 1.000000 0.000000 1.000000 1.000000 3.000000 75% 1.000000 3.000000 1.000000 2.000000 2.000000 1.000000 1.000000 2.000000 1.000000 3.000000 max 1.000000 3.000000 2.000000 4.000000 3.000000 1.000000 2.000000 6.000000 2.000000 12.000000 In\u00a0[\u00a0]: Copied! <pre>#correlation matrix\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(train_df.corr(), vmax=.8, square=True);\n</pre> #correlation matrix f, ax = plt.subplots(figsize=(12, 9)) sns.heatmap(train_df.corr(), vmax=.8, square=True); In\u00a0[21]: Copied! <pre>train_df.to_csv('Bases_tratadas/Titanic_train_df.csv')\ntest_df.to_csv('Bases_tratadas/Titanic_test_df.csv')\n</pre> train_df.to_csv('Bases_tratadas/Titanic_train_df.csv') test_df.to_csv('Bases_tratadas/Titanic_test_df.csv')"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#learning-curve-i","title":"Learning Curve I\u00b6","text":"<p>Este Notebook foi desenvolvido para preparando os dados para aplica\u00e7\u00e3o do <code>Learning Curve</code>.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#titanic-data","title":"Titanic data\u00b6","text":"<p>Tarefa: Prever a sobreviv\u00eancia de um passageiro(a) dado sua classe de ticket, nome, g\u00eanero, idade, n\u00famero de irm\u00e3os/c\u00f4njuges a bordo, n\u00famero de pais/filhos a bordo, n\u00famero do ticket, n\u00famero da cabine e Porto de embarque.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#parte-i-analise-exploratoria-de-dados","title":"Parte I: An\u00e1lise Explorat\u00f3ria de Dados\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#step-1-carrega-base-de-dados","title":"Step 1: Carrega Base de Dados\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#step-2-limpeza-dos-dados","title":"Step 2: Limpeza dos Dados\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_1/#salvando-as-bases-tratadas","title":"Salvando as bases tratadas\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/","title":"Learning Curve II","text":"In\u00a0[3]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#Learning curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import validation_curve\n\n\n# Essa n\u00e3o \u00e9 uma boa pratica minha\n# No futuro seria interessante removre para avaliar os avisos\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\n# Suprimir os avisos de converg\u00eancia\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\n\n%load_ext autoreload\n%autoreload 2\n\nimport utils.learning_curve as curve\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt  #machine learning from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC, LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.linear_model import Perceptron from sklearn.linear_model import SGDClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.model_selection import cross_val_score from sklearn.ensemble import VotingClassifier from sklearn.model_selection import GridSearchCV  #Learning curve from sklearn.model_selection import learning_curve from sklearn.model_selection import ShuffleSplit from sklearn.model_selection import cross_val_predict from sklearn.model_selection import validation_curve   # Essa n\u00e3o \u00e9 uma boa pratica minha # No futuro seria interessante removre para avaliar os avisos import warnings from sklearn.exceptions import ConvergenceWarning  # Suprimir os avisos de converg\u00eancia warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)   %load_ext autoreload %autoreload 2  import utils.learning_curve as curve <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[5]: Copied! <pre>train_df = pd.read_csv('Results/Titanic_train_df.csv')\ntest_df = pd.read_csv('Results/Titanic_test_df.csv')\n</pre> train_df = pd.read_csv('Results/Titanic_train_df.csv') test_df = pd.read_csv('Results/Titanic_test_df.csv') In\u00a0[6]: Copied! <pre>#------------------------------------------------------------------\n# Step 03: Learning model\n#------------------------------------------------------------------\n\nX_data = train_df.drop(\"Survived\", axis=1)          # data: Features\nY_data = train_df[\"Survived\"]                       # data: Labels\nX_test_kaggle  = test_df.drop(\"PassengerId\", axis=1).copy() # test data (kaggle)\n\n# Cria varios conjuntos de Treino e Teste\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n</pre> #------------------------------------------------------------------ # Step 03: Learning model #------------------------------------------------------------------  X_data = train_df.drop(\"Survived\", axis=1)          # data: Features Y_data = train_df[\"Survived\"]                       # data: Labels X_test_kaggle  = test_df.drop(\"PassengerId\", axis=1).copy() # test data (kaggle)  # Cria varios conjuntos de Treino e Teste cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0) <p>O <code>ShuffleSplit</code> \u00e9 uma classe no m\u00f3dulo model_selection do scikit-learn que gera divis\u00f5es aleat\u00f3rias dos dados em conjuntos de treinamento e teste.</p> <p><code>n_splits=100:</code> O n\u00famero de divis\u00f5es (ou splits) que ser\u00e3o criadas. Neste caso, 100 diferentes divis\u00f5es ser\u00e3o geradas.</p> <p><code>test_size=0.2:</code> A propor\u00e7\u00e3o do conjunto de dados que ser\u00e1 usada como conjunto de teste. Aqui, 20% dos dados ser\u00e3o reservados para o conjunto de teste em cada split.</p> <p><code>random_state=0: </code>Um valor de semente para o gerador de n\u00fameros aleat\u00f3rios. Isso garante que os splits gerados sejam reprodut\u00edveis; ou seja, se voc\u00ea executar o c\u00f3digo novamente com o mesmo random_state, voc\u00ea obter\u00e1 exatamente os mesmos splits.</p> <p>O <code>ShuffleSplit</code> divide aleatoriamente os dados em conjuntos de treinamento e teste mantendo a propor\u00e7\u00e3o especificada. \u00c9 particularmente \u00fatil quando voc\u00ea quer avaliar a performance de um modelo em v\u00e1rias divis\u00f5es diferentes dos dados, para obter uma estimativa mais robusta da sua performance.</p> In\u00a0[7]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[8]: Copied! <pre>#grid search: Logistic Regression\nmodel = LogisticRegression()\nif search_param==1:\n    param_range = np.logspace(-6, 5, 12)\n    param_grid = dict(C=param_range)\n    curve.grid_search_model(X_data, Y_data, model, param_grid, cv)\n# Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0}\n</pre> #grid search: Logistic Regression model = LogisticRegression() if search_param==1:     param_range = np.logspace(-6, 5, 12)     param_grid = dict(C=param_range)     curve.grid_search_model(X_data, Y_data, model, param_grid, cv) # Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0} <pre>Best Score: 0.7914525139664803  / Best parameters: {'C': 10000.0}\n</pre> In\u00a0[9]: Copied! <pre>#Validation Curve: Logistic Regression\nif plot_vc == 1:\n    param_range = np.logspace(-6, 3, 10)\n    param_name=\"C\"\n    ylim=[0.55, 0.9]\n    curve.validation_curve_model(X_data, Y_data, model, \"C\", param_range, cv, ylim)\n</pre> #Validation Curve: Logistic Regression if plot_vc == 1:     param_range = np.logspace(-6, 3, 10)     param_name=\"C\"     ylim=[0.55, 0.9]     curve.validation_curve_model(X_data, Y_data, model, \"C\", param_range, cv, ylim) In\u00a0[10]: Copied! <pre>#learn curve\nlogreg  = LogisticRegression(C=1000)\n\nif plot_lc==1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, logreg, cv, train_size)\n</pre> #learn curve logreg  = LogisticRegression(C=1000)  if plot_lc==1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, logreg, cv, train_size) In\u00a0[11]: Copied! <pre># Logistic Regression \nacc_log = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_Logistic.csv')\n</pre> # Logistic Regression  acc_log = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_Logistic.csv') In\u00a0[12]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[13]: Copied! <pre>#grid search: SVM\nif search_param==1:\n    param_range = np.linspace(0.5, 5, 9)\n    param_grid = dict(C=param_range)\n\n    curve.grid_search_model(X_data, Y_data, SVC(), param_grid, cv)\n# Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5}\n</pre> #grid search: SVM if search_param==1:     param_range = np.linspace(0.5, 5, 9)     param_grid = dict(C=param_range)      curve.grid_search_model(X_data, Y_data, SVC(), param_grid, cv) # Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5} <pre>Best Score: 0.6229050279329609  / Best parameters: {'C': 0.5}\n</pre> In\u00a0[14]: Copied! <pre>#Validation Curve: SVC\nif plot_vc == 1:\n    param_range = np.linspace(0.1, 10, 10)\n    param_name=\"C\"\n    ylim=[0.78, 0.90]\n    curve.validation_curve_model(X_data, Y_data, SVC(), \"C\", param_range, cv, ylim, log=False)\n</pre> #Validation Curve: SVC if plot_vc == 1:     param_range = np.linspace(0.1, 10, 10)     param_name=\"C\"     ylim=[0.78, 0.90]     curve.validation_curve_model(X_data, Y_data, SVC(), \"C\", param_range, cv, ylim, log=False) In\u00a0[15]: Copied! <pre>#learn curve: SVC\nsvc = SVC(C=1, probability=True)\n\nif plot_lc == 1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, svc, cv, train_size)\n</pre> #learn curve: SVC svc = SVC(C=1, probability=True)  if plot_lc == 1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, svc, cv, train_size) In\u00a0[16]: Copied! <pre># Support Vector Machines\nacc_svc = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_SVM.csv')\n</pre> # Support Vector Machines acc_svc = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_SVM.csv') In\u00a0[17]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[18]: Copied! <pre>#grid search: KNN\nif search_param==1:\n    param_range = (np.linspace(1, 10, 10)).astype(int)\n    param_grid = dict(n_neighbors=param_range)\n\n    curve.grid_search_model(X_data, Y_data, KNeighborsClassifier(), param_grid, cv)\n# Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2}\n</pre> #grid search: KNN if search_param==1:     param_range = (np.linspace(1, 10, 10)).astype(int)     param_grid = dict(n_neighbors=param_range)      curve.grid_search_model(X_data, Y_data, KNeighborsClassifier(), param_grid, cv) # Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2} <pre>Best Score: 0.6220670391061452  / Best parameters: {'n_neighbors': 2}\n</pre> In\u00a0[19]: Copied! <pre>#Validation Curve: KNN\nif plot_vc==1:\n    param_range = np.linspace(2, 20, 10).astype(int)\n    param_name=\"n_neighbors\"\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, KNeighborsClassifier(), \"n_neighbors\", param_range, cv, ylim, log=False)\n</pre> #Validation Curve: KNN if plot_vc==1:     param_range = np.linspace(2, 20, 10).astype(int)     param_name=\"n_neighbors\"     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, KNeighborsClassifier(), \"n_neighbors\", param_range, cv, ylim, log=False) In\u00a0[20]: Copied! <pre>#learn curve: KNN\nknn = KNeighborsClassifier(n_neighbors = 10)\n\nif plot_lc==1:\n    train_size=np.linspace(.1, 1.0, 15)\n    curve.Learning_curve_model(X_data, Y_data, knn, cv, train_size)\n</pre> #learn curve: KNN knn = KNeighborsClassifier(n_neighbors = 10)  if plot_lc==1:     train_size=np.linspace(.1, 1.0, 15)     curve.Learning_curve_model(X_data, Y_data, knn, cv, train_size) In\u00a0[21]: Copied! <pre># KNN\nacc_knn = curve.predict_model(\n    X = X_data, \n    Y = Y_data, \n    model = logreg, \n    Xtest = X_test_kaggle, \n    test_df = test_df,\n    cv = cv,\n    submit_name = 'Results/Titanic_submission_KNN.csv')\n</pre> # KNN acc_knn = curve.predict_model(     X = X_data,      Y = Y_data,      model = logreg,      Xtest = X_test_kaggle,      test_df = test_df,     cv = cv,     submit_name = 'Results/Titanic_submission_KNN.csv') In\u00a0[22]: Copied! <pre># Lista de modelos e nomes de arquivo de submiss\u00e3o correspondentes\nmodels = [\n    (GaussianNB(), 'Gaussian_Naive_Bayes'),\n    (Perceptron(), 'Perceptron'),\n    (LinearSVC(), 'Linear_SVC'),\n    (SGDClassifier(), 'Stochastic_Gradient_Descent'),\n    (DecisionTreeClassifier(), 'Decision_Tree')\n]\n\ndic_acc = {}\n# Iterar sobre os modelos\nfor model, filename in models:\n    acc = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_{filename}.csv'\n    )\n    dic_acc[filename] = acc\n    print(f'Accuracy for {filename}')\n</pre> # Lista de modelos e nomes de arquivo de submiss\u00e3o correspondentes models = [     (GaussianNB(), 'Gaussian_Naive_Bayes'),     (Perceptron(), 'Perceptron'),     (LinearSVC(), 'Linear_SVC'),     (SGDClassifier(), 'Stochastic_Gradient_Descent'),     (DecisionTreeClassifier(), 'Decision_Tree') ]  dic_acc = {} # Iterar sobre os modelos for model, filename in models:     acc = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_{filename}.csv'     )     dic_acc[filename] = acc     print(f'Accuracy for {filename}')  <pre>Accuracy for Gaussian_Naive_Bayes\nAccuracy for Perceptron\nAccuracy for Linear_SVC\nAccuracy for Stochastic_Gradient_Descent\nAccuracy for Decision_Tree\n</pre> In\u00a0[23]: Copied! <pre>search_param = 1   # 1 -- grid search / 0 -- don't search\nplot_vc      = 1   # 1--display validation curve/ 0-- don't display\nplot_lc      = 1   # 1--display learning curve/ 0 -- don't display\n</pre> search_param = 1   # 1 -- grid search / 0 -- don't search plot_vc      = 1   # 1--display validation curve/ 0-- don't display plot_lc      = 1   # 1--display learning curve/ 0 -- don't display In\u00a0[24]: Copied! <pre>#grid search: KNN (This step is very slow)\nparam_range = (np.linspace(10, 110, 10)).astype(int)\nparam_leaf = (np.linspace(1, 2, 2)).astype(int)\nparam_grid = {'n_estimators':param_range, 'min_samples_leaf':param_leaf}\n\ncurve.grid_search_model(X_data, Y_data, RandomForestClassifier(), param_grid, cv)\n# Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10}\n</pre> #grid search: KNN (This step is very slow) param_range = (np.linspace(10, 110, 10)).astype(int) param_leaf = (np.linspace(1, 2, 2)).astype(int) param_grid = {'n_estimators':param_range, 'min_samples_leaf':param_leaf}  curve.grid_search_model(X_data, Y_data, RandomForestClassifier(), param_grid, cv) # Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10} <pre>Best Score: 0.8232960893854746  / Best parameters: {'min_samples_leaf': 2, 'n_estimators': 10}\n</pre> In\u00a0[25]: Copied! <pre>if plot_vc==1:\n    param_range = np.linspace(10, 110, 10).astype(int)\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(min_samples_leaf=12), \"n_estimators\", param_range, cv, ylim, log=False)\n</pre> if plot_vc==1:     param_range = np.linspace(10, 110, 10).astype(int)     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(min_samples_leaf=12), \"n_estimators\", param_range, cv, ylim, log=False) In\u00a0[26]: Copied! <pre>if plot_vc==1:\n    param_range = np.linspace(1, 21, 10).astype(int)\n    ylim=[0.75, 0.90]\n    curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(n_estimators=80), \"min_samples_leaf\", param_range, cv, ylim, log=False)\n</pre> if plot_vc==1:     param_range = np.linspace(1, 21, 10).astype(int)     ylim=[0.75, 0.90]     curve.validation_curve_model(X_data, Y_data, RandomForestClassifier(n_estimators=80), \"min_samples_leaf\", param_range, cv, ylim, log=False) In\u00a0[27]: Copied! <pre># Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=80, random_state =0, min_samples_leaf = 12)\nacc_random_forest = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_random_forest.csv'\n    )\n</pre> # Random Forest random_forest = RandomForestClassifier(n_estimators=80, random_state =0, min_samples_leaf = 12) acc_random_forest = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_random_forest.csv'     ) In\u00a0[28]: Copied! <pre>#ensemble votring\nensemble_voting = VotingClassifier(estimators=[('lg', logreg), ('sv', svc), ('rf', random_forest),('kn',knn)], voting='soft')\nacc_ensemble_voting = curve.predict_model(\n        X=X_data, \n        Y=Y_data, \n        model=model, \n        Xtest=X_test_kaggle, \n        test_df=test_df,\n        cv=cv,\n        submit_name=f'Results/Titanic_submission_ensemble_voting.csv'\n    )\n</pre> #ensemble votring ensemble_voting = VotingClassifier(estimators=[('lg', logreg), ('sv', svc), ('rf', random_forest),('kn',knn)], voting='soft') acc_ensemble_voting = curve.predict_model(         X=X_data,          Y=Y_data,          model=model,          Xtest=X_test_kaggle,          test_df=test_df,         cv=cv,         submit_name=f'Results/Titanic_submission_ensemble_voting.csv'     ) In\u00a0[29]: Copied! <pre>dic_acc.keys()\n</pre> dic_acc.keys() Out[29]: <pre>dict_keys(['Gaussian_Naive_Bayes', 'Perceptron', 'Linear_SVC', 'Stochastic_Gradient_Descent', 'Decision_Tree'])</pre> In\u00a0[30]: Copied! <pre>acc_gaussian = dic_acc['Gaussian_Naive_Bayes']\nacc_perceptron = dic_acc['Perceptron']\nacc_sgd = dic_acc['Stochastic_Gradient_Descent']\nacc_linear_svc = dic_acc['Linear_SVC']\nacc_decision_tree = dic_acc['Decision_Tree']\n</pre> acc_gaussian = dic_acc['Gaussian_Naive_Bayes'] acc_perceptron = dic_acc['Perceptron'] acc_sgd = dic_acc['Stochastic_Gradient_Descent'] acc_linear_svc = dic_acc['Linear_SVC'] acc_decision_tree = dic_acc['Decision_Tree'] In\u00a0[31]: Copied! <pre>models = pd.DataFrame(\n    {\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Random Forest', \n              'Naive Bayes', 'Perceptron','Stochastic Gradient Decent', 'Linear SVC',\n              'Decision Tree', 'ensemble_voting'],\n    'KFoldScore': [acc_svc.mean(), acc_knn.mean(), acc_log.mean(), acc_random_forest.mean(), \n                acc_gaussian.mean(), acc_perceptron.mean(), acc_sgd.mean(), acc_linear_svc.mean(), \n                acc_decision_tree.mean(), acc_ensemble_voting.mean()],\n    'Std': [acc_svc.std(), acc_knn.std(), acc_log.std(), acc_random_forest.std(), \n            acc_gaussian.std(), acc_perceptron.std(), acc_sgd.std(), acc_linear_svc.std(), \n            acc_decision_tree.std(), acc_ensemble_voting.std()]})\n\nmodels.sort_values(by='KFoldScore', ascending=False)\n</pre> models = pd.DataFrame(     {     'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Random Forest',                'Naive Bayes', 'Perceptron','Stochastic Gradient Decent', 'Linear SVC',               'Decision Tree', 'ensemble_voting'],     'KFoldScore': [acc_svc.mean(), acc_knn.mean(), acc_log.mean(), acc_random_forest.mean(),                  acc_gaussian.mean(), acc_perceptron.mean(), acc_sgd.mean(), acc_linear_svc.mean(),                  acc_decision_tree.mean(), acc_ensemble_voting.mean()],     'Std': [acc_svc.std(), acc_knn.std(), acc_log.std(), acc_random_forest.std(),              acc_gaussian.std(), acc_perceptron.std(), acc_sgd.std(), acc_linear_svc.std(),              acc_decision_tree.std(), acc_ensemble_voting.std()]})  models.sort_values(by='KFoldScore', ascending=False) Out[31]: Model KFoldScore Std 7 Linear SVC 0.802961 0.029316 0 Support Vector Machines 0.790559 0.029808 1 KNN 0.790559 0.029808 2 Logistic Regression 0.790559 0.029808 8 Decision Tree 0.747486 0.036634 9 ensemble_voting 0.747486 0.035394 3 Random Forest 0.746927 0.036638 4 Naive Bayes 0.746816 0.032111 6 Stochastic Gradient Decent 0.562291 0.112604 5 Perceptron 0.542961 0.121304"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#learning-curve-ii","title":"Learning Curve II\u00b6","text":"<p>Este Notebook foi desenvolvido para aplicar a <code>Learning Curve</code>.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#titanic-data","title":"Titanic data\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#part-ii-learning-model","title":"Part II : Learning Model\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#logistic-regression","title":"Logistic Regression\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#support-vector-machines","title":"Support Vector Machines\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#knn","title":"KNN\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#predictions-list","title":"Predictions List\u00b6","text":"<ul> <li>Naive Bayes</li> <li>Perceptron</li> <li>Linear SVC</li> <li>Stochastic Gradient Descent</li> <li>Decision Tree\u00b6</li> </ul>"},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#random-forest","title":"Random Forest\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/Learning_curve_2/#ensemble-votring","title":"Ensemble votring\u00b6","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curve/","title":"Learning curve","text":"In\u00a0[\u00a0]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd In\u00a0[\u00a0]: Copied! <pre># visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>#machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n</pre> #machine learning from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC, LinearSVC from sklearn.ensemble import RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB from sklearn.linear_model import Perceptron from sklearn.linear_model import SGDClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.model_selection import cross_val_score from sklearn.ensemble import VotingClassifier from sklearn.model_selection import GridSearchCV In\u00a0[\u00a0]: Copied! <pre>#Learning curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import validation_curve\n</pre> #Learning curve from sklearn.model_selection import learning_curve from sklearn.model_selection import ShuffleSplit from sklearn.model_selection import cross_val_predict from sklearn.model_selection import validation_curve In\u00a0[\u00a0]: Copied! <pre># Fun\u00e7\u00f5es para type hints\nfrom typing import Any, Dict, Union, List, Optional, Tuple\nfrom sklearn.base import BaseEstimator\n</pre> # Fun\u00e7\u00f5es para type hints from typing import Any, Dict, Union, List, Optional, Tuple from sklearn.base import BaseEstimator In\u00a0[\u00a0]: Copied! <pre>def grid_search_model(X: np.ndarray, \n                      Y: np.ndarray, \n                      model: BaseEstimator, \n                      parameters: Dict[str, Any], \n                      cv: Union[int, Any]) -&gt; None:\n    \"\"\"\n    Realiza uma busca em grade para encontrar os melhores hiperpar\u00e2metros para um modelo de Machine Learning.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser treinado.\n        parameters (Dict[str, Any]): Dicion\u00e1rio de par\u00e2metros a serem testados na busca em grade.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n\n    Returns:\n        None: A fun\u00e7\u00e3o imprime o melhor score e os melhores par\u00e2metros encontrados.\n    \"\"\"\n    CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=cv)\n    CV_model.fit(X, Y)\n    print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)\n\n # Usar BaseEstimator como type hint significa que voc\u00ea pode passar qualquer \n # modelo de aprendizado de m\u00e1quina do scikit-learn para a fun\u00e7\u00e3o, \n # seja ele uma regress\u00e3o linear, uma \u00e1rvore de decis\u00e3o, uma m\u00e1quina de vetores de suporte (SVM), uma rede neural, etc.\n</pre> def grid_search_model(X: np.ndarray,                        Y: np.ndarray,                        model: BaseEstimator,                        parameters: Dict[str, Any],                        cv: Union[int, Any]) -&gt; None:     \"\"\"     Realiza uma busca em grade para encontrar os melhores hiperpar\u00e2metros para um modelo de Machine Learning.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser treinado.         parameters (Dict[str, Any]): Dicion\u00e1rio de par\u00e2metros a serem testados na busca em grade.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.      Returns:         None: A fun\u00e7\u00e3o imprime o melhor score e os melhores par\u00e2metros encontrados.     \"\"\"     CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=cv)     CV_model.fit(X, Y)     print(\"Best Score:\", CV_model.best_score_, \" / Best parameters:\", CV_model.best_params_)   # Usar BaseEstimator como type hint significa que voc\u00ea pode passar qualquer   # modelo de aprendizado de m\u00e1quina do scikit-learn para a fun\u00e7\u00e3o,   # seja ele uma regress\u00e3o linear, uma \u00e1rvore de decis\u00e3o, uma m\u00e1quina de vetores de suporte (SVM), uma rede neural, etc. In\u00a0[\u00a0]: Copied! <pre># validacion curv\ndef validation_curve_model(X: np.ndarray, \n                           Y: np.ndarray, \n                           model: BaseEstimator, \n                           param_name: str, \n                           parameters: List[Any], \n                           cv: Union[int, Any], \n                           ylim: Optional[Tuple[float, float]] = None, \n                           log: bool = True) -&gt; plt.Figure:\n    \"\"\"\n    Plota a curva de valida\u00e7\u00e3o para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser avaliado.\n        param_name (str): Nome do hiperpar\u00e2metro a ser testado.\n        parameters (List[Any]): Lista de valores para o hiperpar\u00e2metro.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n        ylim (Optional[Tuple[float, float]]): Limites para o eixo y no gr\u00e1fico (opcional).\n        log (bool): Se verdadeiro, usa escala logar\u00edtmica para o eixo x.\n\n    Returns:\n        plt.Figure: O objeto de figura do matplotlib contendo a curva de valida\u00e7\u00e3o.\n    \"\"\"\n    train_scores, test_scores = validation_curve(\n        model, X, Y, param_name=param_name, param_range=parameters, cv=cv, scoring=\"accuracy\"\n    )\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.figure()\n    plt.title(\"Curva de Valida\u00e7\u00e3o\")\n    plt.fill_between(parameters, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(parameters, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\n    if log:\n        plt.semilogx(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n        plt.semilogx(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n    else:\n        plt.plot(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n        plt.plot(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n\n    if ylim is not None:\n        plt.ylim(*ylim)\n\n    plt.ylabel('Pontua\u00e7\u00e3o')\n    plt.xlabel(f'Par\u00e2metro {param_name}')\n    plt.legend(loc=\"best\")\n\n    return plt\n</pre> # validacion curv def validation_curve_model(X: np.ndarray,                             Y: np.ndarray,                             model: BaseEstimator,                             param_name: str,                             parameters: List[Any],                             cv: Union[int, Any],                             ylim: Optional[Tuple[float, float]] = None,                             log: bool = True) -&gt; plt.Figure:     \"\"\"     Plota a curva de valida\u00e7\u00e3o para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser avaliado.         param_name (str): Nome do hiperpar\u00e2metro a ser testado.         parameters (List[Any]): Lista de valores para o hiperpar\u00e2metro.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.         ylim (Optional[Tuple[float, float]]): Limites para o eixo y no gr\u00e1fico (opcional).         log (bool): Se verdadeiro, usa escala logar\u00edtmica para o eixo x.      Returns:         plt.Figure: O objeto de figura do matplotlib contendo a curva de valida\u00e7\u00e3o.     \"\"\"     train_scores, test_scores = validation_curve(         model, X, Y, param_name=param_name, param_range=parameters, cv=cv, scoring=\"accuracy\"     )          train_scores_mean = np.mean(train_scores, axis=1)     train_scores_std = np.std(train_scores, axis=1)     test_scores_mean = np.mean(test_scores, axis=1)     test_scores_std = np.std(test_scores, axis=1)      plt.figure()     plt.title(\"Curva de Valida\u00e7\u00e3o\")     plt.fill_between(parameters, train_scores_mean - train_scores_std,                      train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")     plt.fill_between(parameters, test_scores_mean - test_scores_std,                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")      if log:         plt.semilogx(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")         plt.semilogx(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")     else:         plt.plot(parameters, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")         plt.plot(parameters, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")      if ylim is not None:         plt.ylim(*ylim)      plt.ylabel('Pontua\u00e7\u00e3o')     plt.xlabel(f'Par\u00e2metro {param_name}')     plt.legend(loc=\"best\")      return plt In\u00a0[\u00a0]: Copied! <pre># Learning curve\ndef Learning_curve_model(X: np.ndarray, \n                         Y: np.ndarray, \n                         model: BaseEstimator, \n                         cv: Union[int, Any], \n                         train_sizes: Union[np.ndarray, List[int]]) -&gt; plt.Figure:\n    \"\"\"\n    Plota a curva de aprendizado para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o\n    em diferentes tamanhos de conjunto de treinamento.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser avaliado.\n        cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.\n        train_sizes (Union[np.ndarray, List[int]]): Tamanhos dos conjuntos de treinamento a serem usados para gerar a curva de aprendizado.\n\n    Returns:\n        plt.Figure: O objeto de figura do matplotlib contendo a curva de aprendizado.\n    \"\"\"\n    plt.figure()\n    plt.title(\"Curva de Aprendizado\")\n    plt.xlabel(\"Exemplos de Treinamento\")\n    plt.ylabel(\"Pontua\u00e7\u00e3o\")\n\n    train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std  = np.std(train_scores, axis=1)\n    test_scores_mean  = np.mean(test_scores, axis=1)\n    test_scores_std   = np.std(test_scores, axis=1)\n    plt.grid()\n    \n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")\n                     \n    plt.legend(loc=\"best\")\n    return plt\n</pre> # Learning curve def Learning_curve_model(X: np.ndarray,                           Y: np.ndarray,                           model: BaseEstimator,                           cv: Union[int, Any],                           train_sizes: Union[np.ndarray, List[int]]) -&gt; plt.Figure:     \"\"\"     Plota a curva de aprendizado para um modelo de Machine Learning, mostrando o desempenho de treinamento e valida\u00e7\u00e3o     em diferentes tamanhos de conjunto de treinamento.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser avaliado.         cv (Union[int, Any]): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada.         train_sizes (Union[np.ndarray, List[int]]): Tamanhos dos conjuntos de treinamento a serem usados para gerar a curva de aprendizado.      Returns:         plt.Figure: O objeto de figura do matplotlib contendo a curva de aprendizado.     \"\"\"     plt.figure()     plt.title(\"Curva de Aprendizado\")     plt.xlabel(\"Exemplos de Treinamento\")     plt.ylabel(\"Pontua\u00e7\u00e3o\")      train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)      train_scores_mean = np.mean(train_scores, axis=1)     train_scores_std  = np.std(train_scores, axis=1)     test_scores_mean  = np.mean(test_scores, axis=1)     test_scores_std   = np.std(test_scores, axis=1)     plt.grid()          plt.fill_between(train_sizes, train_scores_mean - train_scores_std,                      train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Pontua\u00e7\u00e3o de Treinamento\")     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Pontua\u00e7\u00e3o de Valida\u00e7\u00e3o Cruzada\")                           plt.legend(loc=\"best\")     return plt In\u00a0[\u00a0]: Copied! <pre># lrearning, prediction and printing results\ndef predict_model(X: np.ndarray, \n                  Y: np.ndarray, \n                  model: BaseEstimator, \n                  Xtest: np.ndarray, \n                  submit_name: str, \n                  test_df: pd.DataFrame, \n                  cv: Union[int, Any] = 5) -&gt; np.ndarray:\n    \"\"\"\n    Treina o modelo, faz previs\u00f5es e salva os resultados em um arquivo CSV.\n\n    Args:\n        X (np.ndarray): Dados de entrada (features) para o treinamento.\n        Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.\n        model (BaseEstimator): O modelo de Machine Learning a ser treinado.\n        Xtest (np.ndarray): Dados de entrada (features) para o teste.\n        submit_name (str): Nome do arquivo CSV para salvar as previs\u00f5es.\n        test_df (pd.DataFrame): DataFrame contendo os dados de teste, incluindo o 'PassengerId'.\n        cv (Union[int, Any], optional): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada. Default \u00e9 5.\n\n    Returns:\n        np.ndarray: Array contendo as pontua\u00e7\u00f5es de valida\u00e7\u00e3o cruzada.\n    \"\"\"\n    model.fit(X, Y)\n    Y_pred = model.predict(Xtest)\n    score = cross_val_score(model, X, Y, cv=cv)\n\n    submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n    submission.to_csv(submit_name, index=False)\n    \n    return score\n</pre> # lrearning, prediction and printing results def predict_model(X: np.ndarray,                    Y: np.ndarray,                    model: BaseEstimator,                    Xtest: np.ndarray,                    submit_name: str,                    test_df: pd.DataFrame,                    cv: Union[int, Any] = 5) -&gt; np.ndarray:     \"\"\"     Treina o modelo, faz previs\u00f5es e salva os resultados em um arquivo CSV.      Args:         X (np.ndarray): Dados de entrada (features) para o treinamento.         Y (np.ndarray): Dados de sa\u00edda (r\u00f3tulos) para o treinamento.         model (BaseEstimator): O modelo de Machine Learning a ser treinado.         Xtest (np.ndarray): Dados de entrada (features) para o teste.         submit_name (str): Nome do arquivo CSV para salvar as previs\u00f5es.         test_df (pd.DataFrame): DataFrame contendo os dados de teste, incluindo o 'PassengerId'.         cv (Union[int, Any], optional): N\u00famero de folds para a valida\u00e7\u00e3o cruzada ou um objeto de gerador de valida\u00e7\u00e3o cruzada. Default \u00e9 5.      Returns:         np.ndarray: Array contendo as pontua\u00e7\u00f5es de valida\u00e7\u00e3o cruzada.     \"\"\"     model.fit(X, Y)     Y_pred = model.predict(Xtest)     score = cross_val_score(model, X, Y, cv=cv)      submission = pd.DataFrame({         \"PassengerId\": test_df[\"PassengerId\"],         \"Survived\": Y_pred     })     submission.to_csv(submit_name, index=False)          return score"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/","title":"Learning curves","text":"<ul> <li>Tipos de curvas para avalia\u00e7\u00e3o</li> <li>Curva de Valida\u00e7\u00e3o</li> <li>Curva de Desempenho(curva de aprendizado)</li> <li>Scikit-learn: Curvas de Avalia\u00e7\u00e3o e Aprendizagem</li> <li>Curvas Adicionais de Aprendizado em Machine Learning<ul> <li>Curva de Aprendizado Incremental</li> <li>Curva de Aprendizado de Converg\u00eancia</li> <li>Curva de Aprendizado de Regulariza\u00e7\u00e3o</li> <li>Curva de Aprendizado de Aprendizado Ativo</li> </ul> </li> </ul>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#tipos-de-curvas-para-avaliacao","title":"Tipos de curvas para avalia\u00e7\u00e3o","text":""},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-validacao","title":"Curva de Valida\u00e7\u00e3o","text":"<ul> <li>A curva de valida\u00e7\u00e3o \u00e9 uma ferramenta usada para avaliar o desempenho de um modelo de machine learning variando diferentes hiperpar\u00e2metros.</li> <li>Ela representa o desempenho do modelo em um conjunto de valida\u00e7\u00e3o em rela\u00e7\u00e3o a diferentes configura\u00e7\u00f5es de hiperpar\u00e2metros, permitindo a sele\u00e7\u00e3o da combina\u00e7\u00e3o \u00f3tima de hiperpar\u00e2metros para o modelo.</li> <li>A curva de valida\u00e7\u00e3o geralmente mostra o desempenho do modelo em rela\u00e7\u00e3o a um \u00fanico hiperpar\u00e2metro, mantendo os outros constantes. Isso ajuda a identificar como mudan\u00e7as nos hiperpar\u00e2metros afetam o desempenho do modelo.</li> </ul>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-desempenhocurva-de-aprendizado","title":"Curva de Desempenho(curva de aprendizado)","text":"<ul> <li>A curva de desempenho, tamb\u00e9m conhecida como <code>curva de aprendizado</code>, mostra como o desempenho do modelo varia com a quantidade de dados de treinamento.</li> <li>Ela representa a precis\u00e3o ou outra m\u00e9trica de desempenho do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento.</li> <li>A curva de desempenho \u00e9 \u00fatil para entender se o modelo est\u00e1 sofrendo de subajuste (underfitting) ou sobreajuste (overfitting). No subajuste, o desempenho permanece baixo mesmo com mais dados de treinamento, enquanto no sobreajuste, o desempenho no conjunto de treinamento \u00e9 muito melhor do que no conjunto de valida\u00e7\u00e3o.</li> <li>Analisar a curva de desempenho ajuda a decidir se \u00e9 necess\u00e1rio coletar mais dados, ajustar a complexidade do modelo ou melhorar outras t\u00e9cnicas de regulariza\u00e7\u00e3o para otimizar o desempenho do modelo.</li> </ul> <p>Ambas as curvas s\u00e3o ferramentas poderosas para entender e otimizar modelos de machine learning, ajudando a encontrar configura\u00e7\u00f5es ideais de hiperpar\u00e2metros e melhorando a capacidade de generaliza\u00e7\u00e3o do modelo para novos dados.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#scikit-learn-curvas-de-avaliacao-e-aprendizagem","title":"Scikit-learn: Curvas de Avalia\u00e7\u00e3o e Aprendizagem","text":"<p>As fun\u00e7\u00f5es <code>validation_curve</code> e <code>learning_curve</code> do scikit-learn s\u00e3o duas ferramentas importantes para avaliar o desempenho de modelos de machine learning, mas t\u00eam prop\u00f3sitos ligeiramente diferentes. Aqui est\u00e3o as principais diferen\u00e7as entre elas:</p> <p>Objetivo:</p> <p><code>validation_curve:</code> A fun\u00e7\u00e3o validation_curve \u00e9 usada para avaliar como uma \u00fanica hiperpar\u00e2metro afeta o desempenho do modelo. Ela plota o desempenho do modelo em rela\u00e7\u00e3o a diferentes valores de um hiperpar\u00e2metro espec\u00edfico, permitindo que voc\u00ea identifique o valor ideal desse hiperpar\u00e2metro.</p> <p><code>learning_curve:</code> A fun\u00e7\u00e3o learning_curve, por outro lado, \u00e9 usada para avaliar o desempenho do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Ela mostra como o desempenho do modelo varia \u00e0 medida que o tamanho do conjunto de treinamento aumenta, ajudando a entender se o modelo se beneficiaria de mais dados de treinamento.</p> <p>Par\u00e2metros:</p> <p><code>validation_curve:</code> A fun\u00e7\u00e3o validation_curve requer a especifica\u00e7\u00e3o do modelo, o conjunto de treinamento, o conjunto de teste (ou valida\u00e7\u00e3o cruzada) e o hiperpar\u00e2metro que se deseja avaliar.</p> <p><code>learning_curve:</code> A fun\u00e7\u00e3o learning_curve requer a especifica\u00e7\u00e3o do modelo, o conjunto de treinamento e uma m\u00e9trica de avalia\u00e7\u00e3o (como precis\u00e3o, erro ou outra m\u00e9trica de desempenho). Geralmente, ela tamb\u00e9m requer a especifica\u00e7\u00e3o de uma estrat\u00e9gia de valida\u00e7\u00e3o cruzada.</p> <p>Sa\u00edda:</p> <p><code>validation_curve:</code> A sa\u00edda da fun\u00e7\u00e3o validation_curve \u00e9 um gr\u00e1fico que mostra como o desempenho do modelo varia em rela\u00e7\u00e3o aos valores do hiperpar\u00e2metro especificado.</p> <p><code>learning_curve:</code> A sa\u00edda da fun\u00e7\u00e3o learning_curve \u00e9 um gr\u00e1fico que mostra como o desempenho do modelo varia em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Pode mostrar o erro de treinamento e/ou valida\u00e7\u00e3o em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento.</p> <p>Em resumo, enquanto a validation_curve ajuda a otimizar hiperpar\u00e2metros de modelos, a learning_curve fornece insights sobre a capacidade de generaliza\u00e7\u00e3o do modelo em rela\u00e7\u00e3o ao tamanho do conjunto de treinamento. Ambas s\u00e3o ferramentas valiosas para aprimorar modelos de machine learning, mas t\u00eam prop\u00f3sitos distintos.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curvas-adicionais-de-aprendizado-em-machine-learning","title":"Curvas Adicionais de Aprendizado em Machine Learning","text":"<p>Al\u00e9m das fun\u00e7\u00f5es <code>validation_curve</code> e <code>learning_curve</code>, o scikit-learn oferece outras curvas de aprendizado que fornecem insights adicionais sobre o desempenho e comportamento de modelos de machine learning. Abaixo est\u00e3o algumas dessas curvas adicionais:</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-aprendizado-incremental","title":"Curva de Aprendizado Incremental","text":"<p>Esta curva mostra como o desempenho do modelo evolui \u00e0 medida que novos exemplos de treinamento s\u00e3o adicionados incrementalmente. \u00c9 \u00fatil para entender como o modelo se comporta com o aumento do tamanho do conjunto de dados de treinamento. </p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-aprendizado-de-convergencia","title":"Curva de Aprendizado de Converg\u00eancia","text":"<p>Esta curva avalia como as medidas de desempenho do modelo (como erro ou precis\u00e3o) mudam ao longo do tempo ou do n\u00famero de itera\u00e7\u00f5es do algoritmo de treinamento. Ajuda a determinar se o modelo est\u00e1 convergindo para uma solu\u00e7\u00e3o est\u00e1vel ou se precisa de mais itera\u00e7\u00f5es para melhorar.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-aprendizado-de-regularizacao","title":"Curva de Aprendizado de Regulariza\u00e7\u00e3o","text":"<p>Esta curva mostra como diferentes valores de regulariza\u00e7\u00e3o afetam o desempenho do modelo. \u00c9 \u00fatil para determinar o impacto da regulariza\u00e7\u00e3o nos resultados do modelo e encontrar o melhor valor de regulariza\u00e7\u00e3o para evitar overfitting.</p>"},{"location":"2_machine_learning/2.4_Pos_treinamento/learning_curves/#curva-de-aprendizado-de-aprendizado-ativo","title":"Curva de Aprendizado de Aprendizado Ativo","text":"<p>Esta curva demonstra como o desempenho do modelo melhora \u00e0 medida que o algoritmo de aprendizado ativo seleciona ativamente os exemplos mais informativos para treinamento. \u00c9 \u00fatil para entender como o modelo se beneficia de uma estrat\u00e9gia de aprendizado ativo em compara\u00e7\u00e3o com uma estrat\u00e9gia de aprendizado passivo.</p> <p>Essas curvas adicionais fornecem uma vis\u00e3o mais abrangente do comportamento do modelo durante o treinamento e s\u00e3o \u00fateis para an\u00e1lise detalhada e refinamento de modelos de machine learning.</p>"},{"location":"5_Ferramentas/5.10_latex/","title":"1. \u270d\ufe0f Guia R\u00e1pido de LaTeX em Markdown e Jupyter","text":"<p>O LaTeX \u00e9 uma linguagem de marca\u00e7\u00e3o amplamente utilizada para escrever equa\u00e7\u00f5es matem\u00e1ticas com alta qualidade tipogr\u00e1fica. Ele pode ser integrado tanto em Markdown quanto em Jupyter Notebooks com suporte ao MathJax.</p>"},{"location":"5_Ferramentas/5.10_latex/#11-sintaxe-basica-de-latex","title":"1.1. Sintaxe B\u00e1sica de LaTeX","text":""},{"location":"5_Ferramentas/5.10_latex/#111-formas-de-uso","title":"1.1.1. Formas de uso","text":"<ul> <li>Inline: <code>$ ... $</code> \u2192 Exemplo: <code>$x^2 + y^2 = z^2$</code></li> <li>Bloco: <code>$$ ... $$</code> ou <code>\\[\u2026\\]</code> \u2192 Exemplo:</li> </ul> <pre><code>\\[\n\\frac{a}{b} = c\n\\]\n</code></pre>"},{"location":"5_Ferramentas/5.10_latex/#12-principais-comandos-matematicos","title":"1.2. Principais Comandos Matem\u00e1ticos","text":"Comando Descri\u00e7\u00e3o Exemplo <code>\\frac{a}{b}</code> Fra\u00e7\u00e3o <code>\\frac{1}{2}</code> <code>x^2</code> Expoente <code>x^2</code> <code>\\sqrt{x}</code> Raiz quadrada <code>\\sqrt{4}</code> <code>\\sum</code> Somat\u00f3rio <code>\\sum_{i=1}^n i</code> <code>\\int</code> Integral <code>\\int_{0}^{\\infty} e^{-x} dx</code> <code>\\begin{bmatrix}</code> Matriz <code>\\begin{bmatrix}1 &amp; 2 \\\\ 3 &amp; 4\\end{bmatrix}</code> <code>\\infty</code> Infinito <code>\\infty</code> <code>\\cdot</code> Multiplica\u00e7\u00e3o <code>a \\cdot b</code>"},{"location":"5_Ferramentas/5.10_latex/#13-exemplo-de-equacao-em-bloco","title":"1.3. Exemplo de Equa\u00e7\u00e3o em Bloco","text":"<pre><code>\\begin{align*}\n    x_1 &amp;= 0.769682 \\\\\n    x_2 &amp;= 0.758596 \\\\\n    x_3 &amp;= 0.762273 \\\\\n    x_4 &amp;= 0.776236 \\\\\n    x_5 &amp;= 0.760402\n\\end{align*}\n</code></pre>"},{"location":"5_Ferramentas/5.10_latex/#14-problemas-com-renderizacao-no-jupyter","title":"1.4. Problemas com Renderiza\u00e7\u00e3o no Jupyter","text":"<p>\u00c0s vezes, o ambiente Jupyter pode n\u00e3o renderizar express\u00f5es LaTeX corretamente com <code>align*</code>. Uma solu\u00e7\u00e3o \u00e9 incluir o seguinte c\u00f3digo HTML + JavaScript no in\u00edcio do notebook para configurar o MathJax:</p> <pre><code>&lt;script&gt;\nMathJax = {\n  tex: {\n    inlineMath: [['$', '$'], ['\\\\(', '\\\\)']]\n  }\n};\n&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"5_Ferramentas/5.10_latex/#15-alternativa-em-listas-com-mathjax-inline","title":"1.5. Alternativa em Listas com MathJax Inline","text":"<ul> <li>$x_1 = 0.769682$</li> <li>$x_2 = 0.758596$</li> <li>$x_3 = 0.762273$</li> <li>$x_4 = 0.776236$</li> <li>$x_5 = 0.760402$</li> </ul>"},{"location":"5_Ferramentas/5.2_Git/","title":"1. \ud83d\udcda Principais Comandos do Git","text":"<p>Guia r\u00e1pido de refer\u00eancia para os comandos mais usados no Git.  </p>"},{"location":"5_Ferramentas/5.2_Git/#11-configuracao-inicial","title":"1.1. \ud83d\udd04 Configura\u00e7\u00e3o Inicial","text":"Comando Descri\u00e7\u00e3o <code>git config --global user.name \"Seu Nome\"</code> Define o nome do usu\u00e1rio. <code>git config --global user.email \"seu@email.com\"</code> Define o e-mail do usu\u00e1rio. <code>git config --list</code> Lista todas as configura\u00e7\u00f5es do Git."},{"location":"5_Ferramentas/5.2_Git/#12-iniciar-e-clonar-repositorios","title":"1.2. \ud83d\udcc2 Iniciar e Clonar Reposit\u00f3rios","text":"Comando Descri\u00e7\u00e3o <code>git init</code> Inicializa um reposit\u00f3rio Git local. <code>git clone &lt;URL&gt;</code> Clona um reposit\u00f3rio remoto para a m\u00e1quina local."},{"location":"5_Ferramentas/5.2_Git/#13-trabalhando-com-alteracoes","title":"1.3. \ud83d\udcdd Trabalhando com Altera\u00e7\u00f5es","text":"Comando Descri\u00e7\u00e3o <code>git status</code> Mostra o estado atual do reposit\u00f3rio (arquivos modificados, staged etc.). <code>git add &lt;arquivo&gt;</code> Adiciona um arquivo espec\u00edfico \u00e0 \u00e1rea de staging. <code>git add .</code> Adiciona todos os arquivos modificados ao staging. <code>git commit -m \"mensagem\"</code> Registra as altera\u00e7\u00f5es no reposit\u00f3rio com uma mensagem. <code>git commit --amend</code> Corrige o \u00faltimo commit (mensagem ou arquivos esquecidos)."},{"location":"5_Ferramentas/5.2_Git/#14-sincronizando-com-repositorios-remotos","title":"1.4. \ud83d\udd04 Sincronizando com Reposit\u00f3rios Remotos","text":"Comando Descri\u00e7\u00e3o <code>git pull</code> Puxa as altera\u00e7\u00f5es do reposit\u00f3rio remoto e faz o merge. <code>git pull --rebase</code> Puxa altera\u00e7\u00f5es e aplica seus commits em cima (evita merge commits). <code>git push</code> Envia commits locais para o reposit\u00f3rio remoto. <code>git push -u origin &lt;branch&gt;</code> Define um upstream (vincula branch local ao remoto)."},{"location":"5_Ferramentas/5.2_Git/#15-branches-ramificacoes","title":"1.5. \ud83c\udf3f Branches (Ramifica\u00e7\u00f5es)","text":"Comando Descri\u00e7\u00e3o <code>git branch</code> Lista todas as branches locais. <code>git branch &lt;nome&gt;</code> Cria uma nova branch. <code>git checkout &lt;branch&gt;</code> Muda para a branch especificada. <code>git checkout -b &lt;nova-branch&gt;</code> Cria e muda para uma nova branch. <code>git merge &lt;branch&gt;</code> Mescla a branch especificada na branch atual. <code>git branch -d &lt;branch&gt;</code> Deleta uma branch local (se j\u00e1 estiver mesclada)."},{"location":"5_Ferramentas/5.2_Git/#16-desfazendo-coisas","title":"1.6. \u23ea Desfazendo Coisas","text":"Comando Descri\u00e7\u00e3o <code>git restore &lt;arquivo&gt;</code> Descarta altera\u00e7\u00f5es n\u00e3o commitadas em um arquivo. <code>git reset --hard</code> Remove todas as altera\u00e7\u00f5es locais n\u00e3o commitadas. <code>git reset --soft HEAD~1</code> Remove o \u00faltimo commit, mas mant\u00e9m as altera\u00e7\u00f5es no staging. <code>git revert &lt;commit&gt;</code> Cria um novo commit desfazendo um commit anterior."},{"location":"5_Ferramentas/5.2_Git/#17-historico-e-diferencas","title":"1.7. \ud83d\udd0d Hist\u00f3rico e Diferen\u00e7as","text":"Comando Descri\u00e7\u00e3o <code>git log</code> Mostra o hist\u00f3rico de commits. <code>git log --oneline</code> Hist\u00f3rico compacto (apenas hash e mensagem). <code>git diff</code> Mostra diferen\u00e7as entre arquivos n\u00e3o stageados. <code>git diff --staged</code> Mostra diferen\u00e7as nos arquivos stageados."},{"location":"5_Ferramentas/5.2_Git/#18-tags-e-versoes","title":"1.8. \ud83c\udff7\ufe0f Tags e Vers\u00f5es","text":"Comando Descri\u00e7\u00e3o <code>git tag</code> Lista todas as tags. <code>git tag -a v1.0 -m \"Vers\u00e3o 1.0\"</code> Cria uma tag anotada. <code>git push origin --tags</code> Envia tags para o reposit\u00f3rio remoto. <p>\ud83d\udca1 Dica: Use <code>git &lt;comando&gt; --help</code> para ver a documenta\u00e7\u00e3o detalhada de cada comando.  </p> <p>\ud83d\udccc Quer contribuir? Corrija ou sugira melhorias neste guia! \ud83d\ude80  </p>"},{"location":"5_Ferramentas/5.3_Poetry/","title":"1. \ud83d\udcd8 Guia Completo do Poetry","text":""},{"location":"5_Ferramentas/5.3_Poetry/#11-introducao","title":"1.1. Introdu\u00e7\u00e3o","text":"<p>O Poetry \u00e9 uma ferramenta de gerenciamento de depend\u00eancias e empacotamento para projetos Python. Ele facilita a cria\u00e7\u00e3o de ambientes virtuais, o controle de vers\u00f5es e a publica\u00e7\u00e3o de pacotes.</p>"},{"location":"5_Ferramentas/5.3_Poetry/#12-instalacao-e-configuracao","title":"1.2. Instala\u00e7\u00e3o e Configura\u00e7\u00e3o","text":""},{"location":"5_Ferramentas/5.3_Poetry/#121-instalacao-via-pip","title":"1.2.1. Instala\u00e7\u00e3o via pip","text":"<pre><code>pip install poetry \n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#122-listar-configuracoes","title":"1.2.2. Listar Configura\u00e7\u00f5es","text":"<pre><code>poetry config --list\n</code></pre> <p>Sa\u00edda esperada:</p> <pre><code>cache-dir = \"/path/to/cache/directory\"\nvirtualenvs.create = true\nvirtualenvs.in-project = null\nvirtualenvs.options.always-copy = true\nvirtualenvs.options.no-pip = false\nvirtualenvs.options.no-setuptools = false\nvirtualenvs.options.system-site-packages = false\nvirtualenvs.path = \"{cache-dir}/virtualenvs\"\nvirtualenvs.prefer-active-python = false\nvirtualenvs.prompt = \"{project_name}-py{python_version}\"\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#123-criar-ambientes-virtuais-no-diretorio-do-projeto","title":"1.2.3. Criar ambientes virtuais no diret\u00f3rio do projeto","text":"<pre><code>poetry config virtualenvs.in-project true\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#124-especificar-o-caminho-do-python","title":"1.2.4. Especificar o Caminho do Python","text":"<p>Exemplo de caminho:</p> <ul> <li>Python padr\u00e3o: <code>C:\\Python39\\python.exe</code></li> <li>Anaconda: <code>C:\\Users\\username\\Anaconda3\\python.exe</code></li> </ul> <pre><code>poetry env use C:\\Users\\SeuUsuario\\anaconda3\\python.exe\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#125-verificar-informacoes-do-ambiente","title":"1.2.5. Verificar Informa\u00e7\u00f5es do Ambiente","text":"<pre><code>poetry env info\n</code></pre> <p>Sa\u00edda t\u00edpica:</p> <pre><code>Virtualenv\nPython:         3.11.7\nImplementation: CPython\nPath:           ...\\.venv\nExecutable:     ...\\.venv\\Scripts\\python.exe\nValid:          True\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#126-verificacao-de-criacao-do-venv","title":"1.2.6. Verifica\u00e7\u00e3o de Cria\u00e7\u00e3o do <code>.venv</code>","text":"<pre><code>poetry show\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#13-uso-do-poetry","title":"1.3. Uso do Poetry","text":""},{"location":"5_Ferramentas/5.3_Poetry/#131-iniciar-um-novo-projeto","title":"1.3.1. Iniciar um Novo Projeto","text":"<pre><code>poetry new meu_projeto\npoetry add nome_do_pacote\npoetry install\npoetry lock\npoetry show\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#132-usar-em-projeto-existente","title":"1.3.2. Usar em Projeto Existente","text":"<pre><code>poetry init\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#133-usar-em-projeto-clonado","title":"1.3.3. Usar em Projeto Clonado","text":"<ol> <li>Clone o reposit\u00f3rio.</li> <li>Verifique se h\u00e1 <code>pyproject.toml</code>.</li> <li>Execute:</li> </ol> <pre><code>poetry install\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#134-executar-scripts-com-poetry","title":"1.3.4. Executar Scripts com Poetry","text":"<p>Dentro do ambiente:</p> <pre><code>poetry shell\npython script.py\n</code></pre> <p>Fora do ambiente:</p> <pre><code>poetry run python script.py\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#14-comandos-essenciais-do-poetry","title":"1.4. Comandos Essenciais do Poetry","text":""},{"location":"5_Ferramentas/5.3_Poetry/#141-instalacao-de-dependencias","title":"1.4.1. Instala\u00e7\u00e3o de Depend\u00eancias","text":"<pre><code>poetry install\npoetry add pacote\npoetry add pacote --dev\npoetry remove pacote\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#142-build-e-publicacao","title":"1.4.2. Build e Publica\u00e7\u00e3o","text":"<pre><code>poetry build\npoetry publish\npoetry publish --dry-run\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#143-ambiente-virtual","title":"1.4.3. Ambiente Virtual","text":"<pre><code>poetry shell\npoetry run comando\npoetry env list\npoetry env remove python-versao\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#144-diagnostico-e-informacao","title":"1.4.4. Diagn\u00f3stico e Informa\u00e7\u00e3o","text":"<pre><code>poetry show\npoetry show pacote\npoetry check\npoetry debug info\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#145-configuracoes","title":"1.4.5. Configura\u00e7\u00f5es","text":"<pre><code>poetry config --list\npoetry config repositories.&lt;nome&gt; &lt;url&gt;\npoetry config http-basic.&lt;nome&gt; &lt;usuario&gt; &lt;senha&gt;\n</code></pre>"},{"location":"5_Ferramentas/5.3_Poetry/#2-warning","title":"2. Warning","text":""},{"location":"5_Ferramentas/5.3_Poetry/#21-mudancas-no-comando-poetry-shell-a-partir-da-versao-20","title":"2.1. Mudan\u00e7as no Comando <code>poetry shell</code> (a partir da vers\u00e3o 2.0)","text":"<p>Desde a vers\u00e3o 2.0.0, o comando <code>poetry shell</code> n\u00e3o \u00e9 mais instalado por padr\u00e3o. Em vez disso, o Poetry recomenda utilizar o novo comando <code>env activate</code>, ou, se necess\u00e1rio, instalar o plugin correspondente.</p>"},{"location":"5_Ferramentas/5.3_Poetry/#211-forma-recomendada-ativando-o-ambiente-virtual","title":"2.1.1. \u2705 Forma Recomendada: Ativando o Ambiente Virtual","text":"<pre><code>poetry env activate\n</code></pre> <p>Ativa o ambiente virtual gerenciado pelo Poetry. Nota: esse comando n\u00e3o \u00e9 um substituto direto do antigo <code>poetry shell</code>, mas \u00e9 a forma moderna recomendada.</p>"},{"location":"5_Ferramentas/5.3_Poetry/#212-restaurar-o-comando-antigo-shell","title":"2.1.2. \ud83d\udd04 Restaurar o Comando Antigo (<code>shell</code>)","text":"<pre><code>poetry self add poetry-plugin-shell\n</code></pre> <p>Isso instala o plugin que reabilita o comando <code>shell</code> como antigamente.</p>"},{"location":"5_Ferramentas/5.3_Poetry/#213-executar-scripts-sem-entrar-no-ambiente","title":"2.1.3. \u25b6\ufe0f Executar Scripts sem Entrar no Ambiente","text":"<pre><code>poetry run python seu_script.py\n</code></pre> <p>Executa comandos ou scripts Python diretamente no ambiente virtual gerenciado pelo Poetry, sem ativ\u00e1-lo manualmente.</p>"},{"location":"5_Ferramentas/5.3_Poetry/#214-i-explicacao-tecnica","title":"2.1.4. \u2139\ufe0f Explica\u00e7\u00e3o T\u00e9cnica","text":"<ul> <li>O comando <code>poetry shell</code> foi removido do core para tornar o Poetry mais modular.</li> <li>O novo m\u00e9todo <code>env activate</code> \u00e9 mais flex\u00edvel e expl\u00edcito, e segue uma abordagem alinhada com pr\u00e1ticas modernas.</li> <li>A instala\u00e7\u00e3o de plugins via <code>poetry self add</code> \u00e9 agora o caminho padr\u00e3o para restaurar funcionalidades opcionais.</li> </ul> <p>\ud83d\udcda Documenta\u00e7\u00e3o oficial: \ud83d\udd17 https://python-poetry.org/docs/managing-environments/#activating-the-environment</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/","title":"1. Estruturas de Organiza\u00e7\u00e3o de Pastas","text":"<ol> <li>Cookiecutter Data Science</li> <li>Template popular para estruturar projetos de ci\u00eancia de dados de forma organizada e reprodut\u00edvel.</li> <li>Cookiecutter Data Science</li> <li> <p>cookiecutter docs</p> </li> <li> <p>Project Template for Data Science</p> </li> <li> <p>Modelo de projeto de ci\u00eancia de dados</p> </li> <li> <p>Estrutura projeto: Khuyen Tran:</p> </li> <li>Estrutura de projeto: Khuyen Tran</li> </ol>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#2-diferencas-cookiecutter-e-cookiecutter-data-science","title":"2. Diferen\u00e7as Cookiecutter e Cookiecutter Data Science","text":"<p>A diferen\u00e7a entre <code>pip install cookiecutter</code> e <code>pip install cookiecutter-data-science</code> est\u00e1 nos modelos (ou \u201ccookiecutters\u201d) que eles fornecem:</p> <p>Em resumo, temos dois pacotes relacionados ao Cookiecutter:</p> <ol> <li>pip install cookiecutter:</li> <li>Instala o <code>Cookiecutter</code> em si, que \u00e9 uma ferramenta de linha de comando.</li> <li>Permite criar projetos a partir de modelos pr\u00e9-definidos (chamados \"cookiecutters\").</li> <li> <p>\u00datil para iniciar projetos em v\u00e1rias linguagens e \u00e1reas.</p> </li> <li> <p>pip install cookiecutter-data-science:</p> </li> <li>Instala o pacote espec\u00edfico para ci\u00eancia de dados chamado <code>Cookiecutter Data Science</code>.</li> <li>\u00c9 um pacote espec\u00edfico para ci\u00eancia de dados.</li> <li>Fornece um modelo consistente para projetos de ci\u00eancia de dados.</li> <li>Inclui estrutura de diret\u00f3rios para dados, notebooks, modelos e visualiza\u00e7\u00f5es.</li> </ol> <p>Ambos s\u00e3o \u00fateis, dependendo do tipo de projeto que voc\u00ea deseja iniciar! \ud83d\ude80</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#3-cookiecutter-data-science","title":"3. Cookiecutter Data Science","text":""},{"location":"5_Ferramentas/5.5_Cookiecutter/#301-o-que-e-cookiecutter-data-science","title":"3.0.1. O que \u00e9 Cookiecutter Data Science?","text":"<p>Cookiecutter Data Science \u00e9 um projeto e uma ferramenta que visa facilitar a cria\u00e7\u00e3o e a organiza\u00e7\u00e3o de projetos de ci\u00eancia de dados de maneira estruturada, padronizada e reprodut\u00edvel.</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#302-como-usar-o-cookiecutter-data-science","title":"3.0.2. Como Usar o Cookiecutter Data Science?","text":"<ul> <li>Instala\u00e7\u00e3o: Para usar o Cookiecutter Data Science, voc\u00ea precisa primeiro instalar o Cookiecutter via pip:</li> </ul> <pre><code>pip install cookiecutter-data-science\n</code></pre> <ul> <li>Execu\u00e7\u00e3o: Para criar um novo projeto de ci\u00eancia de dados usando Cookiecutter Data Science (PADR\u00c3O), execute o seguinte comando no terminal:</li> </ul> <pre><code>ccds\n</code></pre> <ul> <li>Personaliza\u00e7\u00e3o: Durante a cria\u00e7\u00e3o do projeto, voc\u00ea ser\u00e1 solicitado a fornecer informa\u00e7\u00f5es como nome do projeto, nome do autor, diret\u00f3rio de trabalho, entre outros. Isso personaliza o template de acordo com as suas necessidades espec\u00edficas.</li> </ul>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#303-beneficios-do-cookiecutter-data-science","title":"3.0.3. Benef\u00edcios do Cookiecutter Data Science","text":"<ul> <li> <p>Estrutura Padr\u00e3o: Oferece uma estrutura de diret\u00f3rios padronizada que inclui pastas para dados brutos, dados processados, notebooks de explora\u00e7\u00e3o, scripts de modelagem, entre outros.</p> </li> <li> <p>Reprodutibilidade: Facilita a reprodutibilidade do projeto ao definir uma organiza\u00e7\u00e3o clara dos dados, scripts e notebooks, garantindo que outros membros da equipe ou colaboradores possam entender e reproduzir os resultados facilmente.</p> </li> <li> <p>Boas Pr\u00e1ticas: Promove boas pr\u00e1ticas de desenvolvimento de software e ci\u00eancia de dados, como separa\u00e7\u00e3o de dados e c\u00f3digo, versionamento de modelos, e documenta\u00e7\u00e3o integrada.</p> </li> </ul>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#31-configurando-o-cookiecutter-data-science","title":"3.1. Configurando o Cookiecutter Data Science","text":"<p>Para configurar o Cookiecutter Data Science (ccds) padr\u00e3o olhe o passo a passo: - Cookiecutter data science - ccds padr\u00e3o.md</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#4-cookiecutter","title":"4. Cookiecutter","text":"<p>O <code>Cookiecutter</code> em si \u00e9 uma ferramenta de linha de comando que permite criar projetos a partir de modelos (ou \u201ctemplates\u201d) pr\u00e9-definidos. No entanto, existem v\u00e1rios pacotes de modelos espec\u00edficos para diferentes tipos de projetos. Al\u00e9m do <code>Cookiecutter Data Science</code>, voc\u00ea pode encontrar outros pacotes de modelos para \u00e1reas como desenvolvimento web, aprendizado de m\u00e1quina, an\u00e1lise de dados e muito mais.</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#41-selecionando-templates-especificos","title":"4.1. Selecionando Templates Espec\u00edficos:","text":"<p>Voc\u00ea pode explorar os templates dispon\u00edveis em cookiecutter.io/templates. </p> <p>Para data science: * cookiecutter-data-science * data-science-template-khuyen * data-science-template-espedito</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#-","title":"---","text":""},{"location":"5_Ferramentas/5.5_Cookiecutter/#5-estrutura-de-diretorios-para-projetos-de-ciencia-de-dadosmachine-learning","title":"5. Estrutura de Diret\u00f3rios para Projetos de Ci\u00eancia de Dados/Machine Learning","text":"<p>A Ferramenta Cookiecutter data science, oference uma estrutura muito boa, por\u00e9m considere criar seu proprio sistema de pastas segue um exemplo de template.</p> <pre><code>project_name/\n\u2502\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/               # Dados brutos, originais e n\u00e3o processados\n\u2502   \u251c\u2500\u2500 processed/         # Dados processados e prontos para uso\n\u2502   \u251c\u2500\u2500 external/          # Dados de fontes externas\n\u2502   \u2514\u2500\u2500 interim/           # Dados intermedi\u00e1rios durante o processamento\n\u2502\n\u251c\u2500\u2500 notebooks/\n\u2502   \u251c\u2500\u2500 exploration/       # Notebooks de explora\u00e7\u00e3o inicial dos dados\n|   |-- preprocessing\n\u2502   \u251c\u2500\u2500 modeling/          # Notebooks de experimenta\u00e7\u00e3o e modelagem\n\u2502   \u2514\u2500\u2500 reporting/         # Notebooks usados para gerar relat\u00f3rios\n\u2502\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 data/              # Scripts para carregar, limpar e processar dados\n\u2502   \u251c\u2500\u2500 features/          # Scripts para gerar e selecionar features\n\u2502   \u251c\u2500\u2500 models/            # Scripts para treinar e avaliar modelos\n\u2502   \u251c\u2500\u2500 visualization/     # Scripts para criar visualiza\u00e7\u00f5es dos dados e resultados\n\u2502   \u2514\u2500\u2500 utils/             # Scripts utilit\u00e1rios e fun\u00e7\u00f5es auxiliares\n\u2502\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 saved/             # Modelos treinados salvos\n\u2502   \u251c\u2500\u2500 checkpoints/       # Checkpoints de treinamento de modelos\n\u2502   \u2514\u2500\u2500 logs/              # Logs de treinamento e valida\u00e7\u00e3o de modelos\n\u2502\n\u251c\u2500\u2500 output/\n\u2502   \u251c\u2500\u2500 figures/           # Gr\u00e1ficos e visualiza\u00e7\u00f5es geradas\n\u2502   \u251c\u2500\u2500 reports/           # Relat\u00f3rios gerados, como PDF, HTML, etc.\n\u2502   \u2514\u2500\u2500 predictions/       # Previs\u00f5es geradas pelos modelos\n\u2502\n\u251c\u2500\u2500 tests/                 # Scripts de testes para o c\u00f3digo\n\u2502\n\u251c\u2500\u2500 requirements.txt       # Lista de depend\u00eancias de pacotes\n\u251c\u2500\u2500 environment.yml        # Configura\u00e7\u00e3o de ambiente Conda (alternativa ao requirements.txt)\n\u251c\u2500\u2500 setup.py               # Script de configura\u00e7\u00e3o do projeto\n\u251c\u2500\u2500 README.md              # Documenta\u00e7\u00e3o inicial do projeto\n\u2514\u2500\u2500 .gitignore             # Arquivos e diret\u00f3rios a serem ignorados pelo Git\n</code></pre>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#51-descricao-dos-diretorios","title":"5.1. Descri\u00e7\u00e3o dos Diret\u00f3rios","text":"<ul> <li> <p>data/: Armazena todos os dados do projeto.</p> </li> <li> <p>notebooks/: Cont\u00e9m notebooks Jupyter organizados por prop\u00f3sito.</p> </li> <li> <p>src/: Scripts e c\u00f3digos fonte organizados por funcionalidade.</p> </li> <li> <p>models/: Diret\u00f3rio para salvar modelos treinados e logs de treinamento.</p> </li> <li> <p>output/: Diret\u00f3rio para armazenar sa\u00eddas do projeto.</p> </li> </ul>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#6-criando-sua-propria-estrutura-de-projetos-com-cookiecutter","title":"6. Criando Sua Pr\u00f3pria Estrutura de Projetos com Cookiecutter","text":""},{"location":"5_Ferramentas/5.5_Cookiecutter/#61-passo-1-instalacao-do-cookiecutter","title":"6.1. Passo 1: Instala\u00e7\u00e3o do Cookiecutter","text":"<p>Antes de tudo, voc\u00ea precisa ter o Cookiecutter instalado. Se ainda n\u00e3o tiver, voc\u00ea pode instal\u00e1-lo usando o pip (gerenciador de pacotes do Python):</p> <pre><code>pip install cookiecutter\n</code></pre>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#62-passo-2-estrutura-basica-do-projeto","title":"6.2. Passo 2: Estrutura B\u00e1sica do Projeto","text":"<p>Comece decidindo a estrutura b\u00e1sica que voc\u00ea deseja para seus projetos. Por exemplo, vamos criar um template b\u00e1sico para um projeto de ci\u00eancia de dados:</p> <pre><code>cookiecutter-template/\n\u251c\u2500\u2500 cookiecutter.json\n\u2514\u2500\u2500 {{cookiecutter.project_slug}}/\n    \u251c\u2500\u2500 data/\n    \u251c\u2500\u2500 models/\n    \u251c\u2500\u2500 notebooks/\n    \u251c\u2500\u2500 src/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u2514\u2500\u2500 main.py\n    \u251c\u2500\u2500 tests/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u2514\u2500\u2500 test_main.py\n    \u251c\u2500\u2500 README.md\n    \u2514\u2500\u2500 requirements.txt\n</code></pre> <ul> <li> <p><code>cookiecutter.json</code>: Este arquivo cont\u00e9m as vari\u00e1veis que ser\u00e3o substitu\u00eddas durante a cria\u00e7\u00e3o do projeto. Por exemplo, <code>project_slug</code> pode ser substitu\u00eddo pelo nome do projeto.</p> </li> <li> <p><code>{{cookiecutter.project_slug}}/</code>: Diret\u00f3rio principal do projeto onde os arquivos e diret\u00f3rios s\u00e3o gerados.</p> </li> </ul>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#63-passo-3-configurando-o-cookiecutterjson","title":"6.3. Passo 3: Configurando o <code>cookiecutter.json</code>","text":"<p>No arquivo <code>cookiecutter.json</code>, voc\u00ea define as vari\u00e1veis que ser\u00e3o usadas no template. Aqui est\u00e1 um exemplo simples:</p> <pre><code>{\n    \"project_name\": \"Meu Projeto\",\n    \"project_slug\": \"{{ cookiecutter.project_name.lower().replace(' ', '_') }}\",\n    \"author_name\": \"Seu Nome\",\n    \"email\": \"seuemail@example.com\",\n    \"description\": \"Descri\u00e7\u00e3o do seu projeto\"\n}\n</code></pre> <ul> <li><code>project_name:</code> Nome do projeto.</li> <li><code>project_slug:</code> Nome do projeto em min\u00fasculas e substitui\u00e7\u00e3o de espa\u00e7os por _.</li> <li><code>author_name:</code> Seu nome.</li> <li><code>email:</code> Seu email.</li> <li><code>description:</code>Descri\u00e7\u00e3o do projeto.</li> </ul>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#64-passo-4-criando-o-template","title":"6.4. Passo 4: Criando o Template","text":"<ol> <li> <p>Crie uma pasta para o template: Por exemplo, cookiecutter-template.</p> </li> <li> <p>Dentro da pasta do template, crie um arquivo <code>cookiecutter.json</code> com as vari\u00e1veis desejadas.</p> </li> <li> <p>Estruture os diret\u00f3rios e arquivos: Dentro da pasta do template, crie a estrutura de diret\u00f3rios e arquivos que deseja que seu projeto tenha. Utilize vari\u00e1veis onde necess\u00e1rio, como <code>{{cookiecutter.project_slug}}/</code>.</p> </li> <li> <p>Inclua scripts e arquivos de configura\u00e7\u00e3o: Adicione qualquer script de inicializa\u00e7\u00e3o ou configura\u00e7\u00e3o que seja necess\u00e1rio para seu projeto.</p> </li> </ol>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#65-passo-5-use-o-cookiecutter-para-gerar-o-projeto","title":"6.5. Passo 5: Use o <code>Cookiecutter</code> para gerar o projeto","text":"<p>Execute o comando abaixo, substituindo <code>path/to/cookiecutter-template</code> pelo caminho para o template criado:</p> <p><pre><code>cookiecutter path/to/cookiecutter-template\n</code></pre> Se o template estiver dispon\u00edvel em um reposit\u00f3rio GitHub, voc\u00ea pode usar o comando com a URL:</p> <pre><code>cookiecutter https://github.com/exemplo/cookiecutter-data-science\n</code></pre>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#66-passo-extra-configuracao-pyprojecttoml","title":"6.6. Passo Extra: Configura\u00e7\u00e3o <code>pyproject.toml</code>","text":"<p>Ao usar o <code>Cookiecutter</code> para gerar a estrutura do projeto, voc\u00ea pode configurar o <code>pyproject.toml</code> para incluir as vari\u00e1veis preenchidas automaticamente.</p> <ol> <li>Defina as vari\u00e1veis no <code>cookiecutter.json</code>:</li> </ol> <p><pre><code>{\n    \"project_name\": \"ml-deploy\",\n    \"project_slug\": \"{{ cookiecutter.project_name.lower().replace(' ', '_') }}\",\n    \"author_name\": \"Seu Nome\",\n    \"email\": \"seuemail@example.com\",\n    \"description\": \"Deploy em Produ\u00e7\u00e3o de um Modelo de Machine Learning com Flask e Heroku\"\n}\n</code></pre> 2.Configure o <code>pyproject.toml</code> para usar as vari\u00e1veis:</p> <pre><code>[tool.poetry]\nname = \"{{ cookiecutter.project_slug }}\"\nversion = \"0.1.0\"\ndescription = \"{{ cookiecutter.description }}\"\nauthors = [\"{{ cookiecutter.author_name }} &lt;{{ cookiecutter.email }}&gt;\"]\n\n[tool.poetry.dependencies]\npython = \"^3.8\"\n# Adicione aqui outras depend\u00eancias do seu projeto\n\n[tool.poetry.dev-dependencies]\npytest = \"^6.2\"\n</code></pre> <p>Pronto.</p>"},{"location":"5_Ferramentas/5.5_Cookiecutter/#7-configuracao-do-projeto-com-cookiecutter-data-science-ccds","title":"7. Configura\u00e7\u00e3o do Projeto com Cookiecutter Data Science (ccds)","text":"<p>Durante a configura\u00e7\u00e3o do seu projeto usando o Cookiecutter Data Science (CCDS), voc\u00ea pode seguir os passos abaixo:</p> <ol> <li> <p>Re-download do Template: Se voc\u00ea j\u00e1 baixou o template do Cookiecutter Data Science anteriormente, ele perguntar\u00e1 se deseja deletar e baixar novamente: <pre><code>You've downloaded C:\\Users\\esped.cookiecutters\\cookiecutter-data-science before. Is it okay to delete and re-download it?\n[y/n] (y): y\n</code></pre></p> </li> <li> <p>Nome do Projeto: Defina o nome do seu projeto: <pre><code>project_name (project_name): \n</code></pre></p> </li> <li> <p>Nome do Reposit\u00f3rio: Escolha um nome para o reposit\u00f3rio do projeto: <pre><code>repo_name (meu_primeiro_bagulho):\n</code></pre></p> </li> <li> <p>Nome do M\u00f3dulo: Defina o nome do m\u00f3dulo Python principal do projeto: <pre><code>module_name (meu_primeiro_bagulho):\n</code></pre></p> </li> <li> <p>Nome do Autor: Informe o seu nome ou o nome da sua organiza\u00e7\u00e3o, empresa ou equipe: <pre><code>author_name (Your name (or your organization/company/team)):\n</code></pre></p> </li> <li> <p>Descri\u00e7\u00e3o do Projeto: Forne\u00e7a uma breve descri\u00e7\u00e3o do projeto:</p> </li> </ol> <pre><code>description (A short description of the project.):\n</code></pre> <ol> <li> <p>Vers\u00e3o do Python: Especifique a vers\u00e3o do Python que ser\u00e1 utilizada no projeto (padr\u00e3o \u00e9 3.10): <pre><code>python_version_number (3.10):\n</code></pre></p> </li> <li> <p>Armazenamento de Datasets: Escolha onde os conjuntos de dados ser\u00e3o armazenados:</p> </li> </ol> <pre><code>Select dataset_storage\n1 - none\n2 - azure\n3 - s3\n4 - gcs\nChoose from [1/2/3/4] (1): 1\n</code></pre> <ol> <li> <p>Gerenciador de Ambiente: Selecione o gerenciador de ambiente que voc\u00ea pretende utilizar: <pre><code>Select environment_manager\n    1 - virtualenv\n    2 - conda\n    3 - pipenv\n    4 - none\nChoose from [1/2/3/4] (1): 4\n</code></pre></p> </li> <li> <p>Arquivo de Depend\u00eancias: Escolha o tipo de arquivo de depend\u00eancias que ser\u00e1 utilizado:  <pre><code>Select dependency_file\n    1 - requirements.txt\n    2 - environment.yml\n    3 - Pipfile\n    Choose from [1/2/3] (1): 3\n</code></pre></p> </li> <li> <p>Pacotes PyData: Decida se deseja incluir pacotes PyData padr\u00e3o no projeto:  <pre><code>Select pydata_packages\n    1 - none\n    2 - basic\n    Choose from [1/2] (1): 1\n</code></pre></p> </li> <li> <p>Licen\u00e7a de C\u00f3digo Aberto: Escolha a licen\u00e7a de c\u00f3digo aberto para o seu projeto:  <pre><code>Select open_source_license\n    1 - No license file\n    2 - MIT\n    3 - BSD-3-Clause\n    Choose from [1/2/3] (1):\n</code></pre></p> </li> <li> <p>Documenta\u00e7\u00e3o: Escolha se deseja incluir documenta\u00e7\u00e3o:  <pre><code>Select docs\n    1 - mkdocs\n    2 - none\n    Choose from [1/2] (1):\n</code></pre></p> </li> <li> <p>Incluir Estrutura de C\u00f3digo: Decida se deseja incluir uma estrutura inicial de c\u00f3digo:  <pre><code>Select include_code_scaffold\n    1 - Yes\n    2 - No\n    Choose from [1/2] (1):\n</code></pre></p> </li> </ol> <p>Essas configura\u00e7\u00f5es ajudar\u00e3o a personalizar seu projeto com base nas suas necessidades espec\u00edficas de desenvolvimento e colabora\u00e7\u00e3o. Certifique-se de revisar e ajustar cada op\u00e7\u00e3o conforme necess\u00e1rio para garantir que o projeto seja configurado de acordo com suas prefer\u00eancias e requisitos. Este texto abrange todos os passos do processo de configura\u00e7\u00e3o inicial usando o Cookiecutter Data Science, explicando cada op\u00e7\u00e3o dispon\u00edvel para criar um projeto de ci\u00eancia de dados personalizado de acordo com suas especifica\u00e7\u00f5es.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/","title":"1. Streamlit e suas Principais Fun\u00e7\u00f5es","text":"<p>Streamlit \u00e9 uma biblioteca de c\u00f3digo aberto em Python que permite a cria\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas para visualiza\u00e7\u00e3o de dados e machine learning. \u00c9 projetada para ser f\u00e1cil de usar, permitindo que voc\u00ea transforme scripts de dados em aplica\u00e7\u00f5es web compartilh\u00e1veis com poucas linhas de c\u00f3digo.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#11-instalacao","title":"1.1. Instala\u00e7\u00e3o","text":"<p>Para instalar Streamlit, voc\u00ea pode usar o pip:</p> <pre><code>pip install streamlit\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#12-execucao-de-um-aplicativo-streamlit","title":"1.2. Execu\u00e7\u00e3o de um Aplicativo Streamlit","text":"<p>Para executar um aplicativo Streamlit, salve seu script Python e execute o comando:</p> <pre><code>streamlit run nome_do_seu_script.py\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#13-principais-funcoes-do-streamlit","title":"1.3. Principais Fun\u00e7\u00f5es do Streamlit","text":""},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#131-titulos-e-textos","title":"1.3.1. T\u00edtulos e Textos","text":"<p>Voc\u00ea pode adicionar t\u00edtulos e textos ao seu aplicativo com fun\u00e7\u00f5es simples.</p> <pre><code>import streamlit as st\n\nst.title(\"Meu Aplicativo Streamlit\")\nst.header(\"Se\u00e7\u00e3o de Cabe\u00e7alho\")\nst.subheader(\"Subcabe\u00e7alho\")\nst.text(\"Este \u00e9 um texto simples.\")\nst.markdown(\"Este \u00e9 um texto em **Markdown**.\")\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#132-exibicao-de-dados","title":"1.3.2. Exibi\u00e7\u00e3o de Dados","text":"<p>Streamlit permite a exibi\u00e7\u00e3o f\u00e1cil de dados usando tabelas e dataframes.</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'col1': [1, 2, 3, 4],\n    'col2': [10, 20, 30, 40]\n})\nst.dataframe(df)\nst.table(df)\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#133-graficos","title":"1.3.3. Gr\u00e1ficos","text":"<p>Voc\u00ea pode usar bibliotecas populares como Matplotlib, Plotly e Altair para criar gr\u00e1ficos interativos.</p> <pre><code>import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4], [10, 20, 25, 30])\nst.pyplot(fig)\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#134-widgets-de-entrada","title":"1.3.4. Widgets de Entrada","text":"<p>Streamlit fornece diversos widgets de entrada para intera\u00e7\u00e3o com o usu\u00e1rio.</p> <pre><code>name = st.text_input(\"Digite seu nome\")\nage = st.number_input(\"Digite sua idade\", min_value=0, max_value=100)\nagree = st.checkbox(\"Eu concordo\")\ncolor = st.selectbox(\"Escolha uma cor\", [\"Azul\", \"Vermelho\", \"Verde\"])\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#135-controle-de-layout","title":"1.3.5. Controle de Layout","text":"<p>Voc\u00ea pode controlar o layout da sua aplica\u00e7\u00e3o usando colunas, containers e expandidos.</p> <pre><code>col1, col2 = st.columns(2)\ncol1.write(\"Esta \u00e9 a coluna 1\")\ncol2.write(\"Esta \u00e9 a coluna 2\")\n\nwith st.expander(\"Mais informa\u00e7\u00f5es\"):\n    st.write(\"Aqui est\u00e3o mais detalhes.\")\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#136-carregamento-de-arquivos","title":"1.3.6. Carregamento de Arquivos","text":"<p>Streamlit facilita o carregamento de arquivos, permitindo que os usu\u00e1rios fa\u00e7am upload de dados para a aplica\u00e7\u00e3o.</p> <pre><code>uploaded_file = st.file_uploader(\"Escolha um arquivo\")\nif uploaded_file is not None:\n    data = pd.read_csv(uploaded_file)\n    st.write(data)\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#137-controle-de-execucao","title":"1.3.7. Controle de Execu\u00e7\u00e3o","text":"<p>Voc\u00ea pode usar bot\u00f5es para controlar a execu\u00e7\u00e3o de partes do c\u00f3digo.</p> <pre><code>if st.button(\"Clique aqui\"):\n    st.write(\"Bot\u00e3o clicado!\")\n</code></pre>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#14-conclusao","title":"1.4. Conclus\u00e3o","text":"<p>Streamlit \u00e9 uma ferramenta poderosa para criar aplica\u00e7\u00f5es web interativas com Python, facilitando a visualiza\u00e7\u00e3o de dados e a constru\u00e7\u00e3o de dashboards. Com suas fun\u00e7\u00f5es intuitivas e de f\u00e1cil uso, voc\u00ea pode rapidamente transformar an\u00e1lises de dados em aplicativos web compartilh\u00e1veis.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#2-dashboard-com-python","title":"2. Dashboard com python","text":"<p>As bibliotecas <code>plotly</code>, <code>plotly.figure_factory</code>, <code>plotly.express</code> e <code>dash</code> s\u00e3o todas partes do ecossistema Plotly para cria\u00e7\u00e3o de gr\u00e1ficos e dashboards interativos em Python, mas cada uma tem um prop\u00f3sito espec\u00edfico. Vamos ver as diferen\u00e7as entre elas:</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#21-plotly","title":"2.1. Plotly","text":"<p><code>plotly</code> \u00e9 a biblioteca principal, que fornece a base para a cria\u00e7\u00e3o de gr\u00e1ficos interativos em Python. Dentro do <code>plotly</code>, voc\u00ea tem v\u00e1rios subm\u00f3dulos, como <code>plotly.graph_objects</code> (tamb\u00e9m conhecido como <code>go</code>), que oferece uma API de baixo n\u00edvel para a constru\u00e7\u00e3o de gr\u00e1ficos complexos e altamente personaliz\u00e1veis.</p> <p>Caracter\u00edsticas: - Flex\u00edvel e altamente configur\u00e1vel. - Permite a constru\u00e7\u00e3o detalhada e personalizada de gr\u00e1ficos. - Inclui suporte para uma ampla gama de tipos de gr\u00e1ficos, como gr\u00e1ficos de linha, barra, dispers\u00e3o, mapas, 3D, etc.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#22-plotlyfigure_factory","title":"2.2. Plotly.figure_factory","text":"<p><code>plotly.figure_factory</code> \u00e9 um subm\u00f3dulo do <code>plotly</code> que fornece fun\u00e7\u00f5es de alto n\u00edvel para a cria\u00e7\u00e3o de gr\u00e1ficos complexos que podem ser dif\u00edceis de criar manualmente com <code>plotly.graph_objects</code>.</p> <p>Caracter\u00edsticas: - Cont\u00e9m fun\u00e7\u00f5es de conveni\u00eancia para a cria\u00e7\u00e3o de gr\u00e1ficos especializados, como dendrogramas, mapas de calor com anota\u00e7\u00f5es, gr\u00e1ficos de violino, etc. - Facilita a cria\u00e7\u00e3o de gr\u00e1ficos complexos sem necessidade de detalhamento excessivo.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#23-plotlyexpress","title":"2.3. Plotly.express","text":"<p><code>plotly.express</code> \u00e9 um m\u00f3dulo de alto n\u00edvel para a cria\u00e7\u00e3o r\u00e1pida e f\u00e1cil de gr\u00e1ficos em Plotly. Ele \u00e9 projetado para ser intuitivo e eficiente, oferecendo uma interface simplificada em compara\u00e7\u00e3o com <code>plotly.graph_objects</code>.</p> <p>Caracter\u00edsticas: - Simplicidade e rapidez na cria\u00e7\u00e3o de gr\u00e1ficos. - Recomendado para a cria\u00e7\u00e3o de gr\u00e1ficos padronizados e menos complexos. - As fun\u00e7\u00f5es de <code>plotly.express</code> geralmente requerem menos c\u00f3digo e s\u00e3o mais f\u00e1ceis de usar, especialmente para explora\u00e7\u00e3o e an\u00e1lise de dados.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#24-dash","title":"2.4. Dash","text":"<p><code>dash</code> \u00e9 um framework de aplica\u00e7\u00e3o web que permite a constru\u00e7\u00e3o de dashboards interativos utilizando componentes de Plotly para visualiza\u00e7\u00f5es. Ele \u00e9 ideal para criar aplica\u00e7\u00f5es anal\u00edticas com interatividade complexa, integrando gr\u00e1ficos, tabelas, controles de entrada e muito mais.</p> <p>Caracter\u00edsticas: - Permite a constru\u00e7\u00e3o de aplica\u00e7\u00f5es web interativas com visualiza\u00e7\u00f5es de dados. - Utiliza Plotly para gr\u00e1ficos, mas tamb\u00e9m integra componentes HTML e controles de interface de usu\u00e1rio (UI) como dropdowns, sliders, etc. - Baseado em Flask, React e Plotly.js, proporcionando flexibilidade e desempenho.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#25-resumo-das-diferencas","title":"2.5. Resumo das Diferen\u00e7as","text":"<ul> <li>plotly: Biblioteca principal com subm\u00f3dulos para gr\u00e1ficos interativos detalhados e configur\u00e1veis.</li> <li>plotly.figure_factory: Subm\u00f3dulo de <code>plotly</code> com fun\u00e7\u00f5es convenientes para gr\u00e1ficos especializados.</li> <li>plotly.express: Interface de alto n\u00edvel para cria\u00e7\u00e3o r\u00e1pida e f\u00e1cil de gr\u00e1ficos comuns.</li> <li>dash: Framework completo para constru\u00e7\u00e3o de dashboards interativos baseados na web.</li> </ul> <p>Cada uma dessas bibliotecas e m\u00f3dulos serve a diferentes prop\u00f3sitos dentro do ecossistema de visualiza\u00e7\u00e3o de dados em Python, permitindo desde a cria\u00e7\u00e3o r\u00e1pida de gr\u00e1ficos simples at\u00e9 a constru\u00e7\u00e3o de complexos dashboards interativos.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#3-plotly-no-ambiente-do-streamlit","title":"3. Plotly no ambiente do Streamlit","text":"<p>No ambiente do Streamlit, voc\u00ea pode utilizar v\u00e1rias bibliotecas para criar gr\u00e1ficos e dashboards interativos. Aqui est\u00e3o as que s\u00e3o mais relevantes:</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#31-plotly","title":"3.1. Plotly","text":"<p>Voc\u00ea pode usar <code>plotly</code> no Streamlit para criar gr\u00e1ficos interativos. Streamlit tem suporte nativo para Plotly, permitindo que voc\u00ea integre gr\u00e1ficos facilmente em suas aplica\u00e7\u00f5es.</p> <p>Como usar: <pre><code>import streamlit as st\nimport plotly.graph_objects as go\n\nfig = go.Figure(data=go.Bar(y=[2, 3, 1]))\nst.plotly_chart(fig)\n</code></pre></p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#32-plotlyfigure_factory","title":"3.2. Plotly.figure_factory","text":"<p>Como <code>plotly.figure_factory</code> \u00e9 um subm\u00f3dulo do <code>plotly</code>, voc\u00ea tamb\u00e9m pode usar suas fun\u00e7\u00f5es para criar gr\u00e1ficos complexos e integr\u00e1-los no Streamlit.</p> <p>Como usar: <pre><code>import streamlit as st\nimport plotly.figure_factory as ff\n\ndata_matrix = [[0.1, 0.2, 0.5], [0.3, 0.8, 0.6]]\nfig = ff.create_annotated_heatmap(data_matrix)\nst.plotly_chart(fig)\n</code></pre></p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#33-plotlyexpress","title":"3.3. Plotly.express","text":"<p><code>plotly.express</code> \u00e9 altamente recomendada para uso com Streamlit devido \u00e0 sua simplicidade e facilidade de uso. Voc\u00ea pode criar rapidamente gr\u00e1ficos comuns e integr\u00e1-los em suas aplica\u00e7\u00f5es Streamlit.</p> <p>Como usar: <pre><code>import streamlit as st\nimport plotly.express as px\n\ndf = px.data.iris()\nfig = px.scatter(df, x='sepal_width', y='sepal_length')\nst.plotly_chart(fig)\n</code></pre></p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#34-dash","title":"3.4. Dash","text":"<p><code>dash</code> n\u00e3o pode ser diretamente usado dentro de uma aplica\u00e7\u00e3o Streamlit, pois \u00e9 um framework web independente para constru\u00e7\u00e3o de dashboards interativos. No entanto, voc\u00ea pode desenvolver uma aplica\u00e7\u00e3o Dash separadamente e depois integr\u00e1-la com um servi\u00e7o web que pode ser acessado a partir de uma aplica\u00e7\u00e3o Streamlit, se necess\u00e1rio.</p>"},{"location":"5_Ferramentas/5.6_Streamlit_Dashboard/#35-resumo","title":"3.5. Resumo","text":"<ul> <li>plotly: Pode ser usado diretamente no Streamlit para criar gr\u00e1ficos interativos.</li> <li>plotly.figure_factory: Pode ser usado no Streamlit como parte do <code>plotly</code> para gr\u00e1ficos especializados.</li> <li>plotly.express: Altamente recomendado para uso no Streamlit devido \u00e0 sua simplicidade e efici\u00eancia.</li> <li>dash: N\u00e3o pode ser usado diretamente no Streamlit, mas pode ser usado para construir dashboards interativos de forma independente.</li> </ul> <p>Essas bibliotecas oferecem uma ampla gama de funcionalidades para visualiza\u00e7\u00e3o de dados e interatividade no ambiente do Streamlit, permitindo a cria\u00e7\u00e3o de aplica\u00e7\u00f5es ricas e interativas.</p>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/","title":"1. Principais Ferramentas para Projetos","text":""},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#11-meus-desenvolvimentos","title":"1.1. Meus Desenvolvimentos","text":"<p>Abrindo um novo projeto passo a passo:</p> <ol> <li>Criar a estrutura de pastas usando o Cookiecutter</li> </ol> <p>A Ferramenta Cookiecutter permite criar uma estrutura de pastas especifica de acordo com template especificado.</p> <p>No meu caso utilizado o data-science-template-espedito, modificado apartir do data-science-template.</p> <p>Ap\u00f3s a instala\u00e7ao do Cookiecutter, basta usar o comando:</p> <pre><code>cookiecutter https://github.com/espeditoalves/data-science-template\n</code></pre> <p>Ap\u00f3s executar esse comando ser\u00e1 feito o download do template para uma pasta raiz do cookiecutter, e em seguida  ser\u00e1 criada sua pasta com os diret\u00f3rios definidos no template</p> <p>Para ter mais detalhes de como configurar e utilizar a ferramenta acesse o relat\u00f3rio Estrutura de pastas com cookiecutter</p>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#12-minha-estrutura-de-organizacao","title":"1.2. Minha estrutura de organiza\u00e7\u00e3o","text":"<pre><code>.\n\u251c\u2500\u2500 config                      \n\u2502   \u251c\u2500\u2500 main.yaml                   # Main configuration file\n\u2502   \u251c\u2500\u2500 model                       # Configurations for training model\n\u2502   \u2502   \u251c\u2500\u2500 model1.yaml             # First variation of parameters to train model\n\u2502   \u2502   \u2514\u2500\u2500 model2.yaml             # Second variation of parameters to train model\n\u2502   \u2514\u2500\u2500 process                     # Configurations for processing data\n\u2502       \u251c\u2500\u2500 process1.yaml           # First variation of parameters to process data\n\u2502       \u2514\u2500\u2500 process2.yaml           # Second variation of parameters to process data\n\u251c\u2500\u2500 data            \n\u2502   \u251c\u2500\u2500 final                       # data after training the model\n\u2502   \u251c\u2500\u2500 processed                   # data after processing\n\u2502   \u2514\u2500\u2500 raw                         # raw data\n\u251c\u2500\u2500 docs                            # documentation for your project\n\u251c\u2500\u2500 .gitignore                      # ignore files that cannot commit to Git\n\u251c\u2500\u2500 Makefile                        # store useful commands to set up the environment\n\u251c\u2500\u2500 models                          # store models\n\u251c\u2500\u2500 notebooks                       # store notebooks\n\u2502   \u251c\u2500\u2500 exploration\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u251c\u2500\u2500 modeling\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u251c\u2500\u2500 preprocessing\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u2514\u2500\u2500 reporting\n\u2502       \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 output                          # store outputs\n\u2502   \u251c\u2500\u2500 figures\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u251c\u2500\u2500 predictions\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u2514\u2500\u2500 reports\n\u2502       \u2514\u2500\u2500 .gitkeep\n{% if cookiecutter.dependency_manager == \"pip\" -%}\n\u251c\u2500\u2500 pyproject.toml                  # Configure black\n{% elif cookiecutter.dependency_manager == \"poetry\" -%}\n\u251c\u2500\u2500 .pre-commit-config.yaml         # configurations for pre-commit\n\u251c\u2500\u2500 pyproject.toml                  # dependencies for poetry\n{%- endif %}\n\u251c\u2500\u2500 README.md                       # describe your project\n\u251c\u2500\u2500 src                             # store source code\n\u2502   \u251c\u2500\u2500 __init__.py                 # make src a Python module \n\u2502   \u251c\u2500\u2500 process.py                  # process data before training model\n\u2502   \u251c\u2500\u2500 train_model.py              # train model\n\u2502   \u2514\u2500\u2500 utils.py                    # store helper functions\n\u2514\u2500\u2500 tests                           # store tests\n    \u251c\u2500\u2500 __init__.py                 # make tests a Python module \n    \u251c\u2500\u2500 test_process.py             # test functions for process.py\n    \u2514\u2500\u2500 test_train_model.py         # test functions for train_model.py\n</code></pre>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#13-cookiecutter-data-science","title":"1.3. Cookiecutter Data Science","text":"<ul> <li>Template popular para estruturar projetos de ci\u00eancia de dados de forma organizada e reprodut\u00edvel.</li> <li>Cookiecutter Data Science</li> <li>cookiecutter docs</li> <li>Estrutura de projeto: Khuyen Tran</li> </ul>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#14-poetry","title":"1.4. Poetry","text":"<p>O <code>poetry</code> \u00e9 uma ferramenta de gerenciamento de depend\u00eancias e ambientes virtuais para projetos em Python. Ele simplifica o processo de cria\u00e7\u00e3o, constru\u00e7\u00e3o e publica\u00e7\u00e3o de projetos Python, proporcionando uma forma mais eficiente e organizada de gerenciar bibliotecas e depend\u00eancias.</p>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#141-principais-funcionalidades-do-poetry","title":"1.4.1. Principais Funcionalidades do <code>poetry</code>","text":"<ol> <li> <p>Gerenciamento de Depend\u00eancias:    O <code>poetry</code> permite definir e resolver as depend\u00eancias do seu projeto de maneira precisa. Ele cria um arquivo <code>pyproject.toml</code> onde todas as depend\u00eancias e configura\u00e7\u00f5es do projeto s\u00e3o listadas, e um arquivo <code>poetry.lock</code> que garante que todos os desenvolvedores do projeto utilizem as mesmas vers\u00f5es das depend\u00eancias.</p> </li> <li> <p>Ambientes Virtuais:    O <code>poetry</code> cria e gerencia automaticamente ambientes virtuais, isolando as depend\u00eancias do projeto do restante do sistema. Isso garante que as bibliotecas e vers\u00f5es usadas em um projeto n\u00e3o interfiram em outros projetos ou no sistema operacional.</p> </li> <li> <p>Publica\u00e7\u00e3o de Pacotes:    Com o <code>poetry</code>, \u00e9 f\u00e1cil publicar pacotes Python no PyPI (Python Package Index). Ele fornece comandos simples para empacotar e distribuir seus projetos.</p> </li> <li> <p>Scripts e Configura\u00e7\u00f5es:    O <code>poetry</code> permite definir scripts de execu\u00e7\u00e3o, configura\u00e7\u00f5es de projeto e metadados diretamente no arquivo <code>pyproject.toml</code>, tornando o processo de configura\u00e7\u00e3o mais simples e centralizado.</p> </li> </ol>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#142-vantagens-do-poetry","title":"1.4.2. Vantagens do <code>poetry</code>","text":"<ul> <li>Simplicidade e Conveni\u00eancia: O <code>poetry</code> combina v\u00e1rias funcionalidades em uma \u00fanica ferramenta, reduzindo a necessidade de m\u00faltiplos utilit\u00e1rios.</li> <li>Consist\u00eancia: Ao usar arquivos de bloqueio (<code>lock</code>), o <code>poetry</code> garante que todos os desenvolvedores de um projeto utilizem exatamente as mesmas vers\u00f5es de bibliotecas, eliminando problemas de incompatibilidade.</li> <li>Isolamento: Ambientes virtuais autom\u00e1ticos garantem que as depend\u00eancias do projeto n\u00e3o afetem o sistema global ou outros projetos.</li> </ul>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#143-exemplo-basico-de-uso","title":"1.4.3. Exemplo B\u00e1sico de Uso","text":"<ol> <li>Iniciar um Novo Projeto: <pre><code>poetry new meu_projeto\ncd meu_projeto\n</code></pre></li> </ol>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#15-como-executar-verificacoes-de-estilo-de-codigo-com-blue","title":"1.5. Como executar verifica\u00e7\u00f5es de estilo de c\u00f3digo com Blue:","text":"<p>O Blue \u00e9 uma ferramenta de formata\u00e7\u00e3o de c\u00f3digo que ajuda a manter a consist\u00eancia do estilo do seu c\u00f3digo Python. Para executar o Blue e verificar as diferen\u00e7as sem aplicar as mudan\u00e7as, use o comando:</p> <pre><code>poetry run blue --check --diff &lt;nome_script.py&gt;\n</code></pre>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#16-extensions-for-vscode","title":"1.6. Extensions for vscode","text":"<ul> <li>autoDocstring</li> <li>Bracket Pair Colorization Toggler</li> <li>vscode-icons</li> <li>Materal Icon Thema</li> <li>markdownlint</li> <li>markdown All in One</li> <li>Markdown Preview Enhanced</li> <li>vscode-pets</li> <li>Rainbow CSV</li> </ul>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#17-dependencies-dev-group","title":"1.7. Dependencies dev-Group","text":"<ol> <li>Blue </li> <li>isort</li> </ol>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#18-mkdocs","title":"1.8. MkDocs","text":"<ul> <li>Criar os arquivos: <code>poetry add --group dev mkdocs</code></li> <li>Iniciar o MkDocs: <code>mkdocs new .</code></li> <li>Servir o site: <code>mkdocs serve</code></li> </ul>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#19-git","title":"1.9. Git","text":"<ul> <li><code>git commit --amend -m \"Novo texto do commit\"</code>: Alterar MENSAGEM Do \u00faltimo commit</li> <li><code>git remote -v</code>:  listar os remotes atuais</li> <li><code>git remote set-url origin &lt;nova_url_do_reposit\u00f3rio&gt;</code>: Muda a URL do remote</li> </ul>"},{"location":"5_Ferramentas/5.7_Minha_Estrutura/#110-markdown-preview-enhanced","title":"1.10. Markdown Preview Enhanced","text":"<ul> <li><code>Ctrl + Shift + v</code>: Visualiza\u00e7\u00e3o previa do arquivo markdown</li> </ul>"},{"location":"5_Ferramentas/5.8_Terminal/","title":"1. Entendendo e Configura\u00e7\u00f5es Terminais","text":""},{"location":"5_Ferramentas/5.8_Terminal/#11-terminal-power-shell","title":"1.1. Terminal Power Shell","text":"<p>O arquivo <code>PowerShell_profile.ps1</code> \u00e9 um script de inicializa\u00e7\u00e3o que \u00e9 executado automaticamente sempre que voc\u00ea inicia uma nova sess\u00e3o do PowerShell. Nele, voc\u00ea pode configurar diversas coisas para personalizar e otimizar seu ambiente de trabalho. </p>"},{"location":"5_Ferramentas/5.8_Terminal/#111-configuracoes-powershell_profileps1","title":"1.1.1. Configura\u00e7\u00f5es: <code>PowerShell_profile.ps1</code>","text":"<p>Aqui est\u00e3o algumas das principais coisas que voc\u00ea pode configurar no seu perfil PowerShell:</p>"},{"location":"5_Ferramentas/5.8_Terminal/#112-aliases","title":"1.1.2. Aliases","text":"<p>Voc\u00ea pode criar aliases para comandos que voc\u00ea usa frequentemente para torn\u00e1-los mais curtos e f\u00e1ceis de digitar. <pre><code># Alias para navegar at\u00e9 um diret\u00f3rio espec\u00edfico\nSet-Alias gotoRepos 'cd C:\\Users\\SeuUsuario\\Reposit\u00f3rios'\n\n# Alias para um comando longo\nSet-Alias gs 'git status'\n</code></pre></p>"},{"location":"5_Ferramentas/5.8_Terminal/#113-funcoes","title":"1.1.3. Fun\u00e7\u00f5es","text":""},{"location":"5_Ferramentas/5.8_Terminal/#114-importar-modulos","title":"1.1.4. Importar M\u00f3dulos","text":""},{"location":"5_Ferramentas/5.8_Terminal/#115-variaveis-personalizadas","title":"1.1.5. Vari\u00e1veis Personalizadas","text":""},{"location":"5_Ferramentas/5.8_Terminal/#116-configuracoes-de-prompt","title":"1.1.6. Configura\u00e7\u00f5es de Prompt","text":"<p>Personalize o prompt do PowerShell para exibir informa\u00e7\u00f5es \u00fateis. <pre><code>function Prompt {\n    $user = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name\n    $hostname = [System.Net.Dns]::GetHostName()\n    \"$user@$hostname $(Get-Location) &gt; \"\n}\n</code></pre></p>"},{"location":"5_Ferramentas/5.8_Terminal/#117-customizacao-de-aparencia","title":"1.1.7. Customiza\u00e7\u00e3o de Apar\u00eancia","text":"<p>Voc\u00ea pode usar m\u00f3dulos como PSReadline para personalizar a apar\u00eancia e o comportamento do seu prompt.</p> <pre><code># Customizando cores do PSReadline\nSet-PSReadlineOption -EditMode Emacs\nSet-PSReadlineOption -HistorySearchCursorMovesToEnd\n\n# Customizando as cores do prompt\n$host.UI.RawUI.ForegroundColor = 'Yellow'\n$host.UI.RawUI.BackgroundColor = 'Black'\n</code></pre>"},{"location":"5_Ferramentas/5.8_Terminal/#118-cmdlets-de-inicializacao","title":"1.1.8. Cmdlets de Inicializa\u00e7\u00e3o","text":"<p>Execute comandos ou scripts espec\u00edficos sempre que uma nova sess\u00e3o do PowerShell for iniciada.</p> <pre><code># Verificar atualiza\u00e7\u00f5es para um script ou ferramenta\n.\\Check-For-Updates.ps1\n\n# Mostrar uma mensagem de boas-vindas\nWrite-Host \"Welcome to your custom PowerShell environment!\" -ForegroundColor Green\n</code></pre>"},{"location":"5_Ferramentas/5.8_Terminal/#119-funcoes-e-cmdlets-de-terceiros","title":"1.1.9. Fun\u00e7\u00f5es e Cmdlets de Terceiros","text":"<p>Voc\u00ea pode adicionar fun\u00e7\u00f5es ou cmdlets \u00fateis de outros scripts ou bibliotecas.</p> <pre><code># Adicionando suporte a posh-git para integra\u00e7\u00e3o com Git\nif (Test-Path (Join-Path $PROFILE \"..\\..\\Modules\\posh-git\\posh-git.psd1\")) {\n    Import-Module posh-git\n}\n\n# Adicionando suporte a oh-my-posh para customiza\u00e7\u00e3o avan\u00e7ada do prompt\nif (Test-Path (Join-Path $PROFILE \"..\\..\\Modules\\oh-my-posh\\oh-my-posh.psd1\")) {\n    Import-Module oh-my-posh\n    Set-Theme Paradox\n}\n</code></pre>"},{"location":"5_Ferramentas/5.8_Terminal/#1110-trabalhando-com-credenciais-e-senhas","title":"1.1.10. Trabalhando com Credenciais e Senhas","text":"<p>Voc\u00ea pode armazenar e gerenciar credenciais de maneira segura.</p> <pre><code># Salvar uma credencial em um arquivo seguro\n$cred = Get-Credential\n$cred | Export-Clixml -Path \"$env:USERPROFILE\\mycredential.xml\"\n\n# Importar uma credencial de um arquivo seguro\n$cred = Import-Clixml -Path \"$env:USERPROFILE\\mycredential.xml\"\n</code></pre> <p>Exibir Pasta Atual : <code>PowerShell_profile.ps1</code></p> <p>No terminal shell use o comando <code>notepad $profile</code>. Quando abrir o arquivo <code>notepad</code>, cole e salve o c\u00f3digo abaixo no caminho e nome <code>C:\\Users\\esped\\Documents\\WindowsPowerShell\\PowerShell_profile.ps1</code>.</p> <pre><code>function prompt {\n    $path = (Get-Location).Path\n    $folderName = $path.Split('\\')[-1]\n    $prompt = \"$folderName&gt; \"\n    Write-Host -NoNewLine -ForegroundColor Cyan $prompt\n    return \" \"\n}\n</code></pre> <p>Descri\u00e7\u00e3o das fun\u00e7\u00f5es acima <pre><code>function prompt {\n    # Obt\u00e9m o caminho completo do diret\u00f3rio atual\n    $path = (Get-Location).Path\n\n    # Divide o caminho usando '\\' como delimitador e obt\u00e9m o \u00faltimo segmento\n    $folderName = $path.Split('\\')[-1]\n\n    # Define o prompt para exibir apenas o nome da pasta atual seguido por '&gt;'\n    $prompt = \"$folderName&gt; \"\n\n    # Escreve o prompt no terminal sem quebrar a linha, e com a cor ciano\n    Write-Host -NoNewLine -ForegroundColor Cyan $prompt\n\n    # Retorna um espa\u00e7o em branco para que o cursor fique ap\u00f3s o prompt personalizado\n    return \" \"\n}\n</code></pre></p>"},{"location":"5_Ferramentas/5.8_Terminal/#1111-conda-no-power-shell","title":"1.1.11. Conda no Power Shell","text":"<p>Adicionar o Anaconda ao <code>PATH</code>:</p> <p>Durante a instala\u00e7\u00e3o do Anaconda, voc\u00ea geralmente tem a op\u00e7\u00e3o de adicionar o Anaconda ao PATH do sistema. Isso permite que o PowerShell (ou qualquer outro terminal) reconhe\u00e7a os comandos do conda sem a necessidade de especificar o caminho completo para o execut\u00e1vel.</p> <p>Se o Anaconda n\u00e3o foi adicionado ao PATH durante a instala\u00e7\u00e3o, voc\u00ea pode fazer isso manualmente seguindo estas etapas:</p> <p>Abra o PowerShell como <code>administrador</code>.</p> <p>Execute o seguinte comando para adicionar o diret\u00f3rio Scripts do Anaconda ao PATH do usu\u00e1rio atual:</p> <pre><code>[Environment]::SetEnvironmentVariable(\"PATH\", \"$env:PATH;C:\\Users\\SeuUsuario\\anaconda3\\Scripts\", \"User\")\n</code></pre> <p>Substitua C:\\Users\\SeuUsuario\\anaconda3\\Scripts pelo caminho onde o Anaconda est\u00e1 instalado no seu sistema.</p> <p>Substitua <code>SeuUsuario</code> por seu <code>usuario</code></p>"},{"location":"5_Ferramentas/5.8_Terminal/#12-terminal-bash","title":"1.2. Terminal bash","text":""},{"location":"5_Ferramentas/5.8_Terminal/#13-minha-configuracao-padrao","title":"1.3. Minha configura\u00e7\u00e3o padrao","text":"<p>Passo a Passo</p>"},{"location":"5_Ferramentas/5.8_Terminal/#131-configurar-o-path-do-conda-para-o-power-shell","title":"1.3.1. Configurar o <code>PATH</code> do Conda para o Power shell","text":"<p>Seguir os passos do item 10. Conda no Power Shell</p>"},{"location":"5_Ferramentas/5.8_Terminal/#132-abrir-o-powershell","title":"1.3.2. Abrir o PowerShell:","text":"<p>Inicie o PowerShell ou PowerShell ISE ou Power shell do vscode. Verificar o Caminho do Arquivo de Perfil:</p> <p>Use o seguinte comando para verificar o caminho do seu arquivo de perfil: <pre><code>echo $PROFILE\n</code></pre></p>"},{"location":"5_Ferramentas/5.8_Terminal/#133-editar-o-arquivo-de-perfil","title":"1.3.3. Editar o Arquivo de Perfil:","text":"<p>Abra o arquivo de perfil no editor de sua prefer\u00eancia (por exemplo, Notepad): <pre><code>notepad $PROFILE\n</code></pre></p>"},{"location":"5_Ferramentas/5.8_Terminal/#134-digite-o-seguinte-comando-e-salve-e-reinicie-o-terminal","title":"1.3.4. Digite o seguinte comando e salve e reinicie o terminal","text":"<pre><code># Fun\u00e7\u00e3o personalizada para exibir o prompt do PowerShell\nfunction prompt {\n    # Obt\u00e9m o caminho completo do diret\u00f3rio atual\n    $path = (Get-Location).Path\n\n    # Divide o caminho usando '\\' como delimitador e obt\u00e9m o \u00faltimo segmento\n    $folderName = $path.Split('\\')[-1]\n\n    # Define o prompt padr\u00e3o para exibir apenas o nome da pasta atual seguido por '&gt;'\n    $prompt = \"$folderName&gt; \"\n\n    # Verifica se um ambiente Conda est\u00e1 ativo\n    $condaEnv = $env:CONDA_DEFAULT_ENV\n    if ($condaEnv) {\n        # Se um ambiente Conda estiver ativo, modifica o prompt para indicar isso\n        $prompt = \"($condaEnv) $prompt\"\n    }\n\n    # Escreve o prompt no terminal sem quebrar a linha, e com a cor ciano\n    Write-Host -NoNewLine -ForegroundColor Cyan $prompt\n\n    # Retorna um espa\u00e7o em branco para que o cursor fique ap\u00f3s o prompt personalizado\n    return \" \"\n}\n\n# Mostrar uma mensagem de boas-vindas\nWrite-Host \"Welcome to your custom PowerShell environment!\" -ForegroundColor Green\n\n# Customiza\u00e7\u00e3o das cores do terminal\n# $host.UI.RawUI.ForegroundColor = 'Yellow'  # Define a cor do texto do terminal como amarelo\n# $host.UI.RawUI.BackgroundColor = 'Black'   # Define a cor de fundo do terminal como preto\n\n# Outras configura\u00e7\u00f5es e comandos podem ser adicionados abaixo\n</code></pre>"},{"location":"5_Ferramentas/5.8_Terminal/#14-seetingjson-padrao-vscode","title":"1.4. Seeting.json padr\u00e3o vscode","text":"<pre><code>{\n    \"workbench.colorTheme\": \"Dracula\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n\n    \"terminal.integrated.defaultProfile.windows\": \"PowerShell\",\n    \"terminal.integrated.profiles.windows\": {\n        \"PowerShell\": {\n            \"source\": \"PowerShell\",\n            \"icon\": \"terminal-powershell\"\n        },\n        \"Anaconda PowerShell Prompt\": {\n            \"path\": \"C:\\\\Users\\\\esped\\\\anaconda3\\\\Scripts\\\\conda.exe\",\n            \"args\": [],\n            \"icon\": \"terminal-powershell\"\n        }\n    },\n    \"editor.fontFamily\": \"'Cascadia Code', Consolas, 'Courier New', monospace\",\n    \"editor.fontLigatures\": true,\n    \"editor.fontSize\": 14,\n    \"powershell.integratedConsole.focusConsoleOnExecute\": false,\n    \"powershell.integratedConsole.showOnStartup\": true\n}\n</code></pre>"},{"location":"5_Ferramentas/5.8_Terminal/#2-lista-de-principais-comandos","title":"2. Lista de Principais comandos","text":"<p>tree <pre><code>tree /F\n</code></pre> O par\u00e2metro <code>/F</code> faz com que o <code>tree</code> liste todos os arquivos al\u00e9m dos diret\u00f3rios.</p>"},{"location":"5_Ferramentas/5.9_mkdocs/","title":"1. Configura\u00e7\u00e3o","text":"<p>Aqui est\u00e3o algumas dicas para configurar o MkDocs.</p>"},{"location":"5_Ferramentas/5.9_mkdocs/#11-tema","title":"1.1. Tema","text":"<p>Use o tema <code>material</code> para uma apar\u00eancia moderna: <pre><code>theme:\n  name: material\n</code></pre></p>"},{"location":"5_Ferramentas/5.9_mkdocs/#2-guia-rapido","title":"2. Guia R\u00e1pido","text":"<p>Este \u00e9 um guia r\u00e1pido para come\u00e7ar a usar o MkDocs.</p>"},{"location":"5_Ferramentas/5.9_mkdocs/#21-passos-basicos","title":"2.1. Passos B\u00e1sicos","text":"<ol> <li>Instale o MkDocs: <code>pip install mkdocs</code>.</li> <li>Crie um novo projeto: <code>mkdocs new .</code>.</li> <li>Inicie o servidor: <code>mkdocs serve</code>.</li> <li>Acesse <code>http://localhost:8000</code> no navegador.</li> </ol>"},{"location":"5_Ferramentas/Introducao_Ferramentas/","title":"1. Introdu\u00e7\u00e3o","text":"<p>A Ci\u00eancia de Dados \u00e9 uma \u00e1rea multidisciplinar que exige n\u00e3o apenas conhecimento estat\u00edstico e habilidades em programa\u00e7\u00e3o, mas tamb\u00e9m dom\u00ednio sobre um conjunto de ferramentas que otimizam o fluxo de trabalho. Este guia apresenta as principais ferramentas utilizadas por profissionais da \u00e1rea, organizadas por fun\u00e7\u00e3o e aplicabilidade no ciclo de vida dos projetos.</p>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#11-principais-ferramentas","title":"1.1. Principais Ferramentas","text":""},{"location":"5_Ferramentas/Introducao_Ferramentas/#111-controle-de-versao","title":"1.1.1. \ud83d\udd27 Controle de Vers\u00e3o","text":"<ul> <li>Git: sistema de controle de vers\u00e3o distribu\u00eddo, essencial para versionar c\u00f3digo e colaborar em equipe. Combinado com plataformas como GitHub ou GitLab, permite o gerenciamento eficiente de reposit\u00f3rios e hist\u00f3rico de altera\u00e7\u00f5es.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#112-gerenciamento-de-dependencias","title":"1.1.2. \ud83d\udce6 Gerenciamento de Depend\u00eancias","text":"<ul> <li>Poetry: ferramenta moderna para gerenciamento de pacotes e ambientes Python. Substitui o tradicional <code>pip</code> + <code>virtualenv</code>, oferecendo controle mais estruturado sobre bibliotecas e vers\u00f5es.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#113-containerizacao-e-ambientes-reprodutiveis","title":"1.1.3. \ud83d\udc33 Containeriza\u00e7\u00e3o e Ambientes Reprodut\u00edveis","text":"<ul> <li>Docker: permite empacotar aplica\u00e7\u00f5es e suas depend\u00eancias em cont\u00eaineres isolados, garantindo portabilidade e reprodutibilidade dos experimentos e pipelines.</li> <li>Docker</li> <li>Docker env guide</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#114-estruturacao-de-projetos","title":"1.1.4. \ud83e\uddec Estrutura\u00e7\u00e3o de Projetos","text":"<ul> <li>Cookiecutter: utilit\u00e1rio para gerar automaticamente estruturas de projeto baseadas em templates personalizados. Ajuda a padronizar a organiza\u00e7\u00e3o de diret\u00f3rios e arquivos.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#115-dashboards-e-aplicacoes-interativas","title":"1.1.5. \ud83d\udcca Dashboards e Aplica\u00e7\u00f5es Interativas","text":"<ul> <li>Streamlit: biblioteca para criar interfaces web interativas com Python, ideal para visualiza\u00e7\u00f5es, apresenta\u00e7\u00e3o de modelos e constru\u00e7\u00e3o de prot\u00f3tipos de maneira r\u00e1pida.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#116-terminal-e-linha-de-comando","title":"1.1.6. \ud83d\udda5\ufe0f Terminal e Linha de Comando","text":"<ul> <li>TerminalO uso do terminal \u00e9 fundamental para operar ferramentas como Git, Poetry e Docker. Comandos de shell otimizam tarefas repetitivas e aumentam a produtividade do cientista de dados.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#117-documentacao-de-projetos","title":"1.1.7. \ud83d\udcda Documenta\u00e7\u00e3o de Projetos","text":"<ul> <li>MkDocs: ferramenta para gerar sites est\u00e1ticos a partir de arquivos Markdown. O tema Material for MkDocs \u00e9 amplamente adotado por seu visual moderno e recursos avan\u00e7ados como busca embutida e navega\u00e7\u00e3o estruturada.</li> </ul>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#118-latex","title":"1.1.8. LaTeX","text":"<p>O LaTeX \u00e9 uma linguagem de marca\u00e7\u00e3o amplamente utilizada para escrever equa\u00e7\u00f5es matem\u00e1ticas com alta qualidade tipogr\u00e1fica. Ele pode ser integrado tanto em Markdown quanto em Jupyter Notebooks com suporte ao MathJax.</p>"},{"location":"5_Ferramentas/Introducao_Ferramentas/#119-outras-ferramentas-relevantes","title":"1.1.9. \ud83e\udde0 Outras Ferramentas Relevantes","text":"<ul> <li>Jupyter Notebooks: embora amplamente usados para prototipagem e explora\u00e7\u00e3o de dados, s\u00e3o ainda mais \u00fateis quando integrados com ferramentas de versionamento e documenta\u00e7\u00e3o.</li> <li>Visual Studio Code (VSCode): editor leve e extens\u00edvel, com suporte a Python, Git, terminal integrado, Jupyter, e plugins que complementam todo o ecossistema.</li> </ul> <p>\ud83e\udded Este site est\u00e1 estruturado para explorar cada uma dessas ferramentas em detalhes, com exemplos pr\u00e1ticos e guias de configura\u00e7\u00e3o passo a passo.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/","title":"5.1.1 MongoDB","text":"<ul> <li>1. MongoDB</li> <li>1.1. O que \u00e9 MongoDB?</li> <li>1.2. Principais Caracter\u00edsticas</li> <li>1.3. Usando a Plataforma Atlas<ul> <li>1.3.1. Passos para Come\u00e7ar com MongoDB Atlas</li> <li>1.3.2. Conex\u00e3o com o VsCode</li> <li>1.3.2.1. Exemplo de Conex\u00e3o com Python (usando <code>pymongo</code>):</li> <li>1.3.2.2. MongoDB no Terminal do VS Code</li> <li>1.3.3. MongoDB Compass</li> </ul> </li> </ul>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#1-mongodb","title":"1. MongoDB","text":""},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#11-o-que-e-mongodb","title":"1.1. O que \u00e9 MongoDB?","text":"<p>MongoDB \u00e9 um banco de dados NoSQL de c\u00f3digo aberto, amplamente utilizado para armazenar dados em formato de documentos JSON (JavaScript Object Notation) flex\u00edveis e escal\u00e1veis. Desenvolvido pela MongoDB Inc., o MongoDB \u00e9 conhecido por sua capacidade de lidar com grandes volumes de dados e por sua alta performance em ambientes distribu\u00eddos.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#12-principais-caracteristicas","title":"1.2. Principais Caracter\u00edsticas","text":"<ol> <li> <p>Modelo de Dados Flex\u00edvel MongoDB utiliza documentos BSON (uma vers\u00e3o bin\u00e1ria do JSON), permitindo um modelo de dados flex\u00edvel que pode evoluir conforme necess\u00e1rio sem a necessidade de uma estrutura r\u00edgida de tabelas e esquemas.</p> </li> <li> <p>Escalabilidade Horizontal Projetado para ser escal\u00e1vel horizontalmente, o MongoDB permite a adi\u00e7\u00e3o de novos n\u00f3s ao cluster para aumentar a capacidade de armazenamento e processamento, suportando grandes volumes de dados e altas taxas de transfer\u00eancia.</p> </li> <li> <p>Consultas e Indexa\u00e7\u00e3o Poderosas MongoDB oferece uma linguagem de consulta rica, permitindo filtros complexos, proje\u00e7\u00f5es, jun\u00e7\u00f5es e agrega\u00e7\u00f5es. Al\u00e9m disso, suporta diversos tipos de \u00edndices, incluindo \u00edndices compostos, geoespaciais e de texto.</p> </li> <li> <p>Alta Disponibilidade Com suporte a replica\u00e7\u00e3o autom\u00e1tica atrav\u00e9s do mecanismo de replica sets, o MongoDB garante alta disponibilidade e redund\u00e2ncia de dados, permitindo recupera\u00e7\u00e3o r\u00e1pida em caso de falhas.</p> </li> <li> <p>Desempenho e Armazenamento Otimizados O MongoDB oferece recursos como armazenamento baseado em mem\u00f3ria (in-memory storage engine), compress\u00e3o de dados e aloca\u00e7\u00e3o eficiente de espa\u00e7o, proporcionando alta performance em diversas cargas de trabalho.</p> </li> </ol>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#13-usando-a-plataforma-atlas","title":"1.3. Usando a Plataforma Atlas","text":"<p>A plataforma MongoDB Atlas oferece uma maneira f\u00e1cil e gratuita de hospedar seu banco de dados MongoDB online, ideal para estudos e pequenos desenvolvimentos. Com a Atlas, voc\u00ea pode configurar e gerenciar clusters MongoDB em quest\u00e3o de minutos, sem a necessidade de manuten\u00e7\u00e3o e administra\u00e7\u00e3o de servidores.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#131-passos-para-comecar-com-mongodb-atlas","title":"1.3.1. Passos para Come\u00e7ar com MongoDB Atlas","text":"<ol> <li>Criar uma Conta:</li> <li> <p>Visite o site MongoDB Atlas e crie uma conta gratuita.</p> </li> <li> <p>Configurar um Cluster:</p> </li> <li>Ap\u00f3s fazer login, clique em \"Build a Cluster\".</li> <li>Escolha a configura\u00e7\u00e3o gratuita (M0 Sandbox) para come\u00e7ar sem custos.</li> <li> <p>Selecione a regi\u00e3o do datacenter mais pr\u00f3xima de voc\u00ea para melhor desempenho.</p> </li> <li> <p>Configurar Usu\u00e1rios e Redes:</p> </li> <li>Adicione um usu\u00e1rio de banco de dados com as permiss\u00f5es necess\u00e1rias.</li> <li> <p>Configure as regras de rede para permitir conex\u00f5es seguras ao seu cluster.</p> </li> <li> <p>Conectar ao Seu Cluster:</p> </li> <li>Obtenha a string de conex\u00e3o fornecida pelo Atlas.</li> <li>Use essa string para conectar-se ao seu banco de dados usando drivers ou ferramentas como MongoDB Compass.</li> </ol>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#132-conexao-com-o-vscode","title":"1.3.2. Conex\u00e3o com o VsCode","text":"<p>Para conectar a sua conta do atlas no Visual Studio Code (VS Code), voc\u00ea pode usar a extens\u00e3o MongoDB for VS Code. </p> <ol> <li> <p>Primeiro, instale a extens\u00e3o a partir da Visual Studio Code Marketplace.</p> </li> <li> <p>Ap\u00f3s a instala\u00e7\u00e3o, clique no \u00edcone da extens\u00e3o MongoDB na barra lateral esquerda.</p> </li> <li> <p>Em seguida, clique em \"Connect\" e selecione \"New Connection\".</p> </li> <li> <p>Insira a string de conex\u00e3o do seu cluster MongoDB Atlas ou do seu servidor MongoDB local. Voc\u00ea pode encontrar a string de conex\u00e3o no MongoDB Atlas na se\u00e7\u00e3o de clusters.</p> </li> <li> <p>Cole a string no campo apropriado na extens\u00e3o e clique em \"Connect\".</p> </li> <li> <p>Ap\u00f3s a conex\u00e3o, voc\u00ea poder\u00e1 explorar seus bancos de dados e cole\u00e7\u00f5es diretamente no VS Code.</p> </li> </ol>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#1321-exemplo-de-conexao-com-python-usando-pymongo","title":"1.3.2.1. Exemplo de Conex\u00e3o com Python (usando <code>pymongo</code>):","text":"<pre><code>from pymongo import MongoClient\n\n# Substitua &lt;username&gt;, &lt;password&gt; e &lt;cluster-url&gt; pelas informa\u00e7\u00f5es do seu cluster Atlas\nclient = MongoClient(\"mongodb+srv://&lt;username&gt;:&lt;password&gt;@&lt;cluster-url&gt;/test?retryWrites=true&amp;w=majority\")\ndb = client.nome_do_banco_de_dados\n\n# Inserir um documento de exemplo\ndb.nome_da_colecao.insert_one({\"nome\": \"Empresa X\", \"cnpj\": \"12.345.678/0001-99\"})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#1322-mongodb-no-terminal-do-vs-code","title":"1.3.2.2. MongoDB no Terminal do VS Code","text":"<p>Para usar o MongoDB no terminal do vscode:</p> <ol> <li>Baixar o software MongoDB Shell</li> <li>Ao fazer a instala\u00e7\u00e3o certifique-se de anotar o caminho de onde est\u00e1 instalando o software.</li> <li>Copie o caminho de onde instalou o software</li> <li>crie uma nova variavel de ambiente com o caminho do MongoDB Shell.</li> <li>Reinicie o Vs Code, aperte F1 e digite MongoDB clica na op\u00e7\u00e3o: MongoDB shell.</li> </ol> <p>Esse procedimento deve permitir usar os comandos do MongoDB no terminal do vscode.</p> <p>video de referencia</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.1_MongoDB/#133-mongodb-compass","title":"1.3.3. MongoDB Compass","text":"<p>O MongoDB Compass \u00e9 uma interface gr\u00e1fica que facilita a intera\u00e7\u00e3o com bancos de dados MongoDB. Tamb\u00e9m \u00e9 possivel utilizar o terminal shell do MongoDB Compass para executar comandos. Seguem os passos para baixar e usar o MongoDB Compass:</p> <ol> <li>Baixar o MongoDB Compass:</li> <li> <p>Acesse o site oficial do MongoDB Compass e baixe a vers\u00e3o compat\u00edvel com o seu sistema operacional.</p> </li> <li> <p>Instalar o MongoDB Compass:</p> </li> <li> <p>Ap\u00f3s o download, siga as instru\u00e7\u00f5es do instalador para instalar o MongoDB Compass em seu computador.</p> </li> <li> <p>Abrir o MongoDB Compass:</p> </li> <li> <p>Ap\u00f3s a instala\u00e7\u00e3o, abra o MongoDB Compass em seu sistema operacional.</p> </li> <li> <p>Conectar ao Banco de Dados:</p> </li> <li>Na tela inicial do MongoDB Compass, clique em \"Connect to MongoDB\".</li> <li>Insira a string de conex\u00e3o do seu banco de dados MongoDB ou clique em \"Fill in connection fields individually\" para inserir manualmente as informa\u00e7\u00f5es de conex\u00e3o, como endere\u00e7o do servidor, porta, nome do banco de dados, nome de usu\u00e1rio e senha, se aplic\u00e1vel.</li> <li> <p>Clique em \"Connect\" para estabelecer a conex\u00e3o com o banco de dados.</p> </li> <li> <p>Explorar e Interagir com o Banco de Dados:</p> </li> <li>Ap\u00f3s a conex\u00e3o bem-sucedida, voc\u00ea ver\u00e1 uma lista de bancos de dados e cole\u00e7\u00f5es no painel \u00e0 esquerda.</li> <li>Clique em um banco de dados para ver suas cole\u00e7\u00f5es e documentos.</li> <li> <p>Use as op\u00e7\u00f5es de consulta, inser\u00e7\u00e3o, atualiza\u00e7\u00e3o e remo\u00e7\u00e3o dispon\u00edveis na interface gr\u00e1fica para interagir com o banco de dados.</p> </li> <li> <p>Explorar Recursos Adicionais (Opcional):</p> </li> <li> <p>Explore os recursos adicionais do MongoDB Compass, como visualiza\u00e7\u00e3o de esquema, cria\u00e7\u00e3o de consultas e agrega\u00e7\u00f5es, e configura\u00e7\u00e3o de \u00edndices.</p> </li> <li> <p>Desconectar-se do Banco de Dados:</p> </li> <li>Quando terminar, clique no \u00edcone de desconex\u00e3o ou feche o MongoDB Compass para encerrar a conex\u00e3o com o banco de dados.</li> </ol> <p>Agora voc\u00ea est\u00e1 pronto para baixar, instalar e usar o MongoDB Compass para interagir com seus bancos de dados MongoDB de forma visual e intuitiva.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/","title":"5.1.2 MongoDB CRUD","text":"<ul> <li>1. Comandos CRUD do MongoDB</li> <li>1.1. Create (Criar)<ul> <li>1.1.1. <code>insertOne</code></li> <li>1.1.2. <code>insertMany</code></li> </ul> </li> <li>1.2. Read (Ler)<ul> <li>1.2.1. <code>find</code></li> <li>1.2.2. <code>findOne</code></li> </ul> </li> <li>1.3. Update (Atualizar)<ul> <li>1.3.1. <code>updateOne</code></li> <li>1.3.2. <code>updateMany</code></li> <li>1.3.3. <code>replaceOne</code></li> </ul> </li> <li>1.4. Delete (Deletar)<ul> <li>1.4.1. <code>deleteOne</code></li> <li>1.4.2. <code>deleteMany</code></li> </ul> </li> <li>2. Operadores do MongoDB</li> </ul>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#1-comandos-crud-do-mongodb","title":"1. Comandos CRUD do MongoDB","text":""},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#11-create-criar","title":"1.1. Create (Criar)","text":"<p>Para inserir documentos em uma cole\u00e7\u00e3o, voc\u00ea pode usar os seguintes comandos:</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#111-insertone","title":"1.1.1. <code>insertOne</code>","text":"<p>Insere um \u00fanico documento na cole\u00e7\u00e3o.</p> <pre><code>db.collection.insertOne({\n  chave1: \"valor1\",\n  chave2: \"valor2\"\n})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#112-insertmany","title":"1.1.2. <code>insertMany</code>","text":"<p>Insere m\u00faltiplos documentos na cole\u00e7\u00e3o.</p> <pre><code>db.collection.insertMany([\n  {\n    chave1: \"valor1\",\n    chave2: \"valor2\"\n  },\n  {\n    chave1: \"valor3\",\n    chave2: \"valor4\"\n  }\n])\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#12-read-ler","title":"1.2. Read (Ler)","text":"<p>Para recuperar documentos de uma cole\u00e7\u00e3o, voc\u00ea pode usar os seguintes comandos:</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#121-find","title":"1.2.1. <code>find</code>","text":"<p>Encontra todos os documentos que correspondem aos crit\u00e9rios de consulta.</p> <pre><code>db.collection.find({\n  chave1: \"valor1\"\n})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#122-findone","title":"1.2.2. <code>findOne</code>","text":"<p>Encontra o primeiro documento que corresponde aos crit\u00e9rios de consulta.</p> <pre><code>db.collection.findOne({\n  chave1: \"valor1\"\n})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#13-update-atualizar","title":"1.3. Update (Atualizar)","text":"<p>Para modificar documentos existentes em uma cole\u00e7\u00e3o, voc\u00ea pode usar os seguintes comandos:</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#131-updateone","title":"1.3.1. <code>updateOne</code>","text":"<p>Atualiza um \u00fanico documento que corresponde aos crit\u00e9rios de consulta.</p> <pre><code>Copiar c\u00f3digo\ndb.collection.updateOne(\n  { chave1: \"valor1\" },\n  { $set: { chave2: \"novoValor\" } }\n)\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#132-updatemany","title":"1.3.2. <code>updateMany</code>","text":"<p>Atualiza todos os documentos que correspondem aos crit\u00e9rios de consulta.</p> <pre><code>Copiar c\u00f3digo\ndb.collection.updateMany(\n  { chave1: \"valor1\" },\n  { $set: { chave2: \"novoValor\" } }\n)\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#133-replaceone","title":"1.3.3. <code>replaceOne</code>","text":"<p>Substitui um \u00fanico documento que corresponde aos crit\u00e9rios de consulta.</p> <pre><code>Copiar c\u00f3digo\ndb.collection.replaceOne(\n  { chave1: \"valor1\" },\n  { chave1: \"novoValor1\", chave2: \"novoValor2\" }\n)\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#14-delete-deletar","title":"1.4. Delete (Deletar)","text":"<p>Para remover documentos de uma cole\u00e7\u00e3o, voc\u00ea pode usar os seguintes comandos:</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#141-deleteone","title":"1.4.1. <code>deleteOne</code>","text":"<p>Remove um \u00fanico documento que corresponde aos crit\u00e9rios de consulta.</p> <pre><code>Copiar c\u00f3digo\ndb.collection.deleteOne({\n  chave1: \"valor1\"\n})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#142-deletemany","title":"1.4.2. <code>deleteMany</code>","text":"<p>Remove todos os documentos que correspondem aos crit\u00e9rios de consulta.</p> <pre><code>Copiar c\u00f3digo\ndb.collection.deleteMany({\n  chave1: \"valor1\"\n})\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.2_MongoDB_crud/#2-operadores-do-mongodb","title":"2. Operadores do MongoDB","text":"<ol> <li>Operadores de Compara\u00e7\u00e3o</li> <li>Operadores L\u00f3gicos</li> <li>Operadores de Elementos</li> <li>Operadores de Avalia\u00e7\u00e3o</li> <li>Operadores de Matriz</li> </ol>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/","title":"1. Operadores do MongoDB","text":""},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#11-operadores-de-comparacao","title":"1.1. Operadores de Compara\u00e7\u00e3o","text":"<p>Esses operadores s\u00e3o usados para comparar valores em consultas.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#111-eq-igual-a","title":"1.1.1. <code>$eq</code> : Igual a.","text":"<pre><code>{ chave: { $eq: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#112-ne-diferente-de","title":"1.1.2. <code>$ne</code>: Diferente de.","text":"<pre><code>{ chave: { $ne: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#113-gt-maior-que","title":"1.1.3. <code>$gt</code>: Maior que.","text":"<pre><code>{ chave: { $gt: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#114-gte-maior-ou-igual-a","title":"1.1.4. <code>$gte</code>: Maior ou igual a.","text":"<pre><code>{ chave: { $gte: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#115-lt-menor-que","title":"1.1.5. <code>$lt</code>: Menor que.","text":"<pre><code>{ chave: { $lt: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#116-lte-menor-ou-igual-a","title":"1.1.6. <code>$lte</code>: Menor ou igual a.","text":"<pre><code>{ chave: { $lte: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#117-in-corresponde-a-qualquer-valor-em-um-array","title":"1.1.7. <code>$in</code>: Corresponde a qualquer valor em um array.","text":"<pre><code>{ chave: { $in: [valor1, valor2, ...] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#118-nin-nao-corresponde-a-nenhum-valor-em-um-array","title":"1.1.8. <code>$nin</code>: N\u00e3o corresponde a nenhum valor em um array.","text":"<pre><code>{ chave: { $nin: [valor1, valor2, ...] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#12-operadores-logicos","title":"1.2. Operadores L\u00f3gicos","text":"<p>Esses operadores s\u00e3o usados para combinar condi\u00e7\u00f5es de consulta.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#121-and-todas-as-condicoes-devem-ser-verdadeiras","title":"1.2.1. <code>$and</code>: Todas as condi\u00e7\u00f5es devem ser verdadeiras.","text":"<pre><code>{ $and: [ { chave1: valor1 }, { chave2: valor2 } ] }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#122-or-pelo-menos-uma-das-condicoes-deve-ser-verdadeira","title":"1.2.2. <code>$or</code>: Pelo menos uma das condi\u00e7\u00f5es deve ser verdadeira.","text":"<pre><code>{ $or: [ { chave1: valor1 }, { chave2: valor2 } ] }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#123-not-inverte-a-condicao","title":"1.2.3. <code>$not</code>: Inverte a condi\u00e7\u00e3o.","text":"<pre><code>{ chave: { $not: { $gt: valor } } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#124-nor-nenhuma-das-condicoes-deve-ser-verdadeira","title":"1.2.4. <code>$nor</code>: Nenhuma das condi\u00e7\u00f5es deve ser verdadeira.","text":"<pre><code>{ $nor: [ { chave1: valor1 }, { chave2: valor2 } ] }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#13-operadores-de-elementos","title":"1.3. Operadores de Elementos","text":"<p>Esses operadores s\u00e3o usados para combinar com base na presen\u00e7a de campos ou tipo de dados.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#131-exists-verifica-se-o-campo-existe","title":"1.3.1. <code>$exists</code>: Verifica se o campo existe.","text":"<pre><code>{ chave: { $exists: true } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#132-type-verifica-o-tipo-do-campo","title":"1.3.2. <code>$type</code>: Verifica o tipo do campo.","text":"<pre><code>{ chave: { $type: \"tipo\" } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#14-operadores-de-avaliacao","title":"1.4. Operadores de Avalia\u00e7\u00e3o","text":"<p>Esses operadores s\u00e3o usados para express\u00f5es e opera\u00e7\u00f5es condicionais.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#141-expr-permite-usar-expressoes-agregadas-em-consultas","title":"1.4.1. <code>$expr</code>: Permite usar express\u00f5es agregadas em consultas.","text":"<pre><code>{ $expr: { $gt: [\"$chave1\", \"$chave2\"] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#142-jsonschema-valida-documentos-com-base-em-um-esquema-json","title":"1.4.2. <code>$jsonSchema</code>: Valida documentos com base em um esquema JSON.","text":"<pre><code>{ $jsonSchema: { propriedades: { chave: { type: \"string\" } } } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#143-mod-realiza-a-operacao-de-modulo","title":"1.4.3. <code>$mod</code>: Realiza a opera\u00e7\u00e3o de m\u00f3dulo.","text":"<pre><code>{ chave: { $mod: [divisor, resto] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#144-regex-permite-usar-expressoes-regulares","title":"1.4.4. <code>$regex</code>: Permite usar express\u00f5es regulares.","text":"<pre><code>{ chave: { $regex: /padr\u00e3o/ } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#145-text-realiza-uma-pesquisa-de-texto","title":"1.4.5. <code>$text</code>: Realiza uma pesquisa de texto.","text":"<pre><code>{ $text: { $search: \"texto\" } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#146-where-usa-javascript-para-avaliar-uma-condicao","title":"1.4.6. <code>$where</code>: Usa JavaScript para avaliar uma condi\u00e7\u00e3o.","text":"<pre><code>{ $where: \"this.chave == valor\" }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#15-operadores-de-matriz","title":"1.5. Operadores de Matriz","text":"<p>Esses operadores s\u00e3o usados para consultar e atualizar arrays.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#151-all-corresponde-a-todos-os-elementos-de-um-array","title":"1.5.1. <code>$all</code>: Corresponde a todos os elementos de um array.","text":"<pre><code>{ chave: { $all: [valor1, valor2, ...] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#elemmatch-corresponde-a-elementos-de-um-array-que-satisfazem-uma-condicao","title":"<code>$elemMatch</code>: Corresponde a elementos de um array que satisfazem uma condi\u00e7\u00e3o.","text":"<pre><code>{ chave: { $elemMatch: { subChave: valor } } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#152-size","title":"1.5.2. <code>$size</code>","text":"<p>Corresponde ao tamanho do array.</p> <pre><code>{ chave: { $size: tamanho } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#16-operadores-de-atualizacao","title":"1.6. Operadores de Atualiza\u00e7\u00e3o","text":"<p>Esses operadores s\u00e3o usados para atualizar documentos.</p>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#161-set-define-o-valor-de-um-campo","title":"1.6.1. <code>$set</code>: Define o valor de um campo.","text":"<pre><code>{ $set: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#unset-remove-um-campo","title":"<code>$unset</code>: Remove um campo.","text":"<pre><code>{ $unset: { chave: \"\" } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#162-inc-incrementa-o-valor-de-um-campo","title":"1.6.2. <code>$inc</code>: Incrementa o valor de um campo.","text":"<pre><code>{ $inc: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#163-mul-multiplica-o-valor-de-um-campo","title":"1.6.3. <code>$mul</code>: Multiplica o valor de um campo.","text":"<pre><code>{ $mul: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#164-rename-renomeia-um-campo","title":"1.6.4. <code>$rename</code>: Renomeia um campo.","text":"<pre><code>{ $rename: { chaveAntiga: \"chaveNova\" } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#165-push-adiciona-um-valor-a-um-array","title":"1.6.5. <code>$push</code>: Adiciona um valor a um array.","text":"<pre><code>{ $push: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#166-addtoset-adiciona-um-valor-a-um-array-se-ele-nao-existir","title":"1.6.6. <code>$addToSet</code>: Adiciona um valor a um array se ele n\u00e3o existir.","text":"<pre><code>{ $addToSet: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#167-pop-remove-o-primeiro-ou-ultimo-valor-de-um-array","title":"1.6.7. <code>$pop</code>: Remove o primeiro ou \u00faltimo valor de um array.","text":"<pre><code>{ $pop: { chave: 1 } } // Remove o \u00faltimo valor\n{ $pop: { chave: -1 } } // Remove o primeiro valor\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#168-pull-remove-valores-que-correspondem-a-uma-condicao","title":"1.6.8. <code>$pull</code>: Remove valores que correspondem a uma condi\u00e7\u00e3o.","text":"<pre><code>{ $pull: { chave: valor } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#169-pullall-remove-todos-os-valores-especificados-de-um-array","title":"1.6.9. <code>$pullAll</code>: Remove todos os valores especificados de um array.","text":"<pre><code>{ $pullAll: { chave: [valor1, valor2, ...] } }\n</code></pre>"},{"location":"5_Ferramentas/5.1_Bancos_de_Dados/5.1.3_MongoDB_operadores/#1610-each-usado-com-push-e-addtoset-para-adicionar-multiplos-valores","title":"1.6.10. <code>$each</code>: Usado com <code>$push</code> e <code>$addToSet</code> para adicionar m\u00faltiplos valores.","text":"<pre><code>{ $push: { chave: { $each: [valor1, valor2, ...] } } }\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/","title":"\ud83d\udc33 Guia Completo do Docker","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#1-introducao","title":"1. Introdu\u00e7\u00e3o","text":"<p>Docker \u00e9 uma plataforma que permite criar, empacotar e executar aplica\u00e7\u00f5es em cont\u00eaineres \u2014 ambientes isolados e port\u00e1teis com todas as depend\u00eancias da aplica\u00e7\u00e3o.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#11-conceitos-fundamentais","title":"1.1. Conceitos Fundamentais","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#111-imagem-docker","title":"1.1.1. Imagem Docker","text":"<p>Pacote leve e imut\u00e1vel com tudo o que a aplica\u00e7\u00e3o precisa para rodar: c\u00f3digo, runtime, libs e configs.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#112-conteiner-docker","title":"1.1.2. Cont\u00eainer Docker","text":"<p>Inst\u00e2ncia de uma imagem em execu\u00e7\u00e3o. Isolado, mas compartilhando recursos com o host.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#113-dockerfile","title":"1.1.3. Dockerfile","text":"<p>Script com instru\u00e7\u00f5es para gerar uma imagem.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#114-docker-compose","title":"1.1.4. Docker Compose","text":"<p>Ferramenta para orquestrar m\u00faltiplos cont\u00eaineres via arquivo YAML.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#115-volumes","title":"1.1.5. Volumes","text":"<p>Permitem persist\u00eancia de dados e compartilhamento entre cont\u00eainer e host.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#12-comandos-essenciais","title":"1.2. Comandos Essenciais","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#121-gerenciamento-de-conteineres","title":"1.2.1. Gerenciamento de Cont\u00eaineres","text":"<pre><code>docker run -it ubuntu bash\ndocker ps\ndocker ps -a\ndocker start &lt;container_id&gt;\ndocker stop &lt;container_id&gt;\ndocker rm &lt;container_id&gt;\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#122-imagens","title":"1.2.2. Imagens","text":"<pre><code>docker pull ubuntu\ndocker images\ndocker rmi &lt;image_id&gt;\ndocker build -t nome_imagem .\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#123-dockerfile-exemplo","title":"1.2.3. Dockerfile (Exemplo)","text":"<pre><code>FROM ubuntu\nRUN apt update &amp;&amp; apt install -y python3\nCMD [\"python3\"]\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#124-volumes","title":"1.2.4. Volumes","text":"<pre><code>docker volume create nome_volume\ndocker volume ls\ndocker run -v nome_volume:/caminho ubuntu\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#125-redes","title":"1.2.5. Redes","text":"<pre><code>docker network ls\ndocker network create nome_rede\ndocker network connect nome_rede container\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#126-docker-compose","title":"1.2.6. Docker Compose","text":"<pre><code>docker-compose up               # Inicia todos os servi\u00e7os definidos no docker-compose.yml e mostra os logs no terminal\ndocker-compose up -d            # Inicia os servi\u00e7os em segundo plano (modo *detached*)\ndocker-compose down             # Para os servi\u00e7os e remove containers, redes e configura\u00e7\u00f5es definidas no docker-compose.yml\ndocker-compose down -v          # Mesmo que o anterior, mas tamb\u00e9m remove os volumes nomeados, apagando dados persistentes\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#2-exemplos-praticos","title":"2. Exemplos Pr\u00e1ticos","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#21-montar-um-volume-com-jupyter-pyspark","title":"2.1. Montar um volume com Jupyter + PySpark","text":"<pre><code>docker run -p 8888:8888 -v C:\\Users\\esped\\Documents\\Respositorio_git\\Repositorio_projetos\\image_spark_project:/home/jovyan/work jupyter/pyspark-notebook:spark-3.3.2\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#analise","title":"An\u00e1lise:","text":"<ul> <li><code>-p 8888:8888</code>: mapeia porta do host para o cont\u00eainer.</li> <li><code>-v caminho_host:/home/jovyan/work</code>: monta volume persistente.</li> <li><code>jupyter/pyspark-notebook:spark-3.3.2</code>: imagem com suporte a PySpark e Jupyter.</li> </ul>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#3-integracao-docker-poetry-no-jupyter","title":"3. Integra\u00e7\u00e3o Docker + Poetry no Jupyter","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#31-objetivo","title":"3.1. Objetivo","text":"<p>Utilizar o ambiente virtual do Poetry como kernel do Jupyter Notebook.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#32-passo-a-passo","title":"3.2. Passo a Passo","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#321-verificar-kernels-disponiveis","title":"3.2.1. Verificar Kernels Dispon\u00edveis","text":"<pre><code>jupyter kernelspec list\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#322-instalar-ipykernel-no-ambiente-do-poetry","title":"3.2.2. Instalar ipykernel no ambiente do Poetry","text":"<pre><code>poetry add ipykernel\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#323-adicionar-kernel-ao-jupyter","title":"3.2.3. Adicionar Kernel ao Jupyter","text":"<pre><code>python -m ipykernel install --user --name=image-spark-project-py3.10 --display-name \"Python (Poetry)\"\n</code></pre> <ul> <li><code>--name</code>: nome interno do kernel</li> <li><code>--display-name</code>: nome vis\u00edvel no Jupyter</li> </ul>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#33-selecionar-kernel-no-jupyter","title":"3.3. Selecionar Kernel no Jupyter","text":"<ul> <li>V\u00e1 em Kernel &gt; Change Kernel</li> <li>Escolha Python (Poetry)</li> </ul>"},{"location":"5_Ferramentas/5.4_Docker/5.4.1_Docker/#4-resumo-final","title":"4. Resumo Final","text":"<p>\u2705 Docker cria ambientes isolados \u2705 Docker Compose orquestra m\u00faltiplos cont\u00eaineres \u2705 Poetry pode ser integrado ao Jupyter via kernel dedicado \u2705 Volumes permitem persist\u00eancia de dados entre host e cont\u00eainer  </p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/","title":"\ud83d\udc33 Como usar <code>.env</code> com Docker Compose corretamente","text":"<p>Este guia explica como usar arquivos <code>.env</code> com o Docker Compose, especialmente quando o <code>.env</code> est\u00e1 fora da raiz do projeto, como na pasta <code>config/</code>.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#objetivo","title":"\u2705 Objetivo","text":"<p>Permitir que o Docker Compose e seus containers usem vari\u00e1veis de ambiente definidas em um arquivo <code>.env</code> localizado em <code>config/.env</code>.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#o-problema-com-variavel-e-env_file","title":"\ud83d\udeab O Problema com <code>${VARIAVEL}</code> e <code>env_file:</code>","text":"<pre><code>env_file:\n  - config/.env\n\nenvironment:\n  POSTGRES_USER: ${POSTGRES_USER}\n  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n</code></pre> <p>Nesse exemplo, <code>${POSTGRES_USER}</code> n\u00e3o ser\u00e1 resolvido a partir do <code>config/.env</code>. O Docker Compose tenta buscar essas vari\u00e1veis do ambiente do seu sistema operacional (host), e n\u00e3o do <code>env_file:</code>.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#solucoes-possiveis","title":"\u2705 Solu\u00e7\u00f5es poss\u00edveis","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#opcao-1-usar-somente-env_file-mais-simples-e-recomendado","title":"\u2705 Op\u00e7\u00e3o 1: Usar somente <code>env_file:</code> (mais simples e recomendado)","text":"<pre><code>services:\n  db:\n    image: postgres:14\n    container_name: container_postgres_financeiro\n    env_file:\n      - config/.env\n</code></pre> <p>\ud83d\udccc N\u00e3o use <code>${VAR}</code> dentro de <code>environment:</code> nesse caso.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#opcao-2-mover-o-env-para-a-raiz-do-projeto","title":"\u2705 Op\u00e7\u00e3o 2: Mover o <code>.env</code> para a raiz do projeto","text":"<p>Estrutura:</p> <pre><code>.\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 docker-compose.yml\n</code></pre> <pre><code>services:\n  db:\n    image: postgres:14\n    container_name: container_postgres_financeiro\n    environment:\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      POSTGRES_DB: ${POSTGRES_DB}\n</code></pre> <p>\u2705 O Docker Compose carrega automaticamente <code>.env</code> da raiz do projeto.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#opcao-3-usar-flag-env-file-no-comando","title":"\u2705 Op\u00e7\u00e3o 3: Usar flag <code>--env-file</code> no comando","text":"<p>Mant\u00e9m o <code>.env</code> na pasta <code>config/</code>, e executa com:</p> <pre><code>docker-compose --env-file config/.env up --build\n</code></pre> <pre><code>services:\n  db:\n    image: postgres:14\n    container_name: container_postgres_financeiro\n    environment:\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      POSTGRES_DB: ${POSTGRES_DB}\n</code></pre> <p>\u2705 O Compose carrega as vari\u00e1veis do <code>.env</code> como se estivessem no ambiente do host.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#comparativo-final","title":"\ud83e\udde0 Comparativo final","text":"Situa\u00e7\u00e3o <code>${VAR}</code> funciona? <code>env_file:</code> necess\u00e1rio? Observa\u00e7\u00f5es <code>.env</code> na raiz do projeto \u2705 \u274c Auto-carregado pelo Compose <code>env_file:</code> com <code>.env</code> em subpasta \u274c \u2705 S\u00f3 passa para o container Usando <code>--env-file</code> na linha de comando \u2705 \u274c Precisa especificar manualmente no comando"},{"location":"5_Ferramentas/5.4_Docker/5.4.2_Docker_env_guide/#recomendado-para-seu-caso","title":"\u2705 Recomendado para seu caso","text":"<p>Se voc\u00ea quer manter <code>.env</code> dentro da pasta <code>config/</code>, use:</p> <ul> <li>Apenas <code>env_file:</code> no <code>docker-compose.yml</code></li> <li>Ou <code>--env-file config/.env</code> no comando</li> </ul> <p>Feito com \ud83d\udc99 por ChatGPT</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/","title":"1. Guia B\u00e1sico sobre Docker","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#11-o-que-e-docker","title":"1.1. O que \u00e9 Docker?","text":"<p>Docker \u00e9 uma plataforma que permite criar, implantar e executar aplica\u00e7\u00f5es em cont\u00eaineres. Cont\u00eaineres s\u00e3o leves, port\u00e1teis e consistentes, proporcionando uma forma eficiente de empacotar e distribuir aplicativos junto com todas as suas depend\u00eancias.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#12-principais-conceitos","title":"1.2. Principais Conceitos","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#121-imagem-docker","title":"1.2.1. Imagem Docker","text":"<p>Uma imagem Docker \u00e9 um pacote leve, independente e execut\u00e1vel que inclui tudo o necess\u00e1rio para rodar um peda\u00e7o de software: c\u00f3digo, runtime, bibliotecas, vari\u00e1veis de ambiente e arquivos de configura\u00e7\u00e3o.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#122-conteiner-docker","title":"1.2.2. Cont\u00eainer Docker","text":"<p>Um cont\u00eainer \u00e9 uma inst\u00e2ncia de uma imagem Docker em execu\u00e7\u00e3o. Ele \u00e9 isolado do sistema host e de outros cont\u00eaineres, mas pode compartilhar recursos do sistema, como arquivos e rede.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#123-dockerfile","title":"1.2.3. Dockerfile","text":"<p>Um Dockerfile \u00e9 um script de texto contendo instru\u00e7\u00f5es para construir uma imagem Docker. Cada linha no Dockerfile representa um comando que ser\u00e1 executado para montar a imagem final.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#124-docker-compose","title":"1.2.4. Docker Compose","text":"<p>Docker Compose \u00e9 uma ferramenta para definir e gerenciar aplica\u00e7\u00f5es Docker multi-cont\u00eainer. Usando um arquivo YAML, voc\u00ea pode especificar os servi\u00e7os, redes e volumes necess\u00e1rios para a aplica\u00e7\u00e3o.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#125-volumes-bind-mounts","title":"1.2.5. Volumes (bind mounts)","text":"<p>Volumes (bind mounts) s\u00e3o usados para persistir dados e compartilhar informa\u00e7\u00f5es entre o host e os cont\u00eaineres ou entre m\u00faltiplos cont\u00eaineres. Eles permitem que os dados sobrevivam ao ciclo de vida dos cont\u00eaineres.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#13-comandos-essenciais","title":"1.3. Comandos Essenciais","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#131-executar-um-conteiner","title":"1.3.1. Executar um Cont\u00eainer","text":"<p><pre><code>docker run -it &lt;image&gt; /bin/bash\n</code></pre> Este comando cria e executa um cont\u00eainer a partir de uma imagem especificada, abrindo um terminal interativo.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#2-exemplos","title":"2. EXEMPLOS","text":""},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#21-montando-um-volume","title":"2.1. Montando um VOLUME","text":"<pre><code>comando docker run -p 8888:8888 -v C:\\Users\\esped\\Documents\\Respositorio_git\\Repositorio_projetos\\image_spark_project:/home/jovyan/work jupyter/pyspark-notebook:spark-3.3.2\n</code></pre> <p>Este comando criou e executou um cont\u00eainer Docker utilizando uma imagem espec\u00edfica para Jupyter notebooks com suporte para PySpark. Al\u00e9m disso, montou um volume que mapeia um diret\u00f3rio no seu sistema host para um diret\u00f3rio dentro do cont\u00eainer, permitindo que voc\u00ea acesse e trabalhe com os arquivos do host diretamente no cont\u00eainer. </p> <p>Vamos analisar seu comando em detalhes:</p> <p>An\u00e1lise do Comando * docker run: Este \u00e9 o comando base para criar e executar um cont\u00eainer a partir de uma imagem Docker.</p> <ul> <li> <p>-p 8888:8888: Este par\u00e2metro mapeia a porta 8888 do seu host para a porta 8888 do cont\u00eainer. Isso \u00e9 necess\u00e1rio porque o Jupyter Notebook, por padr\u00e3o, roda na porta 8888. Com isso, voc\u00ea pode acessar o Jupyter Notebook no seu navegador atrav\u00e9s do endere\u00e7o http://localhost:8888.</p> </li> <li> <p>-v C:\\Users\\esped\\Documents\\Respositorio_git\\Repositorio_projetos\\image_spark_project:/home/jovyan/work: Este par\u00e2metro monta um volume:</p> <ul> <li>C:\\Users\\esped\\Documents\\Respositorio_git\\Repositorio_projetos\\image_spark_project: \u00c9 o caminho do diret\u00f3rio no seu host.</li> <li>/home/jovyan/work: \u00c9 o caminho do diret\u00f3rio dentro do cont\u00eainer onde o volume ser\u00e1 montado. jovyan \u00e9 o nome do usu\u00e1rio padr\u00e3o usado nas imagens de Jupyter Notebook baseadas no Docker Stacks.</li> <li>Montar este volume significa que qualquer altera\u00e7\u00e3o feita no diret\u00f3rio do host <code>C:\\Users\\esped\\Documents\\Respositorio_git\\Repositorio_projetos\\image_spark_project</code> ser\u00e1 refletida no diret\u00f3rio <code>/home/jovyan/work</code> dentro do cont\u00eainer e vice-versa. Isso permite que voc\u00ea trabalhe com seus arquivos diretamente no cont\u00eainer enquanto mant\u00e9m os arquivos no host.</li> </ul> </li> <li> <p>jupyter/pyspark-notebook:spark-3.3.2: Esta \u00e9 a imagem Docker que voc\u00ea est\u00e1 usando. A imagem jupyter/pyspark-notebook \u00e9 uma imagem pr\u00e9-configurada para Jupyter Notebooks com PySpark. A tag spark-3.3.2 especifica a vers\u00e3o do PySpark inclu\u00edda na imagem.</p> </li> </ul>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#22-resumo","title":"2.2. Resumo","text":"<p>Com este comando, voc\u00ea:</p> <p>Iniciou um cont\u00eainer com Jupyter Notebook e PySpark. Montou um volume que permite acesso direto aos arquivos do host no cont\u00eainer. Configurou o cont\u00eainer para que o Jupyter Notebook esteja acess\u00edvel atrav\u00e9s do seu navegador.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#3-poetry-no-docker","title":"3. Poetry no Docker","text":"<p>Para usar o <code>**kernel do Poetry**</code> no Jupyter Notebook, voc\u00ea precisa configurar um kernel espec\u00edfico que aponte para o ambiente virtual do Poetry onde est\u00e3o instaladas as depend\u00eancias do seu projeto. </p> <p>Aqui est\u00e3o os passos para configurar e usar o kernel do Poetry no Jupyter Notebook:</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#301-verificar-os-kernels-disponiveis","title":"3.0.1. Verificar os Kernels Dispon\u00edveis:","text":"<p>Primeiro, verifique quais kernels est\u00e3o dispon\u00edveis atualmente no seu ambiente do Jupyter Notebook. Voc\u00ea pode fazer isso com o comando:</p> <pre><code>jupyter kernelspec list\n</code></pre> <p>Isso listar\u00e1 todos os kernels instalados e seus locais no seu sistema.</p>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#302-instalar-o-kernel-do-poetry","title":"3.0.2. Instalar o Kernel do Poetry:","text":"<p>Se o kernel do Poetry n\u00e3o estiver listado, voc\u00ea precisar\u00e1 instal\u00e1-lo manualmente. Certifique-se de estar no ambiente virtual do Poetry e execute o seguinte comando para instalar o kernel do Poetry:</p> <pre><code>poetry add ipykernel\n</code></pre>"},{"location":"5_Ferramentas/5.4_Docker/5.4_Docker_ob/#303-adicionar-o-kernel-do-poetry-ao-jupyter","title":"3.0.3. Adicionar o Kernel do Poetry ao Jupyter:","text":"<p>Ap\u00f3s instalar o ipykernel no ambiente virtual do Poetry, voc\u00ea pode adicionar o kernel do Poetry ao Jupyter Notebook com o seguinte comando:</p> <pre><code>python -m ipykernel install --user --name=image-spark-project-py3.10 --display-name \"Python (Poetry)\"\n</code></pre> <ul> <li><code>--name=image-spark-project-py3.10</code>: Especifique o nome do ambiente virtual do Poetry que voc\u00ea deseja usar como base para o kernel.</li> <li><code>--display-name \"Python (Poetry)\"</code>: Especifique o nome que deseja que apare\u00e7a na lista de kernels do Jupyter Notebook. Selecionar o Kernel do Poetry no Jupyter Notebook: Depois de adicionar o kernel, voc\u00ea pode selecion\u00e1-lo ao criar um novo notebook ou alterar o kernel de um notebook existente:</li> </ul> <p>Crie um novo notebook ou abra um notebook existente. V\u00e1 para o menu \"Kernel\" e selecione \"Change Kernel\". Selecione \"Python (Poetry)\" ou o nome que voc\u00ea especificou ao adicionar o kernel do Poetry.</p> <p>Agora, o notebook estar\u00e1 utilizando o kernel associado ao ambiente virtual do Poetry, garantindo que todas as depend\u00eancias do seu projeto sejam utilizadas corretamente.</p> <p>Esses passos devem ajudar a configurar e usar o kernel do Poetry no Jupyter Notebook dentro do seu ambiente Docker, garantindo que voc\u00ea esteja trabalhando com as depend\u00eancias corretas do seu projeto.</p>"},{"location":"futuro/Cross_validacion_skShuffle/","title":"Cross validacion skShuffle","text":"In\u00a0[11]: Copied! <pre>from sklearn.model_selection import ShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n</pre> from sklearn.model_selection import ShuffleSplit from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_iris from sklearn.model_selection import cross_val_score  # Carregar dados de exemplo data = load_iris() X, y = data.data, data.target  # Definir o modelo model = RandomForestClassifier() In\u00a0[12]: Copied! <pre># Definir o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)\n\n# Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit\nscores = cross_val_score(model, X, y, cv=shuffle_split)\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</pre> # Definir o ShuffleSplit shuffle_split = ShuffleSplit(n_splits=4, test_size=0.2, random_state=42)  # Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit scores = cross_val_score(model, X, y, cv=shuffle_split)  # Exibir os resultados print(\"Scores de valida\u00e7\u00e3o cruzada:\", scores) print(\"M\u00e9dia dos scores:\", scores.mean()) print(\"Desvio padr\u00e3o dos scores:\", scores.std()) <pre>Scores de valida\u00e7\u00e3o cruzada: [1.         0.96666667 0.96666667 0.93333333]\nM\u00e9dia dos scores: 0.9666666666666668\nDesvio padr\u00e3o dos scores: 0.02357022603955158\n</pre> In\u00a0[13]: Copied! <pre>shuffle_split\n</pre> shuffle_split Out[13]: <pre>ShuffleSplit(n_splits=4, random_state=42, test_size=0.2, train_size=None)</pre> In\u00a0[14]: Copied! <pre># Executar valida\u00e7\u00e3o cruzada\nscores = cross_val_score(model, X, y, cv=4)  # cv=5 define 5 folds\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</pre> # Executar valida\u00e7\u00e3o cruzada scores = cross_val_score(model, X, y, cv=4)  # cv=5 define 5 folds  # Exibir os resultados print(\"Scores de valida\u00e7\u00e3o cruzada:\", scores) print(\"M\u00e9dia dos scores:\", scores.mean()) print(\"Desvio padr\u00e3o dos scores:\", scores.std())  <pre>Scores de valida\u00e7\u00e3o cruzada: [0.97368421 0.94736842 0.94594595 1.        ]\nM\u00e9dia dos scores: 0.9667496443812233\nDesvio padr\u00e3o dos scores: 0.02214779922867332\n</pre> <p>O <code>ShuffleSplit</code> em scikit-learn \u00e9 um gerador de indices de treinamento e teste para valida\u00e7\u00e3o cruzada. Ao contr\u00e1rio de m\u00e9todos que retornam os pr\u00f3prios dados divididos, ShuffleSplit gera \u00edndices que podem ser usados para selecionar subconjuntos de treinamento e teste diretamente dos dados originais.</p> <p>O que ShuffleSplit Retorna</p> <p>O objeto ShuffleSplit n\u00e3o retorna diretamente os dados de treinamento e teste. Em vez disso, ele gera pares de \u00edndices (um para treinamento e outro para teste) que voc\u00ea pode usar para dividir seus dados manualmente.</p> <p>Exemplo de Uso Aqui est\u00e1 um exemplo detalhado de como usar ShuffleSplit e entender o que ele retorna:</p> In\u00a0[23]: Copied! <pre>import pandas as pd\nfrom sklearn.model_selection import ShuffleSplit\nimport numpy as np\n\n# Criar dados de exemplo\ndata = {\n    'feature1': np.arange(5),\n    'feature2': np.arange(5, 10),\n    'label': [0, 1, 0, 1, 0]\n}\ndf = pd.DataFrame(data)\nX = df[['feature1', 'feature2']]\ny = df['label']\n\n# Configurar o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n\n# Mostrar DataFrame e labels\nprint('DataFrame:')\nprint(df)\nprint('Labels:')\nprint(y.values)\n\n# Mostrar \u00edndices gerados\nfor train_index, test_index in shuffle_split.split(X):\n    print('################################')\n    print(\"\u00cdndices de treino:\", train_index)\n    print(\"\u00cdndices de teste:\", test_index)\n    print('-----')\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    print(\"Dados de treino:\")\n    print(X_train)\n    print(y_train.values)\n    print(\"Dados de teste:\")\n    print(X_test)\n    print(y_test.values)\n\n    \n</pre> import pandas as pd from sklearn.model_selection import ShuffleSplit import numpy as np  # Criar dados de exemplo data = {     'feature1': np.arange(5),     'feature2': np.arange(5, 10),     'label': [0, 1, 0, 1, 0] } df = pd.DataFrame(data) X = df[['feature1', 'feature2']] y = df['label']  # Configurar o ShuffleSplit shuffle_split = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)  # Mostrar DataFrame e labels print('DataFrame:') print(df) print('Labels:') print(y.values)  # Mostrar \u00edndices gerados for train_index, test_index in shuffle_split.split(X):     print('################################')     print(\"\u00cdndices de treino:\", train_index)     print(\"\u00cdndices de teste:\", test_index)     print('-----')     X_train, X_test = X.iloc[train_index], X.iloc[test_index]     y_train, y_test = y.iloc[train_index], y.iloc[test_index]     print(\"Dados de treino:\")     print(X_train)     print(y_train.values)     print(\"Dados de teste:\")     print(X_test)     print(y_test.values)        <pre>DataFrame:\n   feature1  feature2  label\n0         0         5      0\n1         1         6      1\n2         2         7      0\n3         3         8      1\n4         4         9      0\nLabels:\n[0 1 0 1 0]\n################################\n\u00cdndices de treino: [4 2 0 3]\n\u00cdndices de teste: [1]\n-----\nDados de treino:\n   feature1  feature2\n4         4         9\n2         2         7\n0         0         5\n3         3         8\n[0 0 0 1]\nDados de teste:\n   feature1  feature2\n1         1         6\n[1]\n################################\n\u00cdndices de treino: [1 2 0 4]\n\u00cdndices de teste: [3]\n-----\nDados de treino:\n   feature1  feature2\n1         1         6\n2         2         7\n0         0         5\n4         4         9\n[1 0 0 0]\nDados de teste:\n   feature1  feature2\n3         3         8\n[1]\n################################\n\u00cdndices de treino: [0 3 4 2]\n\u00cdndices de teste: [1]\n-----\nDados de treino:\n   feature1  feature2\n0         0         5\n3         3         8\n4         4         9\n2         2         7\n[0 1 0 0]\nDados de teste:\n   feature1  feature2\n1         1         6\n[1]\n</pre>"},{"location":"futuro/Cross_validacion_skShuffle/#validacao-cruzada-com-shufflesplit","title":"Valida\u00e7\u00e3o Cruzada com ShuffleSplit\u00b6","text":""},{"location":"futuro/Cross_validacion_skShuffle/#entendendo-o-shuffle_split","title":"Entendendo o <code>shuffle_split</code>\u00b6","text":""},{"location":"futuro/Cross_validacion_skShuffle/","title":"Cross validacion skShuffle","text":"<ul> <li>Ferramentas para Cross-Validation</li> <li>Fun\u00e7\u00e3o <code>ShuffleSplit</code><ul> <li>Quando Usar ShuffleSplit</li> </ul> </li> <li>Fun\u00e7\u00e3o <code>cross_val_score</code></li> </ul>"},{"location":"futuro/Cross_validacion_skShuffle/#ferramentas-para-cross-validation","title":"Ferramentas para Cross-Validation","text":""},{"location":"futuro/Cross_validacion_skShuffle/#funcao-shufflesplit","title":"Fun\u00e7\u00e3o <code>ShuffleSplit</code>","text":"<p>A fun\u00e7\u00e3o ShuffleSplit no pacote scikit-learn \u00e9 uma ferramenta de valida\u00e7\u00e3o cruzada que permite criar divis\u00f5es aleat\u00f3rias dos dados em conjuntos de treinamento e teste. \u00c9 especialmente \u00fatil quando voc\u00ea deseja um controle mais flex\u00edvel sobre o processo de divis\u00e3o dos dados, em compara\u00e7\u00e3o com outras estrat\u00e9gias de valida\u00e7\u00e3o cruzada.</p> <p>Funcionalidades Principais Divis\u00f5es Aleat\u00f3rias: O ShuffleSplit cria divis\u00f5es aleat\u00f3rias dos dados, onde cada divis\u00e3o cont\u00e9m um subconjunto dos dados de treinamento e um subconjunto dos dados de teste. Controle de Tamanho: Voc\u00ea pode especificar o tamanho dos conjuntos de treinamento e teste, permitindo uma personaliza\u00e7\u00e3o fina. Repetibilidade: Voc\u00ea pode definir um seed para o gerador de n\u00fameros aleat\u00f3rios para obter resultados reprodut\u00edveis. Par\u00e2metros Principais n_splits: N\u00famero de reamostragens (divis\u00f5es) a serem geradas. O valor padr\u00e3o \u00e9 10. test_size: Propor\u00e7\u00e3o ou n\u00famero absoluto de amostras no conjunto de teste. Pode ser um float (representando uma propor\u00e7\u00e3o) ou um int (n\u00famero absoluto). train_size: Propor\u00e7\u00e3o ou n\u00famero absoluto de amostras no conjunto de treinamento. Similar ao test_size. random_state: Seed para o gerador de n\u00fameros aleat\u00f3rios para garantir que os resultados sejam reprodut\u00edveis.</p> <p>Exemplo de Uso Aqui est\u00e1 um exemplo de como usar ShuffleSplit:</p> <pre><code>from sklearn.model_selection import ShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n\n# Definir o ShuffleSplit\nshuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\n# Executar valida\u00e7\u00e3o cruzada usando ShuffleSplit\nscores = cross_val_score(model, X, y, cv=shuffle_split)\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</code></pre>"},{"location":"futuro/Cross_validacion_skShuffle/#quando-usar-shufflesplit","title":"Quando Usar ShuffleSplit","text":"<p>Controle Fino: Use ShuffleSplit quando precisar de controle espec\u00edfico sobre o n\u00famero de amostras no conjunto de treinamento e teste. Dados Desbalanceados: Pode ser \u00fatil em conjuntos de dados desbalanceados, onde voc\u00ea quer garantir que cada divis\u00e3o tenha uma propor\u00e7\u00e3o espec\u00edfica de classes.</p> <p>Repetibilidade: \u00datil quando voc\u00ea precisa garantir que as divis\u00f5es sejam as mesmas entre diferentes execu\u00e7\u00f5es, utilizando o par\u00e2metro random_state. Compara\u00e7\u00e3o com Outras T\u00e9cnicas de Valida\u00e7\u00e3o Cruzada K-Fold: Divide os dados em K subconjuntos (folds) de forma sequencial e usa cada fold como conjunto de teste uma vez. ShuffleSplit oferece mais flexibilidade ao permitir divis\u00f5es aleat\u00f3rias repetidas. StratifiedKFold: Similar ao K-Fold, mas preserva a propor\u00e7\u00e3o das classes em cada fold. ShuffleSplit n\u00e3o garante a preserva\u00e7\u00e3o das propor\u00e7\u00f5es de classe por padr\u00e3o, a menos que seja configurado para isso. Em resumo, ShuffleSplit \u00e9 uma ferramenta flex\u00edvel e poderosa para criar divis\u00f5es aleat\u00f3rias dos dados, permitindo uma avalia\u00e7\u00e3o robusta e personalizada do desempenho dos modelos de aprendizado de m\u00e1quina.</p>"},{"location":"futuro/Cross_validacion_skShuffle/#funcao-cross_val_score","title":"Fun\u00e7\u00e3o <code>cross_val_score</code>","text":"<p>A fun\u00e7\u00e3o cross_val_score \u00e9 uma ferramenta essencial no pacote scikit-learn do Python usada para avaliar a performance de um modelo de aprendizado de m\u00e1quina de forma robusta. Aqui est\u00e1 uma vis\u00e3o geral de suas principais funcionalidades:</p> <p>Valida\u00e7\u00e3o Cruzada: A cross_val_score executa a valida\u00e7\u00e3o cruzada, uma t\u00e9cnica usada para avaliar o desempenho de um modelo de aprendizado de m\u00e1quina. A valida\u00e7\u00e3o cruzada divide o conjunto de dados em v\u00e1rias partes, chamadas de folds. O modelo \u00e9 treinado em alguns desses folds (conjunto de treinamento) e avaliado nos folds restantes (conjunto de teste).</p> <p>Estimativa de Performance: A fun\u00e7\u00e3o calcula a performance do modelo em cada um dos folds e retorna uma lista de scores, que podem ser m\u00e9tricas como acur\u00e1cia, precis\u00e3o, recall, F1-score, entre outras, dependendo do problema e da m\u00e9trica escolhida.</p> <p>Redu\u00e7\u00e3o de Overfitting: Ao avaliar o modelo em diferentes subconjuntos dos dados, a valida\u00e7\u00e3o cruzada fornece uma estimativa mais realista de sua performance e ajuda a detectar overfitting, onde o modelo se ajusta excessivamente aos dados de treinamento.</p> <p>Como Usar Aqui est\u00e1 um exemplo b\u00e1sico de como usar a fun\u00e7\u00e3o cross_val_score:</p> <pre><code>from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\n\n# Carregar dados de exemplo\ndata = load_iris()\nX, y = data.data, data.target\n\n# Definir o modelo\nmodel = RandomForestClassifier()\n\n# Executar valida\u00e7\u00e3o cruzada\nscores = cross_val_score(model, X, y, cv=5)  # cv=5 define 5 folds\n\n# Exibir os resultados\nprint(\"Scores de valida\u00e7\u00e3o cruzada:\", scores)\nprint(\"M\u00e9dia dos scores:\", scores.mean())\nprint(\"Desvio padr\u00e3o dos scores:\", scores.std())\n</code></pre> <p>Par\u00e2metros Importantes estimator: O modelo de aprendizado de m\u00e1quina que voc\u00ea deseja avaliar (ex. RandomForestClassifier()). X: As caracter\u00edsticas dos dados de entrada. y: Os r\u00f3tulos ou targets dos dados de entrada. cv: N\u00famero de folds (divis\u00f5es) para a valida\u00e7\u00e3o cruzada. O valor padr\u00e3o \u00e9 5. scoring: M\u00e9trica de avalia\u00e7\u00e3o a ser utilizada (ex. 'accuracy', 'precision', 'recall', etc.). Se n\u00e3o for especificado, a m\u00e9trica padr\u00e3o do modelo ser\u00e1 usada. Retorno A fun\u00e7\u00e3o retorna um array com os scores obtidos em cada um dos folds. Voc\u00ea pode calcular a m\u00e9dia e o desvio padr\u00e3o desses scores para ter uma no\u00e7\u00e3o da variabilidade e performance geral do modelo.</p> <p>Em resumo, cross_val_score \u00e9 uma fun\u00e7\u00e3o poderosa para realizar a valida\u00e7\u00e3o cruzada e obter uma estimativa confi\u00e1vel do desempenho do modelo em diferentes subconjuntos dos dados, ajudando a assegurar que o modelo n\u00e3o est\u00e1 superajustado aos dados de treinamento.</p>"},{"location":"futuro/Cross_validation_pyspark/","title":"Cross validation pyspark","text":"In\u00a0[\u00a0]: Copied! <pre>########################################\n## Title: Spark MLlib Linear Regression Script, with Cross-Validation and Parameter Sweep\n## Language: PySpark\n## Author: Colby T. Ford, Ph.D.\n########################################\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Create initial LinearRegression model\nlr = LinearRegression(labelCol=\"label\", featuresCol=\"features\")\n\n\n# Create ParamGrid for Cross Validation\nlrparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])\n             #  .addGrid(lr.regParam, [0.01, 0.1, 0.5])\n             .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n             #  .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10, 20, 50])\n             #  .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\n\n# Evaluate model\nlrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n\n# Create 5-fold CrossValidator\nlrcv = CrossValidator(estimator = lr,\n                    estimatorParamMaps = lrparamGrid,\n                    evaluator = lrevaluator,\n                    numFolds = 5)\n\n# Run cross validations\nlrcvModel = lrcv.fit(train)\nprint(lrcvModel)\n\n# Get Model Summary Statistics\nlrcvSummary = lrcvModel.bestModel.summary\nprint(\"Coefficient Standard Errors: \" + str(lrcvSummary.coefficientStandardErrors))\nprint(\"P Values: \" + str(lrcvSummary.pValues)) # Last element is the intercept\n\n# Use test set here so we can measure the accuracy of our model on new data\nlrpredictions = lrcvModel.transform(test)\n\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nprint('RMSE:', lrevaluator.evaluate(lrpredictions))\n</pre> ######################################## ## Title: Spark MLlib Linear Regression Script, with Cross-Validation and Parameter Sweep ## Language: PySpark ## Author: Colby T. Ford, Ph.D. ########################################  from pyspark.ml.regression import LinearRegression from pyspark.ml.tuning import ParamGridBuilder, CrossValidator from pyspark.ml.evaluation import RegressionEvaluator  # Create initial LinearRegression model lr = LinearRegression(labelCol=\"label\", featuresCol=\"features\")   # Create ParamGrid for Cross Validation lrparamGrid = (ParamGridBuilder()              .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])              #  .addGrid(lr.regParam, [0.01, 0.1, 0.5])              .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])              #  .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])              .addGrid(lr.maxIter, [1, 5, 10, 20, 50])              #  .addGrid(lr.maxIter, [1, 5, 10])              .build())  # Evaluate model lrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")  # Create 5-fold CrossValidator lrcv = CrossValidator(estimator = lr,                     estimatorParamMaps = lrparamGrid,                     evaluator = lrevaluator,                     numFolds = 5)  # Run cross validations lrcvModel = lrcv.fit(train) print(lrcvModel)  # Get Model Summary Statistics lrcvSummary = lrcvModel.bestModel.summary print(\"Coefficient Standard Errors: \" + str(lrcvSummary.coefficientStandardErrors)) print(\"P Values: \" + str(lrcvSummary.pValues)) # Last element is the intercept  # Use test set here so we can measure the accuracy of our model on new data lrpredictions = lrcvModel.transform(test)  # cvModel uses the best model found from the Cross Validation # Evaluate best model print('RMSE:', lrevaluator.evaluate(lrpredictions))"},{"location":"futuro/book/","title":"Use uma imagem oficial do Rust como base","text":"<p>FROM rust:latest</p>"},{"location":"futuro/book/#instala-o-mdbook-usando-cargo","title":"Instala o mdBook usando Cargo","text":"<p>RUN cargo install mdbook</p>"},{"location":"futuro/book/#define-o-diretorio-de-trabalho-no-container","title":"Define o diret\u00f3rio de trabalho no container","text":"<p>WORKDIR /work</p>"},{"location":"futuro/book/#expoe-a-porta-usada-pelo-mdbook-serve","title":"Exp\u00f5e a porta usada pelo mdBook serve","text":"<p>EXPOSE 3000</p>"},{"location":"futuro/book/#comando-padrao-inicia-o-servidor-mdbook","title":"Comando padr\u00e3o: inicia o servidor mdBook","text":"<p>CMD [\"mdbook\", \"serve\", \"-n\", \"0.0.0.0\"]</p> <p>services:   mdbook:     build:       context: .     volumes:       - .:/work     ports:       - \"3000:3000\"     command: mdbook serve -n 0.0.0.0</p>"},{"location":"futuro/book/#sumario","title":"Sum\u00e1rio","text":"<p>Introdu\u00e7\u00e3o</p>"},{"location":"futuro/book/#ciencia-de-dados","title":"Ci\u00eancia de Dados","text":"<ul> <li>Estat\u00edstica</li> <li>Testes de Hip\u00f3teses<ul> <li>O que s\u00e3o os ts</li> <li>Testes de Hip\u00f3teses com Estat\u00edstica t</li> <li>Intervalo de confian\u00e7a com t student</li> <li>P-valor</li> <li>Notebook: t_student_teste_t</li> <li>Notebook: Permutacion teste</li> </ul> </li> <li>Machine Learning</li> </ul> <p>Este projeto de documenta\u00e7\u00e3o est\u00e1 sendo escrito atrav\u00e9z da biblioteca <code>mdBOOK</code>, seguindo os passos da documenta\u00e7\u00e3o</p> <p>[book] title = \"Ci\u00eancia de Dados\" authors = [\"Espedito Ferreira Alves\"] description = \"Esse livro \u00e9 para salvar os meus conhecimento e estudos sobre ci\u00eancia de dados.\"</p> <p>[output.html] mathjax-support = true</p> <p>[output.html.fold]  enable = true</p> <p>[output.html.playground] editable = true</p>"},{"location":"futuro/format_titulos/","title":"1 1 1 1 Introdu\u00e7\u00e3o","text":"In\u00a0[\u00a0]: Copied! <pre>print('gol')\n</pre> print('gol')"},{"location":"futuro/format_titulos/#1-1-1-1-introducao","title":"1 1 1 1 Introdu\u00e7\u00e3o\u00b6","text":""},{"location":"futuro/format_titulos/#11-11-11-11-o-que-e-estatistica","title":"1.1 1.1 1.1 1.1 O que \u00e9 estat\u00edstica\u00b6","text":""},{"location":"futuro/format_titulos/#111-111-111-111-111-111-exemplos-de-uso","title":"1.1.1 1.1.1 1.1.1 1.1.1 1.1.1 1.1.1 Exemplos de uso\u00b6","text":""},{"location":"futuro/format_titulos/#12-12-12-12-12-12-tipos-de-dados","title":"1.2 1.2 1.2 1.2 1.2 1.2 Tipos de dados\u00b6","text":""},{"location":"futuro/format_titulos/#2-2-2-2-2-2-inferencia","title":"2 2 2 2 2 2. Infer\u00eancia\u00b6","text":""},{"location":"futuro/format_titulos/#21-21-21-21-21-21-teste-de-hipoteses","title":"2.1 2.1 2.1 2.1 2.1 2.1 Teste de hip\u00f3teses\u00b6","text":""},{"location":"futuro/format_titulos/","title":"Format titulos","text":"In\u00a0[\u00a0]: Copied! <pre>import nbformat\nfrom nbformat.v4 import new_notebook\nfrom pathlib import Path\n</pre> import nbformat from nbformat.v4 import new_notebook from pathlib import Path In\u00a0[\u00a0]: Copied! <pre># Define os n\u00edveis de heading (ex: #, ##, ###)\nHEADING_SYMBOLS = ['#', '##', '###', '####']\n</pre> # Define os n\u00edveis de heading (ex: #, ##, ###) HEADING_SYMBOLS = ['#', '##', '###', '####'] In\u00a0[\u00a0]: Copied! <pre># Inicializa contadores por n\u00edvel\ncounters = [0] * len(HEADING_SYMBOLS)\n</pre> # Inicializa contadores por n\u00edvel counters = [0] * len(HEADING_SYMBOLS) In\u00a0[\u00a0]: Copied! <pre>def numerar_heading(text):\n    lines = text.splitlines()\n    new_lines = []\n\n    for line in lines:\n        for i, symbol in enumerate(HEADING_SYMBOLS):\n            if line.strip().startswith(symbol + ' '):\n                # Atualiza contador atual e zera inferiores\n                counters[i] += 1\n                for j in range(i + 1, len(counters)):\n                    counters[j] = 0\n                \n                # Gera prefixo tipo \"1.2.3\"\n                prefix = '.'.join(str(c) for c in counters[:i + 1] if c &gt; 0)\n                new_line = f\"{symbol} {prefix} {line[len(symbol)+1:].strip()}\"\n                new_lines.append(new_line)\n                break\n        else:\n            new_lines.append(line)\n    return '\\n'.join(new_lines)\n</pre> def numerar_heading(text):     lines = text.splitlines()     new_lines = []      for line in lines:         for i, symbol in enumerate(HEADING_SYMBOLS):             if line.strip().startswith(symbol + ' '):                 # Atualiza contador atual e zera inferiores                 counters[i] += 1                 for j in range(i + 1, len(counters)):                     counters[j] = 0                                  # Gera prefixo tipo \"1.2.3\"                 prefix = '.'.join(str(c) for c in counters[:i + 1] if c &gt; 0)                 new_line = f\"{symbol} {prefix} {line[len(symbol)+1:].strip()}\"                 new_lines.append(new_line)                 break         else:             new_lines.append(line)     return '\\n'.join(new_lines) In\u00a0[\u00a0]: Copied! <pre>def aplicar_numeracao_em_notebook(caminho_ipynb):\n    nb = nbformat.read(caminho_ipynb, as_version=4)\n    for cell in nb.cells:\n        if cell.cell_type == 'markdown':\n            cell.source = numerar_heading(cell.source)\n    nbformat.write(nb, caminho_ipynb)\n</pre> def aplicar_numeracao_em_notebook(caminho_ipynb):     nb = nbformat.read(caminho_ipynb, as_version=4)     for cell in nb.cells:         if cell.cell_type == 'markdown':             cell.source = numerar_heading(cell.source)     nbformat.write(nb, caminho_ipynb) In\u00a0[\u00a0]: Copied! <pre># Exemplo de uso\nif __name__ == \"__main__\":\n    caminho = Path(\"teste.ipynb\")  # altere para o caminho correto\n    aplicar_numeracao_em_notebook(caminho)\n    print(f\"Numera\u00e7\u00e3o aplicada com sucesso em: {caminho}\")\n</pre> # Exemplo de uso if __name__ == \"__main__\":     caminho = Path(\"teste.ipynb\")  # altere para o caminho correto     aplicar_numeracao_em_notebook(caminho)     print(f\"Numera\u00e7\u00e3o aplicada com sucesso em: {caminho}\")"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/","title":"PYTHON PARA DATA SCIENCE","text":"PYTHON PARA DATA SCIENCE  1. BIBLIOTECAS <p>Para instalar ou atualizar uma biblioteca no Python, podemos recorrer ao <code>pip</code> que \u00e9 um gerenciador de bibliotecas no Python.</p> In\u00a0[\u00a0]: Copied! <pre># Instalando a biblioteca matplotlib pelo pip\n!pip install matplotlib\n</pre> # Instalando a biblioteca matplotlib pelo pip !pip install matplotlib <pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.5.3)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.15.0)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Instalando uma vers\u00e3o espec\u00edfica do matplotlib\n!pip install matplotlib==3.6.2\n</pre> # Instalando uma vers\u00e3o espec\u00edfica do matplotlib !pip install matplotlib==3.6.2 <pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nRequirement already satisfied: matplotlib==3.6.2 in /usr/local/lib/python3.9/dist-packages (3.6.2)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (1.4.4)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (3.0.9)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (4.39.0)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (0.11.0)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (23.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (2.8.2)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (8.4.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (1.0.7)\nRequirement already satisfied: numpy&gt;=1.19 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.2) (1.22.4)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib==3.6.2) (1.15.0)\n</pre> <p>Existe tamb\u00e9m o PYPI que \u00e9 um reposit\u00f3rio de bibliotecas Python que traz as bibliotecas mais utilizadas pela comunidade junto a informa\u00e7\u00f5es de como usar e acesso as documenta\u00e7\u00f5es de cada uma delas.</p> <ul> <li>PYPI (https://pypi.org/)</li> </ul> In\u00a0[\u00a0]: Copied! <pre># Importando uma biblioteca sem alias\nimport matplotlib\n</pre> # Importando uma biblioteca sem alias import matplotlib In\u00a0[\u00a0]: Copied! <pre>matplotlib.__version__\n</pre> matplotlib.__version__ Out[\u00a0]: <pre>'3.6.2'</pre> In\u00a0[\u00a0]: Copied! <pre># Importando uma biblioteca com alias\nimport matplotlib.pyplot as plt\n</pre> # Importando uma biblioteca com alias import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>plt.show()\n</pre> plt.show() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n</pre> import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre>estudantes = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\"]\nnotas = [8.5, 9, 6.5]\n</pre> estudantes = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\"] notas = [8.5, 9, 6.5] In\u00a0[\u00a0]: Copied! <pre>plt.bar(x = estudantes, height = notas)\n</pre> plt.bar(x = estudantes, height = notas) Out[\u00a0]: <pre>&lt;BarContainer object of 3 artists&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>estudantes_2 = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\", \"Ana\"]\n</pre> estudantes_2 = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\", \"Ana\"] In\u00a0[\u00a0]: Copied! <pre># Importando uma fun\u00e7\u00e3o espec\u00edfica de uma biblioteca\nfrom random import choice\n</pre> # Importando uma fun\u00e7\u00e3o espec\u00edfica de uma biblioteca from random import choice <p>Dica: Voc\u00ea pode notar ao longo de nossa pr\u00e1tica a import\u00e2ncia de recorrer a documenta\u00e7\u00e3o para aprender como utilizar um m\u00e9todo ou pacote na linguagem Python.</p> <p>O m\u00e9todo <code>help()</code>, por exemplo, retorna uma descri\u00e7\u00e3o sobre uma vari\u00e1vel, m\u00e9todo ou classe.</p> <p>https://docs.python.org/pt-br/3/library/functions.html?#help</p> In\u00a0[\u00a0]: Copied! <pre>help(choice)\n</pre> help(choice) <pre>Help on method choice in module random:\n\nchoice(seq) method of random.Random instance\n    Choose a random element from a non-empty sequence.\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>estudante = choice(estudantes_2)\nestudante\n</pre> estudante = choice(estudantes_2) estudante Out[\u00a0]: <pre>'Jos\u00e9'</pre>  2. FUN\u00c7\u00d5ES <p>Na linguagem Python, as fun\u00e7\u00f5es s\u00e3o sequ\u00eancias de instru\u00e7\u00f5es que executam tarefas espec\u00edficas, podendo ser reutilizadas em diferentes partes do c\u00f3digo. Elas podem receber par\u00e2metros de entrada (que podemos chamar de inputs) e tamb\u00e9m retornar resultados.</p> In\u00a0[\u00a0]: Copied! <pre># Notas do(a) estudante\nnotas = {'1\u00ba Trimestre': 8.5, '2\u00ba Trimestre': 9.5, '3\u00ba trimestre': 7}\nnotas\n</pre> # Notas do(a) estudante notas = {'1\u00ba Trimestre': 8.5, '2\u00ba Trimestre': 9.5, '3\u00ba trimestre': 7} notas Out[\u00a0]: <pre>{'1\u00ba Trimestre': 8.5, '2\u00ba Trimestre': 9.5, '3\u00ba trimestre': 7}</pre> In\u00a0[\u00a0]: Copied! <pre># Calculando a soma\nsoma = 0\n\nfor nota in notas.values():\n  soma += nota\n\nsoma\n</pre> # Calculando a soma soma = 0  for nota in notas.values():   soma += nota  soma Out[\u00a0]: <pre>25.0</pre> In\u00a0[\u00a0]: Copied! <pre># Usando a fun\u00e7\u00e3o embutida sum()\nsomatorio = sum(notas.values())\nsomatorio\n</pre> # Usando a fun\u00e7\u00e3o embutida sum() somatorio = sum(notas.values()) somatorio Out[\u00a0]: <pre>25.0</pre> In\u00a0[\u00a0]: Copied! <pre># Usando a fun\u00e7\u00e3o embutida len()\nqtd_notas = len(notas)\nqtd_notas\n</pre> # Usando a fun\u00e7\u00e3o embutida len() qtd_notas = len(notas) qtd_notas Out[\u00a0]: <pre>3</pre> In\u00a0[\u00a0]: Copied! <pre># calculando a m\u00e9dia\nmedia = somatorio / qtd_notas\nmedia\n</pre> # calculando a m\u00e9dia media = somatorio / qtd_notas media Out[\u00a0]: <pre>8.333333333333334</pre> <p>Arredondar a m\u00e9dia usando round():</p> <p>https://docs.python.org/pt-br/3/library/functions.html#round</p> In\u00a0[\u00a0]: Copied! <pre>round?\n</pre> round? In\u00a0[\u00a0]: Copied! <pre>media = somatorio / qtd_notas\nmedia = round(media,1)\nmedia\n</pre> media = somatorio / qtd_notas media = round(media,1) media Out[\u00a0]: <pre>8.3</pre> <p>Depois de explorarmos a built-in functions e aprendermos como utilizar algumas delas, voc\u00ea pode se deparar com a necessidade de resolver um problema espec\u00edfico em que elas n\u00e3o ser\u00e3o o suficiente.</p> <p>Nesse ponto, precisaremos criar as nossas pr\u00f3prias fun\u00e7\u00f5es, ainda mais se precisarmos utiliz\u00e1-las em mais partes de nossos c\u00f3digos.</p> In\u00a0[\u00a0]: Copied! <pre>def media():\n  calculo = (10 + 9 + 8) / 3\n  print(calculo)\n</pre> def media():   calculo = (10 + 9 + 8) / 3   print(calculo) In\u00a0[\u00a0]: Copied! <pre>media()\n</pre> media() <pre>9.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>def media(nota_1, nota_2, nota_3):\n  calculo = (nota_1 + nota_2 + nota_3)/3\n  print(calculo)\n</pre> def media(nota_1, nota_2, nota_3):   calculo = (nota_1 + nota_2 + nota_3)/3   print(calculo) In\u00a0[\u00a0]: Copied! <pre>media(3, 6, 9)\n</pre> media(3, 6, 9) <pre>6.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>nota1 = 8\nnota2 = 7\nnota3 = 6\n\nmedia(nota_1 = nota1, nota_2 = nota2, nota_3 = nota3)\n</pre> nota1 = 8 nota2 = 7 nota3 = 6  media(nota_1 = nota1, nota_2 = nota2, nota_3 = nota3) <pre>7.0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Notas do(a) estudante\nnotas = [8.5, 9.0, 6.0, 10.0]\n</pre> # Notas do(a) estudante notas = [8.5, 9.0, 6.0, 10.0] In\u00a0[\u00a0]: Copied! <pre>def media(lista):\n  calculo = sum(lista) / len(lista)\n  print(calculo)\n</pre> def media(lista):   calculo = sum(lista) / len(lista)   print(calculo) In\u00a0[\u00a0]: Copied! <pre>media(notas)\n</pre> media(notas) <pre>8.375\n</pre> In\u00a0[\u00a0]: Copied! <pre>resultado = media(notas)\n</pre> resultado = media(notas) <pre>8.375\n</pre> In\u00a0[\u00a0]: Copied! <pre>resultado\n</pre> resultado In\u00a0[\u00a0]: Copied! <pre>type(resultado)\n</pre> type(resultado) Out[\u00a0]: <pre>NoneType</pre> <p>Aten\u00e7\u00e3o! Quando utilizamos fun\u00e7\u00f5es precisamos prestar aten\u00e7\u00e3o a uma propriedade chamada escopo de uma fun\u00e7\u00e3o</p> <p>Ela determina onde uma vari\u00e1vel pode ser utilizada dentro do c\u00f3digo. Por exemplo, uma vari\u00e1vel criada dentro de uma fun\u00e7\u00e3o existir\u00e1 apenas dentro da fun\u00e7\u00e3o. Ou seja, encerrando a execu\u00e7\u00e3o da fun\u00e7\u00e3o, a vari\u00e1vel n\u00e3o estar\u00e1 dispon\u00edvel para o usu\u00e1rio no restante do c\u00f3digo.</p> In\u00a0[\u00a0]: Copied! <pre>calculo\n</pre> calculo <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n&lt;ipython-input-34-358730cc7909&gt; in &lt;module&gt;\n----&gt; 1 calculo\n\nNameError: name 'calculo' is not defined</pre> <p>Retomando a atividade anterior, podemos retornar e salvar o valor da m\u00e9dia da seguinte forma:</p> In\u00a0[\u00a0]: Copied! <pre># Notas do(a) estudante\nnotas = [8.5, 9.0, 6.0, 10.0]\n</pre> # Notas do(a) estudante notas = [8.5, 9.0, 6.0, 10.0] In\u00a0[\u00a0]: Copied! <pre>def media(lista):\n  calculo = sum(lista) / len(lista)\n  return calculo\n</pre> def media(lista):   calculo = sum(lista) / len(lista)   return calculo In\u00a0[\u00a0]: Copied! <pre>resultado = media(notas)\n</pre> resultado = media(notas) In\u00a0[\u00a0]: Copied! <pre>resultado\n</pre> resultado Out[\u00a0]: <pre>8.375</pre> In\u00a0[\u00a0]: Copied! <pre># Notas do(a) estudante\nnotas = [6.0, 7.0, 9.0, 5.0]\n</pre> # Notas do(a) estudante notas = [6.0, 7.0, 9.0, 5.0] In\u00a0[\u00a0]: Copied! <pre>def boletim(lista):\n  media = sum(lista) / len(lista)\n\n  if media &gt;= 6:\n    situacao = \"Aprovado(a)\"\n  else:\n    situacao = \"Reprovado(a)\"\n\n  return (media, situacao)\n</pre> def boletim(lista):   media = sum(lista) / len(lista)    if media &gt;= 6:     situacao = \"Aprovado(a)\"   else:     situacao = \"Reprovado(a)\"    return (media, situacao) In\u00a0[\u00a0]: Copied! <pre>boletim(notas)\n</pre> boletim(notas) Out[\u00a0]: <pre>(6.75, 'Aprovado(a)')</pre> In\u00a0[\u00a0]: Copied! <pre>media, situacao = boletim(notas)\n</pre> media, situacao = boletim(notas) In\u00a0[\u00a0]: Copied! <pre>media\n</pre> media Out[\u00a0]: <pre>6.75</pre> In\u00a0[\u00a0]: Copied! <pre>situacao\n</pre> situacao Out[\u00a0]: <pre>'Aprovado(a)'</pre> In\u00a0[\u00a0]: Copied! <pre>print(f'O(a) estudante atingiu uma m\u00e9dia de {media} e foi {situacao}.')\n</pre> print(f'O(a) estudante atingiu uma m\u00e9dia de {media} e foi {situacao}.') <pre>O(a) estudante atingiu uma m\u00e9dia de 6.75 e foi Aprovado(a).\n</pre> In\u00a0[\u00a0]: Copied! <pre># Comparando uma fun\u00e7\u00e3o de qualitativo no formato de fun\u00e7\u00e3o para fun\u00e7\u00e3o an\u00f4nima\nnota = float(input(\"Digite a nota do(a) estudante: \"))\n\ndef qualitativo(x):\n  return x + 0.5\n\nqualitativo(nota)\n</pre> # Comparando uma fun\u00e7\u00e3o de qualitativo no formato de fun\u00e7\u00e3o para fun\u00e7\u00e3o an\u00f4nima nota = float(input(\"Digite a nota do(a) estudante: \"))  def qualitativo(x):   return x + 0.5  qualitativo(nota) <pre>Digite a nota do(a) estudante: 8\n</pre> Out[\u00a0]: <pre>8.5</pre> In\u00a0[\u00a0]: Copied! <pre># Testando a mesma fun\u00e7\u00e3o para uma fun\u00e7\u00e3o lambda\nnota = float(input(\"Digite a nota do(a) estudante: \"))\n\nqualitativo = lambda x: x + 0.5\n\nqualitativo(nota)\n</pre> # Testando a mesma fun\u00e7\u00e3o para uma fun\u00e7\u00e3o lambda nota = float(input(\"Digite a nota do(a) estudante: \"))  qualitativo = lambda x: x + 0.5  qualitativo(nota) <pre>Digite a nota do(a) estudante: 8\n</pre> Out[\u00a0]: <pre>8.5</pre> <p>Partindo para nosso problema:</p> In\u00a0[\u00a0]: Copied! <pre># Recebendo as notas e calculando a m\u00e9dia ponder\u00e1vel\nN1 = float(input(\"Digite a 1\u00aa nota do(a) estudante: \"))\nN2 = float(input(\"Digite a 2\u00aa nota do(a) estudante: \"))\nN3 = float(input(\"Digite a 3\u00aa nota do(a) estudante: \"))\n\nmedia_ponderavel = lambda x, y, z: (x * 3 + y * 2 + z * 5)/10\nmedia_estudante = media_ponderavel(N1, N2, N3)\nmedia_estudante\n</pre> # Recebendo as notas e calculando a m\u00e9dia ponder\u00e1vel N1 = float(input(\"Digite a 1\u00aa nota do(a) estudante: \")) N2 = float(input(\"Digite a 2\u00aa nota do(a) estudante: \")) N3 = float(input(\"Digite a 3\u00aa nota do(a) estudante: \"))  media_ponderavel = lambda x, y, z: (x * 3 + y * 2 + z * 5)/10 media_estudante = media_ponderavel(N1, N2, N3) media_estudante <pre>Digite a 1\u00aa nota do(a) estudante: 8\nDigite a 2\u00aa nota do(a) estudante: 5\nDigite a 3\u00aa nota do(a) estudante: 9\n</pre> Out[\u00a0]: <pre>7.9</pre> In\u00a0[\u00a0]: Copied! <pre># Exibindo a m\u00e9dia\nprint(f'O(a) estudante atingiu uma m\u00e9dia de {media_estudante}')\n</pre> # Exibindo a m\u00e9dia print(f'O(a) estudante atingiu uma m\u00e9dia de {media_estudante}') <pre>O(a) estudante atingiu uma m\u00e9dia de 7.9\n</pre> In\u00a0[\u00a0]: Copied! <pre># Notas do(a) estudante\nnotas = [6.0, 7.0, 9.0, 5.5, 8.0]\nqualitativo = 0.5\n</pre> # Notas do(a) estudante notas = [6.0, 7.0, 9.0, 5.5, 8.0] qualitativo = 0.5 In\u00a0[\u00a0]: Copied! <pre>notas_atualizadas = lambda x: x + qualitativo\nnotas_atualizadas(notas)\n</pre> notas_atualizadas = lambda x: x + qualitativo notas_atualizadas(notas) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-70-42b2d9bbd856&gt; in &lt;module&gt;\n      1 notas_atualizadas = lambda x: x + qualitativo\n----&gt; 2 notas_atualizadas(notas)\n\n&lt;ipython-input-70-42b2d9bbd856&gt; in &lt;lambda&gt;(x)\n----&gt; 1 notas_atualizadas = lambda x: x + qualitativo\n      2 notas_atualizadas(notas)\n\nTypeError: can only concatenate list (not \"float\") to list</pre> In\u00a0[\u00a0]: Copied! <pre># N\u00e3o conseguimos aplicar o lambda em listas direto, \u00e9 necess\u00e1rio \n# utilizarmos junto a ela a fun\u00e7\u00e3o map\nnotas_atualizadas = map(lambda x: x + qualitativo, notas)\nnotas_atualizadas\n</pre> # N\u00e3o conseguimos aplicar o lambda em listas direto, \u00e9 necess\u00e1rio  # utilizarmos junto a ela a fun\u00e7\u00e3o map notas_atualizadas = map(lambda x: x + qualitativo, notas) notas_atualizadas Out[\u00a0]: <pre>&lt;map at 0x7f57f633b5b0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>notas_atualizadas = list(notas_atualizadas)\n</pre> notas_atualizadas = list(notas_atualizadas) In\u00a0[\u00a0]: Copied! <pre>notas_atualizadas\n</pre> notas_atualizadas Out[\u00a0]: <pre>[6.5, 7.5, 9.5, 6.0, 8.5]</pre> In\u00a0[\u00a0]: Copied! <pre>notas\n</pre> notas Out[\u00a0]: <pre>[6.0, 7.0, 9.0, 5.5, 8.0]</pre>  3. ESTRUTURA DE DADOS COMPOSTAS In\u00a0[\u00a0]: Copied! <pre>notas_turma = ['Jo\u00e3o', 8.0, 9.0, 10.0, 'Maria', 9.0, 7.0, 6.0, 'Jos\u00e9', 3.4, 7.0, 7.0, 'Cl\u00e1udia', 5.5, 6.6, 8.0, 'Ana', 6.0, 10.0, 9.5]\n</pre> notas_turma = ['Jo\u00e3o', 8.0, 9.0, 10.0, 'Maria', 9.0, 7.0, 6.0, 'Jos\u00e9', 3.4, 7.0, 7.0, 'Cl\u00e1udia', 5.5, 6.6, 8.0, 'Ana', 6.0, 10.0, 9.5] In\u00a0[\u00a0]: Copied! <pre>nomes = []\nnotas_juntas = []\n\nfor i in range(len(notas_turma)):\n  if i % 4 ==0:\n    nomes.append(notas_turma[i])\n  else:\n    notas_juntas.append(notas_turma[i]) \n</pre> nomes = [] notas_juntas = []  for i in range(len(notas_turma)):   if i % 4 ==0:     nomes.append(notas_turma[i])   else:     notas_juntas.append(notas_turma[i])  In\u00a0[\u00a0]: Copied! <pre>nomes\n</pre> nomes Out[\u00a0]: <pre>['Jo\u00e3o', 'Maria', 'Jos\u00e9', 'Cl\u00e1udia', 'Ana']</pre> In\u00a0[\u00a0]: Copied! <pre>notas_juntas\n</pre> notas_juntas Out[\u00a0]: <pre>[8.0, 9.0, 10.0, 9.0, 7.0, 6.0, 3.4, 7.0, 7.0, 5.5, 6.6, 8.0, 6.0, 10.0, 9.5]</pre> In\u00a0[\u00a0]: Copied! <pre>notas = []\n\nfor i in range(0, len(notas_juntas), 3):\n  notas.append([notas_juntas[i], notas_juntas[i+1], notas_juntas[i+2]])\nnotas\n</pre> notas = []  for i in range(0, len(notas_juntas), 3):   notas.append([notas_juntas[i], notas_juntas[i+1], notas_juntas[i+2]]) notas Out[\u00a0]: <pre>[[8.0, 9.0, 10.0],\n [9.0, 7.0, 6.0],\n [3.4, 7.0, 7.0],\n [5.5, 6.6, 8.0],\n [6.0, 10.0, 9.5]]</pre> In\u00a0[\u00a0]: Copied! <pre>notas[0]\n</pre> notas[0] Out[\u00a0]: <pre>[8.0, 9.0, 10.0]</pre> In\u00a0[\u00a0]: Copied! <pre>notas[0][2]\n</pre> notas[0][2] Out[\u00a0]: <pre>10.0</pre> In\u00a0[\u00a0]: Copied! <pre>estudantes = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\", \"Cl\u00e1udia\", \"Ana\"]\nestudantes\n</pre> estudantes = [\"Jo\u00e3o\", \"Maria\", \"Jos\u00e9\", \"Cl\u00e1udia\", \"Ana\"] estudantes Out[\u00a0]: <pre>['Jo\u00e3o', 'Maria', 'Jos\u00e9', 'Cl\u00e1udia', 'Ana']</pre> In\u00a0[\u00a0]: Copied! <pre>from random import randint\n\ndef gera_codigo():\n  return str(randint(0,999))\n</pre> from random import randint  def gera_codigo():   return str(randint(0,999)) In\u00a0[\u00a0]: Copied! <pre>codigo_estudantes = []\n\nfor i in range(len(estudantes)):\n  codigo_estudantes.append((estudantes[i], estudantes[i][0] + gera_codigo()))\n\ncodigo_estudantes\n</pre> codigo_estudantes = []  for i in range(len(estudantes)):   codigo_estudantes.append((estudantes[i], estudantes[i][0] + gera_codigo()))  codigo_estudantes Out[\u00a0]: <pre>[('Jo\u00e3o', 'J891'),\n ('Maria', 'M316'),\n ('Jos\u00e9', 'J708'),\n ('Cl\u00e1udia', 'C627'),\n ('Ana', 'A317')]</pre> In\u00a0[\u00a0]: Copied! <pre>notas = [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]]\n</pre> notas = [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]] In\u00a0[\u00a0]: Copied! <pre>def media(lista: list=[0]) -&gt; float:\n  ''' Fun\u00e7\u00e3o para calcular a m\u00e9dia de notas passadas por uma lista\n\n  lista: list, default [0]\n    Lista com as notas para calcular a m\u00e9dia\n  return = calculo: float\n    M\u00e9dia calculada\n  '''\n  \n  calculo = sum(lista) / len(lista)\n\n  return calculo\n</pre> def media(lista: list=[0]) -&gt; float:   ''' Fun\u00e7\u00e3o para calcular a m\u00e9dia de notas passadas por uma lista    lista: list, default [0]     Lista com as notas para calcular a m\u00e9dia   return = calculo: float     M\u00e9dia calculada   '''      calculo = sum(lista) / len(lista)    return calculo In\u00a0[\u00a0]: Copied! <pre>medias = [round(media(nota),1) for nota in notas]\nmedias\n</pre> medias = [round(media(nota),1) for nota in notas] medias Out[\u00a0]: <pre>[9.0, 7.3, 5.8, 6.7, 8.5]</pre> In\u00a0[\u00a0]: Copied! <pre>nomes = [('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')]\nmedias = [9.0, 7.3, 5.8, 6.7, 8.5]\n</pre> nomes = [('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')] medias = [9.0, 7.3, 5.8, 6.7, 8.5] In\u00a0[\u00a0]: Copied! <pre># Gerando a lista de nomes (extraindo da tupla)\nnomes = [nome[0] for nome in nomes]\nnomes\n</pre> # Gerando a lista de nomes (extraindo da tupla) nomes = [nome[0] for nome in nomes] nomes Out[\u00a0]: <pre>['Jo\u00e3o', 'Maria', 'Jos\u00e9', 'Cl\u00e1udia', 'Ana']</pre> <p>Dica: Para conseguirmos parear as m\u00e9dias e nomes facilmente, podemos recorrer a mais uma built-in function: <code>zip()</code></p> <p>Ela recebe um ou mais iter\u00e1veis (lista, string, dict, etc.) e retorna-os como um iterador de tuplas onde cada elemento dos iter\u00e1veis s\u00e3o pareados.</p> In\u00a0[\u00a0]: Copied! <pre>estudantes = list(zip(nomes, medias))\nestudantes\n</pre> estudantes = list(zip(nomes, medias)) estudantes Out[\u00a0]: <pre>[('Jo\u00e3o', 9.0), ('Maria', 7.3), ('Jos\u00e9', 5.8), ('Cl\u00e1udia', 6.7), ('Ana', 8.5)]</pre> In\u00a0[\u00a0]: Copied! <pre># Gerando a lista de pessoas candidatas a bolsa\ncandidatos = [estudante[0] for estudante in estudantes if estudante[1] &gt;= 8.0]\ncandidatos\n</pre> # Gerando a lista de pessoas candidatas a bolsa candidatos = [estudante[0] for estudante in estudantes if estudante[1] &gt;= 8.0] candidatos Out[\u00a0]: <pre>['Jo\u00e3o', 'Ana']</pre> In\u00a0[\u00a0]: Copied! <pre>nomes = [('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')]\nnotas = [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]]\nmedias = [9.0, 7.3, 5.8, 6.7, 8.5]\n</pre> nomes = [('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')] notas = [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]] medias = [9.0, 7.3, 5.8, 6.7, 8.5] In\u00a0[\u00a0]: Copied! <pre>situacao = [\"Aprovado(a)\" if media &gt;= 6 else \"Reprovado(a)\" for media in medias]\nsituacao\n</pre> situacao = [\"Aprovado(a)\" if media &gt;= 6 else \"Reprovado(a)\" for media in medias] situacao Out[\u00a0]: <pre>['Aprovado(a)', 'Aprovado(a)', 'Reprovado(a)', 'Aprovado(a)', 'Aprovado(a)']</pre> <p>Dica: Para gerar a lista de listas do enunciado podemos utilizar o formato a seguir</p> <pre>[expr for item in lista de listas]\n</pre> In\u00a0[\u00a0]: Copied! <pre>cadastro = [x for x in [nomes, notas, medias, situacao]]\ncadastro\n</pre> cadastro = [x for x in [nomes, notas, medias, situacao]] cadastro Out[\u00a0]: <pre>[[('Jo\u00e3o', 'J720'),\n  ('Maria', 'M205'),\n  ('Jos\u00e9', 'J371'),\n  ('Cl\u00e1udia', 'C546'),\n  ('Ana', 'A347')],\n [[8.0, 9.0, 10.0],\n  [9.0, 7.0, 6.0],\n  [3.4, 7.0, 7.0],\n  [5.5, 6.6, 8.0],\n  [6.0, 10.0, 9.5]],\n [9.0, 7.3, 5.8, 6.7, 8.5],\n ['Aprovado(a)', 'Aprovado(a)', 'Reprovado(a)', 'Aprovado(a)', 'Aprovado(a)']]</pre> <p>Dica: Podemos recorrer a forma mais simples de gera\u00e7\u00e3o de listas de lista com o uso direto dos colchetes sem necessitar de utilizar as express\u00f5es e o la\u00e7o for na  abrang\u00eancia de listas</p> In\u00a0[\u00a0]: Copied! <pre>lista_completa = [nomes, notas, medias, situacao]\nlista_completa\n</pre> lista_completa = [nomes, notas, medias, situacao] lista_completa Out[\u00a0]: <pre>[[('Jo\u00e3o', 'J720'),\n  ('Maria', 'M205'),\n  ('Jos\u00e9', 'J371'),\n  ('Cl\u00e1udia', 'C546'),\n  ('Ana', 'A347')],\n [[8.0, 9.0, 10.0],\n  [9.0, 7.0, 6.0],\n  [3.4, 7.0, 7.0],\n  [5.5, 6.6, 8.0],\n  [6.0, 10.0, 9.5]],\n [9.0, 7.3, 5.8, 6.7, 8.5],\n ['Aprovado(a)', 'Aprovado(a)', 'Reprovado(a)', 'Aprovado(a)', 'Aprovado(a)']]</pre> In\u00a0[\u00a0]: Copied! <pre>lista_completa = [[('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')],\n                  [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]],\n                  [9.0, 7.3, 5.8, 6.7, 8.5],\n                  ['Aprovado', 'Aprovado', 'Reprovado', 'Aprovado', 'Aprovado']]\n</pre> lista_completa = [[('Jo\u00e3o', 'J720'), ('Maria', 'M205'), ('Jos\u00e9', 'J371'), ('Cl\u00e1udia', 'C546'), ('Ana', 'A347')],                   [[8.0, 9.0, 10.0], [9.0, 7.0, 6.0], [3.4, 7.0, 7.0], [5.5, 6.6, 8.0], [6.0, 10.0, 9.5]],                   [9.0, 7.3, 5.8, 6.7, 8.5],                   ['Aprovado', 'Aprovado', 'Reprovado', 'Aprovado', 'Aprovado']] In\u00a0[\u00a0]: Copied! <pre># Colunas com os tipos dos dados (exceto nome)\ncoluna = [\"Notas\", \"M\u00e9dia Final\", \"Situa\u00e7\u00e3o\"]\n\ncadastro = {coluna[i]: lista_completa[i+1] for i in range(len(coluna))}\ncadastro\n</pre> # Colunas com os tipos dos dados (exceto nome) coluna = [\"Notas\", \"M\u00e9dia Final\", \"Situa\u00e7\u00e3o\"]  cadastro = {coluna[i]: lista_completa[i+1] for i in range(len(coluna))} cadastro Out[\u00a0]: <pre>{'Notas': [[8.0, 9.0, 10.0],\n  [9.0, 7.0, 6.0],\n  [3.4, 7.0, 7.0],\n  [5.5, 6.6, 8.0],\n  [6.0, 10.0, 9.5]],\n 'M\u00e9dia Final': [9.0, 7.3, 5.8, 6.7, 8.5],\n 'Situa\u00e7\u00e3o': ['Aprovado', 'Aprovado', 'Reprovado', 'Aprovado', 'Aprovado']}</pre> In\u00a0[\u00a0]: Copied! <pre># Vamos por fim adicionar o nome dos estudantes, extraindo apenas seus nomes da lista de tuplas\ncadastro[\"Estudante\"] = [lista_completa[0][i][0] for i in range(len(lista_completa[0]))]\ncadastro\n</pre> # Vamos por fim adicionar o nome dos estudantes, extraindo apenas seus nomes da lista de tuplas cadastro[\"Estudante\"] = [lista_completa[0][i][0] for i in range(len(lista_completa[0]))] cadastro Out[\u00a0]: <pre>{'Notas': [[8.0, 9.0, 10.0],\n  [9.0, 7.0, 6.0],\n  [3.4, 7.0, 7.0],\n  [5.5, 6.6, 8.0],\n  [6.0, 10.0, 9.5]],\n 'M\u00e9dia Final': [9.0, 7.3, 5.8, 6.7, 8.5],\n 'Situa\u00e7\u00e3o': ['Aprovado', 'Aprovado', 'Reprovado', 'Aprovado', 'Aprovado'],\n 'Estudante': ['Jo\u00e3o', 'Maria', 'Jos\u00e9', 'Cl\u00e1udia', 'Ana']}</pre>  4. LIDANDO COM EXCE\u00c7\u00d5ES <p>Podemos notar em nosso caminho at\u00e9 aqui a exist\u00eancia de alguns erros e exce\u00e7\u00f5es na execu\u00e7\u00e3o de algum comando. Como uma pessoa cientista de dados ou programador, voc\u00ea precisar\u00e1 estar atento a essas situa\u00e7\u00f5es para evitar bugs ou problemas em seus c\u00f3digos e an\u00e1lises que possam afetar a experi\u00eancia tanto do usu\u00e1rio quanto a efici\u00eancia da sua an\u00e1lise.</p> <p>Existem basicamente duas formas distintas de erros: os erros de sintaxe e as exce\u00e7\u00f5es.</p> <p>Exce\u00e7\u00f5es s\u00e3o erros detectados durante a execu\u00e7\u00e3o e que quebram o fluxo do programa encerrando-o caso n\u00e3o sejam tratadas.</p> <p>Vamos aprender a identificar e tratar algumas das exce\u00e7\u00f5es aqui, mas \u00e9 sempre importante mergulhar na documenta\u00e7\u00e3o para pesquisar e verificar quais se enquadram nos seus projetos.</p> <p>Documenta\u00e7\u00e3o sobre erros e exce\u00e7\u00f5es: https://docs.python.org/3/tutorial/errors.html</p> In\u00a0[2]: Copied! <pre>notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0], \n 'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]}\n</pre> notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0],   'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]} In\u00a0[6]: Copied! <pre>nome = input(\"Digite o nome do(a) estudante: \")\nresultado = notas[nome]\nresultado\n</pre> nome = input(\"Digite o nome do(a) estudante: \") resultado = notas[nome] resultado <pre>Digite o nome do(a) estudante: Afonso\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n&lt;ipython-input-6-088949fbf590&gt; in &lt;module&gt;\n      1 nome = input(\"Digite o nome do(a) estudante: \")\n----&gt; 2 resultado = notas[nome]\n      3 resultado\n\nKeyError: 'Afonso'</pre> In\u00a0[8]: Copied! <pre>try:\n  nome = input(\"Digite o nome do(a) estudante: \")\n  resultado = notas[nome]\nexcept Exception as e:\n  print(type(e), f\"Erro: {e}\")\n</pre> try:   nome = input(\"Digite o nome do(a) estudante: \")   resultado = notas[nome] except Exception as e:   print(type(e), f\"Erro: {e}\") <pre>Digite o nome do(a) estudante: Mirla\n&lt;class 'KeyError'&gt; Erro: 'Mirla'\n</pre> In\u00a0[10]: Copied! <pre>try:\n  nome = input(\"Digite o nome do(a) estudante: \")\n  resultado = notas[nome]\nexcept KeyError:\n  print(\"Estudante n\u00e3o matriculado(a) na turma\")\n</pre> try:   nome = input(\"Digite o nome do(a) estudante: \")   resultado = notas[nome] except KeyError:   print(\"Estudante n\u00e3o matriculado(a) na turma\") <pre>Digite o nome do(a) estudante: Marcelo\nEstudante n\u00e3o matriculado(a) na turma\n</pre> In\u00a0[11]: Copied! <pre>notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0], \n 'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]}\n</pre> notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0],   'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]} In\u00a0[14]: Copied! <pre>try:\n  nome = input(\"Digite o nome do(a) estudante: \")\n  resultado = notas[nome]\nexcept KeyError:\n  print(\"Estudante n\u00e3o matriculado(a) na turma\")\nelse:\n  print(resultado)\n</pre> try:   nome = input(\"Digite o nome do(a) estudante: \")   resultado = notas[nome] except KeyError:   print(\"Estudante n\u00e3o matriculado(a) na turma\") else:   print(resultado) <pre>Digite o nome do(a) estudante: Joaquim\n[5.5, 7.5, 9.0]\n</pre> In\u00a0[15]: Copied! <pre>notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0], \n 'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]}\n</pre> notas = {'Jo\u00e3o': [8.0, 9.0, 10.0], 'Maria': [9.0, 7.0, 6.0], 'Jos\u00e9': [3.4, 7.0, 8.0], 'Cl\u00e1udia': [5.5, 6.6, 8.0],   'Ana': [6.0, 10.0, 9.5], 'Joaquim': [5.5, 7.5, 9.0], 'J\u00falia': [6.0, 8.0, 7.0], 'Pedro': [3.0, 4.0, 6.0]} In\u00a0[17]: Copied! <pre>try:\n  nome = input(\"Digite o nome do(a) estudante: \")\n  resultado = notas[nome]\nexcept KeyError:\n  print(\"Estudante n\u00e3o matriculado(a) na turma\")\nelse:\n  print(resultado)\nfinally:\n  print(\"A consulta foi encerrada!\")\n</pre> try:   nome = input(\"Digite o nome do(a) estudante: \")   resultado = notas[nome] except KeyError:   print(\"Estudante n\u00e3o matriculado(a) na turma\") else:   print(resultado) finally:   print(\"A consulta foi encerrada!\") <pre>Digite o nome do(a) estudante: Bruno\nEstudante n\u00e3o matriculado(a) na turma\nA consulta foi encerrada!\n</pre> <pre>raise NomeDoErro(\"mensagem_desejada\")\n</pre> In\u00a0[18]: Copied! <pre>def media(lista: list=[0]) -&gt; float:\n  ''' Fun\u00e7\u00e3o para calcular a m\u00e9dia de notas passadas por uma lista\n\n  lista: list, default [0]\n    Lista com as notas para calcular a m\u00e9dia\n  return = calculo: float\n    M\u00e9dia calculada\n  '''\n  \n  calculo = sum(lista) / len(lista)\n\n  if len(lista) &gt; 4:\n    raise ValueError(\"A lista n\u00e3o pode possuir mais de 4 notas.\")\n\n  return calculo\n</pre> def media(lista: list=[0]) -&gt; float:   ''' Fun\u00e7\u00e3o para calcular a m\u00e9dia de notas passadas por uma lista    lista: list, default [0]     Lista com as notas para calcular a m\u00e9dia   return = calculo: float     M\u00e9dia calculada   '''      calculo = sum(lista) / len(lista)    if len(lista) &gt; 4:     raise ValueError(\"A lista n\u00e3o pode possuir mais de 4 notas.\")    return calculo In\u00a0[20]: Copied! <pre>notas = [6, 7 , 8, 8, 9]\nresultado = media(notas)\nresultado\n</pre> notas = [6, 7 , 8, 8, 9] resultado = media(notas) resultado <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-20-a84f1db8721f&gt; in &lt;module&gt;\n      1 notas = [6, 7 , 8, 8, 9]\n----&gt; 2 resultado = media(notas)\n      3 resultado\n\n&lt;ipython-input-18-27eb47926b5e&gt; in media(lista)\n     11 \n     12   if len(lista) &gt; 4:\n---&gt; 13     raise ValueError(\"A lista n\u00e3o pode possuir mais de 4 notas.\")\n     14 \n     15   return calculo\n\nValueError: A lista n\u00e3o pode possuir mais de 4 notas.</pre> In\u00a0[21]: Copied! <pre>notas = [6, 7 , 8, 8, 9, \"8\"]\nresultado = media(notas)\nresultado\n</pre> notas = [6, 7 , 8, 8, 9, \"8\"] resultado = media(notas) resultado <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-21-831d84e1e2a0&gt; in &lt;module&gt;\n      1 notas = [6, 7 , 8, 8, 9, \"8\"]\n----&gt; 2 resultado = media(notas)\n      3 resultado\n\n&lt;ipython-input-18-27eb47926b5e&gt; in media(lista)\n      8   '''\n      9 \n---&gt; 10   calculo = sum(lista) / len(lista)\n     11 \n     12   if len(lista) &gt; 4:\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'</pre> In\u00a0[22]: Copied! <pre>try:\n  notas = [6, 7 , 8, 9]\n  resultado = media(notas)\nexcept TypeError:\n  print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\")\nexcept ValueError as e:\n  print(e)\nelse:\n  print(resultado)\nfinally:\n  print(\"A consulta foi encerrada!\")\n</pre> try:   notas = [6, 7 , 8, 9]   resultado = media(notas) except TypeError:   print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\") except ValueError as e:   print(e) else:   print(resultado) finally:   print(\"A consulta foi encerrada!\") <pre>7.5\nA consulta foi encerrada!\n</pre> In\u00a0[23]: Copied! <pre>try:\n  notas = [6, 7 , 8, 9, 8]\n  resultado = media(notas)\nexcept TypeError:\n  print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\")\nexcept ValueError as e:\n  print(e)\nelse:\n  print(resultado)\nfinally:\n  print(\"A consulta foi encerrada!\")\n</pre> try:   notas = [6, 7 , 8, 9, 8]   resultado = media(notas) except TypeError:   print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\") except ValueError as e:   print(e) else:   print(resultado) finally:   print(\"A consulta foi encerrada!\") <pre>A lista n\u00e3o pode possuir mais de 4 notas.\nA consulta foi encerrada!\n</pre> In\u00a0[24]: Copied! <pre>try:\n  notas = [6, 7 , 8, \"9\"]\n  resultado = media(notas)\nexcept TypeError:\n  print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\")\nexcept ValueError as e:\n  print(e)\nelse:\n  print(resultado)\nfinally:\n  print(\"A consulta foi encerrada!\")\n</pre> try:   notas = [6, 7 , 8, \"9\"]   resultado = media(notas) except TypeError:   print(\"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\") except ValueError as e:   print(e) else:   print(resultado) finally:   print(\"A consulta foi encerrada!\") <pre>N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\nA consulta foi encerrada!\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#11-instalacao-e-importacao-de-bibliotecas","title":"1.1 Instala\u00e7\u00e3o e importa\u00e7\u00e3o de bibliotecas\u00b6","text":"<p>Na linguagem Python utiliza-se bastante o conceito de bibliotecas como um conjunto de m\u00f3dulos e fun\u00e7\u00f5es \u00fateis para o usu\u00e1rio. Elas facilitam em reduzir o uso de c\u00f3digos no projeto, mantendo apenas o necess\u00e1rio para a tarefa que desejamos realizar.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#instalando-uma-biblioteca","title":"Instalando uma biblioteca\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#importando-uma-biblioteca","title":"Importando uma biblioteca\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#12-utilizando-pacotesbibliotecas","title":"1.2 Utilizando pacotes/bibliotecas\u00b6","text":"<ul> <li>Documenta\u00e7\u00e3o do Python (https://docs.python.org/pt-br/3/)</li> </ul>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#exemplo-1-vamos-testar-a-biblioteca-matplotlib-para-um-exemplo-de-medias-de-estudantes-de-uma-classe","title":"Exemplo 1: Vamos testar a biblioteca Matplotlib para um exemplo de m\u00e9dias de estudantes de uma classe.\u00b6","text":"<p>(https://matplotlib.org/stable/tutorials/introductory/pyplot.html)</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#exemplo-2-vamos-selecionar-aleatoriamente-um-aluno-para-apresentar-o-seu-trabalho-de-ciencia-de-dados-usando-a-biblioteca-random","title":"Exemplo 2: Vamos selecionar aleatoriamente um aluno para apresentar o seu trabalho de ci\u00eancia de dados usando a biblioteca Random\u00b6","text":"<p>(https://docs.python.org/pt-br/3/library/random.html)</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#21-built-in-function","title":"2.1 Built-in function\u00b6","text":"<p>O interpretador do Python j\u00e1 possui uma s\u00e9rie de fun\u00e7\u00f5es embutidas que podem ser invocadas a qualquer momento. Algumas que vamos utilizar ao longo desse curso s\u00e3o: type(), print(), list(), zip(), sum(), map() etc.</p> <p>Documenta\u00e7\u00e3o: https://docs.python.org/pt-br/3/library/functions.html</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-1","title":"Situa\u00e7\u00e3o 1:\u00b6","text":"<p>A escola em que estamos construindo o nosso case de dados compartilhou os dados das notas de um estudante para que pud\u00e9ssemos calcular a m\u00e9dia deste em at\u00e9 uma casa decimal.</p> <p>Os dados recebidos correspondem a um dicion\u00e1rio com as chaves indicando o trimestre em quest\u00e3o e os valores das notas de cada trimestre do estudante em uma dada mat\u00e9ria.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#22-criando-funcoes","title":"2.2 Criando fun\u00e7\u00f5es\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#funcoes-sem-parametros","title":"Fun\u00e7\u00f5es sem par\u00e2metros\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>def &lt;nome&gt;():\n  &lt;instru\u00e7\u00f5es&gt;\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#funcoes-com-parametros","title":"Fun\u00e7\u00f5es com par\u00e2metros\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>def &lt;nome&gt;(&lt;param_1&gt;, &lt;param_2&gt;, ..., &lt;param_n&gt;):\n  &lt;instru\u00e7\u00f5es&gt;\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-2","title":"Situa\u00e7\u00e3o 2:\u00b6","text":"<p>Recebemos uma demanda de calcular a m\u00e9dia de um estudante a partir de uma lista, sendo poss\u00edvel alterar a quantidade de notas, sem impedir que o c\u00e1lculo seja refeito.</p> <p>Os dados recebidos, desta vez, correspondem a uma lista contendo apenas as notas de um estudante em uma dada mat\u00e9ria.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos aplicar \u00e0s notas de apenas um estudante, mas voc\u00ea pode testar outros casos para treinar.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#23-funcoes-que-retornam-valores","title":"2.3 Fun\u00e7\u00f5es que retornam valores\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>def &lt;nome&gt;(&lt;param_1&gt;, &lt;param_2&gt;, ..., &lt;param_n&gt;):\n  &lt;instru\u00e7\u00f5es&gt;\n  return resultado\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-3","title":"Situa\u00e7\u00e3o 3:\u00b6","text":"<p>Recebemos uma nova demanda, desta vez, de calcular a m\u00e9dia de um estudante a partir de uma lista e retornar tanto a m\u00e9dia quanto a situa\u00e7\u00e3o do estudante (\"Aprovado(a)\" se a nota for maior ou igual a 6.0, caso contr\u00e1rio, ser\u00e1 \"Reprovado(a)\").</p> <p>Al\u00e9m disso, precisamos exibir um pequeno texto em que indicamos a m\u00e9dia do(a) estudante e qual a situa\u00e7\u00e3o. Os dados recebidos correspondem a uma lista contendo apenas as notas de um estudante em uma dada mat\u00e9ria.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos aplicar as notas de apenas um estudante, mas voc\u00ea pode testar outros casos para treinar.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#24-funcoes-lambda","title":"2.4 Fun\u00e7\u00f5es lambda\u00b6","text":"<p>Tamb\u00e9m chamadas de fun\u00e7\u00f5es an\u00f4nimas, s\u00e3o fun\u00e7\u00f5es que n\u00e3o precisam ser definidas, ou seja n\u00e3o possuem um nome, e descrevem em uma \u00fanica linha os comandos que desejamos aplicar.</p> <p>https://docs.python.org/pt-br/3/reference/expressions.html?#lambda</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>lambda &lt;variavel&gt;: &lt;expressao&gt;\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-4","title":"Situa\u00e7\u00e3o 4:\u00b6","text":"<p>Nesta nova demanda, precisamos criar uma calculadora simples da m\u00e9dia ponderada de notas de uma dada mat\u00e9ria. Vamos requisitar ao usu\u00e1rio a entrada das 3 notas (N1, N2, N3) do estudante e devolver a m\u00e9dia ponderada deste estudante. Os pesos das notas s\u00e3o de, respectivamente 3, 2, 5.</p> <p>Precisamos exibir um pequeno texto em que indicamos a m\u00e9dia do(a) estudante.</p> <p>Vamos resolver esse desafio?</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#mapeando-valores","title":"Mapeando valores\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>map(&lt;lambda function&gt;, &lt;iterador&gt;)\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-5","title":"Situa\u00e7\u00e3o 5:\u00b6","text":"<p>Recebemos mais uma demanda, desta vez, para criar uma pequena fun\u00e7\u00e3o que pudesse adicionar qualitativo (pontua\u00e7\u00e3o extra) \u00e0s notas do trimestre dos estudantes da turma que ganhou a gincana de programa\u00e7\u00e3o promovida pela escola. Cada estudante receber\u00e1 o qualitativo de 0.5 acrescido \u00e0 m\u00e9dia.</p> <p>Os dados recebidos correspondem a uma lista contendo as notas de alguns estudantes e uma vari\u00e1vel com o qualitativo recebido.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos aplicar o qualitativo \u00e0s notas de 5 estudantes, mas voc\u00ea pode testar outros casos para treinar.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#31-estruturas-aninhadas","title":"3.1 Estruturas aninhadas\u00b6","text":"<p>Aprendemos anteriormente a manipular listas, tuplas e dicion\u00e1rios para trabalhar com uma sequ\u00eancia ou cole\u00e7\u00e3o de valores sejam num\u00e9ricos, categ\u00f3ricos, etc. Nessa aula, vamos aprofundar em outra situa\u00e7\u00e3o comum para a pessoa cientista de dados que \u00e9 trabalhar com esses tipos de estruturas aninhadas, ou seja, quando possu\u00edmos por exemplo listas dentro de uma lista.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#lista-de-listas","title":"Lista de listas\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>[[a1, a2,...,an], [b1, b2,...,bn], ..., [n1, n2,...,nn]]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-6","title":"Situa\u00e7\u00e3o 6:\u00b6","text":"<p>Recebemos a demanda de transformar uma lista com o nome e as notas dos tr\u00eas trimestres de estudantes em uma lista simples com os nomes separados das notas e uma lista de listas com as tr\u00eas notas de cada estudante separadas umas das outras. Os dados recebidos correspondem a uma lista com os nomes e as respectivas notas de cada estudante.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos trabalhar com uma turma fict\u00edcia de 5 estudantes.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#lista-de-tuplas","title":"Lista de tuplas\u00b6","text":""},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>[(a1, a2,...,an), (b1, b2,...,bn), ..., (n1, n2,...,nn)]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-7","title":"Situa\u00e7\u00e3o 7:\u00b6","text":"<p>Nesta nova demanda, precisamos gerar uma lista de tuplas com os nomes dos estudantes e o c\u00f3digo ID de cada um para a plataforma de an\u00e1lise dos dados. A cria\u00e7\u00e3o do c\u00f3digo consiste em concatenar a primeira letra do nome do estudante a um n\u00famero aleat\u00f3rio de 0 a 999. Os dados recebidos correspondem a uma lista dos nomes de cada estudante.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos trabalhar com uma turma fict\u00edcia de 5 estudantes.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#32-list-comprehension","title":"3.2 List comprehension\u00b6","text":"<p>\u00c9 uma forma simples e concisa de criar uma lista. Podemos aplicar condicionais e la\u00e7os para criar diversos tipos de listas a partir de padr\u00f5es que desejamos para a nossa estrutura de dados.</p> <p>https://docs.python.org/pt-br/3/tutorial/datastructures.html?#list-comprehensions</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>[express\u00e3o for item in lista]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-8","title":"Situa\u00e7\u00e3o 8:\u00b6","text":"<p>Recebemos a demanda de criar uma lista com as m\u00e9dias dos estudantes da lista de listas que criamos na Situa\u00e7\u00e3o 6. Lembrando que cada lista da lista de listas possui as tr\u00eas notas de cada estudante.</p> <p>Vamos resolver esse desafio?</p> <p>Dica: Utilize o formato:</p> <pre>[exress\u00e3o for item in lista]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-9","title":"Situa\u00e7\u00e3o 9:\u00b6","text":"<p>Agora, precisamos utilizar as m\u00e9dias calculadas no exemplo anterior, pareando com o nome dos estudantes. Isto ser\u00e1 necess\u00e1rio para gerar uma lista que selecione aqueles estudantes que possuam uma m\u00e9dia final maior ou igual a 8 para concorrer a uma bolsa para o pr\u00f3ximo ano letivo. Os dados recebidos correspondem a uma lista de tuplas com os nomes e c\u00f3digos dos estudantes e a lista de m\u00e9dias calculadas logo acima.</p> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos trabalhar com uma turma fict\u00edcia de 5 estudantes.</p> <p>Dica: Utilize o formato:</p> <pre>[expr for item in lista if cond]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-10","title":"Situa\u00e7\u00e3o 10:\u00b6","text":"<p>Recebemos duas demandas a respeito desse projeto com as notas dos estudantes:</p> <ul> <li>Criar uma lista da situa\u00e7\u00e3o dos estudantes em que caso se sua m\u00e9dia seja maior ou igual a 6 receber\u00e1 o valor \"Aprovado\" e caso contr\u00e1rio receber\u00e1 o valor \"Reprovado\".</li> <li>Gerar uma lista de listas com:<ul> <li>Lista de tuplas com o nome dos estudantes e seus c\u00f3digos</li> <li>Lista de listas com as notas de cada estudante</li> <li>Lista com as m\u00e9dias de cada estudante</li> <li>Lista da situa\u00e7\u00e3o dos estudantes de acordo com as m\u00e9dias</li> </ul> </li> </ul> <p>Os dados que utilizaremos s\u00e3o os mesmos que geramos nas situa\u00e7\u00f5es anteriores (<code>nomes</code>, <code>notas</code>, <code>medias</code>).</p> <p>Vamos resolver esse desafio?</p> <p>Para seguirmos o processo, vou deixar logo abaixo as estruturas de dados que j\u00e1 produzimos.</p> <p>Dica: Para a lista das situa\u00e7\u00f5es utilize o formato:</p> <pre>[resultado_if if cond else resultado_else for item in lista]\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#33-dict-comprehension","title":"3.3 Dict comprehension\u00b6","text":"<p>\u00c9 uma forma simples e concisa de criar ou modificar um dicion\u00e1rio. Podemos aplicar condicionais e la\u00e7os para criar diversos tipos de dicion\u00e1rios a partir de padr\u00f5es que desejamos para a nossa estrutura de dados e com o suporte de iter\u00e1veis como listas ou sets.</p> <p>https://peps.python.org/pep-0274/</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#formato-padrao","title":"Formato padr\u00e3o:\u00b6","text":"<pre>{chave: valor for item in lista}\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-11","title":"Situa\u00e7\u00e3o 11:\u00b6","text":"<p>Agora, a nossa demanda consiste em gerar um dicion\u00e1rio a partir da lista de listas que criamos na Situa\u00e7\u00e3o 10 para passar para a pessoa respons\u00e1vel por construir as tabelas para a an\u00e1lise dos dados.</p> <ul> <li>As chaves do nosso dicion\u00e1rio ser\u00e3o as colunas identificando o tipo de dado</li> <li>Os valores ser\u00e3o as listas com os dados correspondentes \u00e0quela chave.</li> </ul> <p>Vamos resolver esse desafio?</p> <p>Para facilitar o nosso entendimento do processo vamos trabalhar com uma turma fict\u00edcia de 5 estudantes.</p> <p>Dica: Utilize o formato</p> <pre>{chave: valor for item in lista}\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#41-tratando-excecoes","title":"4.1 Tratando Exce\u00e7\u00f5es\u00b6","text":"<p>O tratamento das exce\u00e7\u00f5es contribui estabelecendo um fluxo alternativo para a execu\u00e7\u00e3o do c\u00f3digo evitando a interrup\u00e7\u00e3o dos processos inesperadamente.</p> <p>Existe uma s\u00e9rie de exce\u00e7\u00f5es e a partir do comportamento que queremos e dos erros que queremos tratar \u00e9 poss\u00edvel construir um caminho para o usu\u00e1rio ou fornecer mais detalhes sobre aquela exce\u00e7\u00e3o.</p> <ul> <li>Hierarquia das Exce\u00e7\u00f5es (https://docs.python.org/3/library/exceptions.html#exception-hierarchy)</li> </ul>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#try-except","title":"Try ... Except\u00b6","text":"<pre>try:\n  # c\u00f3digo a ser executado. Caso uma exce\u00e7\u00e3o seja lan\u00e7ada, pare imediatamente\nexcept &lt;nome_da_excecao as e&gt;:\n  # Se uma exce\u00e7\u00e3o for lan\u00e7ada no try, rode esse c\u00f3digo, sen\u00e3o pule esta etapa\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-12","title":"Situa\u00e7\u00e3o 12:\u00b6","text":"<p>Voc\u00ea criou um c\u00f3digo que l\u00ea um dicion\u00e1rio com as notas dos estudantes e quis retornar a lista de notas de um estudante.</p> <p>Caso o(a) estudante n\u00e3o esteja matriculado(a) na turma devemos tratar a exce\u00e7\u00e3o para aparecer a mensagem \"Estudante n\u00e3o matriculado(a) na turma\".</p> <p>Vamos trabalhar nesse exemplo com a exce\u00e7\u00e3o Key Error que interromper\u00e1 o processo desse peda\u00e7o do c\u00f3digo.</p> <p>Vamos testar esse primeiro tratamento?</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#adicionando-o-else","title":"Adicionando o Else\u00b6","text":"<pre>try:\n  # c\u00f3digo a ser executado. Caso uma exce\u00e7\u00e3o seja lan\u00e7ada, pare imediatamente\nexcept:\n  # Se uma exce\u00e7\u00e3o for lan\u00e7ada no try, rode esse c\u00f3digo, sen\u00e3o pule esta etapa\nelse:\n  # Se n\u00e3o houver uma exe\u00e7\u00e3o lan\u00e7ada pelo try, rode essa parte\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-13","title":"Situa\u00e7\u00e3o 13:\u00b6","text":"<p>Voc\u00ea criou um c\u00f3digo que l\u00ea um dicion\u00e1rio com as notas dos estudantes e quis retornar a lista de notas de um estudante.</p> <p>Caso o(a) estudante n\u00e3o esteja matriculado(a) na classe devemos tratar a exce\u00e7\u00e3o para aparecer a mensagem \"Estudante n\u00e3o matriculado(a) na turma\" e se a exce\u00e7\u00e3o n\u00e3o for lan\u00e7ada devemos exibir a lista com as notas do(a) estudante.</p> <p>Vamos trabalhar nesse exemplo com a exce\u00e7\u00e3o Key Error que interromper\u00e1 o processo desse peda\u00e7o do c\u00f3digo.</p> <p>Vamos testar esse tratamento?</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#adicionando-o-finally","title":"Adicionando o finally\u00b6","text":"<pre>try:\n  # c\u00f3digo a ser executado. Caso uma exce\u00e7\u00e3o seja lan\u00e7ada, pare imediatamente\nexcept:\n  # Se uma exce\u00e7\u00e3o for lan\u00e7ada no try, rode esse c\u00f3digo, sen\u00e3o pule esta etapa\nelse:\n  # Se n\u00e3o houver uma exe\u00e7\u00e3o lan\u00e7ada pelo try, rode essa parte\nfinally:\n  # Rode essa parte (com ou sem exce\u00e7\u00e3o)\n</pre>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-14","title":"Situa\u00e7\u00e3o 14:\u00b6","text":"<p>Voc\u00ea criou um c\u00f3digo que l\u00ea um dicion\u00e1rio com as notas dos estudantes e quis retornar a lista de notas de um estudante.</p> <p>Caso o(a) estudante n\u00e3o esteja matriculado(a) na classe devemos tratar a exce\u00e7\u00e3o para aparecer a mensagem \"Estudante n\u00e3o matriculado(a) na turma\" e se a exce\u00e7\u00e3o n\u00e3o for lan\u00e7ada devemos exibir a lista com as notas do(a) estudante. Um texto avisando que \"A consulta foi encerrada!\" deve ser exibido com ou sem a exce\u00e7\u00e3o ser lan\u00e7ada.</p> <p>Vamos trabalhar nesse exemplo com a exce\u00e7\u00e3o Key Error que interromper\u00e1 o processo desse peda\u00e7o do c\u00f3digo.</p> <p>Vamos testar esse tratamento?</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#42-raise","title":"4.2 Raise\u00b6","text":"<p>Uma outra forma de trabalhar com as exce\u00e7\u00f5es em seu c\u00f3digo, \u00e9 criar as suas pr\u00f3prias exce\u00e7\u00f5es para determinados comportamentos que deseja em seu c\u00f3digo.</p> <p>Para isso, utilizamos a palavra-chave <code>raise</code> junto ao tipo de exce\u00e7\u00e3o que deseja lan\u00e7ar e uma mensagem a ser exibida.</p>"},{"location":"futuro/6_Projeto_Cursos/Aula%2B04%2B-%2BPython%2Bpara%2BData%2BScience/#situacao-15","title":"Situa\u00e7\u00e3o 15:\u00b6","text":"<p>Voc\u00ea criou uma fun\u00e7\u00e3o para calcular a m\u00e9dia de um estudante em uma dada mat\u00e9ria passando em uma lista as notas deste estudante.</p> <p>Voc\u00ea pretende tratar 2 situa\u00e7\u00f5es:</p> <ul> <li>Se a lista possuir um valor n\u00e3o num\u00e9rico o c\u00e1lculo de m\u00e9dia n\u00e3o ser\u00e1 executado e uma mensagem de \"N\u00e3o foi poss\u00edvel calcular a m\u00e9dia do(a) estudante. S\u00f3 s\u00e3o aceitos valores num\u00e9ricos!\" ser\u00e1 exibida.</li> <li>Caso a lista tenha mais de 4 notas, ser\u00e1 lan\u00e7ada uma exce\u00e7\u00e3o do tipo ValueError informando que \"A lista n\u00e3o pode possuir mais de 4 notas.\"</li> </ul> <p>Um texto avisando que \"A consulta foi encerrada!\" deve ser exibido com ou sem a exce\u00e7\u00e3o ser lan\u00e7ada.</p> <p>Vamos resolver esse desafio?</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/","title":"Exercise: Train a simple linear regression model","text":"In\u00a0[3]: Copied! <pre>import pandas\n# !pip install statsmodels\n# !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n# !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv\n\n# Convert it into a table using pandas\ndataset = pandas.read_csv(\"doggy-illness.csv\", delimiter=\"\\t\")\n\n# Print the data\ndataset\n</pre> import pandas # !pip install statsmodels # !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py # !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv  # Convert it into a table using pandas dataset = pandas.read_csv(\"doggy-illness.csv\", delimiter=\"\\t\")  # Print the data dataset Out[3]: male attended_training age body_fat_percentage core_temperature ate_at_tonys_steakhouse needed_intensive_care protein_content_of_last_meal 0 0 1 6.9 38 38.423169 0 0 7.66 1 0 1 5.4 32 39.015998 0 0 13.36 2 1 1 5.4 12 39.148341 0 0 12.90 3 1 0 4.8 23 39.060049 0 0 13.45 4 1 0 4.8 15 38.655439 0 0 10.53 ... ... ... ... ... ... ... ... ... 93 0 0 4.5 38 37.939942 0 0 7.35 94 1 0 1.8 11 38.790426 1 1 12.18 95 0 0 6.6 20 39.489962 0 0 15.84 96 0 0 6.9 32 38.575742 1 1 9.79 97 1 1 6.0 21 39.766447 1 1 21.30 <p>98 rows \u00d7 8 columns</p> <p>We have a variety of information, including what the dogs did the night before, their age, whether they're overweight, and their clinical signs. In this exercise, our y values, or labels, are represented by the <code>core_temperature</code> column, while our feature will be the <code>age</code>, in years.</p> In\u00a0[4]: Copied! <pre>import graphing as graphing\n\ngraphing.histogram(dataset, label_x='age', nbins=10, title=\"Feature\", show=True)\ngraphing.histogram(dataset, label_x='core_temperature', nbins=10, title=\"Label\")\n</pre> import graphing as graphing  graphing.histogram(dataset, label_x='age', nbins=10, title=\"Feature\", show=True) graphing.histogram(dataset, label_x='core_temperature', nbins=10, title=\"Label\")  <p>Looking at our feature (<code>age</code>), we can see dogs were at or under 9 years of age, and ages are evenly distributed. In other words, no particular age is substantially more common than any other.</p> <p>Looking at our label (<code>core_temperature</code>), most dogs seem to have a slightly elevated core temperature (we would normally expect ~37.5 degrees celcius), which indicates they're unwell. A small number of dogs have a temperatue above 40 degrees, which indicates they're quite unwell.</p> <p>Simply because the shape of these distributions is different, we can guess that the feature will not be able to predict the label extremely well. For example, if old age perfectly predicted who would have a high temperature, then the number of old dogs would exactly match the number of dogs with a high temperature.</p> <p>The model might still end up being useful though, so lets continue.</p> <p>The next step is to eyeball the relationship. Lets plot relation between the labels and features.</p> In\u00a0[5]: Copied! <pre>graphing.scatter_2D(dataset, label_x=\"age\", label_y=\"core_temperature\", title='core temperature as a function of age')\n</pre> graphing.scatter_2D(dataset, label_x=\"age\", label_y=\"core_temperature\", title='core temperature as a function of age') <p>It does seem that older dogs tended to have higher temperatures than younger dogs. The relationship is quite 'noisy', though: many dogs of the same age have quite different temperatures.</p> In\u00a0[6]: Copied! <pre>import statsmodels.formula.api as smf\nimport graphing # custom graphing code. See our GitHub repo for details\n\n# First, we define our formula using a special syntax\n# This says that core temperature is explained by age\nformula = \"core_temperature ~ age\"\n\n# Perform linear regression. This method takes care of\n# the entire fitting procedure for us.\nmodel = smf.ols(formula = formula, data = dataset).fit()\n\n# Show a graph of the result\ngraphing.scatter_2D(dataset,    label_x=\"age\", \n                                label_y=\"core_temperature\",\n                                trendline=lambda x: model.params[1] * x + model.params[0]\n                                )\n</pre> import statsmodels.formula.api as smf import graphing # custom graphing code. See our GitHub repo for details  # First, we define our formula using a special syntax # This says that core temperature is explained by age formula = \"core_temperature ~ age\"  # Perform linear regression. This method takes care of # the entire fitting procedure for us. model = smf.ols(formula = formula, data = dataset).fit()  # Show a graph of the result graphing.scatter_2D(dataset,    label_x=\"age\",                                  label_y=\"core_temperature\",                                 trendline=lambda x: model.params[1] * x + model.params[0]                                 ) <p>The line seems to fit the data quite well, validating our hypothesis that there is a positive correlation between a dog's age and their core temperature.</p> In\u00a0[7]: Copied! <pre>print(\"Intercept:\", model.params[0], \"Slope:\", model.params[1])\n</pre> print(\"Intercept:\", model.params[0], \"Slope:\", model.params[1]) <pre>Intercept: 38.0878675488921 Slope: 0.15333957754731808\n</pre> <p>Remember that simple linear regression models are explained by the line intercept and the line slope.</p> <p>Here, our intercept is 38 degrees celcius. This means that when <code>age</code> is <code>0</code>, the model will predict 38 degrees.</p> <p>Our slope is 0.15 degrees celcius, meaning that for every year of age, the model will predict temperatures 0.15 degrees higher.</p> <p>In the box below, try to change the age to a few different values to see different predictions, and compare these with the line in the graph above.</p> In\u00a0[8]: Copied! <pre>def estimate_temperature(age):\n    # Model param[0] is the intercepts and param[1] is the slope\n    return age * model.params[1] + model.params[0]\n\nprint(\"Estimate temperature from age\")\nprint(estimate_temperature(age=0))\n</pre> def estimate_temperature(age):     # Model param[0] is the intercepts and param[1] is the slope     return age * model.params[1] + model.params[0]  print(\"Estimate temperature from age\") print(estimate_temperature(age=0)) <pre>Estimate temperature from age\n38.0878675488921\n</pre>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#exercise-train-a-simple-linear-regression-model","title":"Exercise: Train a simple linear regression model\u00b6","text":"<p>In this exercise, we'll train a simple linear regression model to predict body temperature based on dog's ages, and interpret the result.</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#loading-data","title":"Loading data\u00b6","text":"<p>Let's begin by having a look at our data.</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#data-visualization","title":"Data visualization\u00b6","text":"<p>Let's have a look at how the features and labels are distributed.</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#simple-linear-regression","title":"Simple linear regression\u00b6","text":"<p>Let's formally examine the relationship between our labels and features by fitting a line (simple linear regression model) to the dataset.</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#interpreting-our-model","title":"Interpreting our model\u00b6","text":"<p>Visually, simple linear regression is easy to understand. Let's recap on what the parameters mean though.</p>"},{"location":"futuro/Notebooks_referencia/4-3-exercise-train-linear-regression/#summary","title":"Summary\u00b6","text":"<p>We covered the following concepts in this exercise:</p> <ul> <li>Quickly visualizing a dataset</li> <li>Qualitatively assessing a linear relationship</li> <li>Build a simple linear regression model</li> <li>Understanding parameters of a simple linear regression model</li> </ul>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/","title":"Exercise: Train a multiple linear regression model","text":"In\u00a0[3]: Copied! <pre>import pandas\n# !pip install statsmodels\n# !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n# !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv\n\n#Import the data from the .csv file\ndataset = pandas.read_csv('doggy-illness.csv', delimiter=\"\\t\")\n\n#Let's have a look at the data\ndataset\n</pre> import pandas # !pip install statsmodels # !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py # !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv  #Import the data from the .csv file dataset = pandas.read_csv('doggy-illness.csv', delimiter=\"\\t\")  #Let's have a look at the data dataset Out[3]: male attended_training age body_fat_percentage core_temperature ate_at_tonys_steakhouse needed_intensive_care protein_content_of_last_meal 0 0 1 6.9 38 38.423169 0 0 7.66 1 0 1 5.4 32 39.015998 0 0 13.36 2 1 1 5.4 12 39.148341 0 0 12.90 3 1 0 4.8 23 39.060049 0 0 13.45 4 1 0 4.8 15 38.655439 0 0 10.53 ... ... ... ... ... ... ... ... ... 93 0 0 4.5 38 37.939942 0 0 7.35 94 1 0 1.8 11 38.790426 1 1 12.18 95 0 0 6.6 20 39.489962 0 0 15.84 96 0 0 6.9 32 38.575742 1 1 9.79 97 1 1 6.0 21 39.766447 1 1 21.30 <p>98 rows \u00d7 8 columns</p> <p>For this exercise, we'll try to predict <code>core_temperature</code> from some of the other available features.</p> In\u00a0[4]: Copied! <pre>import graphing # Custom graphing code that uses Plotly. See our GitHub repository for details\n\ngraphing.box_and_whisker(dataset, \"male\", \"core_temperature\", show=True)\ngraphing.box_and_whisker(dataset, \"attended_training\", \"core_temperature\", show=True)\ngraphing.box_and_whisker(dataset, \"ate_at_tonys_steakhouse\", \"core_temperature\", show=True)\ngraphing.scatter_2D(dataset, \"body_fat_percentage\", \"core_temperature\", show=True)\ngraphing.scatter_2D(dataset, \"protein_content_of_last_meal\", \"core_temperature\", show=True)\ngraphing.scatter_2D(dataset, \"age\", \"core_temperature\")\n</pre> import graphing # Custom graphing code that uses Plotly. See our GitHub repository for details  graphing.box_and_whisker(dataset, \"male\", \"core_temperature\", show=True) graphing.box_and_whisker(dataset, \"attended_training\", \"core_temperature\", show=True) graphing.box_and_whisker(dataset, \"ate_at_tonys_steakhouse\", \"core_temperature\", show=True) graphing.scatter_2D(dataset, \"body_fat_percentage\", \"core_temperature\", show=True) graphing.scatter_2D(dataset, \"protein_content_of_last_meal\", \"core_temperature\", show=True) graphing.scatter_2D(dataset, \"age\", \"core_temperature\") <p>At a glance, fatter, older, and male dogs seem to more commonly have higher temperatures than thinner, younger, or female dogs. Dogs who ate a lot of protein last night also seem to be more unwell. The other features don't seem particularly useful.</p> In\u00a0[5]: Copied! <pre>import statsmodels.formula.api as smf\nimport graphing # custom graphing code. See our GitHub repo for details\n\nfor feature in [\"male\", \"age\", \"protein_content_of_last_meal\", \"body_fat_percentage\"]:\n    # Perform linear regression. This method takes care of\n    # the entire fitting procedure for us.\n    formula = \"core_temperature ~ \" + feature\n    simple_model = smf.ols(formula = formula, data = dataset).fit()\n\n    print(feature)\n    print(\"R-squared:\", simple_model.rsquared)\n    \n    # Show a graph of the result\n    graphing.scatter_2D(dataset, label_x=feature, \n                                 label_y=\"core_temperature\",\n                                 title = feature,\n                                 trendline=lambda x: simple_model.params[1] * x + simple_model.params[0],\n                                 show=True)\n</pre> import statsmodels.formula.api as smf import graphing # custom graphing code. See our GitHub repo for details  for feature in [\"male\", \"age\", \"protein_content_of_last_meal\", \"body_fat_percentage\"]:     # Perform linear regression. This method takes care of     # the entire fitting procedure for us.     formula = \"core_temperature ~ \" + feature     simple_model = smf.ols(formula = formula, data = dataset).fit()      print(feature)     print(\"R-squared:\", simple_model.rsquared)          # Show a graph of the result     graphing.scatter_2D(dataset, label_x=feature,                                   label_y=\"core_temperature\",                                  title = feature,                                  trendline=lambda x: simple_model.params[1] * x + simple_model.params[0],                                  show=True) <pre>male\nR-squared: 0.0999007443071992\n</pre> <pre>age\nR-squared: 0.2648116081342463\n</pre> <pre>protein_content_of_last_meal\nR-squared: 0.9155158150005704\n</pre> <pre>body_fat_percentage\nR-squared: 0.00020809002637778296\n</pre> <p>Scrolling through these graphs, we get R-square values of 0.0002 (<code>body_fat_percentage</code>), 0.1 (<code>male</code>), and 0.26 (<code>age</code>).</p> <p>While <code>protein_content_of_last_meal</code> looks very promising too, the relationship looks curved, not linear. We'll leave this feature for now and come back to it in the next exercise.</p> In\u00a0[6]: Copied! <pre>formula = \"core_temperature ~ age\"\nage_trained_model = smf.ols(formula = formula, data = dataset).fit()\nage_naive_model = smf.ols(formula = formula, data = dataset).fit()\nage_naive_model.params[0] = dataset['core_temperature'].mean()\nage_naive_model.params[1] = 0\n\nprint(\"naive R-squared:\", age_naive_model.rsquared)\nprint(\"trained R-squared:\", age_trained_model.rsquared)\n\n# Show a graph of the result\ngraphing.scatter_2D(dataset, label_x=\"age\", \n                                label_y=\"core_temperature\",\n                                title = \"Naive model\",\n                                trendline=lambda x: dataset['core_temperature'].repeat(len(x)), \n                                show=True)\n# Show a graph of the result\ngraphing.scatter_2D(dataset, label_x=\"age\", \n                                label_y=\"core_temperature\",\n                                title = \"Trained model\",\n                                trendline=lambda x: age_trained_model.params[1] * x + age_trained_model.params[0])\n</pre> formula = \"core_temperature ~ age\" age_trained_model = smf.ols(formula = formula, data = dataset).fit() age_naive_model = smf.ols(formula = formula, data = dataset).fit() age_naive_model.params[0] = dataset['core_temperature'].mean() age_naive_model.params[1] = 0  print(\"naive R-squared:\", age_naive_model.rsquared) print(\"trained R-squared:\", age_trained_model.rsquared)  # Show a graph of the result graphing.scatter_2D(dataset, label_x=\"age\",                                  label_y=\"core_temperature\",                                 title = \"Naive model\",                                 trendline=lambda x: dataset['core_temperature'].repeat(len(x)),                                  show=True) # Show a graph of the result graphing.scatter_2D(dataset, label_x=\"age\",                                  label_y=\"core_temperature\",                                 title = \"Trained model\",                                 trendline=lambda x: age_trained_model.params[1] * x + age_trained_model.params[0])   <pre>naive R-squared: 0.0\ntrained R-squared: 0.2648116081342463\n</pre> In\u00a0[7]: Copied! <pre>model = smf.ols(formula = \"core_temperature ~ age + male\", data = dataset).fit()\n\nprint(\"R-squared:\", model.rsquared)\n</pre> model = smf.ols(formula = \"core_temperature ~ age + male\", data = dataset).fit()  print(\"R-squared:\", model.rsquared) <pre>R-squared: 0.3148512699768018\n</pre> <p>By using both features at the same time, we got a better result than any of the one-feature (univariate) models.</p> <p>How can we view this, though? Well, a simple linear regression is drawn in 2D. If we're working with an extra variable, we add one dimension and work in 3D.</p> In\u00a0[8]: Copied! <pre>import numpy as np\n# Show a graph of the result\n# this needs to be 3D, because we now have three variables in play: two features and one label\n\ndef predict(age, male):\n    '''\n    This converts given age and male values into a prediction from the model\n    '''\n    # to make a prediction with statsmodels, we need to provide a dataframe\n    # so create a dataframe with just the age and male variables\n    df = pandas.DataFrame(dict(age=[age], male=[male]))\n    return model.predict(df)\n\n# Create the surface graph\nfig = graphing.surface(\n    x_values=np.array([min(dataset.age), max(dataset.age)]),\n    y_values=np.array([0, 1]),\n    calc_z=predict,\n    axis_title_x=\"Age\",\n    axis_title_y=\"Male\",\n    axis_title_z=\"Core temperature\"\n)\n\n# Add our datapoints to it and display\nfig.add_scatter3d(x=dataset.age, y=dataset.male, z=dataset.core_temperature, mode='markers')\nfig.show()\n</pre> import numpy as np # Show a graph of the result # this needs to be 3D, because we now have three variables in play: two features and one label  def predict(age, male):     '''     This converts given age and male values into a prediction from the model     '''     # to make a prediction with statsmodels, we need to provide a dataframe     # so create a dataframe with just the age and male variables     df = pandas.DataFrame(dict(age=[age], male=[male]))     return model.predict(df)  # Create the surface graph fig = graphing.surface(     x_values=np.array([min(dataset.age), max(dataset.age)]),     y_values=np.array([0, 1]),     calc_z=predict,     axis_title_x=\"Age\",     axis_title_y=\"Male\",     axis_title_z=\"Core temperature\" )  # Add our datapoints to it and display fig.add_scatter3d(x=dataset.age, y=dataset.male, z=dataset.core_temperature, mode='markers') fig.show() <p>The preceding graph above interactive. Try rotating it to see how the model (shown as a solid plane) would predict core temperature from different combinations of age and sex.</p> In\u00a0[9]: Copied! <pre># Print summary information\nmodel.summary()\n</pre> # Print summary information model.summary() Out[9]: OLS Regression Results Dep. Variable: core_temperature   R-squared:             0.315 Model: OLS   Adj. R-squared:        0.300 Method: Least Squares   F-statistic:           21.83 Date: Fri, 16 Jun 2023   Prob (F-statistic): 1.58e-08 Time: 01:12:48   Log-Likelihood:      -85.295 No. Observations:     98   AIC:                   176.6 Df Residuals:     95   BIC:                   184.3 Df Model:      2 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] Intercept    37.9793     0.135   282.094  0.000    37.712    38.247 age     0.1406     0.026     5.459  0.000     0.089     0.192 male     0.3182     0.121     2.634  0.010     0.078     0.558 Omnibus: 21.610   Durbin-Watson:         2.369 Prob(Omnibus):  0.000   Jarque-Bera (JB):      5.227 Skew:  0.121   Prob(JB):             0.0733 Kurtosis:  1.895   Cond. No.               12.9 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.  <p>If we look at the top right-hand corner, we can see our R-squared statistic that we printed out earlier.</p> <p>Slightly down and to the left, we can also see information about the data we trained our model on. For example, we can see that we trained it on 98 observations (<code>No. Observations</code>).</p> <p>Under this, we find information about our parameters in a column called <code>coef</code> (which stands for coefficients, a synonym for parameters in machine learning). Here, we can see the intercept was about <code>38</code>, meaning that the model predicts a core temperature of 38 for a dog with <code>age=0</code> and <code>male=0</code>. Underneath this, we see the parameter for age is 0.14, meaning that for each additional year of age, the predicted temperature would rise 0.14 degrees celsius. For <code>male</code>, we can see a parameter of 0.32, meaning that the model estimates all dogs (that is, where <code>male == 1</code>) to have temperatures 0.32 degrees celsius higher than female dogs (where <code>male == 0</code>).</p> <p>Although we don't have space here to go into detail, the <code>P</code> column is also very useful. This tells us how confident the model is about this parameter value. As a rule of thumb, if the p-value is less than 0.05, there is a good chance that this relationship if trustable. For example, here both <code>age</code> and <code>male</code> are less than 0.05, so we should feel confident using this model in the real world.</p> <p>As a final exercise, let's do the same thing with our earlier simple linear-regression model, relating <code>age</code> to <code>core_temperature</code>. Read through the following table and see what you can make out from this model.</p> In\u00a0[10]: Copied! <pre>age_trained_model.summary()\n</pre> age_trained_model.summary() Out[10]: OLS Regression Results Dep. Variable: core_temperature   R-squared:             0.265 Model: OLS   Adj. R-squared:        0.257 Method: Least Squares   F-statistic:           34.58 Date: Fri, 16 Jun 2023   Prob (F-statistic): 5.94e-08 Time: 01:12:48   Log-Likelihood:      -88.749 No. Observations:     98   AIC:                   181.5 Df Residuals:     96   BIC:                   186.7 Df Model:      1 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] Intercept    38.0879     0.132   288.373  0.000    37.826    38.350 age     0.1533     0.026     5.880  0.000     0.102     0.205 Omnibus: 43.487   Durbin-Watson:         2.492 Prob(Omnibus):  0.000   Jarque-Bera (JB):      6.605 Skew:  0.087   Prob(JB):             0.0368 Kurtosis:  1.740   Cond. No.               11.3 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#exercise-train-a-multiple-linear-regression-model","title":"Exercise: Train a multiple linear regression model\u00b6","text":"<p>In this exercise, we'll train both a simple linear-regression model and a multiple linear-regression model and compare their performance using R-Squared.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#loading-data","title":"Loading data\u00b6","text":"<p>Let's start by having a look at our data.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#data-visualization","title":"Data visualization\u00b6","text":"<p>Let's quickly eyeball which features seem to have some kind of relationship with <code>core_temperature</code>.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#simple-linear-regression","title":"Simple linear regression\u00b6","text":"<p>Let's try to predict <code>core_temperature</code> using simple linear regression, and note the R-Squared for these relationships.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#r-squared","title":"R-Squared\u00b6","text":"<p>We've shown the R-Squared value for these models and used it as a measure of \"correctness\" for our regression, but what is it?</p> <p>Intuitively, we can think of R-Squared as ratio for how much better our regression line is than a naive regression that just goes straight through the mean of all examples.</p> <p>Roughly, the R-Squared is calculated by taking the loss/error of the trained model, and dividing by the loss/error of the naive model. That gives a range where <code>0</code> is better and <code>1</code> is worse, so the whole thing is subtracted from <code>1</code> to flip those results.</p> <p>In the following code, we once again show the scatter plot with <code>age</code> and <code>core_temperature</code>, but this time, we show two regression lines. The first is the naive line that just goes straight through the mean. This has an R-Squared of <code>0</code> (since it's no better than itself). An R-Squared of <code>1</code> would be a line that fit each training example perfectly. The second plot shows our trained regression line, and we once again see its R-Squared.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#multiple-linear-regression","title":"Multiple Linear Regression\u00b6","text":"<p>Instead of modeling these separately, lets try to combine these into a single model. Body fat didn't seem to be useful after all, so let's just use <code>male</code> and <code>age</code> as features.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#inspecting-our-model","title":"Inspecting our model\u00b6","text":"<p>When we have more than two features, it becomes very difficult to visualize these models. We usually have to look at the parameters directly. Let's do that now. Statsmodels, one of the common machine learning and statistics libraries, provides a <code>summary()</code> method that provides information about our model.</p>"},{"location":"futuro/Notebooks_referencia/4-5-exercise-multiple-linear-regression/#summary","title":"Summary\u00b6","text":"<p>We covered the following concepts in this exercise:</p> <ul> <li>Built simple and multiple linear-regression models.</li> <li>Compared the performance of both models by looking at R-Squared values.</li> <li>Inspected models to understand how they work.</li> </ul>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/","title":"Exercise: Fitting a Polynomial Curve","text":"<p>In this exercise, we'll have a look at a different type of regression called polynomial regression. In contrast to linear regression ,which models relationships as straight lines, polynomial regression models relationships as curves.</p> <p>Recall in our previous exercise how the relationship between <code>core_temperature</code> and <code>protein_content_of_last_meal</code> couldn't be properly explained using a straight line. In this exercise, we'll use polynomial regression to fit a curve to the data instead.</p> In\u00a0[1]: Copied! <pre>import pandas\n!pip install statsmodels\n!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv\n\n#Import the data from the .csv file\ndataset = pandas.read_csv('doggy-illness.csv', delimiter=\"\\t\")\n\n#Let's have a look at the data\ndataset\n</pre> import pandas !pip install statsmodels !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py !wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv  #Import the data from the .csv file dataset = pandas.read_csv('doggy-illness.csv', delimiter=\"\\t\")  #Let's have a look at the data dataset <pre>Requirement already satisfied: statsmodels in c:\\users\\esped\\anaconda3\\lib\\site-packages (0.13.5)\nRequirement already satisfied: pandas&gt;=0.25 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from statsmodels) (1.5.3)\nRequirement already satisfied: numpy&gt;=1.22.3 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from statsmodels) (1.23.5)\nRequirement already satisfied: scipy&gt;=1.3 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from statsmodels) (1.10.0)\nRequirement already satisfied: packaging&gt;=21.3 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from statsmodels) (22.0)\nRequirement already satisfied: patsy&gt;=0.5.2 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.3)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from pandas&gt;=0.25-&gt;statsmodels) (2022.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in c:\\users\\esped\\anaconda3\\lib\\site-packages (from pandas&gt;=0.25-&gt;statsmodels) (2.8.2)\nRequirement already satisfied: six in c:\\users\\esped\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.2-&gt;statsmodels) (1.16.0)\n</pre> <pre>'wget' n\ufffdo \ufffd reconhecido como um comando interno\nou externo, um programa oper\ufffdvel ou um arquivo em lotes.\n'wget' n\ufffdo \ufffd reconhecido como um comando interno\nou externo, um programa oper\ufffdvel ou um arquivo em lotes.\n</pre> Out[1]: male attended_training age body_fat_percentage core_temperature ate_at_tonys_steakhouse needed_intensive_care protein_content_of_last_meal 0 0 1 6.9 38 38.423169 0 0 7.66 1 0 1 5.4 32 39.015998 0 0 13.36 2 1 1 5.4 12 39.148341 0 0 12.90 3 1 0 4.8 23 39.060049 0 0 13.45 4 1 0 4.8 15 38.655439 0 0 10.53 ... ... ... ... ... ... ... ... ... 93 0 0 4.5 38 37.939942 0 0 7.35 94 1 0 1.8 11 38.790426 1 1 12.18 95 0 0 6.6 20 39.489962 0 0 15.84 96 0 0 6.9 32 38.575742 1 1 9.79 97 1 1 6.0 21 39.766447 1 1 21.30 <p>98 rows \u00d7 8 columns</p> In\u00a0[2]: Copied! <pre>import statsmodels.formula.api as smf\nimport graphing # custom graphing code. See our GitHub repo for details\n\n# Perform linear regression. This method takes care of\n# the entire fitting procedure for us.\nsimple_formula = \"core_temperature ~ protein_content_of_last_meal\"\nsimple_model = smf.ols(formula = simple_formula, data = dataset).fit()\n\n# Show a graph of the result\ngraphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\", \n                             label_y=\"core_temperature\",\n                             trendline=lambda x: simple_model.params[1] * x + simple_model.params[0])\n</pre> import statsmodels.formula.api as smf import graphing # custom graphing code. See our GitHub repo for details  # Perform linear regression. This method takes care of # the entire fitting procedure for us. simple_formula = \"core_temperature ~ protein_content_of_last_meal\" simple_model = smf.ols(formula = simple_formula, data = dataset).fit()  # Show a graph of the result graphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\",                               label_y=\"core_temperature\",                              trendline=lambda x: simple_model.params[1] * x + simple_model.params[0])  <p>Notice how the relationship between the two variables is not truly linear. Looking at the plot, it's fairly clear to see that the points tend more heavily towards one side of the line, especially for the higher <code>core-temperature</code> and <code>protein_content_of_last_meal</code> values.</p> <p>A straight line might not be the best way to describe this relationship.</p> <p>Let's have a quick look at the model's R-Squared score:</p> In\u00a0[3]: Copied! <pre>print(\"R-squared:\", simple_model.rsquared)\n</pre> print(\"R-squared:\", simple_model.rsquared) <pre>R-squared: 0.9155158150005704\n</pre> <p>That is quite a reasonable R-Squared score, but let's see if we can get an even better one!</p> In\u00a0[4]: Copied! <pre># Perform polynomial regression. This method takes care of\n# the entire fitting procedure for us.\npolynomial_formula = \"core_temperature ~ protein_content_of_last_meal + I(protein_content_of_last_meal**2)\"\npolynomial_model = smf.ols(formula = polynomial_formula, data = dataset).fit()\n\n# Show a graph of the result\ngraphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\", \n                             label_y=\"core_temperature\",\n                             # Our trendline is the equation for the polynomial\n                             trendline=lambda x: polynomial_model.params[2] * x**2 + polynomial_model.params[1] * x + polynomial_model.params[0])\n</pre> # Perform polynomial regression. This method takes care of # the entire fitting procedure for us. polynomial_formula = \"core_temperature ~ protein_content_of_last_meal + I(protein_content_of_last_meal**2)\" polynomial_model = smf.ols(formula = polynomial_formula, data = dataset).fit()  # Show a graph of the result graphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\",                               label_y=\"core_temperature\",                              # Our trendline is the equation for the polynomial                              trendline=lambda x: polynomial_model.params[2] * x**2 + polynomial_model.params[1] * x + polynomial_model.params[0])  <p>That looks a lot better already. Let's confirm by having a quick look at the R-Squared score:</p> In\u00a0[5]: Copied! <pre>print(\"R-squared:\", polynomial_model.rsquared)\n</pre> print(\"R-squared:\", polynomial_model.rsquared) <pre>R-squared: 0.9514426069911689\n</pre> <p>That's a better R-Squared score than the one obtained from the previous model! We can now confidently tell our vet to prioritize dogs who ate a high-protein diet the night before.</p> <p>Let's chart our model as a 3D chart. We'll view $X$ and $X^2$ as two separate parameters. Notice that if you rotate the visual just right, our regression model is still a flat plane. This is why polynomial models are still considered to be <code>linear models</code>.</p> In\u00a0[6]: Copied! <pre>import numpy as np\nfig = graphing.surface(\n    x_values=np.array([min(dataset.protein_content_of_last_meal), max(dataset.protein_content_of_last_meal)]),\n    y_values=np.array([min(dataset.protein_content_of_last_meal)**2, max(dataset.protein_content_of_last_meal)**2]),\n    calc_z=lambda x,y: polynomial_model.params[0] + (polynomial_model.params[1] * x) + (polynomial_model.params[2] * y),\n    axis_title_x=\"x\",\n    axis_title_y=\"x2\",\n    axis_title_z=\"Core temperature\"\n)\n# Add our datapoints to it and display\nfig.add_scatter3d(x=dataset.protein_content_of_last_meal, y=dataset.protein_content_of_last_meal**2, z=dataset.core_temperature, mode='markers')\nfig.show()\n</pre> import numpy as np fig = graphing.surface(     x_values=np.array([min(dataset.protein_content_of_last_meal), max(dataset.protein_content_of_last_meal)]),     y_values=np.array([min(dataset.protein_content_of_last_meal)**2, max(dataset.protein_content_of_last_meal)**2]),     calc_z=lambda x,y: polynomial_model.params[0] + (polynomial_model.params[1] * x) + (polynomial_model.params[2] * y),     axis_title_x=\"x\",     axis_title_y=\"x2\",     axis_title_z=\"Core temperature\" ) # Add our datapoints to it and display fig.add_scatter3d(x=dataset.protein_content_of_last_meal, y=dataset.protein_content_of_last_meal**2, z=dataset.core_temperature, mode='markers') fig.show() In\u00a0[7]: Copied! <pre># Show an extrapolated graph of the linear model\ngraphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\", \n                             label_y=\"core_temperature\",\n                             # We extrapolate over the following range\n                             x_range = [0,100],\n                             trendline=lambda x: simple_model.params[1] * x + simple_model.params[0])\n</pre> # Show an extrapolated graph of the linear model graphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\",                               label_y=\"core_temperature\",                              # We extrapolate over the following range                              x_range = [0,100],                              trendline=lambda x: simple_model.params[1] * x + simple_model.params[0])  <p>Next, we extrapolate the polynomial regression over the same range:</p> In\u00a0[8]: Copied! <pre># Show an extrapolated graph of the polynomial model\ngraphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\", \n                             label_y=\"core_temperature\",\n                             # We extrapolate over the following range\n                             x_range = [0,100],\n                             trendline=lambda x: polynomial_model.params[2] * x**2 + polynomial_model.params[1] * x + polynomial_model.params[0])\n</pre> # Show an extrapolated graph of the polynomial model graphing.scatter_2D(dataset, label_x=\"protein_content_of_last_meal\",                               label_y=\"core_temperature\",                              # We extrapolate over the following range                              x_range = [0,100],                              trendline=lambda x: polynomial_model.params[2] * x**2 + polynomial_model.params[1] * x + polynomial_model.params[0])  <p>These two graphs predict two very different things!</p> <p>The extrapolated polynolmial regression expects <code>core_temperature</code> to go down, while the extrapolated linear regression expects linear expects <code>core_temperature</code> to go up.</p> <p>A quick look at the graphs obtained in the previous exercise confirms that we should expect the <code>core_temeprature</code> to rise, not fall, as the <code>protein_content_of_last_meal</code> increases.</p> <p>In general, it's not recommended to extrapolate from a polynomial regression unless you have an a-priori reason to do so (which is only very rarely the case, so it's best to err on the side of caution, and never extrapolate from  polynomial regressions).</p>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#exercise-fitting-a-polynomial-curve","title":"Exercise: Fitting a Polynomial Curve\u00b6","text":""},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#data-visualization","title":"Data visualization\u00b6","text":"<p>Let's start this exercise by loading and having a look at our data.</p>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#simple-linear-regression","title":"Simple Linear Regression\u00b6","text":"<p>Let's quickly jog our memory by performing the same simple linear regression as we did in the previous exercise, using the <code>temperature</code> and <code>protein_content_of_last_meal</code> columns of the dataset.</p>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#simple-polynomial-regression","title":"Simple Polynomial Regression\u00b6","text":"<p>Let's fit a simple polynomial regression this time. Similar to a simple linear regression, a simple polynomial regression models the relationship between a label and a single feature. Unlike a simple linear regression, a simple polynomial regression can explain relationships that aren't simply straight lines.</p> <p>In our example, we're going to use a three-parameter polynomial.</p>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#extrapolating","title":"Extrapolating\u00b6","text":"<p>Let's see what happens if we extrapolate our data. We'd like to see if dogs that ate meals even higher in protein are expected to get even sicker.</p> <p>Let's start with the linear regression. We can set what range we'd like to extrapolate our data over by using the <code>x_range</code> argument in the plotting function. Let's extrapolate over the range <code>[0,100]</code>:</p>"},{"location":"futuro/Notebooks_referencia/4-7-exercise-polynomial-regression/#summary","title":"Summary\u00b6","text":"<p>We covered the following concepts in this exercise:</p> <ul> <li>Built simple linear regression and simple polynomial regression models.</li> <li>Compared the performance of both models by plotting them and looking at R-Squared values.</li> <li>Extrapolated the models over a wider range of values.</li> </ul>"},{"location":"futuro/Notebooks_referencia/Comandos_ambiente/","title":"Comandos ambiente","text":"In\u00a0[1]: Copied! <pre>\"\"\"\nO resultado da chamada site.getsitepackages() ser\u00e1 uma lista de caminhos onde os pacotes Python podem ser instalados globalmente. \nEsses caminhos podem ser \u00fateis quando voc\u00ea precisa saber onde os m\u00f3dulos externos est\u00e3o instalados no seu sistema.\n\"\"\"\nimport site\nsite.getsitepackages()\n</pre> \"\"\" O resultado da chamada site.getsitepackages() ser\u00e1 uma lista de caminhos onde os pacotes Python podem ser instalados globalmente.  Esses caminhos podem ser \u00fateis quando voc\u00ea precisa saber onde os m\u00f3dulos externos est\u00e3o instalados no seu sistema. \"\"\" import site site.getsitepackages() Out[1]: <pre>['c:\\\\Users\\\\esped\\\\anaconda3',\n 'c:\\\\Users\\\\esped\\\\anaconda3\\\\lib\\\\site-packages']</pre> In\u00a0[2]: Copied! <pre>\"\"\"\nIsso imprimir\u00e1 o caminho do execut\u00e1vel Python associado ao ambiente \nem que o Jupyter Notebook est\u00e1 sendo executado.\n\"\"\"\nimport sys\nsys.executable\n</pre> \"\"\" Isso imprimir\u00e1 o caminho do execut\u00e1vel Python associado ao ambiente  em que o Jupyter Notebook est\u00e1 sendo executado. \"\"\" import sys sys.executable Out[2]: <pre>'c:\\\\Users\\\\esped\\\\anaconda3\\\\python.exe'</pre> In\u00a0[3]: Copied! <pre>\"\"\"\nEsse comando em Python usa o m\u00f3dulo sys para imprimir todos os diret\u00f3rios \nque est\u00e3o atualmente no caminho de busca do Python. \nO caminho de busca (sys.path) \u00e9 uma lista de diret\u00f3rios onde o \ninterpretador Python procura por m\u00f3dulos e pacotes quando voc\u00ea importa algo.\n\"\"\"\nimport sys\nfor path in sys.path:\n    print(path)\n</pre> \"\"\" Esse comando em Python usa o m\u00f3dulo sys para imprimir todos os diret\u00f3rios  que est\u00e3o atualmente no caminho de busca do Python.  O caminho de busca (sys.path) \u00e9 uma lista de diret\u00f3rios onde o  interpretador Python procura por m\u00f3dulos e pacotes quando voc\u00ea importa algo. \"\"\" import sys for path in sys.path:     print(path) <pre>c:\\Users\\esped\\OneDrive\\Documentos\nc:\\Users\\esped\\anaconda3\\python310.zip\nc:\\Users\\esped\\anaconda3\\DLLs\nc:\\Users\\esped\\anaconda3\\lib\nc:\\Users\\esped\\anaconda3\n\nc:\\Users\\esped\\anaconda3\\lib\\site-packages\nc:\\Users\\esped\\anaconda3\\lib\\site-packages\\win32\nc:\\Users\\esped\\anaconda3\\lib\\site-packages\\win32\\lib\nc:\\Users\\esped\\anaconda3\\lib\\site-packages\\Pythonwin\n</pre>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/","title":"Introdu\u00e7\u00e3o","text":"<p>A regress\u00e3o linear simples tem dois par\u00e2metros: intercepta\u00e7\u00e3o (c), que indica o valor do r\u00f3tulo quando o recurso \u00e9 definido como zero; e inclina\u00e7\u00e3o (m), que indica o quanto o r\u00f3tulo aumentar\u00e1 para cada aumento de um ponto no recurso.</p> <p>Usando um racioc\u00ednio matem\u00e1tico, isso \u00e9 simplesmente:</p> <p>y=mx+c</p> <p>Em que y \u00e9 o r\u00f3tulo e x o recurso.</p> <p>Por exemplo, em nosso cen\u00e1rio, se tentarmos prever os pacientes que ter\u00e3o febre com base na idade deles, teremos o seguinte modelo:</p> <p>temperatura=m*idade+c</p> <p>Precisamos encontrar os valores de m e c durante o procedimento de ajuste. Se encontrarmos m = 0,5 e c = 37, podemos visualizar desta forma:</p> <p></p> <p>Isso significa que cada ano de idade est\u00e1 associado ao aumento da temperatura do corpo de 0,5\u00b0C, com um ponto inicial de 37\u00b0C.</p> <p></p> <p>Observando esses dois pontos em um eixo y, podemos ver que a previs\u00e3o era de 39,5, mas o valor real foi de 41.</p> <p></p> <p>Portanto, o modelo estava errado em 1,5 para esse ponto de dados.</p> <p>Normalmente, ajustamos um modelo minimizando a soma residual dos quadrados. Isso significa que a fun\u00e7\u00e3o de custo \u00e9 calculada desta forma:</p> <ol> <li>Calcular a diferen\u00e7a entre os valores reais e previstos (como mostrado anteriormente) para cada ponto de dados.</li> <li>Eleve os valores ao quadrado.</li> <li>Some (ou fa\u00e7a a m\u00e9dia) desses valores elevados ao quadrado.</li> </ol> <p>A presen\u00e7a dessa etapa de elevar ao quadrado significa que nem todos os pontos contribuem de maneira uniforme para a linha: as exce\u00e7\u00f5es\u2014que s\u00e3o pontos que n\u00e3o se enquadram no padr\u00e3o esperado\u2014t\u00eam um erro desproporcionalmente maior, o que pode influenciar a posi\u00e7\u00e3o da linha.</p> <p>O m\u00e9todo fit() funciona de forma diferente dependendo do tipo de modelo de machine learning que voc\u00ea est\u00e1 usando.</p> <p>No caso da regress\u00e3o linear, o m\u00e9todo fit() usa um algoritmo chamado m\u00ednimos quadrados ordin\u00e1rios (OLS) para encontrar os coeficientes que minimizam a soma dos quadrados dos erros entre os valores reais e os valores previstos pelo modelo. O erro \u00e9 a diferen\u00e7a entre o valor real e o valor previsto para cada observa\u00e7\u00e3o.</p> <p>O m\u00e9todo fit() calcula os coeficientes usando uma f\u00f3rmula matem\u00e1tica que envolve a invers\u00e3o da matriz dos dados de treinamento (X) e a multiplica\u00e7\u00e3o pelo vetor dos valores alvo (y). O resultado \u00e9 um vetor de coeficientes que representa a reta que melhor se ajusta aos dados. O m\u00e9todo fit() armazena esses coeficientes como atributos do objeto do modelo, que podem ser acessados depois usando model.coef_ e model.intercept_. Esses coeficientes s\u00e3o usados pelo m\u00e9todo predict() para fazer previs\u00f5es para novos dados.</p> <p>Fonte: https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8</p> <p>O m\u00e9todo fit faz o seguinte processo:</p> <ul> <li><p>Recebe como par\u00e2metros os dados de treinamento (X) e os valores alvo (y) que correspondem \u00e0s classes ou aos valores que queremos prever.</p> </li> <li><p>Escolhe um algoritmo de machine learning adequado para o tipo de problema (classifica\u00e7\u00e3o, regress\u00e3o, clusteriza\u00e7\u00e3o, etc.) e para os dados dispon\u00edveis (n\u00famero de vari\u00e1veis, tipo de vari\u00e1veis, distribui\u00e7\u00e3o dos dados, etc.).</p> </li> <li><p>Aplica o algoritmo aos dados de treinamento e aos valores alvo para encontrar os par\u00e2metros que melhor se ajustam aos dados e que permitem fazer previs\u00f5es precisas. Esses par\u00e2metros podem ser coeficientes, pesos, centros, etc., dependendo do tipo de algoritmo.</p> </li> <li><p>Armazena os par\u00e2metros encontrados como atributos do objeto do modelo, que podem ser acessados depois usando model.params_, onde <code>params_ </code> pode variar de acordo com o algoritmo usado.</p> </li> <li><p>Retorna o objeto do modelo ajustado, que pode ser usado para fazer previs\u00f5es para novos dados usando o m\u00e9todo predict() ou para avaliar a qualidade do modelo usando m\u00e9tricas e testes estat\u00edsticos.</p> </li> </ul> <p>O m\u00e9todo fit() \u00e9 um dos m\u00e9todos mais comuns e importantes das classes de modelos de machine learning do scikit-learn. Ele \u00e9 respons\u00e1vel por ajustar o modelo aos dados de treinamento e aos valores alvo, usando um algoritmo espec\u00edfico de machine learning. O m\u00e9todo fit() pode receber diferentes par\u00e2metros, dependendo do tipo de modelo e do algoritmo usado, mas os principais s\u00e3o:</p> <ul> <li>X: um array bidimensional que cont\u00e9m os dados de treinamento, ou seja, as vari\u00e1veis preditoras ou independentes que ser\u00e3o usadas para prever os valores alvo. Cada linha representa uma observa\u00e7\u00e3o e cada coluna representa uma vari\u00e1vel. O array X pode ser um objeto do tipo numpy.array, pandas.DataFrame ou scipy.sparse.</li> <li>y: um array unidimensional que cont\u00e9m os valores alvo, ou seja, as classes ou os valores que queremos prever com o modelo. Cada elemento do array y corresponde a uma observa\u00e7\u00e3o do array X. O array y pode ser um objeto do tipo numpy.array, pandas.Series ou list.</li> </ul> <p>Alguns exemplos de par\u00e2metros adicionais que podem ser passados ao m\u00e9todo fit() s\u00e3o:</p> <ul> <li>sample_weight: um array unidimensional que cont\u00e9m os pesos das observa\u00e7\u00f5es, ou seja, a import\u00e2ncia relativa de cada observa\u00e7\u00e3o para o ajuste do modelo. Esse par\u00e2metro \u00e9 usado para dar mais \u00eanfase a algumas observa\u00e7\u00f5es que podem ser mais relevantes ou confi\u00e1veis do que outras. O array sample_weight deve ter o mesmo tamanho do array y e pode ser um objeto do tipo numpy.array ou list.</li> <li>solver: uma string que indica o algoritmo usado para resolver o problema de otimiza\u00e7\u00e3o do modelo. Esse par\u00e2metro \u00e9 usado em alguns modelos que envolvem a minimiza\u00e7\u00e3o de uma fun\u00e7\u00e3o custo, como a regress\u00e3o log\u00edstica ou a rede neural. O valor do par\u00e2metro solver pode variar de acordo com o modelo, mas alguns exemplos s\u00e3o: 'liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga', 'adam', etc.</li> <li>max_iter: um inteiro que indica o n\u00famero m\u00e1ximo de itera\u00e7\u00f5es do algoritmo de otimiza\u00e7\u00e3o. Esse par\u00e2metro \u00e9 usado em alguns modelos que envolvem processos iterativos para encontrar os par\u00e2metros \u00f3timos, como a rede neural ou o k-means. O valor do par\u00e2metro max_iter deve ser positivo e suficiente para garantir a converg\u00eancia do algoritmo.</li> </ul> <p>O m\u00e9todo fit() n\u00e3o retorna nenhum valor, mas modifica o estado interno do objeto do modelo, armazenando os par\u00e2metros encontrados pelo algoritmo de machine learning. Esses par\u00e2metros podem ser acessados depois usando atributos espec\u00edficos do objeto do modelo, como model.coef_, model.intercept_, model.cluster_centers_, model.n_iter_, etc. Esses atributos podem variar de acordo com o tipo de modelo e do algoritmo usado.</p> <p>O m\u00e9todo fit() tamb\u00e9m permite que o objeto do modelo seja usado para fazer previs\u00f5es para novos dados usando o m\u00e9todo predict(), ou para avaliar a qualidade do modelo usando m\u00e9tricas e testes estat\u00edsticos.</p> <p></p> <p>A polinomial de tr\u00eas par\u00e2metros, por sua vez, tem uma \u00fanica curvatura:</p> <p>y = intercepta\u00e7\u00e3o + B1x + B2x2</p> <p></p> <p>E uma polinomial de quatro par\u00e2metros pode ter duas curvaturas:</p> <p>y = intercepta\u00e7\u00e3o + B1x + B2x2 + B3*x3</p> <p></p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#introducao","title":"Introdu\u00e7\u00e3o\u00b6","text":"<p>A regress\u00e3o \u00e9 uma t\u00e9cnica de an\u00e1lise de dados simples, comum e altamente \u00fatil, coloquialmente conhecida como \"ajustar uma linha de tend\u00eancia\". A regress\u00e3o identifica a for\u00e7a da rela\u00e7\u00e3o entre um ou mais recursos e um \u00fanico r\u00f3tulo. Sua simplicidade, previsibilidade, capacidade de previs\u00e3o e alto n\u00edvel de interpretabilidade fazem com que essa t\u00e9cnica seja usada em finan\u00e7as, neg\u00f3cios, ci\u00eancias sociais, epidemiologia e medicina.</p> <p>Neste m\u00f3dulo, vamos nos aprofundar no funcionamento da regress\u00e3o, entender suas limita\u00e7\u00f5es e aprender a avaliar o seu desempenho.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#cenario-infestacao-em-uma-clinica-veterinaria","title":"Cen\u00e1rio: Infesta\u00e7\u00e3o em uma cl\u00ednica veterin\u00e1ria\u00b6","text":"<p>Ao longo deste m\u00f3dulo, vamos usar o cen\u00e1rio de exemplo a seguir para explicar os conceitos por tr\u00e1s da regress\u00e3o. Esse cen\u00e1rio foi projetado para fornecer um exemplo de como voc\u00ea pode usar essa t\u00e9cnica ao analisar dados futuros.</p> <p>A institui\u00e7\u00e3o beneficente para c\u00e3es de resgate em avalanches que voc\u00ea dirige teve uma s\u00fabita onda de doen\u00e7as. Depois de um dia de retreinamento e de algumas atividades sociais, muitos de seus c\u00e3es adoeceram. O principal sintoma \u00e9 a febre. Preocupada com os c\u00e3es que ainda n\u00e3o apresentaram sintomas, sua equipe coletou informa\u00e7\u00f5es b\u00e1sicas sobre os primeiros 100 c\u00e3es que adoeceram. Seu trabalho \u00e9 identificar quais tipos de cachorros t\u00eam maior risco de doen\u00e7a, para que eles possam ser verificados preventivamente pelo veterin\u00e1rio.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#objetivos-de-aprendizagem","title":"Objetivos de aprendizagem\u00b6","text":"<p>Neste m\u00f3dulo, voc\u00ea vai:</p> <p>Entender o funcionamento da regress\u00e3o. Trabalhar com novos algoritmos: regress\u00e3o linear, regress\u00e3o linear m\u00faltipla e regress\u00e3o polinomial. Entender os pontos fortes e as limita\u00e7\u00f5es dos modelos de regress\u00e3o. Visualizar fun\u00e7\u00f5es de erro e de custo na regress\u00e3o linear. Entender as m\u00e9tricas b\u00e1sicas de avalia\u00e7\u00e3o da regress\u00e3o.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#o-que-e-regressao","title":"O que \u00e9 regress\u00e3o?\u00b6","text":"<p>A regress\u00e3o \u00e9 uma t\u00e9cnica de an\u00e1lise de dados simples, comum e altamente \u00fatil, geralmente chamada de \"ajustar uma linha\". Em sua forma mais simples, a regress\u00e3o se ajusta a uma linha reta entre uma vari\u00e1vel (recurso) e outra (r\u00f3tulo). Em formas mais complicadas, a regress\u00e3o pode estabelecer rela\u00e7\u00f5es n\u00e3o lineares entre um \u00fanico r\u00f3tulo e v\u00e1rios recursos.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#regressao-linear-simples","title":"Regress\u00e3o linear simples\u00b6","text":"<p>A regress\u00e3o linear simples modela uma rela\u00e7\u00e3o linear entre um \u00fanico recurso e um r\u00f3tulo, geralmente cont\u00ednuo, permitindo que o recurso preveja o r\u00f3tulo. Visualmente, ela pode ser algo do tipo:</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#ajuste-de-regressao-linear","title":"Ajuste de regress\u00e3o linear\u00b6","text":"<p>Normalmente, usamos bibliotecas existentes para ajustar modelos de regress\u00e3o. A regress\u00e3o normalmente visa a encontrar a linha que produz a menor quantidade de erro, em que o erro aqui representa a diferen\u00e7a entre o valor real do ponto de dados e o valor previsto. Por exemplo, na imagem a seguir, a linha preta indica o erro entre a previs\u00e3o, a linha vermelha e um valor real: o ponto.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#pontos-fortes-da-regressao","title":"Pontos fortes da regress\u00e3o\u00b6","text":"<p>As t\u00e9cnicas de regress\u00e3o t\u00eam muitos pontos fortes que os modelos mais complexos n\u00e3o t\u00eam.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#previsivel-e-facil-de-interpretar","title":"Previs\u00edvel e f\u00e1cil de interpretar\u00b6","text":"<p>As regress\u00f5es s\u00e3o f\u00e1ceis de interpretar porque descrevem equa\u00e7\u00f5es matem\u00e1ticas simples, que geralmente podemos transformar em gr\u00e1fico. Modelos mais complexos geralmente s\u00e3o chamados de solu\u00e7\u00f5es de caixa preta, porque \u00e9 dif\u00edcil entender como eles fazem previs\u00f5es ou como eles se comportar\u00e3o com determinadas entradas.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#facil-de-extrapolar","title":"F\u00e1cil de extrapolar\u00b6","text":"<p>As regress\u00f5es facilitam a extrapola\u00e7\u00e3o para fazer previs\u00f5es para valores fora do intervalo do nosso conjuntos de dados. Por exemplo, \u00e9 simples estimar, em nosso exemplo anterior, que um c\u00e3o de nove anos ter\u00e1 uma temperatura de 40,5\u00b0C. A extrapola\u00e7\u00e3o deve sempre ser feita com cuidado: esse mesmo modelo acabaria prevendo que um indiv\u00edduo de 90 anos teria quase a temperatura necess\u00e1ria para ferver \u00e1gua.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#o-ajuste-ideal-costuma-estar-garantido","title":"O ajuste ideal costuma estar garantido\u00b6","text":"<p>A maioria dos modelos de aprendizado de m\u00e1quina usa descendente de gradiente para ajustar modelos, o que implica em ajustar o algoritmo do descendente de gradiente e n\u00e3o oferece nenhuma garantia de que uma solu\u00e7\u00e3o ideal ser\u00e1 encontrada. Por outro lado, a regress\u00e3o linear que usa a soma de quadrados como uma fun\u00e7\u00e3o de custo n\u00e3o precisa de um procedimento iterativo de descendente de gradiente. Em vez disso, a matem\u00e1tica pode ser usada de forma inteligente para se calcular o local ideal para posicionar a linha. A matem\u00e1tica est\u00e1 fora do escopo deste m\u00f3dulo, mas \u00e9 \u00fatil saber que na regress\u00e3o linear n\u00e3o \u00e9 necess\u00e1rio aten\u00e7\u00e3o especial ao processo de ajuste, e a solu\u00e7\u00e3o ideal est\u00e1 garantida (contanto que o tamanho da amostra n\u00e3o seja grande demais).</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#metodo-fit-presente-nos-modelos","title":"Metodo Fit () presente nos modelos\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear/#mais-alguns-detalhes","title":"Mais alguns detalhes !!\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear/#regressao-polinomial","title":"Regress\u00e3o polinomial\u00b6","text":"<p>At\u00e9 agora, vimos apenas modelos de regress\u00e3o linear, modelos que podem ser modelados como linhas retas. No entanto, os modelos de regress\u00e3o podem funcionar com praticamente qualquer outro tipo de rela\u00e7\u00e3o.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#o-que-e-regressao-polinomial","title":"O que \u00e9 regress\u00e3o polinomial?\u00b6","text":"<p>Os modelos de regress\u00e3o modelam regress\u00f5es como tipos espec\u00edficos de curva. As polinomiais s\u00e3o uma fam\u00edlia de curvas, variando de formas simples a complexas. Quanto mais par\u00e2metros na equa\u00e7\u00e3o (modelo), mais complexa \u00e9 a curva.</p> <p>Por exemplo, uma polinomial de dois par\u00e2metros \u00e9 simplesmente uma linha reta:</p> <p>y = intercepta\u00e7\u00e3o + B1*x</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#polinomial-comparada-a-outras-curvas","title":"Polinomial comparada a outras curvas\u00b6","text":"<p>H\u00e1 diversos tipos de curvas, como curva logar\u00edtmica e curva log\u00edstica, e todas elas podem ser usadas com a regress\u00e3o.</p> <p>Uma grande vantagem da regress\u00e3o polinomial \u00e9 que ela pode ser usada para examinar todos os tipos de rela\u00e7\u00f5es. Por exemplo, a regress\u00e3o polinomial pode ser usada para rela\u00e7\u00f5es que s\u00e3o negativas em um determinado intervalo de valores de recursos, mas positivas em outros. Ela tamb\u00e9m pode ser usada quando o r\u00f3tulo (valor y) n\u00e3o tiver limite superior te\u00f3rico.</p> <p>A principal desvantagem das curvas polinomiais \u00e9 que elas geralmente extrapolam de maneira insatisfat\u00f3ria. Em outras palavras, se tentarmos prever valores maiores ou menores do que nossos dados de treinamento, as polinomiais podem prever valores extremos irreais. Outra desvantagem \u00e9 que \u00e9 f\u00e1cil sobreajustar uma curva polinomial. Isso significa que um ru\u00eddo nos dados pode alterar a forma da curva de maneira muito mais significativa do que em modelos mais simples, como na regress\u00e3o linear simples.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear/#as-curvas-podem-ser-usadas-com-varios-recursos","title":"As curvas podem ser usadas com v\u00e1rios recursos?\u00b6","text":"<p>Vimos como a regress\u00e3o m\u00faltipla pode ajustar v\u00e1rias rela\u00e7\u00f5es lineares ao mesmo tempo. No entanto, n\u00e3o h\u00e1 necessidade de que eles sejam limitados a rela\u00e7\u00f5es lineares. Todos os tipos de curvas podem ser usados nessas rela\u00e7\u00f5es quando for apropriado. Apesar disso, deve-se ter o cuidado de n\u00e3o usar curvas como as polinomiais com v\u00e1rios recursos quando elas n\u00e3o forem necess\u00e1rias. Isso ocorre porque as rela\u00e7\u00f5es podem acabar muito complexas, o que torna mais dif\u00edcil entender os modelos e avaliar se eles far\u00e3o previs\u00f5es que n\u00e3o fazem sentido do ponto de vista do mundo real.</p>"},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/","title":"1\u00b0 Exemplo Simples","text":"In\u00a0[22]: Copied! <pre># Importar o m\u00f3dulo de regress\u00e3o linear do sklearn\nfrom sklearn.linear_model import LinearRegression\n\n# Criar um objeto do tipo LinearRegression\nmodel = LinearRegression()\n\n# Criar os dados de treinamento (X) e os valores alvo (y)\nX = [[1.60], [1.65], [1.70], [1.75], [1.80]] # altura em metros\ny = [50, 55, 60, 65, 70] # peso em quilos\n\n# Ajustar o modelo aos dados de treinamento usando o m\u00e9todo fit\nmodel.fit(X, y)\n</pre> # Importar o m\u00f3dulo de regress\u00e3o linear do sklearn from sklearn.linear_model import LinearRegression  # Criar um objeto do tipo LinearRegression model = LinearRegression()  # Criar os dados de treinamento (X) e os valores alvo (y) X = [[1.60], [1.65], [1.70], [1.75], [1.80]] # altura em metros y = [50, 55, 60, 65, 70] # peso em quilos  # Ajustar o modelo aos dados de treinamento usando o m\u00e9todo fit model.fit(X, y) Out[22]: <pre>LinearRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression<pre>LinearRegression()</pre> In\u00a0[23]: Copied! <pre># Criar um novo dado de entrada (X_new)\nX_new = [[1.85]] # altura em metros\n\n# Usar o m\u00e9todo predict para fazer a previs\u00e3o\ny_pred = model.predict(X_new)\n\n# Imprimir o resultado\nprint(f\"O peso estimado para uma pessoa com {X_new[0][0]} metros de altura \u00e9 {y_pred[0]:.2f} quilos.\")\n</pre> # Criar um novo dado de entrada (X_new) X_new = [[1.85]] # altura em metros  # Usar o m\u00e9todo predict para fazer a previs\u00e3o y_pred = model.predict(X_new)  # Imprimir o resultado print(f\"O peso estimado para uma pessoa com {X_new[0][0]} metros de altura \u00e9 {y_pred[0]:.2f} quilos.\") <pre>O peso estimado para uma pessoa com 1.85 metros de altura \u00e9 75.00 quilos.\n</pre> In\u00a0[24]: Copied! <pre># importando as libs\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n# fonte: # fonte: http://www.portalaction.com.br/analise-de-regressao/12-estimacao-dos-parametros-do-modelo\n# criando vari\u00e1veis que ser\u00e3o usadas daqui para frente\n# vari\u00e1vel preditora\nX = np.array([ 220, 220, 220, 220, 220, 225, 225, 225, 225, 225, 230, 230, 230, 230, 230, 235, 235, 235, 235, 235 ])\n# vari\u00e1vel alvo\ny = np.array([ 137, 137, 137, 136, 135, 135, 133, 132, 133, 133, 128, 124, 126, 129, 126, 122, 122, 122, 119, 122 ])\n</pre> # importando as libs import numpy as np import pandas as pd from sklearn.linear_model import LinearRegression import statsmodels.api as sm # fonte: # fonte: http://www.portalaction.com.br/analise-de-regressao/12-estimacao-dos-parametros-do-modelo # criando vari\u00e1veis que ser\u00e3o usadas daqui para frente # vari\u00e1vel preditora X = np.array([ 220, 220, 220, 220, 220, 225, 225, 225, 225, 225, 230, 230, 230, 230, 230, 235, 235, 235, 235, 235 ]) # vari\u00e1vel alvo y = np.array([ 137, 137, 137, 136, 135, 135, 133, 132, 133, 133, 128, 124, 126, 129, 126, 122, 122, 122, 119, 122 ]) In\u00a0[8]: Copied! <pre># \u00e9 necess\u00e1rio adicionar uma constante a matriz X\nX_sm = sm.add_constant(X)\n# OLS vem de Ordinary Least Squares e o m\u00e9todo fit ir\u00e1 treinar o modelo\nresults = sm.OLS(y, X_sm).fit()\n# mostrando as estat\u00edsticas do modelo\nresults.summary()\n# mostrando as previs\u00f5es para o mesmo conjunto passado\nresults.predict(X_sm)\n</pre> # \u00e9 necess\u00e1rio adicionar uma constante a matriz X X_sm = sm.add_constant(X) # OLS vem de Ordinary Least Squares e o m\u00e9todo fit ir\u00e1 treinar o modelo results = sm.OLS(y, X_sm).fit() # mostrando as estat\u00edsticas do modelo results.summary() # mostrando as previs\u00f5es para o mesmo conjunto passado results.predict(X_sm) Out[8]: <pre>array([137.14, 137.14, 137.14, 137.14, 137.14, 131.98, 131.98, 131.98,\n       131.98, 131.98, 126.82, 126.82, 126.82, 126.82, 126.82, 121.66,\n       121.66, 121.66, 121.66, 121.66])</pre> In\u00a0[12]: Copied! <pre># Fonte: https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8\n\nclass SimpleLinearRegression:\n    def __init__(self):\n        self.coef_ = None\n        self.intercept_ = None\n        self.formula = None\n        self.X = None\n        self.y = None\n    \n    def fit(self, X, y):\n        X = np.array(X)\n        y = np.array(y)\n        \n        self.X = X\n        self.y = y\n        soma_xy = sum(X * y)\n        soma_x_ao_quadrado = sum(X * X)\n        soma_x = sum(X)\n        soma_y = sum(y)\n        n = len(X)\n        media_x = X.mean()\n        media_y = y.mean()\n        \n        # build formula y = ax + b\n        a = ( soma_xy - n * media_x * media_y ) / ( soma_x_ao_quadrado - n * ( media_x ** 2 ) )\n        b = media_y - (a * media_x)\n        \n        self.coef_ = np.array([ b ])\n        self.intercept_ = np.array([ a ])\n        \n        self.formula = lambda _x : (a * _x) + b\n    \n    def predict(self, x):\n        return np.array(list(map(self.formula, x)))\n    \n    # fonte: https://edisciplinas.usp.br/pluginfile.php/1479289/mod_resource/content/0/regr_lin.pdf\n    def sum_total_quadratic(self):\n        median = self.y.mean()\n        return sum( ( y - median ) ** 2 )\n    \n    def sum_error_quadratic(self):\n        predicted = self.predict(x=self.X)\n        return sum( ( self.y - predicted ) ** 2 )\n\n    def regression_quadratic_sum(self):\n        return self.sum_total_quadratic() - self.sum_error_quadratic()\n    \n    def score(self):\n        return self.regression_quadratic_sum() / self.sum_total_quadratic()\n</pre> # Fonte: https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8  class SimpleLinearRegression:     def __init__(self):         self.coef_ = None         self.intercept_ = None         self.formula = None         self.X = None         self.y = None          def fit(self, X, y):         X = np.array(X)         y = np.array(y)                  self.X = X         self.y = y         soma_xy = sum(X * y)         soma_x_ao_quadrado = sum(X * X)         soma_x = sum(X)         soma_y = sum(y)         n = len(X)         media_x = X.mean()         media_y = y.mean()                  # build formula y = ax + b         a = ( soma_xy - n * media_x * media_y ) / ( soma_x_ao_quadrado - n * ( media_x ** 2 ) )         b = media_y - (a * media_x)                  self.coef_ = np.array([ b ])         self.intercept_ = np.array([ a ])                  self.formula = lambda _x : (a * _x) + b          def predict(self, x):         return np.array(list(map(self.formula, x)))          # fonte: https://edisciplinas.usp.br/pluginfile.php/1479289/mod_resource/content/0/regr_lin.pdf     def sum_total_quadratic(self):         median = self.y.mean()         return sum( ( y - median ) ** 2 )          def sum_error_quadratic(self):         predicted = self.predict(x=self.X)         return sum( ( self.y - predicted ) ** 2 )      def regression_quadratic_sum(self):         return self.sum_total_quadratic() - self.sum_error_quadratic()          def score(self):         return self.regression_quadratic_sum() / self.sum_total_quadratic() In\u00a0[17]: Copied! <pre>df = pd.DataFrame()\ndf['x'] = x\ndf['y'] = y\n# passando os valores de x e y como Dataframes\nx_v = df[['x']]\ny_v = df[['y']]\n# criando e treinando o modelo\nmodel = LinearRegression()\nmodel.fit(x_v, y_v)\n# para visualizar os coeficientes encontrados\nmodel.coef_\n# para visualizar o R\u00b2\nmodel.score()\n# mostrando as previs\u00f5es para o mesmo conjunto passado\nmodel.predict(X_sm)\n</pre> df = pd.DataFrame() df['x'] = x df['y'] = y # passando os valores de x e y como Dataframes x_v = df[['x']] y_v = df[['y']] # criando e treinando o modelo model = LinearRegression() model.fit(x_v, y_v) # para visualizar os coeficientes encontrados model.coef_ # para visualizar o R\u00b2 model.score() # mostrando as previs\u00f5es para o mesmo conjunto passado model.predict(X_sm) <pre>O peso estimado para uma pessoa com 1.85 metros de altura \u00e9 75.00 quilos.\n</pre> In\u00a0[25]: Copied! <pre># Importar as bibliotecas necess\u00e1rias\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# Criar um objeto do tipo LinearRegression\nmodel = LinearRegression()\n\n# Ajustar o modelo aos dados de treinamento usando o m\u00e9todo fit\nmodel.fit(X_train, y_train)\n\n# Fazer previs\u00f5es para os dados de teste usando o m\u00e9todo predict\ny_pred = model.predict(X_test)\n\n# Calcular o R\u00b2 usando a fun\u00e7\u00e3o r2_score\nr2 = r2_score(y_test, y_pred)\n\n# Calcular o RMSE usando a fun\u00e7\u00e3o mean_squared_error e tirando a raiz quadrada\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n\n# Imprimir os resultados\nprint(f\"O coeficiente R\u00b2 \u00e9 {r2:.2f}\")\nprint(f\"O RMSE \u00e9 {rmse:.2f}\")\n</pre> # Importar as bibliotecas necess\u00e1rias from sklearn.linear_model import LinearRegression from sklearn.metrics import r2_score, mean_squared_error  # Criar um objeto do tipo LinearRegression model = LinearRegression()  # Ajustar o modelo aos dados de treinamento usando o m\u00e9todo fit model.fit(X_train, y_train)  # Fazer previs\u00f5es para os dados de teste usando o m\u00e9todo predict y_pred = model.predict(X_test)  # Calcular o R\u00b2 usando a fun\u00e7\u00e3o r2_score r2 = r2_score(y_test, y_pred)  # Calcular o RMSE usando a fun\u00e7\u00e3o mean_squared_error e tirando a raiz quadrada rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Imprimir os resultados print(f\"O coeficiente R\u00b2 \u00e9 {r2:.2f}\") print(f\"O RMSE \u00e9 {rmse:.2f}\") <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[25], line 9\n      6 model = LinearRegression()\n      8 # Ajustar o modelo aos dados de treinamento usando o m\u00e9todo fit\n----&gt; 9 model.fit(X_train, y_train)\n     11 # Fazer previs\u00f5es para os dados de teste usando o m\u00e9todo predict\n     12 y_pred = model.predict(X_test)\n\nNameError: name 'X_train' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/#1-exemplo-simples","title":"1\u00b0 Exemplo Simples\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/#exemplo-pratico-usando-scikit-learn-e-statsmodels","title":"Exemplo pr\u00e1tico usando scikit-learn e statsmodels\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/#escrevendo-o-modelo-com-o-scikit-learn","title":"Escrevendo o modelo com o scikit-learn\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/#abaixo-exemplo-de-como-o-metodo-fit-e-construido","title":"Abaixo exemplo de como o metodo fit() \u00e9 construido\u00b6","text":""},{"location":"futuro/Notebooks_referencia/Regressao_linear_exemplos/#outros-exemplos","title":"outros exemplos\u00b6","text":""},{"location":"futuro/Notebooks_referencia/graphing/","title":"Graphing","text":"In\u00a0[\u00a0]: Copied! <pre>'''\nSeveral no-fuss methods for creating plots\n'''\nfrom typing import Dict, Optional, Callable, Tuple, Union, List\nfrom numpy import exp\nimport numpy\nfrom numpy.core.fromnumeric import repeat, shape\nimport pandas\nimport plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as graph_objects\n</pre> ''' Several no-fuss methods for creating plots ''' from typing import Dict, Optional, Callable, Tuple, Union, List from numpy import exp import numpy from numpy.core.fromnumeric import repeat, shape import pandas import plotly.express as px import plotly.io as pio import plotly.graph_objects as graph_objects In\u00a0[\u00a0]: Copied! <pre># Set the default theme\ntemplate =  graph_objects.layout.Template()\ntemplate.layout = graph_objects.Layout(\n                                    title_x=0.5,\n                                    # border width and size\n                                    margin=dict(l=2, r=2, b=2, t=30),\n                                    height=400,\n                                    # Interaction\n                                    hovermode=\"closest\",\n                                    # axes\n                                    xaxis_showline=True,\n                                    xaxis_linewidth=2,\n                                    yaxis_showline=True,\n                                    yaxis_linewidth=2,\n                                    # Pick a slightly different P.O.V from default\n                                    # this avoids the extremities of the y and x axes\n                                    # being cropped off\n                                    scene_camera=dict(eye=dict(x=1.5, y=1.5, z=0.1))\n                                    )\n</pre> # Set the default theme template =  graph_objects.layout.Template() template.layout = graph_objects.Layout(                                     title_x=0.5,                                     # border width and size                                     margin=dict(l=2, r=2, b=2, t=30),                                     height=400,                                     # Interaction                                     hovermode=\"closest\",                                     # axes                                     xaxis_showline=True,                                     xaxis_linewidth=2,                                     yaxis_showline=True,                                     yaxis_linewidth=2,                                     # Pick a slightly different P.O.V from default                                     # this avoids the extremities of the y and x axes                                     # being cropped off                                     scene_camera=dict(eye=dict(x=1.5, y=1.5, z=0.1))                                     ) In\u00a0[\u00a0]: Copied! <pre>template.data.scatter = [graph_objects.Scatter(marker=dict(opacity=0.8))]\ntemplate.data.scatter3d = [graph_objects.Scatter3d(marker=dict(opacity=0.8))]\ntemplate.data.surface = [graph_objects.Surface()]\ntemplate.data.histogram = [graph_objects.Histogram(marker=dict(line=dict(width=1)))]\ntemplate.data.box = [graph_objects.Box(boxpoints='outliers', notched=False)]\n</pre> template.data.scatter = [graph_objects.Scatter(marker=dict(opacity=0.8))] template.data.scatter3d = [graph_objects.Scatter3d(marker=dict(opacity=0.8))] template.data.surface = [graph_objects.Surface()] template.data.histogram = [graph_objects.Histogram(marker=dict(line=dict(width=1)))] template.data.box = [graph_objects.Box(boxpoints='outliers', notched=False)] In\u00a0[\u00a0]: Copied! <pre>pio.templates[\"custom_template\"] = template\npio.templates.default = \"plotly_white+custom_template\"\n</pre> pio.templates[\"custom_template\"] = template pio.templates.default = \"plotly_white+custom_template\" In\u00a0[\u00a0]: Copied! <pre># Trendline colors\n# Take note that the text for this course often refers to colours explicitly\n# such as \"looking at the red line\". Changing the variable below may result \n# in this text being inconsistent\ncolours_trendline = px.colors.qualitative.Set1  \n</pre> # Trendline colors # Take note that the text for this course often refers to colours explicitly # such as \"looking at the red line\". Changing the variable below may result  # in this text being inconsistent colours_trendline = px.colors.qualitative.Set1   In\u00a0[\u00a0]: Copied! <pre>def _to_human_readable(text:str):\n    '''\n    Converts a label into a human readable form\n    '''\n    return text.replace(\"_\", \" \")\n</pre> def _to_human_readable(text:str):     '''     Converts a label into a human readable form     '''     return text.replace(\"_\", \" \") In\u00a0[\u00a0]: Copied! <pre>def _prepare_labels(df:pandas.DataFrame, labels:List[Optional[str]], replace_nones:bool=True):\n    '''\n    Ensures labels are human readable.\n    Automatically picks data if labels not provided explicitly\n    '''\n\n    human_readable = {}\n\n    if isinstance(replace_nones, bool):\n        replace_nones = [replace_nones] * len(labels)\n\n    for i in range(len(labels)):\n        lab = labels[i]\n        if replace_nones[i] and (lab is None):\n            lab = df.columns[i]\n            labels[i] = lab\n\n        # make human-readable\n        if lab is not None:\n            human_readable[lab] = _to_human_readable(lab)\n\n    return labels, human_readable\n</pre> def _prepare_labels(df:pandas.DataFrame, labels:List[Optional[str]], replace_nones:bool=True):     '''     Ensures labels are human readable.     Automatically picks data if labels not provided explicitly     '''      human_readable = {}      if isinstance(replace_nones, bool):         replace_nones = [replace_nones] * len(labels)      for i in range(len(labels)):         lab = labels[i]         if replace_nones[i] and (lab is None):             lab = df.columns[i]             labels[i] = lab          # make human-readable         if lab is not None:             human_readable[lab] = _to_human_readable(lab)      return labels, human_readable In\u00a0[\u00a0]: Copied! <pre>def box_and_whisker(df:pandas.DataFrame,\n                label_x:Optional[str]=None,\n                label_y:Optional[str]=None,\n                label_x2:Optional[str]=None,\n                title=None,\n                show:bool=False):\n    '''\n    Creates a box and whisker plot and optionally shows it. Returns the figure for that plot.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    df: The data\n    label_x: What to group by. Defaults to None\n    label_y: What to plot on the y axis. Defaults to count of df.columns[0]\n    label_x2: If provided, splits boxplots into 2+ per x value, each with its own colour\n    title: Plot title\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured\n\n    '''\n\n    # Automatically pick columns if not specified\n    selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_x2], replace_nones=[False, True, False])\n\n    fig = px.box(df,\n                    x=selected_columns[0],\n                    y=selected_columns[1],\n                    color=label_x2,\n                    labels=axis_labels,\n                    title=title)\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def box_and_whisker(df:pandas.DataFrame,                 label_x:Optional[str]=None,                 label_y:Optional[str]=None,                 label_x2:Optional[str]=None,                 title=None,                 show:bool=False):     '''     Creates a box and whisker plot and optionally shows it. Returns the figure for that plot.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      df: The data     label_x: What to group by. Defaults to None     label_y: What to plot on the y axis. Defaults to count of df.columns[0]     label_x2: If provided, splits boxplots into 2+ per x value, each with its own colour     title: Plot title     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured      '''      # Automatically pick columns if not specified     selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_x2], replace_nones=[False, True, False])      fig = px.box(df,                     x=selected_columns[0],                     y=selected_columns[1],                     color=label_x2,                     labels=axis_labels,                     title=title)      # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def histogram(df:pandas.DataFrame,\n                label_x:Optional[str]=None,\n                label_y:Optional[str]=None,\n                label_colour:Optional[str]=None,\n                nbins:Optional[int]=None,\n                title=None,\n                include_boxplot=False,\n                histfunc:Optional[str]=None,\n                show:bool=False):\n    '''\n    Creates a 2D histogram and optionally shows it. Returns the figure for that histogram.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    df: The data\n    label_x: What to bin by. Defaults to df.columns[0]\n    label_y: If provided, the sum of these numbers becomes the y axis. Defaults to count of label_x\n    label_colour: If provided, creates a stacked histogram, splitting each bar by this column\n    title: Plot title\n    nbins: the number of bins to show. None for automatic\n    histfunc: How to calculate y. See plotly for options\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured\n\n    '''\n\n    # Automatically pick columns if not specified\n    selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_colour], replace_nones=[True, False, False])\n\n\n    fig = px.histogram(df,\n                        x=selected_columns[0],\n                        y=selected_columns[1],\n                        nbins=nbins,\n                        color=label_colour,\n                        labels=axis_labels,\n                        title=title,\n                        marginal=\"box\" if include_boxplot else None,\n                        histfunc=histfunc\n                        )\n\n    # Set the boxplot notches to False by default to deal with plotting bug\n    # But only call this line if the user wants to include a boxplot\n    if include_boxplot:\n        fig.data[1].notched = False\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def histogram(df:pandas.DataFrame,                 label_x:Optional[str]=None,                 label_y:Optional[str]=None,                 label_colour:Optional[str]=None,                 nbins:Optional[int]=None,                 title=None,                 include_boxplot=False,                 histfunc:Optional[str]=None,                 show:bool=False):     '''     Creates a 2D histogram and optionally shows it. Returns the figure for that histogram.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      df: The data     label_x: What to bin by. Defaults to df.columns[0]     label_y: If provided, the sum of these numbers becomes the y axis. Defaults to count of label_x     label_colour: If provided, creates a stacked histogram, splitting each bar by this column     title: Plot title     nbins: the number of bins to show. None for automatic     histfunc: How to calculate y. See plotly for options     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured      '''      # Automatically pick columns if not specified     selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_colour], replace_nones=[True, False, False])       fig = px.histogram(df,                         x=selected_columns[0],                         y=selected_columns[1],                         nbins=nbins,                         color=label_colour,                         labels=axis_labels,                         title=title,                         marginal=\"box\" if include_boxplot else None,                         histfunc=histfunc                         )      # Set the boxplot notches to False by default to deal with plotting bug     # But only call this line if the user wants to include a boxplot     if include_boxplot:         fig.data[1].notched = False      # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def multiple_histogram(df:pandas.DataFrame,\n                label_x:str,\n                label_group:str,\n                label_y:Optional[str]=None,\n                histfunc:str='count',\n                nbins:Optional[int]=None,\n                title=None,\n                show:bool=False):\n    '''\n    Creates a 2D histogram and optionally shows it. Returns the figure for that histogram.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    df: The data\n    label_x: What to bin by. Defaults to df.columns[0]\n    label_y: If provided, the sum of these numbers becomes the y axis. Defaults to count of label_x\n    title: Plot title\n    nbins: the number of bins to show. None for automatic\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured\n\n    '''\n\n    assert (histfunc != 'count') or (label_y == None), \"Set histfunc to a value such as sum or avg if using label_y\"\n\n    # Automatically pick columns if not specified\n    selected_columns, axis_labels = _prepare_labels(df,  [label_x, label_y, label_group], replace_nones=[True, False, False])\n\n    fig = graph_objects.Figure(layout=dict(\n                                    title=title,\n                                    xaxis_title_text=axis_labels[label_x],\n                                    yaxis_title_text=histfunc if label_y is None else (histfunc + \" of \" + axis_labels[label_y]))\n                                )\n\n    group_values = sorted(set(df[label_group]))\n\n    for group_value in group_values:\n        dat = df[df[label_group] == group_value]\n        x = dat[selected_columns[0]]\n\n        if label_y is None:\n            y = None\n        else:\n            y = dat[selected_columns[1]]\n\n        fig.add_trace(graph_objects.Histogram(\n            x=x,\n            y=y,\n            histfunc=histfunc,\n            name=group_value, # name used in legend and hover labels\n            nbinsx=nbins))\n\n    #Place legend title\n    fig.update_layout(legend_title_text=label_group)\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def multiple_histogram(df:pandas.DataFrame,                 label_x:str,                 label_group:str,                 label_y:Optional[str]=None,                 histfunc:str='count',                 nbins:Optional[int]=None,                 title=None,                 show:bool=False):     '''     Creates a 2D histogram and optionally shows it. Returns the figure for that histogram.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      df: The data     label_x: What to bin by. Defaults to df.columns[0]     label_y: If provided, the sum of these numbers becomes the y axis. Defaults to count of label_x     title: Plot title     nbins: the number of bins to show. None for automatic     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured      '''      assert (histfunc != 'count') or (label_y == None), \"Set histfunc to a value such as sum or avg if using label_y\"      # Automatically pick columns if not specified     selected_columns, axis_labels = _prepare_labels(df,  [label_x, label_y, label_group], replace_nones=[True, False, False])      fig = graph_objects.Figure(layout=dict(                                     title=title,                                     xaxis_title_text=axis_labels[label_x],                                     yaxis_title_text=histfunc if label_y is None else (histfunc + \" of \" + axis_labels[label_y]))                                 )      group_values = sorted(set(df[label_group]))      for group_value in group_values:         dat = df[df[label_group] == group_value]         x = dat[selected_columns[0]]          if label_y is None:             y = None         else:             y = dat[selected_columns[1]]          fig.add_trace(graph_objects.Histogram(             x=x,             y=y,             histfunc=histfunc,             name=group_value, # name used in legend and hover labels             nbinsx=nbins))      #Place legend title     fig.update_layout(legend_title_text=label_group)      # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def line_2D(\n                trendline:Union[Tuple[str,Callable],List[Tuple[str,Callable]], Dict[str,List[float]]],\n                x_range:List[float]=[0,1],\n                label_x:str='x',\n                label_y:str='y',\n                legend_title:str=\"Line\",\n                title=None,\n                show:bool=False):\n    '''\n    Creates a 2D line plot *using functions* and optionally shows it. Returns the figure for that plot.\n    If you simply want a line plot using data, call scatter_2D then write fig.update_traces(mode='lines')\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    trendline:  (name, function) tuples. The functions accept X (a numpy array) and return Y (an iterable). Alternatively a dict of pre-calculated values\n    x_range:    Sets the x-axis range. If this has more than three values, it is interpeted as each x-value to be graphed\n    label_x:    The title for the x-axis\n    label_y:    The title for the y-axis\n    legend_title: The title for the legend\n    title:      The plot title. If None and a single function is provided, the title is automatically set. Use \"\" to avoid\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured \n\n    '''\n\n    if isinstance(trendline, tuple):\n        trendline = [trendline]\n\n    x = numpy.array([])\n    y = numpy.array([])\n\n    if len(x_range) == 2:\n        x_vals = numpy.linspace(x_range[0], x_range[1], num=200)\n    else:\n        # X-range is interpreted as x_vals\n        x_vals = numpy.array(x_range)\n        x_vals.sort()\n\n        # Rewrite x_range to actually be an x-axis range\n        x_range = [x_vals[0], x_vals[-1]]\n\n    names = []\n\n    if isinstance(trendline, dict):\n        for cur in trendline.items():\n            name = cur[0]\n            x = numpy.concatenate([x, x_vals])\n            names = names + ([name] * len(x_vals))\n            y = numpy.concatenate([y, cur[1]])\n    else:\n        for cur in trendline:\n            name = cur[0]\n            x = numpy.concatenate([x, x_vals])\n            names = names + ([name] * len(x_vals))\n            y = numpy.concatenate([y, cur[1](x=x_vals)])\n    \n    data = dict()\n    data[label_x] = x\n    data[label_y] = y\n    data[legend_title] = names\n\n    df = pandas.DataFrame(data)\n\n    # Pick a title if none provided and we only have one function\n    if (title is None) and (len(trendline) == 1):\n        title = trendline[0][0]\n\n    # Create as a 2d scatter but with lines\n    fig = scatter_2D(df, label_colour=legend_title, title=title, show=False, x_range=x_range)\n    fig.update_traces(mode='lines')\n\n    # Don't show a legend if we only have one function plotted\n    if len(trendline) == 1:\n        fig.update_layout(showlegend=False)\n\n    if show:\n        fig.show()\n\n    return fig\n</pre> def line_2D(                 trendline:Union[Tuple[str,Callable],List[Tuple[str,Callable]], Dict[str,List[float]]],                 x_range:List[float]=[0,1],                 label_x:str='x',                 label_y:str='y',                 legend_title:str=\"Line\",                 title=None,                 show:bool=False):     '''     Creates a 2D line plot *using functions* and optionally shows it. Returns the figure for that plot.     If you simply want a line plot using data, call scatter_2D then write fig.update_traces(mode='lines')      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      trendline:  (name, function) tuples. The functions accept X (a numpy array) and return Y (an iterable). Alternatively a dict of pre-calculated values     x_range:    Sets the x-axis range. If this has more than three values, it is interpeted as each x-value to be graphed     label_x:    The title for the x-axis     label_y:    The title for the y-axis     legend_title: The title for the legend     title:      The plot title. If None and a single function is provided, the title is automatically set. Use \"\" to avoid     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured       '''      if isinstance(trendline, tuple):         trendline = [trendline]      x = numpy.array([])     y = numpy.array([])      if len(x_range) == 2:         x_vals = numpy.linspace(x_range[0], x_range[1], num=200)     else:         # X-range is interpreted as x_vals         x_vals = numpy.array(x_range)         x_vals.sort()          # Rewrite x_range to actually be an x-axis range         x_range = [x_vals[0], x_vals[-1]]      names = []      if isinstance(trendline, dict):         for cur in trendline.items():             name = cur[0]             x = numpy.concatenate([x, x_vals])             names = names + ([name] * len(x_vals))             y = numpy.concatenate([y, cur[1]])     else:         for cur in trendline:             name = cur[0]             x = numpy.concatenate([x, x_vals])             names = names + ([name] * len(x_vals))             y = numpy.concatenate([y, cur[1](x=x_vals)])          data = dict()     data[label_x] = x     data[label_y] = y     data[legend_title] = names      df = pandas.DataFrame(data)      # Pick a title if none provided and we only have one function     if (title is None) and (len(trendline) == 1):         title = trendline[0][0]      # Create as a 2d scatter but with lines     fig = scatter_2D(df, label_colour=legend_title, title=title, show=False, x_range=x_range)     fig.update_traces(mode='lines')      # Don't show a legend if we only have one function plotted     if len(trendline) == 1:         fig.update_layout(showlegend=False)      if show:         fig.show()      return fig In\u00a0[\u00a0]: Copied! <pre>def scatter_2D(df:pandas.DataFrame,\n                label_x:Optional[str]=None,\n                label_y:Optional[str]=None,\n                label_colour:Optional[str]=None,\n                label_size:Optional[str]=None,\n                size_multiplier:float=1,\n                title=None,\n                show:bool=False,\n                x_range:Optional[List[float]]=None,\n                trendline:Union[Callable,List[Callable],None]=None):\n    '''\n    Creates a 2D scatter plot and optionally shows it. Returns the figure for that scatter.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    df: The data\n    label_x: The label to extract from df to plot on the x axis. Defaults to df.columns[0]\n    label_y: The label to extract from df to plot on the y axis. Defaults to df.columns[1]\n    label_colour: The label to extract from df to colour points by\n    title: Plot title\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured \n    x_range:    Overrides the x-axis range\n    trendline:  A function that accepts X (a numpy array) and returns Y (an iterable)\n\n    '''\n\n    # Automatically pick columns if not specified\n    selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_colour], [True, True, False])\n\n\n    # Create the figure and plot\n    fig = px.scatter(df,\n                x=selected_columns[0],\n                y=selected_columns[1],\n                color=selected_columns[2],\n                labels=axis_labels,\n                hover_data=[label_size],\n                title=title\n                )\n\n    if label_size is None:\n        # User a marker size inversely proportional to the number of points\n        size = int((round(22.0 - 19/(1+exp(-(df.shape[0]/100-2)))) * size_multiplier))\n    else:\n        # Set the size based on a label\n        size = df[label_size]*size_multiplier\n\n    fig.update_traces(marker={'size': size})\n\n    if x_range is not None:\n        fig.update_xaxes(range=[x_range[0], x_range[1]])\n\n    # Create trendlines\n    if trendline is not None:\n        if isinstance(trendline, Callable):\n            trendline = [trendline]\n        x_min = min(df[selected_columns[0]]) if x_range is None else x_range[0]\n        x_max = max(df[selected_columns[0]]) if x_range is None else x_range[1]\n        evaluate_for = numpy.linspace(x_min, x_max, num=200)\n        shapes = []\n        for t,colour in zip(trendline,colours_trendline):\n            y_vals = t(evaluate_for)\n            path = \"M\" + \" L \".join([str(c[0]) + \" \" + str(c[1]) for c in zip(evaluate_for,y_vals)])\n            shapes.append(dict(\n                                type=\"path\",\n                                path=path,\n                                line_color=colour,\n                            )\n                        )\n\n        fig.update_layout(shapes=shapes)\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def scatter_2D(df:pandas.DataFrame,                 label_x:Optional[str]=None,                 label_y:Optional[str]=None,                 label_colour:Optional[str]=None,                 label_size:Optional[str]=None,                 size_multiplier:float=1,                 title=None,                 show:bool=False,                 x_range:Optional[List[float]]=None,                 trendline:Union[Callable,List[Callable],None]=None):     '''     Creates a 2D scatter plot and optionally shows it. Returns the figure for that scatter.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      df: The data     label_x: The label to extract from df to plot on the x axis. Defaults to df.columns[0]     label_y: The label to extract from df to plot on the y axis. Defaults to df.columns[1]     label_colour: The label to extract from df to colour points by     title: Plot title     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured      x_range:    Overrides the x-axis range     trendline:  A function that accepts X (a numpy array) and returns Y (an iterable)      '''      # Automatically pick columns if not specified     selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_colour], [True, True, False])       # Create the figure and plot     fig = px.scatter(df,                 x=selected_columns[0],                 y=selected_columns[1],                 color=selected_columns[2],                 labels=axis_labels,                 hover_data=[label_size],                 title=title                 )      if label_size is None:         # User a marker size inversely proportional to the number of points         size = int((round(22.0 - 19/(1+exp(-(df.shape[0]/100-2)))) * size_multiplier))     else:         # Set the size based on a label         size = df[label_size]*size_multiplier      fig.update_traces(marker={'size': size})      if x_range is not None:         fig.update_xaxes(range=[x_range[0], x_range[1]])      # Create trendlines     if trendline is not None:         if isinstance(trendline, Callable):             trendline = [trendline]         x_min = min(df[selected_columns[0]]) if x_range is None else x_range[0]         x_max = max(df[selected_columns[0]]) if x_range is None else x_range[1]         evaluate_for = numpy.linspace(x_min, x_max, num=200)         shapes = []         for t,colour in zip(trendline,colours_trendline):             y_vals = t(evaluate_for)             path = \"M\" + \" L \".join([str(c[0]) + \" \" + str(c[1]) for c in zip(evaluate_for,y_vals)])             shapes.append(dict(                                 type=\"path\",                                 path=path,                                 line_color=colour,                             )                         )          fig.update_layout(shapes=shapes)      # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def scatter_3D(df:pandas.DataFrame,\n                label_x:Optional[str]=None,\n                label_y:Optional[str]=None,\n                label_z:Optional[str]=None,\n                label_colour:Optional[str]=None,\n                title=None,\n                show:bool=False):\n    '''\n    Creates a 3D scatter plot and optionally shows it. Returns the figure for that scatter.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    df: The data\n    label_x: The label to extract from df to plot on the x axis. Defaults to df.columns[0]\n    label_y: The label to extract from df to plot on the y axis. Defaults to df.columns[1]\n    label_z: The label to extract from df to plot on the z axis. Defaults to df.columns[2]\n    label_colour: The label to extract from df to colour points by. Defaults to label_x\n    title: Plot title\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured\n    '''\n\n    # Automatically pick columns if not specified\n    selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_z])\n\n    if label_colour is None:\n        # Colour by the Z dimension\n        label_colour = selected_columns[2]\n    else:\n        axis_labels[label_colour] = _to_human_readable(label_colour)\n\n    # Create the figure and plot\n    fig = px.scatter_3d(df,\n                x=selected_columns[0],\n                y=selected_columns[1],\n                z=selected_columns[2],\n                color=label_colour,\n                labels=axis_labels,\n                title=title)\n\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def scatter_3D(df:pandas.DataFrame,                 label_x:Optional[str]=None,                 label_y:Optional[str]=None,                 label_z:Optional[str]=None,                 label_colour:Optional[str]=None,                 title=None,                 show:bool=False):     '''     Creates a 3D scatter plot and optionally shows it. Returns the figure for that scatter.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      df: The data     label_x: The label to extract from df to plot on the x axis. Defaults to df.columns[0]     label_y: The label to extract from df to plot on the y axis. Defaults to df.columns[1]     label_z: The label to extract from df to plot on the z axis. Defaults to df.columns[2]     label_colour: The label to extract from df to colour points by. Defaults to label_x     title: Plot title     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured     '''      # Automatically pick columns if not specified     selected_columns, axis_labels = _prepare_labels(df, [label_x, label_y, label_z])      if label_colour is None:         # Colour by the Z dimension         label_colour = selected_columns[2]     else:         axis_labels[label_colour] = _to_human_readable(label_colour)      # Create the figure and plot     fig = px.scatter_3d(df,                 x=selected_columns[0],                 y=selected_columns[1],                 z=selected_columns[2],                 color=label_colour,                 labels=axis_labels,                 title=title)       # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def surface(x_values,\n            y_values,\n            calc_z:Callable,\n            title=None,\n            axis_title_x:Optional[str]=None,\n            axis_title_y:Optional[str]=None,\n            axis_title_z:Optional[str]=None,\n            show:bool=False):\n    '''\n    Creates a surface plot using a function. Returns the figure for that plot.\n\n    Note that if calling this from jupyter notebooks and not capturing the output\n    it will appear on screen as though `.show()` has been called\n\n    x_value: A numpy array of x values\n    y_value: A numpy array of y values\n    calc_z: A function to calculate z, given an x and a y value\n    title: Plot title\n    axis_title_x: Title for the x axis\n    axis_title_y: Title for the y axis\n    axis_title_z: Title for the z axis\n    show:   appears on screen. NB that this is not needed if this is called from a\n            notebook and the output is not captured\n    '''\n\n    # Check arguments\n    assert len(x_values.shape) == 1, \"Provide x_values as 1D\"\n    assert len(y_values.shape) == 1, \"Provide y_values as 1D\"\n\n\n    # Calculate z for a range of x and y inputs\n    # Note that z seems to be expected to be indexed [y,x] not [x,y] though this appears to\n    # be counter to the documentation. If z is indexed [x, y] the result is flipped.\n    # Potentially there is a bug here somewhere causing this issue or in plotly itself\n    z = numpy.zeros((y_values.shape[0], x_values.shape[0]))\n    for i_x in range(x_values.shape[0]):\n        for i_y in range(y_values.shape[0]):\n            z[i_y, i_x] = calc_z(x_values[i_x], y_values[i_y])\n            \n    # Create a graph of cost\n    fig = graph_objects.Figure(data=[graph_objects.Surface(x=x_values, y=y_values, z=z)])\n    fig.update_layout(title=title,\n                      scene_xaxis_title=axis_title_x,\n                      scene_yaxis_title=axis_title_y,\n                      scene_zaxis_title=axis_title_z)\n\n    #Add z-axis as colourbar title\n    fig.update_traces(colorbar_title_text= axis_title_z, selector=dict(type='surface'))\n\n    # Show the plot, if requested\n    if show:\n        fig.show()\n\n    # return the figure\n    return fig\n</pre> def surface(x_values,             y_values,             calc_z:Callable,             title=None,             axis_title_x:Optional[str]=None,             axis_title_y:Optional[str]=None,             axis_title_z:Optional[str]=None,             show:bool=False):     '''     Creates a surface plot using a function. Returns the figure for that plot.      Note that if calling this from jupyter notebooks and not capturing the output     it will appear on screen as though `.show()` has been called      x_value: A numpy array of x values     y_value: A numpy array of y values     calc_z: A function to calculate z, given an x and a y value     title: Plot title     axis_title_x: Title for the x axis     axis_title_y: Title for the y axis     axis_title_z: Title for the z axis     show:   appears on screen. NB that this is not needed if this is called from a             notebook and the output is not captured     '''      # Check arguments     assert len(x_values.shape) == 1, \"Provide x_values as 1D\"     assert len(y_values.shape) == 1, \"Provide y_values as 1D\"       # Calculate z for a range of x and y inputs     # Note that z seems to be expected to be indexed [y,x] not [x,y] though this appears to     # be counter to the documentation. If z is indexed [x, y] the result is flipped.     # Potentially there is a bug here somewhere causing this issue or in plotly itself     z = numpy.zeros((y_values.shape[0], x_values.shape[0]))     for i_x in range(x_values.shape[0]):         for i_y in range(y_values.shape[0]):             z[i_y, i_x] = calc_z(x_values[i_x], y_values[i_y])                  # Create a graph of cost     fig = graph_objects.Figure(data=[graph_objects.Surface(x=x_values, y=y_values, z=z)])     fig.update_layout(title=title,                       scene_xaxis_title=axis_title_x,                       scene_yaxis_title=axis_title_y,                       scene_zaxis_title=axis_title_z)      #Add z-axis as colourbar title     fig.update_traces(colorbar_title_text= axis_title_z, selector=dict(type='surface'))      # Show the plot, if requested     if show:         fig.show()      # return the figure     return fig In\u00a0[\u00a0]: Copied! <pre>def model_to_surface_plot(model, plot_features:List[str], data:pandas.DataFrame):\n    '''Plots two features of a model as a surface. Other values are set at their means\n    \n    model:          A model that accepts a dataframe for prediction\n    plot_features:  Two features to plot\n    data:           A dataframe the model was trained or tested on\n    '''\n\n    # Give status as this can take several seconds to run\n    print(\"Creating plot...\")\n\n    \n    other_features = [f for f in data.columns if f not in plot_features]\n\n    means = numpy.average(data[other_features], axis=0)\n    mins = numpy.min(data[plot_features], axis=0)\n    maxes = numpy.max(data[plot_features], axis=0)\n\n    df = pandas.DataFrame()\n\n    for f,m in zip(other_features, means):\n        df[f] = [m]\n\n    def predict(x, y):\n        '''\n        Makes a prediction using the model\n        '''\n        df[plot_features[0]] = [x]\n        df[plot_features[1]] = [y]\n\n        return model.predict(df)\n\n    # Create a 3d plot of predictions\n    x_vals = numpy.array(numpy.linspace(mins[plot_features[0]], maxes[plot_features[0]],20))\n    y_vals = numpy.array(numpy.linspace(mins[plot_features[1]], maxes[plot_features[1]],20))\n\n    return surface(x_vals, \n                    y_vals, \n                    predict, \n                    title=\"Model Prediction\", \n                    axis_title_x=plot_features[0], \n                    axis_title_y=plot_features[1], \n                    axis_title_z=\"Probability\")\n</pre> def model_to_surface_plot(model, plot_features:List[str], data:pandas.DataFrame):     '''Plots two features of a model as a surface. Other values are set at their means          model:          A model that accepts a dataframe for prediction     plot_features:  Two features to plot     data:           A dataframe the model was trained or tested on     '''      # Give status as this can take several seconds to run     print(\"Creating plot...\")           other_features = [f for f in data.columns if f not in plot_features]      means = numpy.average(data[other_features], axis=0)     mins = numpy.min(data[plot_features], axis=0)     maxes = numpy.max(data[plot_features], axis=0)      df = pandas.DataFrame()      for f,m in zip(other_features, means):         df[f] = [m]      def predict(x, y):         '''         Makes a prediction using the model         '''         df[plot_features[0]] = [x]         df[plot_features[1]] = [y]          return model.predict(df)      # Create a 3d plot of predictions     x_vals = numpy.array(numpy.linspace(mins[plot_features[0]], maxes[plot_features[0]],20))     y_vals = numpy.array(numpy.linspace(mins[plot_features[1]], maxes[plot_features[1]],20))      return surface(x_vals,                      y_vals,                      predict,                      title=\"Model Prediction\",                      axis_title_x=plot_features[0],                      axis_title_y=plot_features[1],                      axis_title_z=\"Probability\") In\u00a0[\u00a0]: Copied! <pre>def save_plot_as_image(fig, file=\"./plot.jpg\", width=None, height=\"400\", scale=1, format=\"jpg\"):\n    \"\"\"\n    Convert a figure to a static image and write it to a file or writeable object\n    If \"width\" not set, plotly will set the aspect ration based on \"hight\"\n\n    Parameters  \n\n        fig \u2013 Figure object or dict representing a figure\n        file (str or writeable) \u2013 A string representing a local file path or a writeable object (e.g. an open file descriptor)\n        format (str or None) \u2013 The desired image format:\n\n                \u2019png\u2019\n                \u2019jpg\u2019 or \u2018jpeg\u2019\n                \u2019webp\u2019\n                \u2019svg\u2019\n                \u2019pdf\u2019\n                \u2019eps\u2019 (Requires the poppler library to be installed and on the PATH)\n\n        width (int or None) \u2013 The width of the exported image in layout pixels. \n        height (int or None) \u2013 The height of the exported image in layout pixels. \n\n        scale (int or float or None) \u2013 The scale factor to use when exporting the figure. \n        A scale factor larger than 1.0 will increase the image resolution with respect to the \n        figure\u2019s layout pixel dimensions. Whereas as scale factor of less than 1.0 will decrease \n        the image resolution.\n    \"\"\"\n    pio.write_image(fig, \n                    file=file, \n                    width=width, \n                    height=height, \n                    scale=scale,\n                    format=format, \n                    engine=\"kaleido\",\n                    )\n</pre> def save_plot_as_image(fig, file=\"./plot.jpg\", width=None, height=\"400\", scale=1, format=\"jpg\"):     \"\"\"     Convert a figure to a static image and write it to a file or writeable object     If \"width\" not set, plotly will set the aspect ration based on \"hight\"      Parameters            fig \u2013 Figure object or dict representing a figure         file (str or writeable) \u2013 A string representing a local file path or a writeable object (e.g. an open file descriptor)         format (str or None) \u2013 The desired image format:                  \u2019png\u2019                 \u2019jpg\u2019 or \u2018jpeg\u2019                 \u2019webp\u2019                 \u2019svg\u2019                 \u2019pdf\u2019                 \u2019eps\u2019 (Requires the poppler library to be installed and on the PATH)          width (int or None) \u2013 The width of the exported image in layout pixels.          height (int or None) \u2013 The height of the exported image in layout pixels.           scale (int or float or None) \u2013 The scale factor to use when exporting the figure.          A scale factor larger than 1.0 will increase the image resolution with respect to the          figure\u2019s layout pixel dimensions. Whereas as scale factor of less than 1.0 will decrease          the image resolution.     \"\"\"     pio.write_image(fig,                      file=file,                      width=width,                      height=height,                      scale=scale,                     format=format,                      engine=\"kaleido\",                     )"},{"location":"futuro/exemplos/01_Funcion_Built-in/","title":"Important Built-in Functions","text":"<p>https://docs.python.org/3/tutorial/datastructures.html</p> <p>Documenta\u00e7\u00e3o: https://docs.python.org/pt-br/3/library/functions.html</p>  Important Built-in Functions <p>A list comprehension \u00e9 uma forma concisa e elegante de criar listas em Python. Ela permite que voc\u00ea crie uma nova lista aplicando uma express\u00e3o a cada elemento de uma sequ\u00eancia (como uma lista, tupla ou conjunto).</p> <ol> <li>Sintaxe<ul> <li>A sintaxe geral de uma list comprehension \u00e9: <code>[express\u00e3o for elemento in sequ\u00eancia]</code>.</li> <li>Voc\u00ea pode adicionar uma cl\u00e1usula if para filtrar elementos: <code>[express\u00e3o for elemento in sequ\u00eancia if condi\u00e7\u00e3o]</code>.</li> </ul> </li> </ol> <ul> <li>Outro op\u00e7\u00e3o de Formato padr\u00e3o:<pre>[express\u00e3o for item in lista]\n[expr for item in lista if cond]\n</pre> </li> </ul> <ol> <li>Exemplos</li> </ol> In\u00a0[2]: Copied! <pre># Criando uma lista de quadrados para\nnumeros = [1, 2, 3, 4, 5]\nquadrados = [x**2 for x in numeros]\nprint(quadrados)  # Output: [1, 4, 9, 16, 25]\n</pre> # Criando uma lista de quadrados para numeros = [1, 2, 3, 4, 5] quadrados = [x**2 for x in numeros] print(quadrados)  # Output: [1, 4, 9, 16, 25]  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[3]: Copied! <pre># Filtrando n\u00fameros pares\nnumeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nnumeros_pares = [x for x in numeros if x % 2 == 0]\nprint(numeros_pares)\n</pre> # Filtrando n\u00fameros pares numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] numeros_pares = [x for x in numeros if x % 2 == 0] print(numeros_pares) <pre>[2, 4, 6, 8, 10]\n</pre> In\u00a0[4]: Copied! <pre># Criando uma lista de strings em mai\u00fasculas\npalavras = ['python', '\u00e9', 'incr\u00edvel']\nmaiusculas = [palavra.upper() for palavra in palavras]\nprint(maiusculas)\n</pre> # Criando uma lista de strings em mai\u00fasculas palavras = ['python', '\u00e9', 'incr\u00edvel'] maiusculas = [palavra.upper() for palavra in palavras] print(maiusculas) <pre>['PYTHON', '\u00c9', 'INCR\u00cdVEL']\n</pre> In\u00a0[5]: Copied! <pre># Gerando uma lista de tuplas\nnumeros = [1,2,3]\ntuplas = [(x, x**2) for x in numeros]\nprint(tuplas)\n</pre> # Gerando uma lista de tuplas numeros = [1,2,3] tuplas = [(x, x**2) for x in numeros] print(tuplas) <pre>[(1, 1), (2, 4), (3, 9)]\n</pre> <p>As fun\u00e7\u00f5es lambda em Python s\u00e3o fun\u00e7\u00f5es an\u00f4nimas que podem ser definidas em uma \u00fanica linha de c\u00f3digo. Elas s\u00e3o \u00fateis para criar pequenas fun\u00e7\u00f5es sem a necessidade de dar um nome a elas.</p> <p>https://docs.python.org/pt-br/3/reference/expressions.html?#lambda</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral de uma fun\u00e7\u00e3o lambda \u00e9: <code>lambda argumentos: express\u00e3o</code>.</li> <li>Voc\u00ea pode usar uma fun\u00e7\u00e3o lambda em qualquer lugar onde normalmente usaria uma fun\u00e7\u00e3o regular.</li> </ul> </li> </ol> <ul> <li>Outra op\u00e7\u00e3o de formato Geral<pre>lambda &lt;variavel_entrada&gt;: &lt;expressao&gt;\n</pre> </li> </ul> <ol> <li>Exemplos</li> </ol> In\u00a0[6]: Copied! <pre># Fun\u00e7\u00e3o que retorna o quadrado de um n\u00famero\ndobrar = lambda x_entrada: x_entrada * 2\nprint(dobrar(5))\n</pre> # Fun\u00e7\u00e3o que retorna o quadrado de um n\u00famero dobrar = lambda x_entrada: x_entrada * 2 print(dobrar(5)) <pre>10\n</pre> In\u00a0[7]: Copied! <pre># Fun\u00e7\u00e3o que verifica se um numero \u00e9 par\neh_par = lambda x_entrada: x_entrada % 2 == 0\nprint(eh_par(7))\n</pre> # Fun\u00e7\u00e3o que verifica se um numero \u00e9 par eh_par = lambda x_entrada: x_entrada % 2 == 0 print(eh_par(7)) <pre>False\n</pre> In\u00a0[8]: Copied! <pre># Fun\u00e7\u00e3o que soma 2 em cada elemento de uma lista\nsoma_dois = lambda lista_entrada: [x + 2 for x in lista_entrada]\n\n# Exemplo de uso:\nnumeros = [1, 3, 5, 7]\nresultado = soma_dois(numeros)\nprint(f\"Resultado: {resultado}\")\n</pre> # Fun\u00e7\u00e3o que soma 2 em cada elemento de uma lista soma_dois = lambda lista_entrada: [x + 2 for x in lista_entrada]  # Exemplo de uso: numeros = [1, 3, 5, 7] resultado = soma_dois(numeros) print(f\"Resultado: {resultado}\")  <pre>Resultado: [3, 5, 7, 9]\n</pre> In\u00a0[9]: Copied! <pre># Fun\u00e7\u00e3o para order um dicionario\nprodutos = [\n    {\"nome\": \"Ma\u00e7\u00e3\", \"preco\": 2.5},\n    {\"nome\": \"Banana\", \"preco\": 1.8},\n    {\"nome\": \"Laranja\", \"preco\": 0.1}\n]\nprodutos_ordenados = sorted(produtos, key=lambda preso_entrada: preso_entrada[\"preco\"])\nprodutos_ordenados\n</pre> # Fun\u00e7\u00e3o para order um dicionario produtos = [     {\"nome\": \"Ma\u00e7\u00e3\", \"preco\": 2.5},     {\"nome\": \"Banana\", \"preco\": 1.8},     {\"nome\": \"Laranja\", \"preco\": 0.1} ] produtos_ordenados = sorted(produtos, key=lambda preso_entrada: preso_entrada[\"preco\"]) produtos_ordenados Out[9]: <pre>[{'nome': 'Laranja', 'preco': 0.1},\n {'nome': 'Banana', 'preco': 1.8},\n {'nome': 'Ma\u00e7\u00e3', 'preco': 2.5}]</pre> In\u00a0[10]: Copied! <pre># Mapeamento de uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista\nnumeros = [1, 2, 3, 4, 5]\nquadrados = list(\n    map(lambda x_entrada: x_entrada**2, numeros)\n    )\nprint(quadrados)\n</pre> # Mapeamento de uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista numeros = [1, 2, 3, 4, 5] quadrados = list(     map(lambda x_entrada: x_entrada**2, numeros)     ) print(quadrados)  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[11]: Copied! <pre># Filtrando uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista\nnumeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nnumeros_pares = list(\n    filter(lambda x_entrada: x_entrada % 2 == 0, numeros )\n)\nnumeros_pares\n</pre> # Filtrando uma lista: Aplicando uma fun\u00e7\u00e3o `lambda` em uma lista numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  numeros_pares = list(     filter(lambda x_entrada: x_entrada % 2 == 0, numeros ) ) numeros_pares Out[11]: <pre>[2, 4, 6, 8, 10]</pre> <p>A fun\u00e7\u00e3o map() em Python \u00e9 usada para aplicar uma fun\u00e7\u00e3o a cada elemento de uma sequ\u00eancia (como uma lista, tupla ou conjunto) e retornar um iterador com os resultados.</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral da fun\u00e7\u00e3o map() \u00e9: <code>map(funcao, sequencia)</code>.</li> <li>A fun\u00e7\u00e3o funcao \u00e9 aplicada a cada elemento da sequencia.</li> </ul> </li> </ol> <ul> <li>Outra o\u00e7\u00e3o de formato Geral:<pre>map(&lt;lambda function&gt;, &lt;iterador&gt;)\n</pre> </li> </ul> In\u00a0[12]: Copied! <pre># Eleva cada n\u00famero ao quadrado: Aplica uma fun\u00e7\u00e3o em cada element de uma lista\nnumeros = [1, 2, 3, 4, 5]\nquadrados = list(\n    map(lambda x_entrada: x_entrada**2, numeros)\n    )\nprint(quadrados)\n</pre> # Eleva cada n\u00famero ao quadrado: Aplica uma fun\u00e7\u00e3o em cada element de uma lista numeros = [1, 2, 3, 4, 5] quadrados = list(     map(lambda x_entrada: x_entrada**2, numeros)     ) print(quadrados)  <pre>[1, 4, 9, 16, 25]\n</pre> In\u00a0[13]: Copied! <pre>palavras = [\"python\", \"\u00e9\", \"incr\u00edvel\"]\nresultado = list(\n    map(lambda x_entrada: x_entrada.upper(), palavras)\n)\nprint(resultado)\n</pre> palavras = [\"python\", \"\u00e9\", \"incr\u00edvel\"] resultado = list(     map(lambda x_entrada: x_entrada.upper(), palavras) ) print(resultado) <pre>['PYTHON', '\u00c9', 'INCR\u00cdVEL']\n</pre> <p>A fun\u00e7\u00e3o <code>filter()</code> em Python \u00e9 usada para filtrar elementos de uma sequ\u00eancia (como uma lista, tupla ou conjunto) com base em uma condi\u00e7\u00e3o especificada. Ela retorna um iterador contendo apenas os elementos que atendem \u00e0 condi\u00e7\u00e3o</p> <ol> <li>Sintaxe:<ul> <li>A sintaxe geral da fun\u00e7\u00e3o filter() \u00e9: <code>filter(funcao, sequencia)</code>.</li> <li>A fun\u00e7\u00e3o funcao deve retornar True ou False para cada elemento da sequencia.</li> </ul> </li> </ol> <p>2.Exemplo</p> In\u00a0[14]: Copied! <pre># Filtrando n\u00fameros pares: Aplicando a um filtro em uma lista de elementos\nnumeros = [1, 2, 3, 4, 5]\nnumeros_pares = list(\n    filter(lambda x: x % 2 == 0, numeros)\n    )\nprint(numeros_pares)\n</pre> # Filtrando n\u00fameros pares: Aplicando a um filtro em uma lista de elementos numeros = [1, 2, 3, 4, 5] numeros_pares = list(     filter(lambda x: x % 2 == 0, numeros)     ) print(numeros_pares)  <pre>[2, 4]\n</pre> <p>O zip() \u00e9 uma fun\u00e7\u00e3o embutida do Python que combina elementos de duas ou mais sequ\u00eancias, como listas ou tuplas. Ele cria um iterador que produz tuplas contendo um elemento de cada sequ\u00eancia. O zip() \u00e9 uma ferramenta poderosa para combinar e descompactar sequ\u00eancias.</p> <ol> <li>sintaxe: <code>zip(iter\u00e1vel1, iter\u00e1vel2, ...)</code></li> </ol> <ol> <li>Exemplo</li> </ol> In\u00a0[18]: Copied! <pre># Usando zip() para combinar as listas\nlista1 = [1, 2, 3]\nlista2 = ['a', 'b', 'c']\n\ncombinacao = list(\n    zip(lista1, lista2)\n)\n\nprint(combinacao) \n</pre> # Usando zip() para combinar as listas lista1 = [1, 2, 3] lista2 = ['a', 'b', 'c']  combinacao = list(     zip(lista1, lista2) )  print(combinacao)   <pre>[(1, 'a'), (2, 'b'), (3, 'c')]\n</pre> In\u00a0[22]: Copied! <pre># Descompactando uma lista de tuplas\n\ntuplas = [(1, 'a'), (2, 'b'), (3, 'c')]\n\n# Usando zip() para descompactar as tuplas\ndescompactado1, descompactado2 = zip(*tuplas)\n\nprint(descompactado1)\nprint(descompactado2)\n\nprint(\"--------------------------------\")\nprint(tuplas)\nprint(*tuplas)\n</pre> # Descompactando uma lista de tuplas  tuplas = [(1, 'a'), (2, 'b'), (3, 'c')]  # Usando zip() para descompactar as tuplas descompactado1, descompactado2 = zip(*tuplas)  print(descompactado1) print(descompactado2)  print(\"--------------------------------\") print(tuplas) print(*tuplas)  <pre>(1, 2, 3)\n('a', 'b', 'c')\n--------------------------------\n[(1, 'a'), (2, 'b'), (3, 'c')]\n(1, 'a') (2, 'b') (3, 'c')\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[16]: Copied! <pre>numeros = [1, 2, 3, 4, 5]\n\n# Eleva cada n\u00famero ao quadrado, e filtra baseado em uma condi\u00e7\u00e3o.\nquadrados = list(\n    filter(lambda x: x**2 == 4, numeros)\n    )\nprint(quadrados)\n</pre> numeros = [1, 2, 3, 4, 5]  # Eleva cada n\u00famero ao quadrado, e filtra baseado em uma condi\u00e7\u00e3o. quadrados = list(     filter(lambda x: x**2 == 4, numeros)     ) print(quadrados)  <pre>[2]\n</pre> In\u00a0[17]: Copied! <pre>numeros = [1, 2, 3, 4, 5]\n\n# Eleva cada n\u00famero ao quadrado e verifica uma condi\u00e7\u00e3o.\nquadrados = list(\n    map(lambda x: x**2 == 4, numeros)\n    )\nprint(quadrados)\n</pre> numeros = [1, 2, 3, 4, 5]  # Eleva cada n\u00famero ao quadrado e verifica uma condi\u00e7\u00e3o. quadrados = list(     map(lambda x: x**2 == 4, numeros)     ) print(quadrados)  <pre>[False, True, False, False, False]\n</pre>"},{"location":"futuro/exemplos/01_Funcion_Built-in/#1-list-comprehension","title":"1. <code>list comprehension</code>\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#2-lambda","title":"2. <code>Lambda</code>\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#3-map","title":"3. <code>Map</code>\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#3-filter","title":"3. <code>Filter</code>\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#4-zip","title":"4. <code>Zip()</code>\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#entendendo-algumas-diferencas-entre-map-e-filter","title":"Entendendo algumas diferen\u00e7as entre MAP e FILTER\u00b6","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/","title":"01 Funcion Built in","text":""},{"location":"futuro/exemplos/01_Funcion_Built-in/#funcoes-built-in-do-python","title":"Fun\u00e7\u00f5es Built-in do Python","text":"<p>O Python possui v\u00e1rias fun\u00e7\u00f5es built-in que est\u00e3o sempre dispon\u00edveis para uso. Aqui est\u00e3o algumas delas em ordem alfab\u00e9tica:</p> <ul> <li><code>abs(x)</code>: Retorna o valor absoluto de um n\u00famero (inteiro ou ponto flutuante).</li> <li><code>all(iterable)</code>: Retorna True se todos os elementos do iter\u00e1vel forem verdadeiros (ou se o iter\u00e1vel estiver vazio).</li> <li><code>any(iterable)</code>: Retorna True se qualquer elemento do iter\u00e1vel for verdadeiro.</li> <li><code>ascii(object)</code>: Retorna uma representa\u00e7\u00e3o imprim\u00edvel de um objeto, escapando caracteres n\u00e3o-ASCII.</li> <li><code>bin(x)</code>: Converte um n\u00famero inteiro para uma string de bin\u00e1rios prefixada com \u201c0b\u201d.</li> <li><code>bool(x)</code>: Retorna um valor booleano (True ou False).</li> <li><code>bytearray(source[, encoding[, errors]])</code>: Retorna um novo vetor de bytes mut\u00e1vel.</li> <li><code>bytes([source[, encoding[, errors]]])</code>: Retorna um objeto de bytes imut\u00e1vel.</li> <li><code>callable(object)</code>: Verifica se o objeto \u00e9 cham\u00e1vel (pode ser chamado como uma fun\u00e7\u00e3o).</li> <li><code>chr(i)</code>: Retorna uma string representando um caractere Unicode cujo c\u00f3digo \u00e9 i.</li> <li><code>complex(real[, imag])</code>: Retorna um n\u00famero complexo.</li> <li><code>delattr(object, name)</code>: Remove um atributo de um objeto.</li> <li><code>dict([iterable])</code>: Retorna um dicion\u00e1rio.</li> <li><code>divmod(a, b)</code>: Retorna o quociente e o resto da divis\u00e3o de a por b.</li> <li><code>enumerate(iterable, start=0)</code>: Retorna um objeto enumerado (pares \u00edndice-valor).</li> <li><code>filter(function, iterable)</code>: Filtra elementos do iter\u00e1vel com base em uma fun\u00e7\u00e3o.</li> <li><code>float(x)</code>: Converte um n\u00famero ou string para um ponto flutuante.</li> <li><code>format(value[, format_spec])</code>: Formata um valor de acordo com a especifica\u00e7\u00e3o de formato.</li> <li><code>frozenset([iterable])</code>: Retorna um conjunto imut\u00e1vel.</li> <li><code>getattr(object, name[, default])</code>: Retorna o valor de um atributo de um objeto.</li> <li><code>globals()</code>: Retorna um dicion\u00e1rio com as vari\u00e1veis globais.</li> <li><code>hasattr(object, name)</code>: Verifica se um objeto tem um atributo.</li> <li><code>hash(object)</code>: Retorna o valor hash de um objeto.</li> <li><code>hex(x)</code>: Converte um n\u00famero inteiro para uma string hexadecimal.</li> <li><code>id(object)</code>: Retorna o identificador \u00fanico de um objeto.</li> <li><code>input([prompt])</code>: L\u00ea uma linha da entrada padr\u00e3o.</li> <li><code>int(x[, base])</code>: Converte um n\u00famero ou string para um inteiro.</li> <li><code>isinstance(object, classinfo)</code>: Verifica se um objeto \u00e9 uma inst\u00e2ncia de uma classe.</li> <li><code>issubclass(class, classinfo)</code>: Verifica se uma classe \u00e9 subclasse de outra.</li> <li><code>iter(iterable[, sentinel])</code>: Retorna um iterador para o iter\u00e1vel.</li> <li><code>len(s)</code>: Retorna o n\u00famero de elementos em uma sequ\u00eancia (string, lista, tupla, etc.).</li> <li><code>list([iterable])</code>: Retorna uma lista.</li> <li><code>locals()</code>: Retorna um dicion\u00e1rio com as vari\u00e1veis locais.</li> <li><code>map(function, iterable, ...)</code>: Aplica uma fun\u00e7\u00e3o a cada elemento do iter\u00e1vel.</li> <li><code>max(iterable[, key])</code>: Retorna o maior elemento do iter\u00e1vel.</li> <li><code>memoryview(obj)</code>: Retorna uma vis\u00e3o de mem\u00f3ria de um objeto.</li> <li><code>min(iterable[, key])</code>: Retorna o menor elemento do iter\u00e1vel.</li> <li><code>next(iterator[, default])</code>: Retorna o pr\u00f3ximo elemento de um iterador.</li> <li><code>object()</code>: Retorna um novo objeto vazio.</li> <li><code>oct(x)</code>: Converte um n\u00famero inteiro para uma string octal.</li> <li><code>open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</code>: Abre um arquivo.</li> <li><code>ord(c)</code>: Retorna o valor Unicode do caractere.</li> <li><code>pow(x, y[, z])</code>: Calcula x elevado \u00e0 pot\u00eancia y (opcionalmente m\u00f3dulo z).</li> <li><code>print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)</code>: Imprime objetos na sa\u00edda padr\u00e3o.</li> <li><code>property([fget[, fset[, fdel[, doc]]]])</code>: Retorna uma propriedade.</li> <li><code>range(stop)</code>, <code>range(start, stop[, step])</code>: Retorna uma sequ\u00eancia de valores.</li> </ul>"},{"location":"futuro/exemplos/02_Loc_Iloc/","title":"02 Loc Iloc","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import pandas as pd import numpy as np  import matplotlib.pyplot as plt import seaborn as sns In\u00a0[3]: Copied! <pre># Exemplo de DataFrame\ndata = {\n    'PassengerId': [1, 2, 3],\n    'Survived': [1, 0, 1],\n    'Pclass': [3, 1, 3],\n    'Name': ['Name1', 'Name2', 'Name3'],\n    'Sex': ['male', 'female', 'female']\n}\ndf_train = pd.DataFrame(data)\n</pre> # Exemplo de DataFrame data = {     'PassengerId': [1, 2, 3],     'Survived': [1, 0, 1],     'Pclass': [3, 1, 3],     'Name': ['Name1', 'Name2', 'Name3'],     'Sex': ['male', 'female', 'female'] } df_train = pd.DataFrame(data) In\u00a0[5]: Copied! <pre>df_train.loc[0:4, 'Survived':'Sex']\n</pre> df_train.loc[0:4, 'Survived':'Sex'] Out[5]: Survived Pclass Name Sex 0 1 3 Name1 male 1 0 1 Name2 female 2 1 3 Name3 female In\u00a0[6]: Copied! <pre>df_train.loc[0:4, 'Sex']\n</pre> df_train.loc[0:4, 'Sex'] Out[6]: <pre>0      male\n1    female\n2    female\nName: Sex, dtype: object</pre> In\u00a0[7]: Copied! <pre>df_train.loc[0:4]['Sex']\n</pre> df_train.loc[0:4]['Sex'] Out[7]: <pre>0      male\n1    female\n2    female\nName: Sex, dtype: object</pre> In\u00a0[9]: Copied! <pre>df_train.iloc[0:4, 2:4]\n</pre> df_train.iloc[0:4, 2:4] Out[9]: Pclass Name 0 3 Name1 1 1 Name2 2 3 Name3"},{"location":"futuro/exemplos/Learning_curve_1/","title":"Titanic data","text":"In\u00a0[1]: Copied! <pre># data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> # data analysis and wrangling import pandas as pd import numpy as np import random as rnd  # visualization import seaborn as sns import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>#-----------------------------------------------------------\n# Step 01: load data using panda\n#-----------------------------------------------------------\ntrain_df = pd.read_csv('Bases/Titanic_train.csv')  # train set\ntest_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set\ncombine  = [train_df, test_df]\n</pre> #----------------------------------------------------------- # Step 01: load data using panda #----------------------------------------------------------- train_df = pd.read_csv('Bases/Titanic_train.csv')  # train set test_df  = pd.read_csv('Bases/Titanic_test.csv')   # test  set combine  = [train_df, test_df] In\u00a0[3]: Copied! <pre>#-----------------------------------------------------------\n# Step 02: Acquire and clean data\n#-----------------------------------------------------------\ntrain_df.head(5)\n</pre> #----------------------------------------------------------- # Step 02: Acquire and clean data #----------------------------------------------------------- train_df.head(5) Out[3]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S In\u00a0[4]: Copied! <pre>train_df.info()\n</pre> train_df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n</pre> In\u00a0[5]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[5]: PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 In\u00a0[6]: Copied! <pre>train_df.describe(include=['O'])\n</pre> train_df.describe(include=['O']) Out[6]: Name Sex Ticket Cabin Embarked count 891 891 891 204 889 unique 891 2 681 147 3 top Braund, Mr. Owen Harris male 347082 B96 B98 S freq 1 577 7 4 644 <p>Training data statistics:</p> <ul> <li>891 training samples</li> <li>Age, Cabin, Embarked: incomplete data</li> <li>Data type:<ul> <li>object: Name, Sex, Ticket, Cabin, Embarked</li> <li>int64: PassengerId, Survived, Pclass, SibSp, Parch</li> <li>float64: Age, Fare</li> </ul> </li> <li>Survive rate: 0.383838</li> </ul> <p>Estat\u00edsticas dos dados de treinamento:</p> <ul> <li>891 amostras de treinamento</li> <li>Idade, Cabine, Embarque: dados incompletos</li> <li>Tipo de dados:<ul> <li>objeto: Nome, Sexo, Bilhete, Cabine, Embarque</li> <li>int64: PassengerId, Sobreviveu, Classe, SibSp, Parch</li> <li>float64: Idade, Tarifa</li> <li>Taxa de sobreviv\u00eancia: 0.383838</li> </ul> </li> </ul> In\u00a0[7]: Copied! <pre> # remove Features: Ticket, Cabin\n#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n#test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1)\n#combine  = [train_df, test_df]\n# aplica a logica para ambos os datasets\nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].fillna('U')\n    dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\n    \nfor dataset in combine:\n    dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0, \n                                            'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)\n    \ntrain_df.head()\n    \n</pre>  # remove Features: Ticket, Cabin #train_df = train_df.drop(['Ticket', 'Cabin'], axis=1) #test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1) #combine  = [train_df, test_df] # aplica a logica para ambos os datasets for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].fillna('U')     dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)      for dataset in combine:     dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0,                                              'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)      train_df.head()      Out[7]: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 1 S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 0 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 1 S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 0 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 1 S In\u00a0[8]: Copied! <pre>train_df = train_df.drop(['Ticket'], axis=1)\ntest_df  = test_df.drop(['Ticket'], axis=1)\ncombine  = [train_df, test_df]\n\n\n# survival rate distribtion as a function of Pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> train_df = train_df.drop(['Ticket'], axis=1) test_df  = test_df.drop(['Ticket'], axis=1) combine  = [train_df, test_df]   # survival rate distribtion as a function of Pclass train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[8]: Pclass Survived 0 1 0.629630 1 2 0.472826 2 3 0.242363 In\u00a0[9]: Copied! <pre># obtain Title from name (Mr, Mrs, Miss etc)\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')\n    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')\n    dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'\n    dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'\n\n#: count survived rate for different titles\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n</pre> # obtain Title from name (Mr, Mrs, Miss etc) for dataset in combine:     dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)   for dataset in combine:     dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')     dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')     dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')     dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')     dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')     dataset.loc[(dataset.Sex == 'male')   &amp; (dataset.Title == 'Dr'),'Title'] = 'Mr'     dataset.loc[(dataset.Sex == 'female') &amp; (dataset.Title == 'Dr'),'Title'] = 'Mrs'  #: count survived rate for different titles train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False) Out[9]: Title Survived 3 Mrs 0.795276 1 Miss 0.702703 5 Royalty 0.600000 0 Master 0.575000 4 Officer 0.181818 2 Mr 0.158700 In\u00a0[10]: Copied! <pre>train_df.head(5)\n</pre> train_df.head(5) Out[10]: PassengerId Survived Pclass Name Sex Age SibSp Parch Fare Cabin Embarked Title 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 7.2500 1 S Mr 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 71.2833 0 C Mrs 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 7.9250 1 S Miss 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 53.1000 0 S Mrs 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 8.0500 1 S Mr In\u00a0[11]: Copied! <pre># Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...)\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\n# if age &lt; 16, set 'Sex' to Child\nfor dataset in combine:\n    dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'\n    \n# Covert 'Sex' to numbers (female:1, male:2)\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # Covert 'Title' to numbers (Mr-&gt;1, Miss-&gt;2 ...) title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6} for dataset in combine:     dataset['Title'] = dataset['Title'].map(title_mapping)     dataset['Title'] = dataset['Title'].fillna(0)  # Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data train_df = train_df.drop(['Name', 'PassengerId'], axis=1) test_df = test_df.drop(['Name'], axis=1) combine = [train_df, test_df]  # if age &lt; 16, set 'Sex' to Child for dataset in combine:     dataset.loc[(dataset.Age &lt; 16),'Sex'] = 'Child'      # Covert 'Sex' to numbers (female:1, male:2) for dataset in combine:     dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)  train_df.head() Out[11]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 22.0 1 0 7.2500 1 S 1 1 1 1 1 38.0 1 0 71.2833 0 C 3 2 1 3 1 26.0 0 0 7.9250 1 S 2 3 1 1 1 35.0 1 0 53.1000 0 S 3 4 0 3 0 35.0 0 0 8.0500 1 S 1 In\u00a0[12]: Copied! <pre># Age distribution for different values of Pclass and gender\n#grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n#grid.map(plt.hist, 'Age', bins=20)\n#grid.add_legend()\n</pre> # Age distribution for different values of Pclass and gender #grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6) #grid.map(plt.hist, 'Age', bins=20) #grid.add_legend() In\u00a0[13]: Copied! <pre># Guess age values using median values for age across set of Pclass and gender frature combinations\nfor dataset in combine:\n    dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)\n\n# create Age bands and determine correlations with Survived\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> # Guess age values using median values for age across set of Pclass and gender frature combinations for dataset in combine:     dataset['Age']=dataset.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.mean())).astype(int)  # create Age bands and determine correlations with Survived train_df['AgeBand'] = pd.cut(train_df['Age'], 5) train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True) <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\4175406704.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n</pre> Out[13]: AgeBand Survived 0 (-0.08, 16.0] 0.550000 1 (16.0, 32.0] 0.339506 2 (32.0, 48.0] 0.404444 3 (48.0, 64.0] 0.434783 4 (64.0, 80.0] 0.090909 In\u00a0[14]: Copied! <pre>for dataset in combine:\n    dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> for dataset in combine:     dataset.loc[ dataset['Age'] &lt;= 16, 'Age'] = 0     dataset.loc[(dataset['Age'] &gt; 16) &amp; (dataset['Age'] &lt;= 32), 'Age'] = 1     dataset.loc[(dataset['Age'] &gt; 32) &amp; (dataset['Age'] &lt;= 48), 'Age'] = 2     dataset.loc[(dataset['Age'] &gt; 48) &amp; (dataset['Age'] &lt;= 64), 'Age'] = 3     dataset.loc[ dataset['Age'] &gt; 64, 'Age'] = 4  train_df = train_df.drop(['AgeBand'], axis=1) combine = [train_df, test_df] train_df.head() Out[14]: Survived Pclass Sex Age SibSp Parch Fare Cabin Embarked Title 0 0 3 0 1 1 0 7.2500 1 S 1 1 1 1 1 2 1 0 71.2833 0 C 3 2 1 3 1 1 0 0 7.9250 1 S 2 3 1 1 1 2 1 0 53.1000 0 S 3 4 0 3 0 2 0 0 8.0500 1 S 1 In\u00a0[15]: Copied! <pre># Create family size from 'sibsq + parch + 1'\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\n#create another feature called IsAlone\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n    dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2\n\ntrain_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()\n\n#drop Parch, SibSp, and FamilySize features in favor of IsAlone\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # Create family size from 'sibsq + parch + 1' for dataset in combine:     dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1  train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)  #create another feature called IsAlone for dataset in combine:     dataset['IsAlone'] = 0     dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1     dataset.loc[(dataset['FamilySize'] &gt; 4),  'IsAlone'] = 2  train_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()  #drop Parch, SibSp, and FamilySize features in favor of IsAlone train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1) combine = [train_df, test_df] train_df.head() Out[15]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone 0 0 3 0 1 7.2500 1 S 1 0 1 1 1 1 2 71.2833 0 C 3 0 2 1 3 1 1 7.9250 1 S 2 1 3 1 1 1 2 53.1000 0 S 3 0 4 0 3 0 2 8.0500 1 S 1 1 In\u00a0[16]: Copied! <pre># Create an artfical feature combinbing PClass and Age.\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()\n</pre> # Create an artfical feature combinbing PClass and Age. for dataset in combine:     dataset['Age*Class'] = dataset.Age * dataset.Pclass  train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head() Out[16]: Age*Class Age Pclass 0 3 1 3 1 2 2 1 2 3 1 3 3 2 2 1 4 6 2 3 In\u00a0[17]: Copied! <pre># fill the missing values of Embarked feature with the most common occurance\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()\n</pre> # fill the missing values of Embarked feature with the most common occurance freq_port = train_df.Embarked.dropna().mode()[0] for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].fillna(freq_port) train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)  for dataset in combine:     dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)  train_df.head() Out[17]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 7.2500 1 0 1 0 3 1 1 1 1 2 71.2833 0 1 3 0 2 2 1 3 1 1 7.9250 1 0 2 1 3 3 1 1 1 2 53.1000 0 0 3 0 2 4 0 3 0 2 8.0500 1 0 1 1 6 In\u00a0[18]: Copied! <pre># fill the missing values of Fare\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n\n# Create FareBand\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n\n# Convert the Fare feature to ordinal values based on the FareBand\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()\n</pre> # fill the missing values of Fare test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)  # Create FareBand train_df['FareBand'] = pd.qcut(train_df['Fare'], 4) train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)  # Convert the Fare feature to ordinal values based on the FareBand for dataset in combine:     dataset.loc[ dataset['Fare'] &lt;= 7.91, 'Fare'] = 0     dataset.loc[(dataset['Fare'] &gt; 7.91) &amp; (dataset['Fare'] &lt;= 14.454), 'Fare'] = 1     dataset.loc[(dataset['Fare'] &gt; 14.454) &amp; (dataset['Fare'] &lt;= 31), 'Fare']   = 2     dataset.loc[ dataset['Fare'] &gt; 31, 'Fare'] = 3     dataset['Fare'] = dataset['Fare'].astype(int)  train_df = train_df.drop(['FareBand'], axis=1) combine = [train_df, test_df] train_df.head() <pre>C:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\nC:\\Users\\esped\\AppData\\Local\\Temp\\ipykernel_7164\\2165973158.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n</pre> Out[18]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class 0 0 3 0 1 0 1 0 1 0 3 1 1 1 1 2 3 0 1 3 0 2 2 1 3 1 1 1 1 0 2 1 3 3 1 1 1 2 3 0 0 3 0 2 4 0 3 0 2 1 1 0 1 1 6 In\u00a0[19]: Copied! <pre>train_df.describe()\n</pre> train_df.describe() Out[19]: Survived Pclass Sex Age Fare Cabin Embarked Title IsAlone Age*Class count 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 891.000000 mean 0.383838 2.308642 0.490460 1.332211 1.505051 0.771044 0.361392 1.711560 0.741863 2.785634 std 0.486592 0.836071 0.660838 0.822210 1.118148 0.420397 0.635673 1.036888 0.575364 1.755907 min 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 25% 0.000000 2.000000 0.000000 1.000000 0.500000 1.000000 0.000000 1.000000 0.000000 2.000000 50% 0.000000 3.000000 0.000000 1.000000 2.000000 1.000000 0.000000 1.000000 1.000000 3.000000 75% 1.000000 3.000000 1.000000 2.000000 2.000000 1.000000 1.000000 2.000000 1.000000 3.000000 max 1.000000 3.000000 2.000000 4.000000 3.000000 1.000000 2.000000 6.000000 2.000000 12.000000 In\u00a0[20]: Copied! <pre>#correlation matrix\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(train_df.corr(), vmax=.8, square=True);\n</pre> #correlation matrix f, ax = plt.subplots(figsize=(12, 9)) sns.heatmap(train_df.corr(), vmax=.8, square=True); In\u00a0[21]: Copied! <pre>train_df.to_csv('Bases_tratadas/Titanic_train_df.csv')\ntest_df.to_csv('Bases_tratadas/Titanic_test_df.csv')\n</pre> train_df.to_csv('Bases_tratadas/Titanic_train_df.csv') test_df.to_csv('Bases_tratadas/Titanic_test_df.csv')"},{"location":"futuro/exemplos/Learning_curve_1/#titanic-data","title":"Titanic data\u00b6","text":"<p>Tarefa: Prever a sobreviv\u00eancia de um passageiro(a) dado sua classe de ticket, nome, g\u00eanero, idade, n\u00famero de irm\u00e3os/c\u00f4njuges a bordo, n\u00famero de pais/filhos a bordo, n\u00famero do ticket, n\u00famero da cabine e Porto de embarque.</p>"},{"location":"futuro/exemplos/Learning_curve_1/#parte-i-analise-exploratoria-de-dados","title":"Parte I: An\u00e1lise Explorat\u00f3ria de Dados\u00b6","text":""},{"location":"futuro/exemplos/Learning_curve_1/#step-1-carrega-base-de-dados","title":"Step 1: Carrega Base de Dados\u00b6","text":""},{"location":"futuro/exemplos/Learning_curve_1/#step-2-limpeza-dos-dados","title":"Step 2: Limpeza dos Dados\u00b6","text":""},{"location":"futuro/exemplos/Learning_curve_1/#salvando-as-bases-tratadas","title":"Salvando as bases tratadas\u00b6","text":""},{"location":"futuro/exemplos/Teste/","title":"Configura\u00e7\u00e3o do Teste","text":""},{"location":"futuro/exemplos/codigo/","title":"Exemplos de C\u00f3digo","text":""},{"location":"futuro/exemplos/codigo/#python","title":"Python","text":"<pre><code>def hello_world():\n    print(\"Ol\u00e1, mundo!\")\n</code></pre>"},{"location":"futuro/exemplos/datas_spark/","title":"Datas spark","text":"In\u00a0[2]: Copied! <pre>import os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"c:/spark/spark-3.3.2-bin-hadoop2/\"\n</pre> import os os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" os.environ[\"SPARK_HOME\"] = \"c:/spark/spark-3.3.2-bin-hadoop2/\" In\u00a0[3]: Copied! <pre>import findspark\nfindspark.init(\"C:/spark/spark-3.3.2-bin-hadoop2/\")\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master('teste').getOrCreate()\n</pre> import findspark findspark.init(\"C:/spark/spark-3.3.2-bin-hadoop2/\")  from pyspark.sql import SparkSession spark = SparkSession.builder.master('teste').getOrCreate() In\u00a0[\u00a0]: Copied! <pre>spark\n</pre> spark Out[\u00a0]: <p>SparkSession - in-memory</p> <p>SparkContext</p> <p>Spark UI</p> Version <code>v3.3.2</code> Master <code>local[*]</code> AppName <code>pyspark-shell</code> In\u00a0[\u00a0]: Copied! <pre>formatos_data_hora = [\n    # Formatos de data e hora\n    \"YYYY-MM-DD HH:MM:SS\",  # 2024-05-29 13:45:30 (ISO)\n    \"YYYY-MM-DD HH:MM:SS.sss\",  # 2024-05-29 13:45:30.123 (ISO)\n    \"DD-MM-YYYY HH:MM:SS\",  # 29-05-2024 13:45:30 (Brasileiro)\n    \"DD/MM/YYYY HH:MM:SS\",  # 29/05/2024 13:45:30 (Brasileiro)\n    \"MM-DD-YYYY HH:MM:SS\",  # 05-29-2024 13:45:30 (USA)\n    \"MM/DD/YYYY HH:MM:SS\",  # 05/29/2024 13:45:30 (USA)\n    \"YYYY/MM/DD HH:MM:SS\",  # 2024/05/29 13:45:30 (ISO)\n    \"YYYY.MM.DD HH:MM:SS\",  # 2024.05.29 13:45:30 (ISO)\n    \"DD.MM.YYYY HH:MM:SS\",  # 29.05.2024 13:45:30 (Europeu)\n    \"DD.MM.YYYY HH:MM:SS.sss\",  # 29.05.2024 13:45:30.123 (Europeu)\n    \"DD/MM/YYYY, HH:MM:SS\",  # 29/05/2024, 13:45:30 (Brasileiro)\n    \"YYYY-MM-DD'T'HH:MM:SS\",  # 2024-05-29T13:45:30 (ISO 8601)\n    \"YYYY-MM-DD'T'HH:MM:SS.sss\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)\n    \"YYYYMMDDTHHMMSS\",  # 20240529T134530 (ISO 8601 compacto)\n    \"YYYYMMDDHHMMSS\",  # 20240529134530 (Compacto)\n    \"YYYY/MM/DD HH:MM\",  # 2024/05/29 13:45 (ISO)\n    \"MM/DD/YYYY HH:MM\",  # 05/29/2024 13:45 (USA)\n    \"DD-MM-YYYY HH:MM\",  # 29-05-2024 13:45 (Brasileiro)\n    \"DD/MM/YYYY HH:MM\",  # 29/05/2024 13:45 (Brasileiro)\n    \"DD.MM.YYYY HH:MM\",  # 29.05.2024 13:45 (Europeu)\n    \"YYYY-MM-DD HH:MM\",  # 2024-05-29 13:45 (ISO)\n    \"DD/MM/YY HH:MM\",  # 29/05/24 13:45 (Brasileiro)\n    \"DD/MM/YY HH:MM:SS\",  # 29/05/24 13:45:30 (Brasileiro)\n    \"MM/DD/YY HH:MM\",  # 05/29/24 13:45 (USA)\n    \"MM/DD/YY HH:MM:SS\",  # 05/29/24 13:45:30 (USA)\n    \"DD.MM.YY HH:MM\",  # 29.05.24 13:45 (Europeu)\n    \"DD.MM.YY HH:MM:SS\",  # 29.05.24 13:45:30 (Europeu)\n    \"YYYY-MM-DD HH:MM:SS Z\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)\n    \"YYYY-MM-DD HH:MM:SSZZ\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)\n    \"YYYY-MM-DDTHH:MM:SSZZ\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"YYYY-MM-DDTHH:MM:SS.sssZZ\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)\n    \"YYYY/MM/DDTHH:MM:SSZZ\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"YYYY-MM-DDTHH:MM:SS.sssZ\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)\n    \"YYYY-MM-DDTHH:MM:SSZ\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)\n    \"YYYYMMDD HH:MM:SS\",  # 20240529 13:45:30 (Compacto)\n    \"YYYYMMDD HH:MM:SS.sss\",  # 20240529 13:45:30.123 (Compacto)\n    \"YYYYMMDD'T'HHMMSSZ\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)\n    \"YYYYMMDD'T'HHMMSS.sssZ\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)\n    \n    # Formatos de data e hora com AM/PM\n    \"YYYY-MM-DD hh:MM:SS AM/PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:MM:SS AM/PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM/DD/YYYY hh:MM:SS AM/PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)\n    \"YYYY/MM/DD hh:MM:SS AM/PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"DD-MM-YYYY hh:MM:SS AM/PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:MM:SS AM/PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \n    # Formatos de data sem hora\n    \"YYYY-MM-DD\",  # 2024-05-29 (ISO)\n    \"DD-MM-YYYY\",  # 29-05-2024 (Brasileiro)\n    \"DD/MM/YYYY\",  # 29/05/2024 (Brasileiro)\n    \"MM-DD-YYYY\",  # 05-29-2024 (USA)\n    \"MM/DD/YYYY\",  # 05/29/2024 (USA)\n    \"YYYY/MM/DD\",  # 2024/05/29 (ISO)\n    \"YYYY.MM.DD\",  # 2024.05.29 (ISO)\n    \"DD.MM.YYYY\",  # 29.05.2024 (Europeu)\n    \"DD/MM/YY\",  # 29/05/24 (Brasileiro)\n    \"MM/DD/YY\",  # 05/29/24 (USA)\n    \"DD.MM.YY\",  # 29.05.24 (Europeu)\n    \n    \"YYYY/MM/DD hh:mm:ss A\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:mm:ss A\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:mm:ss A\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \"YYYY/MM/DD hh:mm A\",  # 2024/05/29 01:45 PM (ISO com AM/PM)\n    \"DD/MM/YYYY hh:mm A\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)\n    \"MM-DD-YYYY hh:mm A\",  # 05-29-2024 01:45 PM (USA com AM/PM)\n    \n    \"YYYYMMDD\",  # 20240529 (Compacto)\n    \"YYMMDD\",  # 240529 (Compacto curto)\n    \"YY/MM/DD\",  # 24/05/29 (Curto)\n    \"YY-MM-DD\",  # 24-05-29 (Curto)\n    \"YY.MM.DD\",  # 24.05.29 (Curto)\n    \n    \"DD MMM YYYY\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)\n    \"DD MMMM YYYY\",  # 29 May 2024 (Dia, m\u00eas completo e ano)\n    \"MMM DD, YYYY\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)\n    \"MMMM DD, YYYY\",  # May 29, 2024 (M\u00eas completo, dia e ano)\n    \"MMM DD YYYY\",  # May 29 2024 (M\u00eas abreviado, dia e ano)\n    \"MMMM DD YYYY\",  # May 29 2024 (M\u00eas completo, dia e ano)\n    \n    \"DD/MMM/YYYY\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)\n    \"DD-MMM-YYYY\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)\n    \"DD MMM, YYYY\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)\n    \n    \"E, MMM DD YYYY HH:MM:SS\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)\n    \"EEEE, MMMM DD, YYYY HH:MM:SS\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)\n    \n    \"E, DD MMM YYYY HH:MM:SS\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)\n    \"EEEE, DD MMMM YYYY HH:MM:SS\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)\n    \n    \"E, DD MMM YYYY hh:mm:ss A\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)\n    \"EEEE, DD MMMM YYYY hh:mm:ss A\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)\n    \n    \"E, MMM DD YYYY hh:mm:ss A\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)\n    \"EEEE, MMMM DD, YYYY hh:mm:ss A\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)\n    \n    \"E, MMM DD, YY HH:MM\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)\n    \"EEEE, MMMM DD, YY HH:MM\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)\n    \n    \"E, DD MMM, YY HH:MM\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)\n    \"EEEE, DD MMMM, YY HH:MM\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora)\n]\n</pre> formatos_data_hora = [     # Formatos de data e hora     \"YYYY-MM-DD HH:MM:SS\",  # 2024-05-29 13:45:30 (ISO)     \"YYYY-MM-DD HH:MM:SS.sss\",  # 2024-05-29 13:45:30.123 (ISO)     \"DD-MM-YYYY HH:MM:SS\",  # 29-05-2024 13:45:30 (Brasileiro)     \"DD/MM/YYYY HH:MM:SS\",  # 29/05/2024 13:45:30 (Brasileiro)     \"MM-DD-YYYY HH:MM:SS\",  # 05-29-2024 13:45:30 (USA)     \"MM/DD/YYYY HH:MM:SS\",  # 05/29/2024 13:45:30 (USA)     \"YYYY/MM/DD HH:MM:SS\",  # 2024/05/29 13:45:30 (ISO)     \"YYYY.MM.DD HH:MM:SS\",  # 2024.05.29 13:45:30 (ISO)     \"DD.MM.YYYY HH:MM:SS\",  # 29.05.2024 13:45:30 (Europeu)     \"DD.MM.YYYY HH:MM:SS.sss\",  # 29.05.2024 13:45:30.123 (Europeu)     \"DD/MM/YYYY, HH:MM:SS\",  # 29/05/2024, 13:45:30 (Brasileiro)     \"YYYY-MM-DD'T'HH:MM:SS\",  # 2024-05-29T13:45:30 (ISO 8601)     \"YYYY-MM-DD'T'HH:MM:SS.sss\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)     \"YYYYMMDDTHHMMSS\",  # 20240529T134530 (ISO 8601 compacto)     \"YYYYMMDDHHMMSS\",  # 20240529134530 (Compacto)     \"YYYY/MM/DD HH:MM\",  # 2024/05/29 13:45 (ISO)     \"MM/DD/YYYY HH:MM\",  # 05/29/2024 13:45 (USA)     \"DD-MM-YYYY HH:MM\",  # 29-05-2024 13:45 (Brasileiro)     \"DD/MM/YYYY HH:MM\",  # 29/05/2024 13:45 (Brasileiro)     \"DD.MM.YYYY HH:MM\",  # 29.05.2024 13:45 (Europeu)     \"YYYY-MM-DD HH:MM\",  # 2024-05-29 13:45 (ISO)     \"DD/MM/YY HH:MM\",  # 29/05/24 13:45 (Brasileiro)     \"DD/MM/YY HH:MM:SS\",  # 29/05/24 13:45:30 (Brasileiro)     \"MM/DD/YY HH:MM\",  # 05/29/24 13:45 (USA)     \"MM/DD/YY HH:MM:SS\",  # 05/29/24 13:45:30 (USA)     \"DD.MM.YY HH:MM\",  # 29.05.24 13:45 (Europeu)     \"DD.MM.YY HH:MM:SS\",  # 29.05.24 13:45:30 (Europeu)     \"YYYY-MM-DD HH:MM:SS Z\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)     \"YYYY-MM-DD HH:MM:SSZZ\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)     \"YYYY-MM-DDTHH:MM:SSZZ\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"YYYY-MM-DDTHH:MM:SS.sssZZ\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)     \"YYYY/MM/DDTHH:MM:SSZZ\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"YYYY-MM-DDTHH:MM:SS.sssZ\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)     \"YYYY-MM-DDTHH:MM:SSZ\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)     \"YYYYMMDD HH:MM:SS\",  # 20240529 13:45:30 (Compacto)     \"YYYYMMDD HH:MM:SS.sss\",  # 20240529 13:45:30.123 (Compacto)     \"YYYYMMDD'T'HHMMSSZ\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)     \"YYYYMMDD'T'HHMMSS.sssZ\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)          # Formatos de data e hora com AM/PM     \"YYYY-MM-DD hh:MM:SS AM/PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:MM:SS AM/PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM/DD/YYYY hh:MM:SS AM/PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)     \"YYYY/MM/DD hh:MM:SS AM/PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"DD-MM-YYYY hh:MM:SS AM/PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:MM:SS AM/PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)          # Formatos de data sem hora     \"YYYY-MM-DD\",  # 2024-05-29 (ISO)     \"DD-MM-YYYY\",  # 29-05-2024 (Brasileiro)     \"DD/MM/YYYY\",  # 29/05/2024 (Brasileiro)     \"MM-DD-YYYY\",  # 05-29-2024 (USA)     \"MM/DD/YYYY\",  # 05/29/2024 (USA)     \"YYYY/MM/DD\",  # 2024/05/29 (ISO)     \"YYYY.MM.DD\",  # 2024.05.29 (ISO)     \"DD.MM.YYYY\",  # 29.05.2024 (Europeu)     \"DD/MM/YY\",  # 29/05/24 (Brasileiro)     \"MM/DD/YY\",  # 05/29/24 (USA)     \"DD.MM.YY\",  # 29.05.24 (Europeu)          \"YYYY/MM/DD hh:mm:ss A\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:mm:ss A\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:mm:ss A\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)     \"YYYY/MM/DD hh:mm A\",  # 2024/05/29 01:45 PM (ISO com AM/PM)     \"DD/MM/YYYY hh:mm A\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)     \"MM-DD-YYYY hh:mm A\",  # 05-29-2024 01:45 PM (USA com AM/PM)          \"YYYYMMDD\",  # 20240529 (Compacto)     \"YYMMDD\",  # 240529 (Compacto curto)     \"YY/MM/DD\",  # 24/05/29 (Curto)     \"YY-MM-DD\",  # 24-05-29 (Curto)     \"YY.MM.DD\",  # 24.05.29 (Curto)          \"DD MMM YYYY\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)     \"DD MMMM YYYY\",  # 29 May 2024 (Dia, m\u00eas completo e ano)     \"MMM DD, YYYY\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)     \"MMMM DD, YYYY\",  # May 29, 2024 (M\u00eas completo, dia e ano)     \"MMM DD YYYY\",  # May 29 2024 (M\u00eas abreviado, dia e ano)     \"MMMM DD YYYY\",  # May 29 2024 (M\u00eas completo, dia e ano)          \"DD/MMM/YYYY\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)     \"DD-MMM-YYYY\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)     \"DD MMM, YYYY\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)          \"E, MMM DD YYYY HH:MM:SS\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)     \"EEEE, MMMM DD, YYYY HH:MM:SS\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)          \"E, DD MMM YYYY HH:MM:SS\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)     \"EEEE, DD MMMM YYYY HH:MM:SS\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)          \"E, DD MMM YYYY hh:mm:ss A\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)     \"EEEE, DD MMMM YYYY hh:mm:ss A\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)          \"E, MMM DD YYYY hh:mm:ss A\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)     \"EEEE, MMMM DD, YYYY hh:mm:ss A\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)          \"E, MMM DD, YY HH:MM\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)     \"EEEE, MMMM DD, YY HH:MM\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)          \"E, DD MMM, YY HH:MM\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)     \"EEEE, DD MMMM, YY HH:MM\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora) ]  In\u00a0[\u00a0]: Copied! <pre>exemplos_formatos_data_hora = [\n    # Formatos de data e hora\n    \"2024-05-29 13:45:30\",  # 2024-05-29 13:45:30 (ISO)\n    \"2024-05-29 13:45:30.123\",  # 2024-05-29 13:45:30.123 (ISO)\n    \"29-05-2024 13:45:30\",  # 29-05-2024 13:45:30 (Brasileiro)\n    \"29/05/2024 13:45:30\",  # 29/05/2024 13:45:30 (Brasileiro)\n    \"05-29-2024 13:45:30\",  # 05-29-2024 13:45:30 (USA)\n    \"05/29/2024 13:45:30\",  # 05/29/2024 13:45:30 (USA)\n    \"2024/05/29 13:45:30\",  # 2024/05/29 13:45:30 (ISO)\n    \"2024.05.29 13:45:30\",  # 2024.05.29 13:45:30 (ISO)\n    \"29.05.2024 13:45:30\",  # 29.05.2024 13:45:30 (Europeu)\n    \"29.05.2024 13:45:30.123\",  # 29.05.2024 13:45:30.123 (Europeu)\n    \"29/05/2024, 13:45:30\",  # 29/05/2024, 13:45:30 (Brasileiro)\n    \"2024-05-29T13:45:30\",  # 2024-05-29T13:45:30 (ISO 8601)\n    \"2024-05-29T13:45:30.123\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)\n    \"20240529T134530\",  # 20240529T134530 (ISO 8601 compacto)\n    \"20240529134530\",  # 20240529134530 (Compacto)\n    \"2024/05/29 13:45\",  # 2024/05/29 13:45 (ISO)\n    \"05/29/2024 13:45\",  # 05/29/2024 13:45 (USA)\n    \"29-05-2024 13:45\",  # 29-05-2024 13:45 (Brasileiro)\n    \"29/05/2024 13:45\",  # 29/05/2024 13:45 (Brasileiro)\n    \"29.05.2024 13:45\",  # 29.05.2024 13:45 (Europeu)\n    \"2024-05-29 13:45\",  # 2024-05-29 13:45 (ISO)\n    \"29/05/24 13:45\",  # 29/05/24 13:45 (Brasileiro)\n    \"29/05/24 13:45:30\",  # 29/05/24 13:45:30 (Brasileiro)\n    \"05/29/24 13:45\",  # 05/29/24 13:45 (USA)\n    \"05/29/24 13:45:30\",  # 05/29/24 13:45:30 (USA)\n    \"29.05.24 13:45\",  # 29.05.24 13:45 (Europeu)\n    \"29.05.24 13:45:30\",  # 29.05.24 13:45:30 (Europeu)\n    \"2024-05-29 13:45:30 +0000\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)\n    \"2024-05-29 13:45:30+0000\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)\n    \"2024-05-29T13:45:30+0000\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"2024-05-29T13:45:30.123+0000\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)\n    \"2024/05/29T13:45:30+0000\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)\n    \"2024-05-29T13:45:30.123Z\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)\n    \"2024-05-29T13:45:30Z\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)\n    \"20240529 13:45:30\",  # 20240529 13:45:30 (Compacto)\n    \"20240529 13:45:30.123\",  # 20240529 13:45:30.123 (Compacto)\n    \"20240529T134530Z\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)\n    \"20240529T134530.123Z\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)\n    \n    # Formatos de data e hora com AM/PM\n    \"2024-05-29 01:45:30 PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)\n    \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05/29/2024 01:45:30 PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)\n    \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"29-05-2024 01:45:30 PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \n    # Formatos de data sem hora\n    \"2024-05-29\",  # 2024-05-29 (ISO)\n    \"29-05-2024\",  # 29-05-2024 (Brasileiro)\n    \"29/05/2024\",  # 29/05/2024 (Brasileiro)\n    \"05-29-2024\",  # 05-29-2024 (USA)\n    \"05/29/2024\",  # 05/29/2024 (USA)\n    \"2024/05/29\",  # 2024/05/29 (ISO)\n    \"2024.05.29\",  # 2024.05.29 (ISO)\n    \"29.05.2024\",  # 29.05.2024 (Europeu)\n    \"29/05/24\",  # 29/05/24 (Brasileiro)\n    \"05/29/24\",  # 05/29/24 (USA)\n    \"29.05.24\",  # 29.05.24 (Europeu)\n    \n    \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)\n    \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)\n    \"2024/05/29 01:45 PM\",  # 2024/05/29 01:45 PM (ISO com AM/PM)\n    \"29/05/2024 01:45 PM\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)\n    \"05-29-2024 01:45 PM\",  # 05-29-2024 01:45 PM (USA com AM/PM)\n    \n    \"20240529\",  # 20240529 (Compacto)\n    \"240529\",  # 240529 (Compacto curto)\n    \"24/05/29\",  # 24/05/29 (Curto)\n    \"24-05-29\",  # 24-05-29 (Curto)\n    \"24.05.29\",  # 24.05.29 (Curto)\n    \n    \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)\n    \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas completo e ano)\n    \"May 29, 2024\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)\n    \"May 29, 2024\",  # May 29, 2024 (M\u00eas completo, dia e ano)\n    \"May 29 2024\",  # May 29 2024 (M\u00eas abreviado, dia e ano)\n    \"May 29 2024\",  # May 29 2024 (M\u00eas completo, dia e ano)\n    \n    \"29/May/2024\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)\n    \"29-May-2024\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)\n    \"29 May, 2024\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)\n    \n    \"Wed, May 29 2024 13:45:30\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)\n    \"Wednesday, May 29, 2024 13:45:30\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)\n    \n    \"Wed, 29 May 2024 13:45:30\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)\n    \"Wednesday, 29 May 2024 13:45:30\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)\n    \n    \"Wed, 29 May 2024 01:45:30 PM\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)\n    \"Wednesday, 29 May 2024 01:45:30 PM\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)\n    \n    \"Wed, May 29 2024 01:45:30 PM\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)\n    \"Wednesday, May 29, 2024 01:45:30 PM\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)\n    \n    \"Wed, May 29, 24 13:45\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)\n    \"Wednesday, May 29, 24 13:45\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)\n    \n    \"Wed, 29 May, 24 13:45\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)\n    \"Wednesday, 29 May, 24 13:45\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora)\n]\n</pre> exemplos_formatos_data_hora = [     # Formatos de data e hora     \"2024-05-29 13:45:30\",  # 2024-05-29 13:45:30 (ISO)     \"2024-05-29 13:45:30.123\",  # 2024-05-29 13:45:30.123 (ISO)     \"29-05-2024 13:45:30\",  # 29-05-2024 13:45:30 (Brasileiro)     \"29/05/2024 13:45:30\",  # 29/05/2024 13:45:30 (Brasileiro)     \"05-29-2024 13:45:30\",  # 05-29-2024 13:45:30 (USA)     \"05/29/2024 13:45:30\",  # 05/29/2024 13:45:30 (USA)     \"2024/05/29 13:45:30\",  # 2024/05/29 13:45:30 (ISO)     \"2024.05.29 13:45:30\",  # 2024.05.29 13:45:30 (ISO)     \"29.05.2024 13:45:30\",  # 29.05.2024 13:45:30 (Europeu)     \"29.05.2024 13:45:30.123\",  # 29.05.2024 13:45:30.123 (Europeu)     \"29/05/2024, 13:45:30\",  # 29/05/2024, 13:45:30 (Brasileiro)     \"2024-05-29T13:45:30\",  # 2024-05-29T13:45:30 (ISO 8601)     \"2024-05-29T13:45:30.123\",  # 2024-05-29T13:45:30.123 (ISO 8601 com milissegundos)     \"20240529T134530\",  # 20240529T134530 (ISO 8601 compacto)     \"20240529134530\",  # 20240529134530 (Compacto)     \"2024/05/29 13:45\",  # 2024/05/29 13:45 (ISO)     \"05/29/2024 13:45\",  # 05/29/2024 13:45 (USA)     \"29-05-2024 13:45\",  # 29-05-2024 13:45 (Brasileiro)     \"29/05/2024 13:45\",  # 29/05/2024 13:45 (Brasileiro)     \"29.05.2024 13:45\",  # 29.05.2024 13:45 (Europeu)     \"2024-05-29 13:45\",  # 2024-05-29 13:45 (ISO)     \"29/05/24 13:45\",  # 29/05/24 13:45 (Brasileiro)     \"29/05/24 13:45:30\",  # 29/05/24 13:45:30 (Brasileiro)     \"05/29/24 13:45\",  # 05/29/24 13:45 (USA)     \"05/29/24 13:45:30\",  # 05/29/24 13:45:30 (USA)     \"29.05.24 13:45\",  # 29.05.24 13:45 (Europeu)     \"29.05.24 13:45:30\",  # 29.05.24 13:45:30 (Europeu)     \"2024-05-29 13:45:30 +0000\",  # 2024-05-29 13:45:30 +0000 (ISO com fuso hor\u00e1rio)     \"2024-05-29 13:45:30+0000\",  # 2024-05-29 13:45:30+0000 (ISO com fuso hor\u00e1rio compacto)     \"2024-05-29T13:45:30+0000\",  # 2024-05-29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"2024-05-29T13:45:30.123+0000\",  # 2024-05-29T13:45:30.123+0000 (ISO 8601 com milissegundos e fuso hor\u00e1rio)     \"2024/05/29T13:45:30+0000\",  # 2024/05/29T13:45:30+0000 (ISO 8601 com fuso hor\u00e1rio)     \"2024-05-29T13:45:30.123Z\",  # 2024-05-29T13:45:30.123Z (ISO 8601 com milissegundos e fuso hor\u00e1rio Zulu)     \"2024-05-29T13:45:30Z\",  # 2024-05-29T13:45:30Z (ISO 8601 com fuso hor\u00e1rio Zulu)     \"20240529 13:45:30\",  # 20240529 13:45:30 (Compacto)     \"20240529 13:45:30.123\",  # 20240529 13:45:30.123 (Compacto)     \"20240529T134530Z\",  # 20240529T134530Z (ISO 8601 compacto com fuso hor\u00e1rio Zulu)     \"20240529T134530.123Z\",  # 20240529T134530.123Z (ISO 8601 compacto com milissegundos e fuso hor\u00e1rio Zulu)          # Formatos de data e hora com AM/PM     \"2024-05-29 01:45:30 PM\",  # 2024-05-29 01:45:30 PM (ISO com AM/PM)     \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"05/29/2024 01:45:30 PM\",  # 05/29/2024 01:45:30 PM (USA com AM/PM)     \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"29-05-2024 01:45:30 PM\",  # 29-05-2024 01:45:30 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)          # Formatos de data sem hora     \"2024-05-29\",  # 2024-05-29 (ISO)     \"29-05-2024\",  # 29-05-2024 (Brasileiro)     \"29/05/2024\",  # 29/05/2024 (Brasileiro)     \"05-29-2024\",  # 05-29-2024 (USA)     \"05/29/2024\",  # 05/29/2024 (USA)     \"2024/05/29\",  # 2024/05/29 (ISO)     \"2024.05.29\",  # 2024.05.29 (ISO)     \"29.05.2024\",  # 29.05.2024 (Europeu)     \"29/05/24\",  # 29/05/24 (Brasileiro)     \"05/29/24\",  # 05/29/24 (USA)     \"29.05.24\",  # 29.05.24 (Europeu)          \"2024/05/29 01:45:30 PM\",  # 2024/05/29 01:45:30 PM (ISO com AM/PM)     \"29/05/2024 01:45:30 PM\",  # 29/05/2024 01:45:30 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45:30 PM\",  # 05-29-2024 01:45:30 PM (USA com AM/PM)     \"2024/05/29 01:45 PM\",  # 2024/05/29 01:45 PM (ISO com AM/PM)     \"29/05/2024 01:45 PM\",  # 29/05/2024 01:45 PM (Brasileiro com AM/PM)     \"05-29-2024 01:45 PM\",  # 05-29-2024 01:45 PM (USA com AM/PM)          \"20240529\",  # 20240529 (Compacto)     \"240529\",  # 240529 (Compacto curto)     \"24/05/29\",  # 24/05/29 (Curto)     \"24-05-29\",  # 24-05-29 (Curto)     \"24.05.29\",  # 24.05.29 (Curto)          \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas abreviado e ano)     \"29 May 2024\",  # 29 May 2024 (Dia, m\u00eas completo e ano)     \"May 29, 2024\",  # May 29, 2024 (M\u00eas abreviado, dia e ano)     \"May 29, 2024\",  # May 29, 2024 (M\u00eas completo, dia e ano)     \"May 29 2024\",  # May 29 2024 (M\u00eas abreviado, dia e ano)     \"May 29 2024\",  # May 29 2024 (M\u00eas completo, dia e ano)          \"29/May/2024\",  # 29/May/2024 (Dia, m\u00eas abreviado e ano)     \"29-May-2024\",  # 29-May-2024 (Dia, m\u00eas abreviado e ano)     \"29 May, 2024\",  # 29 May, 2024 (Dia, m\u00eas abreviado e ano)          \"Wed, May 29 2024 13:45:30\",  # Wed, May 29 2024 13:45:30 (Dia da semana, m\u00eas abreviado, dia, ano e hora)     \"Wednesday, May 29, 2024 13:45:30\",  # Wednesday, May 29, 2024 13:45:30 (Dia da semana, m\u00eas completo, dia, ano e hora)          \"Wed, 29 May 2024 13:45:30\",  # Wed, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas abreviado, ano e hora)     \"Wednesday, 29 May 2024 13:45:30\",  # Wednesday, 29 May 2024 13:45:30 (Dia da semana, dia, m\u00eas completo, ano e hora)          \"Wed, 29 May 2024 01:45:30 PM\",  # Wed, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas abreviado, ano e hora com AM/PM)     \"Wednesday, 29 May 2024 01:45:30 PM\",  # Wednesday, 29 May 2024 01:45:30 PM (Dia da semana, dia, m\u00eas completo, ano e hora com AM/PM)          \"Wed, May 29 2024 01:45:30 PM\",  # Wed, May 29 2024 01:45:30 PM (Dia da semana, m\u00eas abreviado, dia, ano e hora com AM/PM)     \"Wednesday, May 29, 2024 01:45:30 PM\",  # Wednesday, May 29, 2024 01:45:30 PM (Dia da semana, m\u00eas completo, dia, ano e hora com AM/PM)          \"Wed, May 29, 24 13:45\",  # Wed, May 29, 24 13:45 (Dia da semana, m\u00eas abreviado, dia, ano curto e hora)     \"Wednesday, May 29, 24 13:45\",  # Wednesday, May 29, 24 13:45 (Dia da semana, m\u00eas completo, dia, ano curto e hora)          \"Wed, 29 May, 24 13:45\",  # Wed, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas abreviado, ano curto e hora)     \"Wednesday, 29 May, 24 13:45\",  # Wednesday, 29 May, 24 13:45 (Dia da semana, dia, m\u00eas completo, ano curto e hora) ]"},{"location":"futuro/exemplos/markdown/","title":"Exemplos de Markdown","text":""},{"location":"futuro/exemplos/markdown/#cabecalhos","title":"Cabe\u00e7alhos","text":"<p>```markdown</p>"},{"location":"futuro/exemplos/markdown/#titulo-1","title":"T\u00edtulo 1","text":""},{"location":"futuro/exemplos/markdown/#titulo-2","title":"T\u00edtulo 2","text":""},{"location":"futuro/exemplos/markdown/#titulo-3","title":"T\u00edtulo 3","text":""}]}